<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Integrated Inferences</title>
  <meta name="description" content="Bayesian causal models for integrated inferences." />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Integrated Inferences" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://macartan.github.io/integrated_inferences/" />
  <meta property="og:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />
  <meta property="og:description" content="Bayesian causal models for integrated inferences." />
  <meta name="github-repo" content="macartan/integrated_inferences" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Integrated Inferences" />
  
  <meta name="twitter:description" content="Bayesian causal models for integrated inferences." />
  <meta name="twitter:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Integrated Inferences</h1>
<p class="author"><em>Macartan Humphreys and Alan Jacobs</em></p>
<p class="date" style="margin-top: 1.5em;"><em>[Draft] 2021-08-27</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#intro"><span class="toc-section-number">1</span> Introduction</a>
<ul>
<li><a href="#the-case-for-causal-models"><span class="toc-section-number">1.1</span> The Case for Causal Models</a>
<ul>
<li><a href="#the-limits-to-design-based-inference"><span class="toc-section-number">1.1.1</span> The limits to design-based inference</a></li>
<li><a href="#qualitative-and-mixed-method-inference"><span class="toc-section-number">1.1.2</span> Qualitative and mixed-method inference</a></li>
<li><a href="#connecting-theory-and-empirics"><span class="toc-section-number">1.1.3</span> Connecting theory and empirics</a></li>
</ul></li>
<li><a href="#key-contributions"><span class="toc-section-number">1.2</span> Key contributions</a></li>
<li><a href="#the-road-ahead"><span class="toc-section-number">1.3</span> The Road Ahead</a></li>
</ul></li>
<li><a href="#part-foundations">(PART) Foundations</a></li>
<li><a href="#models"><span class="toc-section-number">2</span> Causal Models</a>
<ul>
<li><a href="#counterfactualmodel"><span class="toc-section-number">2.1</span> The counterfactual model</a>
<ul>
<li><a href="#potential-outcomes"><span class="toc-section-number">2.1.1</span> Potential outcomes</a></li>
<li><a href="#generalization"><span class="toc-section-number">2.1.2</span> Generalization</a></li>
<li><a href="#summaries-of-potential-outcomes"><span class="toc-section-number">2.1.3</span> Summaries of potential outcomes</a></li>
</ul></li>
<li><a href="#causal-models-and-directed-acyclic-graphs"><span class="toc-section-number">2.2</span> Causal Models and Directed Acyclic Graphs</a>
<ul>
<li><a href="#components-of-a-causal-model"><span class="toc-section-number">2.2.1</span> Components of a Causal Model</a></li>
<li><a href="#rules-for-graphing-causal-models"><span class="toc-section-number">2.2.2</span> Rules for graphing causal models</a></li>
<li><a href="#conditional-independence-from-dags"><span class="toc-section-number">2.2.3</span> Conditional independence from DAGs</a></li>
</ul></li>
<li><a href="#chapter-appendix"><span class="toc-section-number">2.3</span> Chapter Appendix</a>
<ul>
<li><a href="#steps-for-constructing-causal-models"><span class="toc-section-number">2.3.1</span> Steps for constructing causal models</a></li>
<li><a href="#model-construction-in-code"><span class="toc-section-number">2.3.2</span> Model construction in code</a></li>
<li><a href="#test-yourself-can-you-read-conditional-independence-from-a-graph"><span class="toc-section-number">2.3.3</span> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li><a href="#illustratemodels"><span class="toc-section-number">3</span> Illustrating Causal Models</a>
<ul>
<li><a href="#welfare-state-reform-pierson-1994"><span class="toc-section-number">3.1</span> Welfare state reform: Pierson (1994)</a></li>
<li><a href="#military-interventions-saunders-2011"><span class="toc-section-number">3.2</span> Military Interventions: Saunders (2011)</a></li>
<li><a href="#development-and-democratization-przeworski-and-limongi-1997"><span class="toc-section-number">3.3</span> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li><a href="#theory"><span class="toc-section-number">4</span> Theories as causal models</a>
<ul>
<li><a href="#theory-as-a-lower-level-model"><span class="toc-section-number">4.1</span> Theory as a “lower-level” model</a></li>
<li><a href="#illustration-of-unpacking-causal-types"><span class="toc-section-number">4.2</span> Illustration of unpacking causal types</a>
<ul>
<li><a href="#type-disaggregation-in-a-mediation-model"><span class="toc-section-number">4.2.1</span> Type disaggregation in a mediation model</a></li>
<li><a href="#type-disaggregation-in-a-moderation-model"><span class="toc-section-number">4.2.2</span> Type disaggregation in a moderation model</a></li>
</ul></li>
<li><a href="#rules-for-moving-between-higher--and-lower-level-models"><span class="toc-section-number">4.3</span> Rules for moving between higher- and lower-level models</a>
<ul>
<li><a href="#moving-down-levels"><span class="toc-section-number">4.3.1</span> Moving down levels</a></li>
<li><a href="#moving-up-levels"><span class="toc-section-number">4.3.2</span> Moving up levels</a></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">4.4</span> Conclusion</a>
<ul>
<li><a href="#quantifying-the-gains-of-a-theory"><span class="toc-section-number">4.4.1</span> Quantifying the gains of a theory</a></li>
</ul></li>
<li><a href="#chapter-appendices"><span class="toc-section-number">4.5</span> Chapter Appendices</a>
<ul>
<li><a href="#summary-boxes"><span class="toc-section-number">4.5.1</span> Summary Boxes</a></li>
<li><a href="#illustration-of-a-mapping-from-a-game-to-a-dag"><span class="toc-section-number">4.5.2</span> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li><a href="#questions"><span class="toc-section-number">5</span> Causal Queries</a>
<ul>
<li><a href="#case-level-causal-effects"><span class="toc-section-number">5.1</span> Case-level causal effects</a></li>
<li><a href="#case-level-causal-attribution"><span class="toc-section-number">5.2</span> Case-level causal attribution</a></li>
<li><a href="#case-level-explanation"><span class="toc-section-number">5.3</span> Case-level explanation</a></li>
<li><a href="#average-causal-effects"><span class="toc-section-number">5.4</span> Average causal effects</a></li>
<li><a href="#causal-paths"><span class="toc-section-number">5.5</span> Causal Paths</a></li>
</ul></li>
<li><a href="#bayeschapter"><span class="toc-section-number">6</span> Bayesian Answers</a>
<ul>
<li><a href="#bayes-basics"><span class="toc-section-number">6.1</span> Bayes Basics</a>
<ul>
<li><a href="#simple-instances"><span class="toc-section-number">6.1.1</span> Simple instances</a></li>
<li><a href="#bayes-rule-for-discrete-hypotheses"><span class="toc-section-number">6.1.2</span> Bayes’ Rule for Discrete Hypotheses</a></li>
<li><a href="#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><span class="toc-section-number">6.1.3</span> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li><a href="#moments"><span class="toc-section-number">6.1.4</span> Moments</a></li>
<li><a href="#bayes-estimation-in-practice"><span class="toc-section-number">6.1.5</span> Bayes estimation in practice</a></li>
</ul></li>
<li><a href="#bayes-applied"><span class="toc-section-number">6.2</span> Bayes applied</a>
<ul>
<li><a href="#simple-bayesian-process-tracing"><span class="toc-section-number">6.2.1</span> Simple Bayesian Process Tracing</a></li>
<li><a href="#a-generalization-bayesian-inference-on-queries"><span class="toc-section-number">6.2.2</span> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li><a href="#three-principles-of-bayesian-updating"><span class="toc-section-number">6.3</span> Three principles of Bayesian updating</a>
<ul>
<li><a href="#AppPriors"><span class="toc-section-number">6.3.1</span> Priors matter</a></li>
<li><a href="#simultaneous-joint-updating"><span class="toc-section-number">6.3.2</span> Simultaneous, joint updating</a></li>
<li><a href="#posteriors-are-independent-of-the-ordering-of-data"><span class="toc-section-number">6.3.3</span> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li><a href="#part-model-based-causal-inference">(PART) Model-Based Causal Inference</a></li>
<li><a href="#pt"><span class="toc-section-number">7</span> Process Tracing with Causal Models</a>
<ul>
<li><a href="#process-tracing-and-causal-models"><span class="toc-section-number">7.1</span> Process tracing and causal models</a>
<ul>
<li><a href="#the-intuition"><span class="toc-section-number">7.1.1</span> The intuition</a></li>
<li><a href="#a-formalization-of-the-general-approach"><span class="toc-section-number">7.1.2</span> A formalization of the general approach</a></li>
<li><a href="#illustration-with-code"><span class="toc-section-number">7.1.3</span> Illustration with code</a></li>
</ul></li>
<li><a href="#mapping-from-models-to-classic-qualitative-tests"><span class="toc-section-number">7.2</span> Mapping from models to classic qualitative tests</a></li>
<li><a href="#principles-of-learning"><span class="toc-section-number">7.3</span> Principles of learning</a>
<ul>
<li><a href="#a-dag-alone-does-not-get-you-probative-value"><span class="toc-section-number">7.3.1</span> A DAG alone does not get you probative value</a></li>
<li><a href="#learning-requires-uncertainty"><span class="toc-section-number">7.3.2</span> Learning requires uncertainty</a></li>
<li><a href="#multiple-ways-for-queries-to-be-satisfied"><span class="toc-section-number">7.3.3</span> Multiple ways for queries to be satisfied</a></li>
<li><a href="#beware-of-highly-unlikely-queries"><span class="toc-section-number">7.3.4</span> Beware of highly unlikely queries</a></li>
<li><a href="#population-level-uncertainty-does-not-alter-case-level-causal-inference"><span class="toc-section-number">7.3.5</span> Population-level uncertainty does not alter case-level causal inference</a></li>
<li><a href="#probative-value-requires-d-connection"><span class="toc-section-number">7.3.6</span> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li><a href="#probative-value"><span class="toc-section-number">7.3.7</span> Probative value</a></li>
</ul></li>
</ul></li>
<li><a href="#ptapp"><span class="toc-section-number">8</span> Application: Process Tracing with a Causal Model</a>
<ul>
<li><a href="#inequality-and-democratization-the-debate"><span class="toc-section-number">8.1</span> Inequality and Democratization: The Debate</a></li>
<li><a href="#a-structural-causal-model"><span class="toc-section-number">8.2</span> A Structural Causal Model</a>
<ul>
<li><a href="#forming-priors"><span class="toc-section-number">8.2.1</span> Forming Priors</a></li>
</ul></li>
<li><a href="#results"><span class="toc-section-number">8.3</span> Results</a></li>
<li><a href="#pathways"><span class="toc-section-number">8.4</span> Pathways</a>
<ul>
<li><a href="#cases-with-incomplete-data"><span class="toc-section-number">8.4.1</span> Cases with incomplete data</a></li>
<li><a href="#inferences-for-cases-with-observed-democratization"><span class="toc-section-number">8.4.2</span> Inferences for cases with observed democratization</a></li>
</ul></li>
<li><a href="#model-definition-and-inference-in-code"><span class="toc-section-number">8.5</span> Model definition and inference in code</a></li>
<li><a href="#concluding-thoughts"><span class="toc-section-number">8.6</span> Concluding thoughts</a></li>
</ul></li>
<li><a href="#mixing"><span class="toc-section-number">9</span> Integrated inferences</a>
<ul>
<li><a href="#sample-inference"><span class="toc-section-number">9.1</span> Sample inference</a></li>
<li><a href="#from-sample-queries-to-general-processes"><span class="toc-section-number">9.2</span> From sample queries to general processes</a>
<ul>
<li><a href="#set-up"><span class="toc-section-number">9.2.1</span> Set up</a></li>
<li><a href="#inference"><span class="toc-section-number">9.2.2</span> Inference</a></li>
<li><a href="#wrinkles"><span class="toc-section-number">9.2.3</span> Wrinkles</a></li>
</ul></li>
<li><a href="#mixed-methods"><span class="toc-section-number">9.3</span> Mixed methods</a></li>
<li><a href="#considerations"><span class="toc-section-number">9.4</span> Considerations</a>
<ul>
<li><a href="#probative-value-can-be-derived-from-a-causal-structure-plus-data"><span class="toc-section-number">9.4.1</span> Probative value can be derived from a causal structure plus data</a></li>
<li><a href="#learning-without-identification"><span class="toc-section-number">9.4.2</span> Learning without identification</a></li>
<li><a href="#beyond-binary-data"><span class="toc-section-number">9.4.3</span> Beyond binary data</a></li>
<li><a href="#measurement-error"><span class="toc-section-number">9.4.4</span> Measurement error</a></li>
<li><a href="#spillovers"><span class="toc-section-number">9.4.5</span> Spillovers</a></li>
<li><a href="#clustering"><span class="toc-section-number">9.4.6</span> Clustering</a></li>
<li><a href="#parameteric-models"><span class="toc-section-number">9.4.7</span> Parameteric models</a></li>
<li><a href="#prior-databeliefs-channel-the-learning-from-new-data"><span class="toc-section-number">9.4.8</span> Prior data/beliefs “channel” the learning from new data</a></li>
</ul></li>
<li><a href="#conclusion-1"><span class="toc-section-number">9.5</span> Conclusion</a></li>
</ul></li>
<li><a href="#mixingapp"><span class="toc-section-number">10</span> Mixed-Method Application: Inequality and Democracy Revisited</a>
<ul>
<li><a href="#a-trained-model"><span class="toc-section-number">10.1</span> A trained model</a></li>
<li><a href="#data"><span class="toc-section-number">10.2</span> Data</a></li>
<li><a href="#inference-1"><span class="toc-section-number">10.3</span> Inference</a>
<ul>
<li><a href="#did-inequality-cause-democracy"><span class="toc-section-number">10.3.1</span> Did inequality <em>cause</em> democracy?</a></li>
<li><a href="#did-inequality-prevent-democracy"><span class="toc-section-number">10.3.2</span> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li><a href="#exercises"><span class="toc-section-number">10.4</span> Exercises</a></li>
</ul></li>
<li><a href="#mm"><span class="toc-section-number">11</span> Mixing models</a>
<ul>
<li><a href="#a-jigsaw-puzzle-integrating-across-a-model"><span class="toc-section-number">11.1</span> A jigsaw puzzle: Integrating across a model</a></li>
<li><a href="#combining-observational-and-experimental-data"><span class="toc-section-number">11.2</span> Combining observational and experimental data</a></li>
<li><a href="#transportation-of-findings-across-contexts"><span class="toc-section-number">11.3</span> Transportation of findings across contexts</a></li>
<li><a href="#multilevel-models-meta-analysis"><span class="toc-section-number">11.4</span> Multilevel models, meta-analysis</a></li>
</ul></li>
<li><a href="#part-design-choices">(PART) Design Choices</a></li>
<li><a href="#elements"><span class="toc-section-number">12</span> Elements of Design</a>
<ul>
<li><a href="#model-inquiry-data-strategy-answer-strategy"><span class="toc-section-number">12.1</span> Model, inquiry, data strategy, answer strategy</a>
<ul>
<li><a href="#defining-a-model"><span class="toc-section-number">12.1.1</span> Defining a model</a></li>
</ul></li>
<li><a href="#evaluating-a-design"><span class="toc-section-number">12.2</span> Evaluating a design</a>
<ul>
<li><a href="#expected-error-and-expected-posterior-variance"><span class="toc-section-number">12.2.1</span> Expected error and expected posterior variance</a></li>
<li><a href="#illustration"><span class="toc-section-number">12.2.2</span> Illustration</a></li>
</ul></li>
<li><a href="#illustration-of-design-decaration-in-code"><span class="toc-section-number">12.3</span> Illustration of Design Decaration in code</a></li>
</ul></li>
<li><a href="#clue"><span class="toc-section-number">13</span> Clue Selection as a Decision Problem</a>
<ul>
<li><a href="#core-logic"><span class="toc-section-number">13.1</span> Core logic</a></li>
<li><a href="#a-strategic-approach"><span class="toc-section-number">13.2</span> A strategic approach</a>
<ul>
<li><a href="#clue-selection-with-a-simple-example"><span class="toc-section-number">13.2.1</span> Clue selection with a simple example</a></li>
<li><a href="#dependence-on-prior-beliefs"><span class="toc-section-number">13.2.2</span> Dependence on prior beliefs</a></li>
<li><a href="#clue-selection-for-the-democratization-model"><span class="toc-section-number">13.2.3</span> Clue selection for the democratization model</a></li>
</ul></li>
<li><a href="#dynamic-strategies"><span class="toc-section-number">13.3</span> Dynamic Strategies</a></li>
<li><a href="#conclusion-2"><span class="toc-section-number">13.4</span> Conclusion</a></li>
</ul></li>
<li><a href="#caseselection"><span class="toc-section-number">14</span> Mixed methods data strategies</a>
<ul>
<li><a href="#case-selection-strategies"><span class="toc-section-number">14.1</span> Case selection strategies</a>
<ul>
<li><a href="#no-general-rules"><span class="toc-section-number">14.1.1</span> No general rules</a></li>
<li><a href="#specific-case-walk-through"><span class="toc-section-number">14.1.2</span> Specific case walk through</a></li>
<li><a href="#case-selection-from-causal-models-a-simulation-based-approach"><span class="toc-section-number">14.1.3</span> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
<li><a href="#wide-or-deep"><span class="toc-section-number">14.2</span> Wide or Deep</a>
<ul>
<li><a href="#walk-through-of-a-simple-comparison"><span class="toc-section-number">14.2.1</span> Walk-through of a simple comparison</a></li>
<li><a href="#results-from-simulations"><span class="toc-section-number">14.2.2</span> Results from simulations</a></li>
</ul></li>
<li><a href="#principles"><span class="toc-section-number">14.3</span> Principles</a></li>
</ul></li>
<li><a href="#part-models-in-question">(PART) Models in Question</a></li>
<li><a href="#justifying"><span class="toc-section-number">15</span> Justifying models</a>
<ul>
<li><a href="#nothing-from-nothing"><span class="toc-section-number">15.1</span> Nothing from nothing</a></li>
<li><a href="#justifying-the-classic-process-tracing-tests"><span class="toc-section-number">15.2</span> Justifying the classic process tracing tests</a></li>
<li><a href="#justification-from-experimental-designs"><span class="toc-section-number">15.3</span> Justification from experimental designs</a>
<ul>
<li><a href="#mediator"><span class="toc-section-number">15.3.1</span> Mediator</a></li>
<li><a href="#moderator"><span class="toc-section-number">15.3.2</span> Moderator</a></li>
</ul></li>
<li><a href="#causal-discovery"><span class="toc-section-number">15.4</span> Causal discovery</a></li>
<li><a href="#exercise"><span class="toc-section-number">15.5</span> Exercise</a></li>
</ul></li>
<li><a href="#evaluation"><span class="toc-section-number">16</span> Evaluating models</a>
<ul>
<li><a href="#five-strategies"><span class="toc-section-number">16.1</span> Five Strategies</a>
<ul>
<li><a href="#check-conditional-independence"><span class="toc-section-number">16.1.1</span> Check conditional independence</a></li>
<li><a href="#computational-clues"><span class="toc-section-number">16.1.2</span> Computational clues</a></li>
<li><a href="#bayesian-p-value-are-the-data-unexpected-given-your-model"><span class="toc-section-number">16.1.3</span> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li><a href="#leave-one-out-loo-cross-validation"><span class="toc-section-number">16.1.4</span> Leave-one-out (LOO) cross-validation</a></li>
<li><a href="#sensitivity"><span class="toc-section-number">16.1.5</span> Sensitivity</a></li>
</ul></li>
<li><a href="#evaluating-the-democracy-inequality-model"><span class="toc-section-number">16.2</span> Evaluating the Democracy-Inequality model</a>
<ul>
<li><a href="#check-assumptions-of-conditional-independence"><span class="toc-section-number">16.2.1</span> Check assumptions of conditional independence</a></li>
<li><a href="#bayesian-p-value"><span class="toc-section-number">16.2.2</span> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li><a href="#loo-validation"><span class="toc-section-number">16.2.3</span> LOO validation</a></li>
<li><a href="#sensitivity-to-priors"><span class="toc-section-number">16.2.4</span> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">17</span> Final Words</a>
<ul>
<li><a href="#the-benefits"><span class="toc-section-number">17.1</span> The benefits</a></li>
<li><a href="#the-worries"><span class="toc-section-number">17.2</span> The worries</a></li>
<li><a href="#the-future"><span class="toc-section-number">17.3</span> The future</a></li>
</ul></li>
<li><a href="#part-appendices">(PART) Appendices</a></li>
<li><a href="#examplesappendix"><span class="toc-section-number">18</span> <code>CausalQueries</code></a></li>
<li><a href="#references">References</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="preface" class="section level1 unnumbered">
<h1 class="unnumbered">Preface</h1>
<p>Placeholder</p>
<!--chapter:end:index.Rmd-->
</div>
<div id="intro" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Placeholder</p>
<div id="the-case-for-causal-models" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> The Case for Causal Models</h2>
<div id="the-limits-to-design-based-inference" class="section level3" number="1.1.1">
<h3 number="1.1.1"><span class="header-section-number">1.1.1</span> The limits to design-based inference</h3>
</div>
<div id="qualitative-and-mixed-method-inference" class="section level3" number="1.1.2">
<h3 number="1.1.2"><span class="header-section-number">1.1.2</span> Qualitative and mixed-method inference</h3>
</div>
<div id="connecting-theory-and-empirics" class="section level3" number="1.1.3">
<h3 number="1.1.3"><span class="header-section-number">1.1.3</span> Connecting theory and empirics</h3>
</div>
</div>
<div id="key-contributions" class="section level2" number="1.2">
<h2 number="1.2"><span class="header-section-number">1.2</span> Key contributions</h2>
</div>
<div id="the-road-ahead" class="section level2" number="1.3">
<h2 number="1.3"><span class="header-section-number">1.3</span> The Road Ahead</h2>
<!--chapter:end:01-intro.Rmd-->
</div>
</div>
<div id="part-foundations" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Foundations</h1>
</div>
<div id="models" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Causal Models</h1>
<div class="headerbox">
<div class="center">

</div>
<p>We provide a lay language primer on the logic of causal models.</p>
</div>
<p><br></p>
<p>Causal claims are everywhere. Causal knowledge is often the end goal of empirical social science. It is also a key <em>input</em> into causal inference. Rarely do we arrive at causal inquiry fully agnostic about causal relations in the domain of interest.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
Causal assumptions are also hidden in seemingly descriptive statements: claims that someone is guilty, or exploited, or powerful, or weak, involve beliefs about how things would be were conditions different. Even when scholars carefully try to avoid causal claim-making, causal verbs–depends, drives, produces, influences—tend to surface.</p>
<p>But while causal claims are commonplace, it is not always clear (1) what exactly is meant by a causal relation and (2) how causal knowledge about one thing can be marshaled to justify causal claims about another. For our purposes, the counterfactual view of causality addresses the first question. Causal models address the second.</p>
<!-- In this chapter we provide a basic introduction to causal models. Subsequent chapters in Part I layer on other foundational components of the book's framework, including a causal-model-based understanding of theory, the definition of common causal estimands within causal models, and the basics of Bayesian inference.  -->
<!-- While here we focus on the formal definition of causal models, in Chapter 10 we discuss strategies for generating them.  -->
<div id="counterfactualmodel" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> The counterfactual model</h2>
<p>We begin with what we might think of as a meta-model, the counterfactual model of causation.
<!-- The counterfactual model is perhaps the dominant approach to causal relations in the social sciences.  -->
At its core, a counterfactual understanding of causation captures a simple notion of causation as “difference-making.”<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> In the counterfactual view, to say that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> is to say: <em>had</em> <span class="math inline">\(X\)</span> been different, <span class="math inline">\(Y\)</span> <em>would have been</em> different. Implicitly, the antecedent, “had <span class="math inline">\(X\)</span> been different,” imagines a <em>controlled</em> change in <span class="math inline">\(X\)</span>—an intervention that altered <span class="math inline">\(X\)</span>’s value—rather than a naturally arising difference in <span class="math inline">\(X\)</span>. The counterfactual claim, then, is not that <span class="math inline">\(Y\)</span> is different in those cases in which <span class="math inline">\(X\)</span> is different; it is, rather, that if one could somehow have <em>made</em> <span class="math inline">\(X\)</span> different, <span class="math inline">\(Y\)</span> would have been different.</p>
<!-- An example. Consider the claim that India democratized ($Y$) because it had a relatively high level of economic equality ($X$) (drawing on the logic of @boix2003democracy). In the counterfactual view, this is equivalent to saying that, had India *not* had a high level of equality---where we imagine that we *made* equality in India lower---the country would not have democratized. High economic equality made a difference. -->
<p>Consider a toy example. Students in class A perform well without studying. Students in class B perform well if they study, and do not perform well if they do not study. Moreover, only class B students in fact study, and all perform well.</p>
<p>When we say that one of the class B students did well <em>because</em> they studied, we are comparing the outcome that they experienced to the outcome they would have experienced if they had been in class B (as they were) but (counterfactually) had not studied. Notably, we are <em>not</em> comparing their realized outcome to the outcome they would have experienced if they had been among the people that in fact didn’t study (i.e., if they had been class A students).</p>
<p>A second example. Consider the claim that India democratized (<span class="math inline">\(Y\)</span>) because it had a relatively high level of economic equality (<span class="math inline">\(X\)</span>) (drawing on the logic of <span class="citation"><a href="#ref-boix2003democracy" role="doc-biblioref">Boix</a> (<a href="#ref-boix2003democracy" role="doc-biblioref">2003</a>)</span>). In the counterfactual view, this is equivalent to saying that, had India <em>not</em> had a high level of equality, the country would not have democratized. High economic equality made a difference. The comparison for the causal statement is with the outcome India would have experienced under an intervention that boosted its historical level of economic inequality — <em>not</em> with how India would have performed if it had been one of the countries that <em>in fact</em> had higher levels of inequality, cases that likely differ from India in other causally relevant ways.</p>
<!-- AJ: see Slack thread about whether we're expressing the controlled chang right. https://gbiqq.slack.com/archives/C02C1DHUJ1M/p1629990240000600 -->
<!-- Causal effects are thus unmeasurable quantities. They are not differences between possible observations in the world, but differences between outcomes in the world and counterfactual outcomes that need to be inferred rather than measured.       -->
<p>Along with this notion of causation as difference-making, we also want to allow for <em>variability</em> in how <span class="math inline">\(X\)</span> acts on the world. <span class="math inline">\(X\)</span> might sometimes make a difference, for some units of interest, and sometimes not. High levels of equality might generate democratization in some countries or historical settings but not in others. Moreover, while equality might make democratization happen in some times in places, it might <em>prevent</em> that same outcome in others. We need a language to describe these different types of relations.</p>
<div id="potential-outcomes" class="section level3" number="2.1.1">
<h3 number="2.1.1"><span class="header-section-number">2.1.1</span> Potential outcomes</h3>
<p>The “potential outcomes” framework is useful for describing the different kinds of counterfactual causal relations that might prevail between variables . In this framework we characterize how a given unit responds to a causal variable by positing the outcomes that it <em>would</em> take on at different values of the causal variable.</p>
<p>A setting in which it is quite natural to think about potential outcomes is medical treatment. Imagine some individuals in a diseased population are observed to have received a drug (<span class="math inline">\(X=1\)</span>) while others have not (<span class="math inline">\(X=0\)</span>). Assume that, subsequently, a researcher observes which individuals become healthy (<span class="math inline">\(Y=1\)</span>) and which do not (<span class="math inline">\(Y=0\)</span>). Given the assignments of all other individuals,<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> we can treat each individual as belonging to one of four unobserved response “types,” defined by the outcomes that the individual <em>would have</em> if they received or did not receive treatment:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<!-- AJ: SUTVA Footnote above needs to be made clearer. -->
<ul>
<li><strong>a</strong>dverse: Those individuals who would get better if and only if they do not receive the treatment</li>
<li><strong>b</strong>eneficial: Those who would get better if and only if they do receive the treatment</li>
<li><strong>c</strong>hronic: Those who will remain sick whether or not they receive treatment</li>
<li><strong>d</strong>estined: Those who will get better whether or not they receive treatment</li>
</ul>
<p>Table @ref(tab:PO) maps the four types (<span class="math inline">\(a, b, c, d\)</span>) onto their respective potential outcomes. In each column, we have simply written down the outcome that a patient of a given type would experience if they are not treated, and the outcome they would experience if they are treated.</p>
<!-- \begin{table}[h!]
\begin{tabular}{l|cccc} \small

& Type a & Type b & Type c & Type d \\

& **a**dverse effects & **b**eneficial Effects & **c**hronic cases & **d**estined cases \\
\hline
Not treated &    Healthy &       Sick &       Sick &    Healthy \\
Treated &       Sick &    Healthy &       Sick &    Healthy \\
\end{tabular}  
\caption{Potential Outcomes: What would happen to each of four possible types of case if they were or were not treated.}
\label{tabPO}
\end{table} -->
<table>
<caption>(#tab:PO). Potential outcomes: What would happen to each of four possible types of case if they were or were not treated.</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">Type a</th>
<th align="center">Type b</th>
<th align="center">Type c</th>
<th align="center">Type d</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td align="center"><strong>a</strong>dverse effects</td>
<td align="center"><strong>b</strong>eneficial Effects</td>
<td align="center"><strong>c</strong>hronic cases</td>
<td align="center"><strong>d</strong>estined cases</td>
</tr>
<tr class="even">
<td>Outcome if not treated</td>
<td align="center">Healthy</td>
<td align="center">Sick</td>
<td align="center">Sick</td>
<td align="center">Healthy</td>
</tr>
<tr class="odd">
<td>Outcome if treated</td>
<td align="center">Sick</td>
<td align="center">Healthy</td>
<td align="center">Sick</td>
<td align="center">Healthy</td>
</tr>
</tbody>
</table>
<p>We highlight that, in this framework, case-level causal relations are treated as deterministic. A given case has a set of potential outcomes. Any uncertainty about outcomes enters as incomplete knowledge of a case’s “type,” not from underlying randomness in causal relations. This understanding of causality—as ontologically deterministic, but empirically imperfectly understood—is compatible with views of causation commonly employed by qualitative researchers (see, e.g., <span class="citation"><a href="#ref-mahoney2008toward" role="doc-biblioref">Mahoney</a> (<a href="#ref-mahoney2008toward" role="doc-biblioref">2008</a>)</span>), and with understandings of causal determinism going back at least to <span class="citation"><a href="#ref-laplace1901philosophical" role="doc-biblioref">Laplace</a> (<a href="#ref-laplace1901philosophical" role="doc-biblioref">1901</a>)</span>.</p>
<p>As we will also see, we can readily express this kind of incompleteness of knowledge within a causal model framework: indeed, the way in which causal models manage uncertainty is central to how they allow us to pose questions of interest and to learn from evidence. There are certainly situations we could imagine in which one might want to conceptualize potential outcomes themselves as random (for instance, if individuals in different conditions play different lotteries). But for the vast majority of the settings we condsider, not much of importance is lost if we treat potential outcomes as deterministic but possibly unknown: at the end of the day something will occur or it will not occur, we just do not know which it is.</p>
</div>
<div id="generalization" class="section level3" number="2.1.2">
<h3 number="2.1.2"><span class="header-section-number">2.1.2</span> Generalization</h3>
<p>Throughout the book, we generalize from this simple setup. Whenever we have one causal variable and one outcome, and both variables are binary (i.e., each can take on two possible values, 0 or 1), there are only four sets of possible potential outcomes, or “types.” More generally, for any pair of causal and outcome variables, we will use <span class="math inline">\(\theta^Y\)</span> to denote a case’s type in regard to outcome variable <span class="math inline">\(Y\)</span>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> We, further, add subscripts to denote particular types. Where there are four possible types, for instance, we use the notation <span class="math inline">\(\theta^Y_{ij}\)</span>, where <span class="math inline">\(i\)</span> represents the case’s potential outcome when <span class="math inline">\(X=0\)</span> and <span class="math inline">\(j\)</span> is the case’s potential outcome when <span class="math inline">\(X=1\)</span>.</p>
<p>Adopting this notation, for a causal structure with one binary causal variable and a binary outcome, the four types can be represented as <span class="math inline">\(\{\theta^Y_{10}, \theta^Y_{01}, \theta^Y_{00}, \theta^Y_{11}\}\)</span>, as shown in Table @ref(tab:POGEN):</p>
<table style="width:100%;">
<caption>(#tab:POGEN). Generalizing from Table @ref(tab:PO), the table gives for each causal type the values that <span class="math inline">\(Y\)</span> would take on if <span class="math inline">\(X\)</span> is set at <span class="math inline">\(0\)</span> and if <span class="math inline">\(X\)</span> is set at 1.</caption>
<colgroup>
<col width="11%" />
<col width="22%" />
<col width="24%" />
<col width="20%" />
<col width="21%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="center">Type a</th>
<th align="center">Type b</th>
<th align="center">Type c</th>
<th align="center">Type d</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td align="center"><span class="math inline">\(\theta^Y=\theta^Y_{10}\)</span></td>
<td align="center"><span class="math inline">\(\theta^Y=\theta^Y_{01}\)</span></td>
<td align="center"><span class="math inline">\(\theta^Y=\theta^Y_{00}\)</span></td>
<td align="center"><span class="math inline">\(\theta^Y=\theta^Y_{11}\)</span></td>
</tr>
<tr class="even">
<td>Set <span class="math inline">\(X=0\)</span></td>
<td align="center"><span class="math inline">\(Y(0)=1\)</span></td>
<td align="center"><span class="math inline">\(Y(0)=0\)</span></td>
<td align="center"><span class="math inline">\(Y(0)=0\)</span></td>
<td align="center"><span class="math inline">\(Y(0)=1\)</span></td>
</tr>
<tr class="odd">
<td>Set <span class="math inline">\(X=1\)</span></td>
<td align="center"><span class="math inline">\(Y(1)=0\)</span></td>
<td align="center"><span class="math inline">\(Y(1)=1\)</span></td>
<td align="center"><span class="math inline">\(Y(1)=0\)</span></td>
<td align="center"><span class="math inline">\(Y(1)=1\)</span></td>
</tr>
</tbody>
</table>
<!-- Let $Y(x)$ denote the "potential" outcome (the value $Y$ would take on) when $X=x$. Then, if $X$ is a binary variable, the effect of $X$ on $Y$ is simply defined as $Y(1) -  Y(0)$.  -->
<!-- These types differ in their ''potential outcomes'' | that is on what outcomes, $Y$,  they *would* have depending on their treatment condition $X$ . More formally, we let $Y(x)$ denote a case or type's potential outcome  when $X=x$. Thus, the potential outcomes are $Y(0)=1, Y(1)=0$ for type $a$; $Y(0)=0, Y(1)=1$ for type $b$; $Y(0)=0, Y(1)=0$ for type $c$; and $Y(0)=1, Y(1)=1$ for type $d$.   -->
<!-- For any given response type, the causal effect of $X$ on $Y$ is $Y(1) -  Y(0)$. Thus, the causal effect is $-1$ for $a$ types, $1$ for $b$ types, and $0$ for both $c$ and $d$ types. -->
<p>Returning to the matter of inequality and democratization to illustrate, let <span class="math inline">\(I=1\)</span> represent a high level of economic equality and <span class="math inline">\(I=0\)</span> its absence; let <span class="math inline">\(D=1\)</span> represent democratization and <span class="math inline">\(D=0\)</span> its absence. A <span class="math inline">\(\theta^D_{10}\)</span> (or <span class="math inline">\(a\)</span>) type is a case in which a high level of equality, if it occurs, <em>prevents</em> democratization in a country that would otherwise have democratized. The causal effect of high equality in a case, <span class="math inline">\(i\)</span>, of <span class="math inline">\(\theta^D_{10}\)</span> type is <span class="math inline">\(\tau_i= -1\)</span>. A <span class="math inline">\(\theta^D_{01}\)</span> type (or <span class="math inline">\(b\)</span> type) is a case in which high equality, if it occurs, generates democratization in a country that would otherwise have remained non-democratic (effect <span class="math inline">\(\tau_i= 1\)</span>). A <span class="math inline">\(\theta^D_{00}\)</span> type (<span class="math inline">\(c\)</span> type) is a case that will not democratize regardless of the level of equality (effect <span class="math inline">\(\tau_i = 0\)</span>); and a <span class="math inline">\(\theta^D_{11}\)</span> type (<span class="math inline">\(d\)</span> type) is one that will democratize regardless of the level of equality (again, effect <span class="math inline">\(\tau_i= 0\)</span>).</p>
<p>In this setting, a causal <em>explanation</em> of a given case outcome amounts to a statement about its type. The claim that India’s high level of equality was a cause of its democratization is equivalent to saying that India democratized and is <span class="math inline">\(\theta^D_{01}\)</span> type. To claim that Sierra Leone democratized because of low inequality is equivalent to saying that Sierra Leone democratized and is a <span class="math inline">\(\theta^D_{10}\)</span> type. To claim, on the other hand, that Malawi democratized for reasons having nothing to do with its level of economic equality is to characterize Malawi as a <span class="math inline">\(\theta^D_{11}\)</span> type (which already specifies its outcome).</p>
<p>Now, let us consider more complex causal relations. Suppose now that there are two binary causal variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. We can specify any given case’s potential outcomes for each of the different possible combinations of causal conditions—there now being four such conditions, as each causal variable may take on <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> when the other is at <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.</p>
<p>As for notation, we now need to expand <span class="math inline">\(\theta\)</span>’s subscript since we need to represent the value that <span class="math inline">\(Y\)</span> takes on under each of the four possible combinations of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> values. We construct the four-digit subscript with the ordering:</p>
<p><span class="math display">\[Y_{hijk} \left\{\begin{array}{ccc}  h&amp; =&amp; Y|(X_1=0, X_2=0)\\
 i &amp;=&amp; Y|(X_1=1, X_2=0)\\
 j &amp;=&amp; Y|(X_1=0, X_2=1)\\
 k &amp;=&amp; Y|(X_1=1, X_2=1)
 \end{array} \right.\]</span></p>
<p>Thus, for instance, <span class="math inline">\(\theta^Y_{0100}\)</span> means that <span class="math inline">\(Y\)</span> is 1 if <span class="math inline">\(X_1=1\)</span> and <span class="math inline">\(X_2=0\)</span> and is 0 otherwise.</p>
<p>We now have 16 causal types: 16 different patterns that <span class="math inline">\(Y\)</span> might display in response to changes in <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. The full set is represented in Table @ref(tab:PO16), which also makes clear how we read types off of four-digit subscripts. For instance, the table shows us that for nodal type <span class="math inline">\(\theta^Y_{0101}\)</span>, <span class="math inline">\(X_1\)</span> has a positive causal effect on <span class="math inline">\(Y\)</span> but <span class="math inline">\(X_2\)</span> has no effect. On the other hand, for type <span class="math inline">\(\theta^Y_{0011}\)</span>, <span class="math inline">\(X_2\)</span> has a positive effect while <span class="math inline">\(X_1\)</span> has none.</p>
<p>We also capture interactions here. For instance, in a <span class="math inline">\(\theta^Y_{0001}\)</span> type, <span class="math inline">\(X_2\)</span> has a positive causal effect if and only if <span class="math inline">\(X_1\)</span> is 1. In that type, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> serve as “complements.” For <span class="math inline">\(\theta^Y_{0111}\)</span>, <span class="math inline">\(X_2\)</span> has a positive causal effect if and only if <span class="math inline">\(X_1\)</span> is 0. In that setup, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are “substitutes.”</p>
<!-- let $Y(x_1, x_2)$ denote the outcome when $X_1=x_1$ and  $X_2=x_2$. Then the quantity $\left(Y(1, 1) - Y(0, 1)\right) - \left(Y(1, 0) - Y(0, 0)\right)$ describes the interactive effect of two treatments: it captures how the effect of $X_1$ changing from $0$ to $1$ is different between those situations in which $X_2=1$ and those situations in which $X_2=0$. -->
<table>
<caption>(#tab:PO16)With two binary causal variables, there are 16 causal types: 16 ways in which <span class="math inline">\(Y\)</span> might respond to changes in the other two variables.</caption>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\theta^Y\)</span></th>
<th align="right">if <span class="math inline">\(X_1=0, X_2=0\)</span></th>
<th align="right">if <span class="math inline">\(X_1=1,X_2=0\)</span></th>
<th align="right">if <span class="math inline">\(X_1=0,X_2=1\)</span></th>
<th align="right">if <span class="math inline">\(X_1=1, X_2=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0000}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1000}\)</span></td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0100}\)</span></td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1100}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0010}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1010}\)</span></td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0110}\)</span></td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1110}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0001}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1001}\)</span></td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0101}\)</span></td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1101}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0011}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1011}\)</span></td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta^Y_{0111}\)</span></td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta^Y_{1111}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>This is a rich framework in that it allows for all possible ways in which a set of multiple causes can interact with each other. Often, when seeking to explain the outcome in a case, researchers proceed as though causes are necessarily <em>rival</em>, where <span class="math inline">\(X_1\)</span> being a cause of <span class="math inline">\(Y\)</span> implies that <span class="math inline">\(X_2\)</span> was not. Did Malawi democratize because it was a relatively economically equal society <em>or</em> because of international pressure to do so? In the counterfactual model, however, causal relations can be non-rival. If two out of three people vote for an outcome under majority rule, for example, then both of the two supporters caused the outcome: the outcome would not have occurred if <em>either</em> supporter’s vote were different. This typological, potential-outcomes conceptualization provides a straightforward way of representing this kind of complex causation.</p>
<p>Because of this complexity, when we say that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in a given case, we will generally mean that <span class="math inline">\(X\)</span> was <em>a</em> cause, not <em>the</em> (only) cause. Malawi might not have democratized if <em>either</em> a relatively high level of economic equality <em>or</em> international pressure had been absent. For most social phenomena that we study, there will be multiple, and sometimes a great many, difference-makers for any given case outcome.</p>
<p>We will mostly use <span class="math inline">\(\theta^Y_{ij}\)</span>-style notation in this book to refer to types. We will, however, occasionally revert to the simpler <span class="math inline">\(a, b, c, d\)</span> designations when that helps ease exposition. As types play a central role in the causal-model framework, we recommend getting comfortable with both forms of notation before going further.</p>
<!-- ## Counter-intuitive implications of the counterfactual model -->
<!-- Although the counterfactual framework is now widely employed, it contains a set of implications that might sit uncomfortably with common conceptions of how causal inference operates. -->
<!-- Second, it is often intuitive to think of causal processes as sets of transitive relations: if $A$ causes $B$ and  $B$ causes $C$, then we might think that $A$ causes $C$. Yet, in the counterfactual model, causal relations are *not* transitive. In a classic illustration, imagine a boulder that rolls down a hill, causing you to duck, and that ducking in turn saves your life. As a counterfactual matter, the boulder clearly caused the ducking and the ducking your survival. But the boulder rolling down the hill did not save your life. To consider an example from the social realm, think about situations in which action begets reaction. For instance, a rebellion causes a military crackdown, and the military crackdown causes the regime to survive; yet the rebellion did not cause the regime to survive. (For discussions see @hall2004two and @paul2013causation.) The insight has implications both for process tracing and for correlational approaches to establishing causation. Finding in a causal link in a case from $A$ to $B$ and a causal link from $B$ to $C$ is not equivalent to finding that $A$ caused $C$. Likewise, identifying a population-level causal effect of $X$ on some suspected mediator $M$, and another effect of $M$ on $Y$, does not establish an $X\rightarrow Y$ causal relationship. -->
<!-- <!-- I do not find the next point convincing. -->
<!-- Third, notions of causality going back at least to Hume [@hume2000enquiry] treat causal relations as characterized by spatio-temporal contiguity between cause and effect, or at least of the intermediate steps between them. Yet in the counterfactural model, there is no requirement that causes be temporally or spatially connected to their effects. For instance, *potentially* intervening events that did *not* occur can have causal effects, even though they make no spatio-temporal contact with the observable events that seem to lie along the path from $X$ to $Y$. The plague that put Friar John into quarantine meant that he did not deliver the letter to Romeo to inform him that Juliet was not dead, which in turn led to Romeo's death. There is a *causal* path from the plague to Romeo's death, but no *spatio-temporal* one.  -->
<!-- Fourth, hypothesis-testing at the case level sometimes proceeds as though competing explanations amount to rival causes, where $A$ caused $B$ implies that $C$ did not. But in the counterfactual model, causal relations are neither rival nor decomposable. If two out of three people vote for an outcome under majority rule, for example, then both of the two supporters caused the outcome: the outcome would not have occurred if *either* supporter's vote were different. The causes are not rival. Now, imagine that all three of three voters supported an outcome. Then the three votes jointly caused the outcome. However, this joint cause is not decomposable into its component parts: none of the individual votes had *any* effect on the outcome. A change in any one vote would have made no difference. -->
<!-- <!-- Does the latter example above  satisfy minimality? Is a graph minimal that points from all three yesses to the outcome? -->
<!-- Thus, there appear to be some tensions between the counterfactual model and some common notions of causality. These tensions largely disappear, however, once we properly specify causal models as systems of causal relations. For this work, Directed Acyclic Graphs provide a powerful tool.    -->
<p>Using the same framework, we can generalize to structures in which a unit has any number of causes and also to cases in which causes and outcomes are non-binary. As one might imagine, the number of types increases rapidly (very rapidly) as the number of considered causal variables increases, as it also does as we allow <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> to take on more than 2 possible values. For example, if there are <span class="math inline">\(n\)</span> binary causes of an outcome, then there can be <span class="math inline">\(2^{\left(2^n\right)}\)</span> types of this form: that is, <span class="math inline">\(k=2^n\)</span> combinations of values of causes to consider, and <span class="math inline">\(2^k\)</span> distinct ways to react to each combination. If causes and outcomes are ternary instead of binary, we have <span class="math inline">\(3^{\left(3^n\right)}\)</span> causal types of this form. Yet, the basic principle of representing possible causal relations as patterns of potential outcomes remains unchanged, at least as long as variables are discrete.</p>
</div>
<div id="summaries-of-potential-outcomes" class="section level3" number="2.1.3">
<h3 number="2.1.3"><span class="header-section-number">2.1.3</span> Summaries of potential outcomes</h3>
<p>So far, we have focused on causal relations at the level of an individual case. Causal relations at the level of a population is, however, simply a summary of causal relations for cases, and the same basic ideas can be used. We could, for instance, summarize our beliefs about the relationship between economic equality and democratization by saying that we think that the world is comprised of a mixture of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span> types, as defined above. We could get more specific and express a belief about what proportions of cases in the world are of each of the four types. For instance, we might believe that <span class="math inline">\(a\)</span> types and <span class="math inline">\(d\)</span> types are quite rare while <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> types are quite common. Moreover, our belief about the proportions of <span class="math inline">\(b\)</span> (positive effect) and <span class="math inline">\(a\)</span> (negative effect) cases imply a belief about equality’s <em>average</em> effect on democratization as, in a binary setup, this quantity is simply the proportion of <span class="math inline">\(b\)</span> types minus the proportion of <span class="math inline">\(a\)</span> types. Such summaries allow us to move from discussion of the cause of a single outcome to discussions of average effects, a distinction that we take up again in Chapter @ref(questions).</p>
</div>
</div>
<div id="causal-models-and-directed-acyclic-graphs" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Causal Models and Directed Acyclic Graphs</h2>
<p>So far we have discussed how a single outcome is affected by one or more possible causes. However, these same ideas can be used to describe more complex relations between collections of variables — for example, with one variable affecting another directly as well as indirectly via its impact on some mediating variable.</p>
<p>Potential outcomes tables can be used to describe such complex relations. However, as causal structures become more complex—especially, as the number of variables in a domain increases—a causal model can be a powerful organizing tool. In this section, we show how causal models and their visual counterparts, directed acyclic graphs (DAGs), can represent substantive beliefs about counterfactual causal relationships in the world. The key ideas in this section can be found in many texts (see, e.g., <span class="citation"><a href="#ref-halpern2005causesa" role="doc-biblioref">Halpern and Pearl</a> (<a href="#ref-halpern2005causesa" role="doc-biblioref">2005</a>)</span> and <span class="citation"><a href="#ref-galles1998axiomatic" role="doc-biblioref">Galles and Pearl</a> (<a href="#ref-galles1998axiomatic" role="doc-biblioref">1998</a>)</span>), and we introduce here a set of basic principles that readers will need to keep in mind in order to follow the argumentation in this book.</p>
<p>As we shift to talking about networks of causal relations between variables we will also shift our language. When talking about causal networks, or causal graphs, we will generally refer to variables as “nodes.” And we will sometimes use familial terms to describe relations between nodes. For instance, two nodes directly connected by an arrow are known as “parent” and “child,” while two nodes with a child in common (both directly affecting the same variable) are “spouses.” We can also say that <span class="math inline">\(I\)</span> is an “ancestor” of <span class="math inline">\(D\)</span> (a node upstream from <span class="math inline">\(D\)</span>’s parent) and conversely that <span class="math inline">\(D\)</span> is a descendant of <span class="math inline">\(I\)</span> (a node downstream from <span class="math inline">\(I\)</span>’s child).</p>
<p>Return to our running democratization example, but suppose now that we have more fully specified beliefs about how the level of economic inequality can have an effect on whether a country democratizes. We might believe that inequality affects the likelihood of democratization by generating demands for redistribution, which in turn can cause the mobilization of lower-income citizens, which in turn can cause democratization. We might also believe that mobilization itself is not just a function of redistributive preferences but also of the degree of ethnic homogeneity, which shapes the capacities of lower-income citizens for collective action. In this model <span class="math inline">\(R\)</span> is a parent of <span class="math inline">\(M\)</span>, <span class="math inline">\(I\)</span> is an ancestor of <span class="math inline">\(M\)</span> but not a parent. <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> are spouses and <span class="math inline">\(M\)</span> is their child. We can visualize this model as a Directed Acyclic Diagram (DAG) in Figure @ref(fig:simpleDAG).</p>
<div class="figure" style="text-align: center">
<img src="ii_files/figure-html/simpleDAG-1.png" alt="A simple causal model in which high inequality ($I$) affects the democratization ($D$) via redistributive demands and mass mobilization ($M$), which is also a function of ethnic homogeneity ($E$). The arrows show relations of causal dependence between variables.  The graph does not capture the ranges of the variables and the functional relations between them." width="80%" />
<p class="caption">
(#fig:simpleDAG)A simple causal model in which high inequality (<span class="math inline">\(I\)</span>) affects the democratization (<span class="math inline">\(D\)</span>) via redistributive demands and mass mobilization (<span class="math inline">\(M\)</span>), which is also a function of ethnic homogeneity (<span class="math inline">\(E\)</span>). The arrows show relations of causal dependence between variables. The graph does not capture the ranges of the variables and the functional relations between them.
</p>
</div>
<p>Fundamentally, we treat causal models in this book as formalizations of our <em>beliefs</em> about how the world works—or, more specifically, about causal relations within a given domain. We can express these beliefs with widely varying degrees of specificity and certainty. The formalization of <em>prior</em> beliefs in the form of a causal model is the starting point for research design and inference in this book’s analytic framework. Using the democratization example, we will now walk through the three components of a causal model in which our beliefs get embedded: nodes, functions, and distributions.</p>
<div id="components-of-a-causal-model" class="section level3" number="2.2.1">
<h3 number="2.2.1"><span class="header-section-number">2.2.1</span> Components of a Causal Model</h3>
<p>The three components of a causal model are (i) the nodes—that is, the set of variables we are focused on and how are they defined (ii) the functional relations—which nodes are “explained” by which other nodes and how, and (iii) probability distributions over unexplained elements of a model.</p>
<div id="the-nodes" class="section level4" number="2.2.1.1">
<h4 number="2.2.1.1"><span class="header-section-number">2.2.1.1</span> The nodes</h4>
<p>The first component of a causal model is the set of variables (nodes) across which the model characterizes causal relations. On the graph in Figure @ref(fig:simpleDAG), the five included variables are represented by the five lettered nodes. (In addition we mark <span class="math inline">\(\theta^D\)</span> on the graph though, as will be made clear, we will not think of this as a variable.)</p>
<p>In identifying the nodes, we also need to specify the  over which they can vary. We might specify, for instance, that all nodes in the model are binary, taking on the values 0 or 1. We could, alternatively, define a set of categories across which a node ranges or allow a node to take on any real number value or any value between a set of bounds.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>Notice that some of these nodes have arrows pointing <em>into</em> them: <span class="math inline">\(R, M\)</span>, and <span class="math inline">\(D\)</span> are endogenous nodes, meaning that their values are determined entirely by other nodes in the model.</p>
<p>Other nodes have arrows pointing out of them but no arrows pointing into them: <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>. <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> are “exogenous” nodes; they influence other nodes in the model but themselves have no causes specified in the model.</p>
<p>The <span class="math inline">\(\theta\)</span> terms require a little more explanation since they do not describe substantive nodes. These terms can be thought of as unobservable features that affect outcomes. They might capture random processes—noise—or contextual features that we do not understand. In many presentations of causal models, we will see these features referred to as “exogenous” variables, often labelled as sets <span class="math inline">\(\mathcal U\)</span>, to be distinguished from the endogenous—named–variables often labelled as <span class="math inline">\(\mathcal V\)</span>.</p>
<p>Consistent with our discussion above, we will generally use <span class="math inline">\(\theta\)</span> to denote these exogeneous variables. The reason for this is that we can think of these nodes as capturing the functional relations between endogeneous variables and as being quantities of direct interest for causal inquiry. We more fully develop this point below.</p>
<!-- For instance, here $\theta^D$ captures *how* and *whether* $D$'s parent produces $D$. In the present example, we believe democratization to be potentially affected by mobilization, and two of $\theta^D$'s possible values allow for such an effect: $\theta^D_{01}$ and $\theta^D_{10}$. We also know that democratization is affected by other things, even if we do not know what they are and have not represented them explicitly in the model. The values $\theta^D_{00}$ (no democratization regardless of mobilization) and $\theta^D_{11}$ (always democratization regardless of mobilization) capture all "other" factors---factors other than mobilization---that may affect democratization.  -->
<!-- Similarly, $\theta^M$ represents how $M$ responds to $R$ and $E$, while $\theta^R$ captures how $R$ responds to $I$. The $\theta^I$ and $\theta^E$ terms, pointing into the two exogenous nodes, represent all processes outside the model that assign these exogenous nodes to their values. -->
<!-- ^[Readers familiar with the literature on causal models will know that $U$ terms are typically used to capture unspecified exogenous influences on included nodes. We could have, here, included a term $U_D$ to indicate an "error" term or uncertainty regarding exactly what value $D$ will take given knowledge of $M$. We use the concept of a type and the $\theta$ notation, instead, to highlight the fact that, in non-parametric models, this "residual" component can be thought of as *the* locus of learning about the questions we are asking.] -->
<!-- Going forward, we set every node in our working example to be binary. -->
</div>
<div id="the-functions" class="section level4" number="2.2.1.2">
<h4 number="2.2.1.2"><span class="header-section-number">2.2.1.2</span> The functions</h4>
<p>Next, we need to specify our beliefs about the causal relations among the nodes in our model. How is the value of one node affected by, and how does it affect, the values of others? For each endogenous node—each node influenced by others in the model—we need to express beliefs about how its value is affected by its parents, its immediate causes.</p>
<p>The DAG already represents a critical part of these beliefs: the arrows, or directed edges, tell us <em>which nodes we believe to be direct causal inputs into other nodes</em>. So, for instance, we believe that democratization (<span class="math inline">\(D\)</span>) is determined jointly by mobilization (<span class="math inline">\(M\)</span>) and some exogenous, unspecified factor (or set of factors), <span class="math inline">\(\theta^D\)</span>. As we have said, we can think of <span class="math inline">\(\theta^D\)</span> as all of the other influences on democratization, besides mobilization, that we either do not know of or have decided not to explicitly include in the model. We believe, likewise, that <span class="math inline">\(M\)</span> is determined by <span class="math inline">\(I\)</span> and an unspecified exogenous factor (or set of factors), <span class="math inline">\(\theta^M\)</span>. And we are conceptualizing inequality (<span class="math inline">\(I\)</span>) and ethnic heterogeneity (<span class="math inline">\(E\)</span>) as shaped solely by a factors exogenous to the model, captured by <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^E\)</span>, respectively.</p>
<!-- (For all intents and purposes, $I$ and $E$ behave as  exogenous node here since its value is determined solely by an exogenous node.)  -->
<p>We emphasize that an arrow indicates a <em>direct</em> relationship, given the other nodes in the graph. Likewise, the <em>absence</em> of an arrow between two nodes indicates the belief that there is no direct relationship between the them. Consider, for instance, the absence of a an arrow running direcly from <span class="math inline">\(R\)</span> to <span class="math inline">\(D\)</span>. This omission represents the belief that any effect of redistributive preferences on democratization work <em>only</em> through mass mobilization; or, equivalently, that <span class="math inline">\(R\)</span> has no effect on <span class="math inline">\(D\)</span> <em>given</em> <span class="math inline">\(M\)</span>. The omission of an <span class="math inline">\(R \rightarrow D\)</span> arrow means we are building quite a strong assumption into the model; the missing arrow rules out, for example, the possibility that <span class="math inline">\(R\)</span> moderates the effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(D\)</span>.</p>
<p>Beyond the beliefs captured by the arrows in a DAG, we can express more specific beliefs about causal relations in the form of a causal function.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Specifying a function means writing down whatever general or theoretical knowledge we have about the direct causal relations between nodes. A function specifies how the value that one node takes on is determined by the values that other nodes—its parents—take on.</p>
<!-- For each endogenous node, we can specify two kinds of nodes as direct causes:  (i) other endogenous nodes, which we call the node's *parents*;^[For node $V_i$, we write its parents as $PA_i$.] and (ii) an exogenous node. Thus, for instance, the node $Y$ in Figure \@ref(fig:simpleDAG) has as its direct causes the node $R$, its parent (an endogenous node itself) and the random-disturbance, $U_Y$.^[Any node with no parents in $\mathcal V$ must be a function of a member of $\mathcal U$; otherwise, we could not consider it endogenous. A node that is a function of one or more members of $\mathcal V$, however, can be modeled without a $U_i$ term if we believe that it is fully determined by nodes specified in $\mathcal V$.]  -->
<p>We can specify this relationship in a vast variety of ways. It is useful however to distinguish broadly between parametric and non-parametric approaches. We take a non-parametric approach in this book, but it is helpful to juxtapose that approach to a parametric one.</p>
<p><strong>Parametric approaches.</strong> A parametric approach specifies a functional form that relates parents to children. For instance, we might model one node as a linear function of another and write <span class="math inline">\(D=\beta M\)</span>, where <span class="math inline">\(\beta\)</span> is a parameter that we do not know the value of at the outset of a study but about which we wish to learn. If we believe <span class="math inline">\(D\)</span> to be linearly affected by <span class="math inline">\(M\)</span> but also subject to forces that we do not yet understand and have not yet specified in our theory, then we can write: <span class="math inline">\(D=\alpha + \beta M+\theta^D\)</span>. In this function, <span class="math inline">\(\alpha, \beta\)</span> might be the parameters of interest, with <span class="math inline">\(\theta^D\)</span> treated merely as a random disturbance. We can be still more agnostic by, for example, including parameters that govern how other parameters operate. Consider, for instance the function, <span class="math inline">\(D=\beta M^{\theta^D}\)</span>. Here, <span class="math inline">\(D\)</span> and <span class="math inline">\(M\)</span> are linearly related if <span class="math inline">\(\theta^D=1\)</span>, but not otherwise.</p>
<p>Note that functions can be written to be quite specific or extremely general, depending on the state of prior knowledge about the phenomenon under investigation. The use of a structural model <em>does not require precise knowledge of specific causal relations</em>, even of the functional forms through which two nodes are related.</p>
<!-- ^[Here the difference between $\beta$ and $U_D$ is that $\beta$ is a parameter that we believe takes a constant value for all units, even if its value is unknown, while $U_D$ represents some unknown factor or combination of factors the value of which may vary across units, over a pre-specified range.] -->
<!-- * We may even be uncertain about whether or in what direction one node affects another. Or we may believe that their relationship varies across cases for reasons that we do not yet understand. We can capture this type of uncertainty as an interaction such as: $D=M U_D$. Here, the value of our random-disturbance term does not merely represent noise around an $M \rightarrow D$ relationship. Rather, $U_D$ now conditions, or moderates, the strength, sign, or existence of the relationship itself. Which of these $U_D$ conditions will depend on the $U_D$'s specified range. For instance, if we allow $U_D$ to take on the values $-1, 0$ or $1$, then $U_D$ will determine whether $M$ has a negative effect, no effect, or a positive effect on $D$. If instead, $U_D$ is allowed to vary continuously between $0$ and $1$, inclusive, then it conditions the strength and existence of a positive causal effect of $M$ on $D$, though not the sign of that effect.  As we discuss in later chapters, our investigation might then center on drawing inferences about $U_D$ in order to assess $M$'s causal effect. -->
<p><strong>The non-parametric approach.</strong> With discrete data, causal functions can take fully <em>non-parametric</em> form, allowing for <em>any possible relation</em> between parents and children. We use this framework for most of this book, so spend a little more time developing the approach here.</p>
<p>Drawing on our original four causal types from earlier in this chapter we can fully specify causal relations between <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span> by specifying a node <span class="math inline">\(\theta_D\)</span> that ranges across four possible values <span class="math inline">\(\{\theta^D_{10}, \theta^D_{01}, \theta^D_{00}, \theta^D_{11}\}\)</span> where:</p>
<p><span class="math display">\[D(M, \theta^D_{ij}) = \left\{\begin{array}{ccx} i &amp; \text{if} &amp; M=0 \\ j &amp; \text{if} &amp; M=1 \end{array}\right.\]</span></p>
<p>In essence, <span class="math inline">\(\theta^D\)</span> determines the function that relates <span class="math inline">\(M\)</span> to <span class="math inline">\(D\)</span> and so <span class="math inline">\(\theta^D\)</span> in practice ranges over all possible functional forms. We can think of <span class="math inline">\(\theta^D\)</span> as an unknown factor that conditions the effect of mobilization on democratization, determining whether <span class="math inline">\(M\)</span> has a negative effect, a positive effect, no effect with democratization never occurring, or no effect with democratization bound to occur regardless of mobilization. Importantly however, while we might think of <span class="math inline">\(\theta^D\)</span> as an unknown or random quantity, in this formulation <span class="math inline">\(\theta^D\)</span> should not be thought of as a nuisance, but specifically the quantity that we want to learn about: we want to know whether <span class="math inline">\(M\)</span> likely had a positive, negative, or no effect on <span class="math inline">\(D\)</span>.</p>
<p>Using our causal type framework, we can similarly use <span class="math inline">\(\theta\)</span> terms to designate causal relations involving any number of parent nodes. Every substantively defined node, <span class="math inline">\(J\)</span>, in a graph can be thought of as having a <span class="math inline">\(\theta^J\)</span> term pointing into it, and the value of <span class="math inline">\(\theta^J\)</span> gives the mapping from <span class="math inline">\(J\)</span>’s parents (if it has any) to the value of <span class="math inline">\(J\)</span>.</p>
<!-- With two parent nodes, for instance, we simply use causal types of the form $\theta^Y_{hijk}$, as illustrated above.  -->
<!-- We may, for instance, believe that an outcome occurs when and only when _two_ conditions are present. Redistributive demands and ethnic homogeneity may be individually necessary and jointly sufficient conditions for mobilization. We can express this belief with a slightly more complex function: $M=E R$. According to this function, $M=1$ (mobilization occurs) if _both_ $E=1$ (ethnic homogeneity is present) and $R=1$ (redistributive preferences are present), but $M=0$ (mobilization does not occur) otherwise. Note that this formulation also builds in causal heterogeneity: here, we are saying that redistributive preferences have an effect on mobilization when and only when ethnic homogeneity is present, and vice versa. -->
<p>Applied to the binary nodes in Figure @ref(fig:simpleDAG), <span class="math inline">\(\theta^J\)</span> ranges as follows:</p>
<ul>
<li><strong>Nodes with no parents</strong>: For an exogenous node like <span class="math inline">\(I\)</span>, <span class="math inline">\(\theta^I\)</span> represents an “assignment” process and can take on one of two values, <span class="math inline">\(\theta^I_{0}\)</span>, meaning that <span class="math inline">\(I\)</span> is “assigned” to <span class="math inline">\(0\)</span> or <span class="math inline">\(\theta^I_{1}\)</span>, meaning that <span class="math inline">\(I\)</span> is assigned to 1.</li>
<li><strong>Binary nodes with 1 binary parent</strong>: For endogenous node <span class="math inline">\(R\)</span>, with only one parent (<span class="math inline">\(I\)</span>), <span class="math inline">\(\theta^R\)</span> takes on one of four values of the form <span class="math inline">\(\theta^R_{ij}\)</span> (our four original types, <span class="math inline">\(\theta^R_{10}\)</span>, <span class="math inline">\(\theta^R_{01}\)</span>, etc.).</li>
<li><strong>Binary nodes with 2 binary parents</strong>: <span class="math inline">\(\theta^M\)</span> will take on a possible 16 values of the form <span class="math inline">\(\theta^M_{hijk}\)</span> (<span class="math inline">\(\theta^M_{0000}\)</span>, <span class="math inline">\(\theta^M_{0001}\)</span>, etc.).</li>
</ul>
<p>For analytic applications later in the book, we will want to be able to think both about the causal type operation at a particular <em>node</em> and about <em>collections</em> of causal types across a model. We thus refer to <span class="math inline">\(\theta^J\)</span> as a unit’s <em>nodal</em> causal type, or simply nodal type, for <span class="math inline">\(J\)</span>. We refer to the collection of nodal types across all nodes for a given unit (i.e., a case) as the case’s <em>unit causal type</em>, or simply <em>causal type</em>, denoted by <span class="math inline">\(\theta\)</span>. Since the nodal types of exogenous include values of exogenous nodes, then the unit’s causal type fully specifies all node values as well as all <em>counterfactual</em> node values for a unit.</p>
<p>We will sometimes refer to the values of <span class="math inline">\(\theta\)</span> as a unit’s <em>context</em>. To capture the idea that <span class="math inline">\(\theta\)</span> captures not just how a unit reacts to situations but also which situations it is reacting to. There is thus no <em>formal</em> distinction between a unit’s type and a unit’s situation—between, say, a hungry person, and a person that has had no food.</p>
<div class="headerbox">
<div class="center">

</div>
<p>Box: Nodal types, causal types</p>
<table>
<colgroup>
<col width="21%" />
<col width="15%" />
<col width="62%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>term</strong></th>
<th align="center"><strong>symbol</strong></th>
<th align="center"><strong>meaning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">nodal type</td>
<td align="center"><span class="math inline">\(\theta^X\)</span></td>
<td align="center">The way that a node responds to the values of its parents. Example: <span class="math inline">\(\theta^Y_{10}\)</span>: <span class="math inline">\(Y\)</span> takes the value 1 if <span class="math inline">\(X=0\)</span> and 0 if <span class="math inline">\(X=1\)</span>.</td>
</tr>
<tr class="even">
<td align="center">causal type</td>
<td align="center"><span class="math inline">\(\theta\)</span></td>
<td align="center">A causal type is a concatenation of nodal types, one for each node. Example: <span class="math inline">\((\theta^X_0, \theta^Y_{00})\)</span>, is a type that has <span class="math inline">\(X=0\)</span> and <span class="math inline">\(Y=0\)</span> no matter what the value of <span class="math inline">\(X\)</span>.</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<!-- It is thus worth dwelling for a moment on what this kind of function is doing. We have started with a graph in which mobilization can have an effect on democratization and the understanding that this effect, both its existence and its sign, may vary across cases. Cases, in other words, may be of different causal types. Further, we do not know what it is that shapes $D$'s response to $M$---what makes a case one type versus another. We thus use $\theta_D$ as a stand-in for the unknown and unspecified moderators of $M$'s effect. We might, at this stage, wonder what the point is of including $\theta_D$ in the model; are we not essentially just placing a question mark on the graph? We are, and that is precisely the point. As we will see in later chapters, non-substantive, causal-type nodes can play a key role in specifying (a) what we are uncertain about in a causal network and (b) what we would like to find out. Embedding our questions about the world directly into a model of the world, in turn, allows us to answer those questions in ways systematically and transparently guided by prior knowledge. -->
<!-- In fact, we can include factors as another node's "parents" even if we are unsure that those factors matter. Including nodes on the righthand side in a functional equation allows for the possibility that those nodes matter, and in turn sets us up to investigate their possible effect empirically.^[For instance, in $B=AU_B+C$, $A$ will only affect $B$ if $\theta^B$ takes on a non-zero value. ] -->
<!-- ### Interpretation of functional equations -->
<p>A few important aspects of causal functions are worth highlighting.</p>
<ol style="list-style-type: decimal">
<li><p>These functions express <em>causal</em> beliefs. When we write <span class="math inline">\(D=\beta M\)</span> as a function, we do not just mean that we believe the values of <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span> in the world to be linearly related. We mean that we believe that the value of <span class="math inline">\(M\)</span> <em>determines</em> the value of <span class="math inline">\(D\)</span> through this linear function. Functions are, in this sense, <em>directional</em> statements, with causes on the righthand side and an outcome on the left.</p></li>
<li><p>The collection of simple functions that map from the values of parents a given node to the values of that node are sufficient to represent potentially complex web of causal relations into its constituent causal links. For each node, we do not need to think through entire sequences of causation that might precede it. We need only specify how we believe it to be affected by its parents—that is to say, those nodes pointing directly into it. Our outcome of interest, <span class="math inline">\(D\)</span>, may be shaped by multiple, long chains of causality. To theorize how <span class="math inline">\(D\)</span> is generated, however, we write down how we believe <span class="math inline">\(D\)</span> is shaped by its parent—its direct cause, <span class="math inline">\(M\)</span>. We then, separately, express a belief about how <span class="math inline">\(M\)</span> is shaped by <em>its</em> parents, <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>. A node’s function must include as inputs all, and only, those nodes that point directly into that node.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p></li>
<li><p>As in the general potential-outcomes framework, all relations in a causal model are conceptualized as deterministic at the case level. There is not as much at stake here though as you might think at first; by this we simply mean that a node’s value is <em>determined</em> by the values of its parents <em>along with</em> any stochastic or unknown components. We express uncertainty about causal relations, however, either as unknown parameters (e.g., <span class="math inline">\(\beta\)</span>, above) or as random disturbances, the <span class="math inline">\(U\)</span> terms, or the causal types <span class="math inline">\(\theta\)</span>.</p></li>
<li><p><em>The values of the exogenous nodes</em>—those with no arrows pointing in to them—<em>are sufficient to determine the values of all other nodes in the model.</em> In other words, context determines all other values. For instance, in Figure @ref(fig:simpleDAG), knowing the values of <span class="math inline">\(I\)</span>, <span class="math inline">\(E\)</span>, and <span class="math inline">\(\theta^D\)</span> as well as the causal functions (including the values of any parameters they contain) would tell us the values of <span class="math inline">\(R\)</span>, <span class="math inline">\(M\)</span>, and <span class="math inline">\(D\)</span>.</p></li>
</ol>
<!-- ]  nodes that have no parents are called *roots*.^[Thus in our usage all elements of $\mathcal{U}$ are roots, but so are nodes in $\mathcal{V}$ that depend on nodes in $\mathcal{U}$ only.]  We will say that $\mathcal{F}$ is a set of *ordered structural equations* if no node is its own descendant and if no element in $\mathcal{U}$ is parent to more than one element of \(\mathcal{V}\).^[This last condition can be achieved by shifting any parent of multiple children in $\mathcal{U}$ to $\mathcal{V}$.] -->
<!-- Do we need to define roots? -->
<!-- For notational simplicity we generally write functional equations in the form $c(a,b)$ rather than $f_c(a,b)$. -->
<!-- **The distributions**. So far, we have specified the nodes in the model and their causal relations, possibly with uncertainty. These relations imply  -->
<!-- In general, $U$ terms---capturing unspecified disturbances---represent features of the world that we are *not* able to directly observe. In some cases, we may not even have a specific conceptualization of the phenomena in the world to which a $U$ term corresponds. Nonetheless, we may be able to make *inferences* about the value of a $U$ term from observed data. Indeed, given the role of the exogenous terms in a model in determining the operation of the world that the model describes, learning about a case's context becomes central to model-based causal inquiry and, as we shall see, lies at the heart of the framework that we are elaborating. -->
</div>
<div id="the-distributions" class="section level4" number="2.2.1.3">
<h4 number="2.2.1.3"><span class="header-section-number">2.2.1.3</span> The distributions</h4>
<p>Putting these two pieces together gives what is termed a <em>structural causal model.</em> In a structural causal model, all endogenous nodes are, either directly or by implication, functions of a case’s context (the values of the set of exogenous nodes).<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> What we have not yet inscribed into the model, however, is any beliefs about how <em>likely</em> or <em>common</em> different kinds of contexts might be. Thus, for instance, a structural causal model consistent with Figure @ref(fig:simpleDAG) stipulates that <span class="math inline">\(I\)</span>, <span class="math inline">\(E\)</span>, and <span class="math inline">\(\theta^D\)</span> may have effects on <span class="math inline">\(D\)</span>, but it says nothing in itself about the distribution of <span class="math inline">\(I\)</span>, <span class="math inline">\(E\)</span>, and <span class="math inline">\(\theta^D\)</span> themselves, beyond limitations on their ranges.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> We have not said anything, for instance, about how common high inequality is across the relevant domain of cases, how common ethnic homogeneity is, or how unspecified inputs are distributed.</p>
<p>In many research situations, we will have beliefs not just about how the world works under different conditions, but also about what kinds of conditions are more likely than others. We can express these beliefs about context as probability distributions over the models exogenous terms.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> For instance, a structural causal model might support a claim of the form: “<span class="math inline">\(R\)</span> has a positive effect on <span class="math inline">\(M\)</span> if and only if <span class="math inline">\(E=1\)</span> holds.” We might, then, add to this a belief that <span class="math inline">\(E=1\)</span> in 25% of cases in the population of interest. Including this belief about context implies, in turn, that <span class="math inline">\(R\)</span> has a positive effect on <span class="math inline">\(M\)</span> a quarter of the time. As with the functions, we can also (and typically would) build uncertainty into this belief by specifying a <em>distribution</em> over possible shares of cases with ethnic homogeneity, with our degree of uncertainty captured by the distribution’s variance.</p>
<p>With our non-parametric representation of functional forms, we let <span class="math inline">\(\lambda_j^X\)</span> denote the probability that <span class="math inline">\(\theta^X = \theta^X_j\)</span>. For instance in a simple <span class="math inline">\(X \rightarrow Y\)</span> model, <span class="math inline">\(\lambda^Y_{01}\)</span> denotes the probability that <span class="math inline">\(\theta^Y = \theta^Y_{01}\)</span>.
<!-- FLAG: FLESH OUT INCLUDING HOW CONFOUNDING IS TREATED --></p>
<!-- Am trying to render all the indented paragraphs below as a single, multi-paragraph footnote. Have read up and tried all sorts of things, no luck yet. -->
<!-- Thus, a probabilistic causal model is a structural causal model coupled with a probability distribution over the model's exogenous nodes. A corresponding probabilistic model, however, might support a stronger claim of the form: "Condition $C$ arises with frequency $\pi^C$, and so $X$ causes $Y$ with probability $\pi^C$." -->
<div class="headerbox">
<div class="center">

</div>
<p><strong>Technical Note on the Markov Property</strong></p>
<p>The assumptions that no node is its own descendant and that the <span class="math inline">\(\theta\)</span> terms are generated independently make the model <em>Markovian</em>, and the parents of a given node are Markovian parents. Knowing the set of Markovian parents allows one to write relatively simple factorizations of a joint probability distribution, exploiting the fact (“the Markov condition”) that all nodes are <em>conditionally independent</em> of their nondescendants, conditional on their parents. nodes <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are “conditionally independent” given <span class="math inline">\(C\)</span> if <span class="math inline">\(P(a|b,c) = P(a|c)\)</span> for all values of <span class="math inline">\(a, b\)</span> and <span class="math inline">\(c\)</span>.<br />
To see how this Markovian property allows for simple factorization of <span class="math inline">\(P\)</span> for Figure @ref(fig:simpleDAG), note that <span class="math inline">\(P(X, R, Y)\)</span> can always be written as:
<span class="math display">\[P(X, R, Y) = P(X)P(R|X)P(Y|R, X)\]</span>
If we believe, as in the figure, that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> only through <span class="math inline">\(R\)</span> then we have the slightly simpler factorization:
<span class="math display">\[P(X, R, Y) = P(X)P(R|X)P(Y|R)\]</span>
Or, more generally:</p>
<p><span class="math display">\[\begin{equation} 
P(v_1,v_2,\dots v_n) = \prod P(v_i|pa_i)
(\#eq:markov)
\end{equation}\]</span></p>
<p>The distribution <span class="math inline">\(P\)</span> on <span class="math inline">\(\theta\)</span> induces a joint probability distribution on <span class="math inline">\(\mathcal{V}\)</span> that captures not just information about how likely different states are to arise but also the relations of conditional independence between nodes that are implied by the underlying causal process. For example, if we thought that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> via <span class="math inline">\(R\)</span> (and only via <span class="math inline">\(R\)</span>), we would then hold that <span class="math inline">\(P(Y | R) = P(Y | X, R)\)</span>: in other words if <span class="math inline">\(X\)</span> matters for <span class="math inline">\(Y\)</span> only via <span class="math inline">\(R\)</span> then, conditional on <span class="math inline">\(R\)</span>, <span class="math inline">\(X\)</span> should not be informative about <span class="math inline">\(Y\)</span>.<br />
In this way, a probability distribution <span class="math inline">\(P\)</span> over a set of nodes can be consistent with some causal models but not others. This does not, however, mean that a specific causal model can be extracted from <span class="math inline">\(P\)</span>. To demonstrate with a simple example for two nodes, any probability distribution on <span class="math inline">\((X,Y)\)</span> with <span class="math inline">\(P(x)\neq P(x|y)\)</span> is consistent both with a model in which <span class="math inline">\(X\)</span> is a parent of <span class="math inline">\(Y\)</span> and with a model in which <span class="math inline">\(Y\)</span> is a parent of <span class="math inline">\(X\)</span>.</p>
</div>
<p><br></p>
<p>Once we introduce beliefs about the distribution of values of the exogenous terms in a model, we have specified a <em>probabilistic causal model.</em> We need not say much more, for the moment, about the probabilistic components of causal models. But to foreshadow the argument to come, our prior beliefs about the likelihoods of different contexts play a central role in the framework that we present in this book. We will see how the encoding of contextual knowledge—beliefs that some kinds of conditions are more common than others—forms a key foundation for causal inference. At the same time, our expressions of <em>uncertainty</em> about context represent scope for learning: it is the very things that we are, at a study’s outset, uncertain about that we can update our beliefs about as we encounter evidence.</p>
</div>
</div>
<div id="rules-for-graphing-causal-models" class="section level3" number="2.2.2">
<h3 number="2.2.2"><span class="header-section-number">2.2.2</span> Rules for graphing causal models</h3>
<p>The diagram in Figure @ref(fig:simpleDAG) is a causal DAG <span class="citation">(<a href="#ref-hernan2006instruments" role="doc-biblioref">Hernán and Robins 2006</a>)</span>. We endow it with the interpretation that an arrow from a parent to a child that a change in the parent can, under some circumstances, induce a change in the child. Though we have already been making use of this causal graph to help us visualize elements of a causal model, we now explicitly point out a number of general features of causal graphs as we will be using them throughout this book. Causal graphs have their own distinctive “grammar,” a set of rules that give them important analytic features.</p>
<p><strong>Directed, acyclic.</strong> A causal graph represents elements of a causal model as a set of nodes (or vertices), representing nodes, connected by a collection of single-headed arrows (or directed edges). We draw an arrow from node <span class="math inline">\(A\)</span> to node <span class="math inline">\(B\)</span> if and only if we believe that <span class="math inline">\(A\)</span> can have a direct effect on <span class="math inline">\(B\)</span>. The resulting diagram is a <em>directed acyclic</em> graph (DAG) if there are no paths along directed edges that lead from any node back to itself—i.e., if the graph contains no causal cycles. The absence of cycles (or “feedback loops”) is less constraining than it might appear at first. In particular if one thinks that <span class="math inline">\(A\)</span> today causes <span class="math inline">\(B\)</span> tomorrow which in turn causes <span class="math inline">\(A\)</span> today, we can represent this as <span class="math inline">\(A_1 \rightarrow B \rightarrow A_2\)</span> rather than <span class="math inline">\(A \leftrightarrow B\)</span>. That is, we timestamp the nodes, turning what might informally appear as feedback into a non cyclical chain.</p>
<p><strong>Meaning of missing arrows.</strong> The <em>absence</em> of an arrow between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> means that <span class="math inline">\(A\)</span> is not a direct cause of <span class="math inline">\(B\)</span>.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> Here lies an important asymmetry: drawing such an arrow does not mean that we know that <span class="math inline">\(A\)</span> <em>does</em> directly cause <span class="math inline">\(B\)</span>; but omitting such an arrow implies that we know that <span class="math inline">\(A\)</span> does <em>not</em> directly cause <span class="math inline">\(B\)</span>. We say more, in other words, with the arrows we omit than with the arrows that we include.</p>
<p>Returning to Figure @ref(fig:simpleDAG), we have here expressed the belief that redistributive preferences exert no direct effect on democratization; we have done so by <em>not</em> drawing an arrow directly from <span class="math inline">\(R\)</span> to <span class="math inline">\(D\)</span>. In the context of this model, saying that redistributive preferences have no direct effect on democratization is to say that any effect of redistributive preferences on democratization <em>must</em> run through mobilization; there is no other pathway through which such an effect can operate. This might be a way of encoding the knowledge that mass preferences for redistribution cannot induce autocratic elites to liberalize the regime absent collective action in pursuit of those preferences.</p>
<p>The same goes for the effects of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span>, <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span>, and <span class="math inline">\(E\)</span> on <span class="math inline">\(D\)</span>: the graph in Figure @ref(fig:simpleDAG) implies that we believe that these effects also do not operate directly, but only along the indicated, mediated paths.</p>
<p><strong>Sometimes-causes.</strong> The existence of an arrow from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> does not imply that <span class="math inline">\(A\)</span> always has a direct effect on <span class="math inline">\(B\)</span>. Consider, for instance, the arrow running from <span class="math inline">\(R\)</span> to <span class="math inline">\(M\)</span>. The existence of this arrow requires that <span class="math inline">\(M\)</span> appears somewhere in <span class="math inline">\(R\)</span>’s functional equation, as a node’s functional equation must include all nodes pointing directly into it. Imagine, though, that <span class="math inline">\(M\)</span>’s causal function is specified as: <span class="math inline">\(M = RE\)</span>. This function allows for the <em>possibility</em> that <span class="math inline">\(R\)</span> affects <span class="math inline">\(M\)</span>, as it will whenever <span class="math inline">\(E=1\)</span>. However, it also allows that <span class="math inline">\(R\)</span> will have no effect, as it will when <span class="math inline">\(E=0\)</span>.</p>
<p>This example also, incidentally, demonstrates another important consequence of context, the values of the exogenous nodes: a case’s context determines not just the settings on the endogenous nodes, but also the causal <em>effects</em> that prevail among the nodes. Under the functional equation <span class="math inline">\(M=RE\)</span>, a case’s ethnic-compositional context determines whether or not redistributive preferences will have an effect on mobilization.</p>
<p><strong>Representing <span class="math inline">\(U\)</span> on the graph.</strong> As a matter of convention, explicitly including <span class="math inline">\(U\)</span> terms is optional. In practice, <span class="math inline">\(U\)</span>’s are often excluded from the visual representation of a model on the understanding that every node on the graph is subject to some unaccounted-for influence and thus, implicitly, has a <span class="math inline">\(U\)</span> term pointing into it. In this book, we will generally draw the <span class="math inline">\(U\)</span> terms where they are of particular theoretical or analytic interest but will otherwise omit them. Whether we include or omit <span class="math inline">\(U\)</span> terms, we will generally treat those nodes in a graph that have no arrows pointing into them as the exogenous nodes that define the context.</p>
<p><strong>No excluded common causes, no unobserved confounding</strong> Any cause common to multiple nodes on the graph must itself be represented on the graph. If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> on a graph are both affected by some third node, <span class="math inline">\(C\)</span>, then we must represent this common cause. Put differently, any two nodes without common causes on the graph are taken to be independent of one another. Thus, the graph in Figure @ref(fig:simpleDAG) implies that the values of <span class="math inline">\(I\)</span>, <span class="math inline">\(E\)</span>, and <span class="math inline">\(\theta^D\)</span> are all determined independently of one another. If in fact we believed that a country’s level of inequality and its ethnic composition were both shaped by, say, its colonial heritage, then this DAG would <em>not</em> be an accurate representation of our beliefs about the world. To make it accurate, we would need to add to the graph a node capturing that colonial heritage and include arrows running from colonial heritage to both <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>.</p>
<p>This rule ensures that the graph captures all potential correlations among nodes that are implied by our beliefs. If <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> are in fact driven by some common cause, then this means not just that these two nodes will be correlated but also that each will be correlated with any consequences of the other. For instance, a common cause of <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> would also imply a correlation between <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>. <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> are implied to be independent in the current graph but would be implied to be correlated if a common node pointed into both <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>.</p>
<p>Of particular interest in Figure @ref(fig:simpleDAG) is the implied independence of <span class="math inline">\(\theta^D\)</span> from every other node. Imagine, for instance, an additional node pointing into both <span class="math inline">\(I\)</span> and <span class="math inline">\(\theta^D\)</span>. This would represent a classic form of confounding: the assignment of cases to values on the explanatory node would be correlated with case’s potential outcomes on <span class="math inline">\(D\)</span>. The omission of any such pathway is precisely equivalent to expressing the belief that <span class="math inline">\(I\)</span> is exogenous, or (as if) randomly assigned.</p>
<p><strong>Representing excluded common causes, unobserved confounding if you have it.</strong> It may be however that there are common causes for nodes that we simply do not understand. We are open to the idea that some unknown feature determines both <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span>. In this case it is as if <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^D\)</span> are not independently distributed. This is often represented by adding a dotted line, or a two headed arrow, connecting nodes whose shocks are not independent. Figure @ref(fig:simpleDAGb) illustrates. In general we will allow for this kind of unobserved confounding in the models in this book and seek to learn about the joint distribution of errors in such cases.</p>
<div class="figure" style="text-align: center">
<img src="ii_files/figure-html/simpleDAGb-1.png" alt="A DAG with unobserved confounding" width="60%" />
<p class="caption">
(#fig:simpleDAGb)A DAG with unobserved confounding
</p>
</div>
<p><strong>Licence to exclude nodes.</strong> The flip side of this rule is that a causal graph, to do the work it must do, does not need to include everything we know about a substantive domain of interest. We may know quite a lot about the causes of economic inequality, for example. But we can safely omit any other factor from the graph as long as it does not affect multiple nodes in the model. Indeed, we can choose to capture any number of unspecified factors in a <span class="math inline">\(U\)</span> term. We may be aware of a vast range of forces shaping whether countries democratize, but choose to bracket them for the purposes of an examination of the role of economic inequality. This bracketing is permissible as long as none of these unspecified factors also act on other nodes included in the model.</p>
<p><strong>You can’t read functional equations from a graph.</strong> As should be clear, a DAG does not represent all features of a causal model. What it does record is which nodes enter into the structural equation for every other node: what can directly cause what. But the DAG contains no other information about the form of those causal relations. Thus, for instance, the DAG in Figure @ref(fig:simpleDAG) tells us that <span class="math inline">\(M\)</span> is function of both <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>, but it does not tell us whether that joint effect is additive (<span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> separately increase mobilization), interactive (the effect of each depends on the value of the other), or whether either effect if linear, curvilinear or something else. This lack of information about functional forms often puzzles those encountering causal graphs for the first time; surely it would be convenient to visually differentiate, say, additive from conditioning effects. As one thinks about the variety of possible causal functions, it quickly becomes clear that there would be no simple visual way of capturing all possible functional relations. Moreover, as we shall now see, causal graphs are a tool designed with a particular analytic purpose in mind—a purpose to which we now turn.</p>
</div>
<div id="conditional-independence-from-dags" class="section level3" number="2.2.3">
<h3 number="2.2.3"><span class="header-section-number">2.2.3</span> Conditional independence from DAGs</h3>
<p>If we encode our prior knowledge using the grammar of a causal graph, we can put that knowledge to work for us in powerful ways. In particular, the rules of DAG-construction allow for an easy reading of the <em>conditional independencies</em> implied by our beliefs.</p>
<p>To begin thinking about conditional independence, it can be helpful to conceptualize dependencies between nodes as generating <em>flows of information</em>. Let us first consider a simple relationship of dependence. Returning to Figure @ref(fig:simpleDAG), the arrow running from <span class="math inline">\(I\)</span> to <span class="math inline">\(R\)</span>, implying a direct causal dependency, means that if we expect <span class="math inline">\(I\)</span> and <span class="math inline">\(R\)</span> to be correlated. Put differently, observing the value of one of these nodes also gives us information about the value of the other. If we measured redistributive preferences, the graph implies that we would also be in a better position to infer the level of inequality, and vice versa. Likewise, <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> are also linked in a relationship of dependence: since inequality can affect mobilization (through <span class="math inline">\(R\)</span>), knowing the the level of inequality would allow us to improve our estimate of the level of mobilization and vice versa.</p>
<p>In contrast, consider <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>, which are in this graph indicated as being <em>independent</em> of one another. Learning the level of inequality, according to this graph, would give us no information whatsoever about the degree of ethnic homogeneity, and vice-versa.</p>
<p>Moreover, sometimes what you learn depends on <em>what you already know.</em> Suppose that we already knew the level of redistributive preferences. Would we then be in a position to learn about the level of inequality by observing the level of mobilization? According to this graph we would not: since the causal link—and, hence, flow of information between <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span>—runs through <span class="math inline">\(R\)</span>, and we already know <span class="math inline">\(R\)</span>, there is nothing left to be learned about <span class="math inline">\(I\)</span> by also observing <span class="math inline">\(M\)</span>. Anything we could have learned about inequality by observing mobilization is already captured by the level of redistributive preferences, which we have already seen. In other words, if we were not to include <span class="math inline">\(R\)</span> in the causal model, then <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> would be dependent and informative about each other. When we do include <span class="math inline">\(R\)</span> in the causal graph, <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> are independent of one another, hence uninformative about each other. We can express this idea by saying that <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> are <em>conditionally independent given <span class="math inline">\(R\)</span></em>.</p>
<p>We say that two nodes, <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>, are “conditionally independent” given a set of nodes <span class="math inline">\(\mathcal B\)</span> if, once we have knowledge of the values in <span class="math inline">\(\mathcal B\)</span>, knowledge of <span class="math inline">\(A\)</span> provides no information about <span class="math inline">\(C\)</span> and vice-versa. Taking <span class="math inline">\(\mathcal B\)</span> into account thus “breaks” any relationship that might exist unconditionally between <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>.</p>
<p>To take up another example, suppose that war is a cause of both military casualties and price inflation, as depicted in Figure @ref(fig:warDAG). Casualties and inflation will then be (unconditionally) correlated with one another because of their shared cause. If I learn that there have been military casualties, this information will lead me to think it more likely that there is also war and, in turn, price inflation (and vice versa). However, assuming that war is their only common cause, we would say that military casualties and price inflation are <em>conditionally independent given war.</em> If we already know that there is war, then we can learn nothing further about the level of casualties (price inflation) by learning about price inflation (casualties). We can think of war, when observed, as blocking the flow of information between its two consequences; everything we would learn about inflation from casualties is already contained in the observation that there is war. Put differently, if we were just to look at cases where war is present (i.e., if we hold war constant), we should find no correlation between military casualties and price inflation; likewise, for cases in which war is absent.</p>
<div class="figure" style="text-align: center">
<img src="ii_files/figure-html/warDAG-1.png" alt="This graph represents a simple causal model in which war ($W$) affects both military casualties ($C$) and price inflation ($P$)." width="60%" />
<p class="caption">
(#fig:warDAG)This graph represents a simple causal model in which war (<span class="math inline">\(W\)</span>) affects both military casualties (<span class="math inline">\(C\)</span>) and price inflation (<span class="math inline">\(P\)</span>).
</p>
</div>
<p>Relations of conditional independence are central to the strategy of statistical control, or covariate adjustment, in correlation-based forms of causal inference, such as regression. In a regression framework, identifying the causal effect of an explanatory node, <span class="math inline">\(X\)</span>, on a dependent node, <span class="math inline">\(Y\)</span>, requires the assumption that <span class="math inline">\(X\)</span>’s value is conditionally independent of <span class="math inline">\(Y\)</span>’s potential outcomes (over values of <span class="math inline">\(X\)</span>) given the model’s covariates. To draw a causal inference from a regression coefficient, in other words, we have to believe that including the covariates in the model “breaks” any biasing correlation between the value of the causal node and its unit-level effect.</p>
<p>As we will explore, however, relations of conditional independence are of more general interest in that they tell us, given a model, <em>when information about one feature of the world may be informative about another feature of the world, given what we already know</em>. By identifying the possibilities for learning, relations of conditional independence can thus guide research design.</p>
<!-- Some possibilities are excluded by the framework, however: for example, one cannot represent uncertainty regarding whether $A$ causes $B$ or $B$ causes $A$. -->
<!-- It would be nice to make a less general statement than the above as it sounds like none of this has any relevance if we think there's reciprocal causation in the causal system of interest; and that sounds like it excludes A LOT of problems political scientists are interested in. Pearl has a bit of discussion of the fact that one can compute the effect of interventions for models with cyclic features as well. So can we put this point more narrowly? Have been looking into this a bit but not yet sure exactly how to do that. -->
<!-- The above point is something I want to get more clarity around. Also, why we are defining roots as we are. -->
<!-- In Figure \@ref(fig:simpleDAG) we show a simple DAG that represents a situation in which $X$ is a parent of $M$, and $M$ is a parent of $Y$. In this example, the three nodes $\theta^X$, $\theta^M$, and $\theta^Y$ are all exogenous and thus elements of \(\mathcal{U}\). $X$, $M$, and $Y$ are endogenous and members of  \(\mathcal{V}\). If these three nodes were binary, then there would be eight possible realizations of outcomes, i.e., of \(\mathcal{V}\). In the underlying model,  $\theta^X$ is an ancestor of $X$, $M$, and $Y$ which are all descendants of $\theta^X$. The elements of $\mathcal{U}$ are all roots, though $X$ is also  a root as it has no parent in $\mathcal{V}$.   -->
<!-- In addition we will usually omit nodes from a graph only if they are single parents---this has the advantage of clarifying that all uncertainty is over the value of roots, and not over functional forms given roots; this is without loss of generality as parameters for functional equations can themselves be represented as roots.      -->
<!-- As a very simple example one might imagine that $A$ an $B$ are independently generated binary nodes; $C$ is an indicator for whether $A$ and $B$ have the same value. Then obviously if you know $C$, then knowing $A$ tells you everything about $B$. -->
<p>To see more systematically how a DAG can reveal conditional independencies, it is useful spell out three pairs of features of the flow of information in causal graphs:</p>
<div class="figure" style="text-align: center">
<img src="ii_files/figure-html/pathsexp-1.png" alt="\label{fig:CI} Three elementary relations of conditional independence." width="70%" />
<p class="caption">
(#fig:pathsexp) Three elementary relations of conditional independence.
</p>
</div>
<p>(1a) Information can flow unconditionally along a path of arrows pointing in the same direction. In Panel 1 of Figure , information flows across all three nodes. Learning about any one will tell us something about the other two.</p>
<p>(1b) Learning the value of a node along a path of arrows pointing in the same direction <em>blocks</em> flows of information across that node. Knowing the value of <span class="math inline">\(B\)</span> in Panel 1 renders <span class="math inline">\(A\)</span> no longer informative about <span class="math inline">\(C\)</span>, and vice versa: anything that <span class="math inline">\(A\)</span> might tell us about <span class="math inline">\(C\)</span> is already captured by the information about <span class="math inline">\(B\)</span>.</p>
<p>(2a) Information can flow unconditionally across the branches of any forked path. In Panel 2 learning only <span class="math inline">\(A\)</span> can provide information about <span class="math inline">\(C\)</span> and vice-versa.</p>
<p>(2b) Learning the value of the node at the forking point blocks <em>flows</em> of information across the branches of a forked path. In Panel 2, learning <span class="math inline">\(A\)</span> provides no information about <span class="math inline">\(C\)</span> if we already know the value of <span class="math inline">\(B\)</span>.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<p>(3a) When two or more arrowheads collide, generating an inverted fork, there is no unconditional flow of information between the incoming sequences of arrows. In Panel 3, learning only <span class="math inline">\(A\)</span> provides no information about <span class="math inline">\(C\)</span>, and vice-versa.</p>
<p>(3b) Collisions can be sites of <em>conditional</em> flows of information. In the jargon of causal graphs, <span class="math inline">\(B\)</span> in Panel 2 is a “collider” for <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> Although information does not flow unconditionally across colliding sequences, it does flow across them <em>conditional</em> on knowing the value of the collider node or any of its downstream consequences. In Panel 2, learning <span class="math inline">\(A\)</span> <em>does</em> provide new information about <span class="math inline">\(C\)</span>, and vice-versa, <em>if</em> we also know the value of <span class="math inline">\(B\)</span> (or, in principle, the value of anything that <span class="math inline">\(B\)</span> causes).</p>
<p>The last point is somewhat counter-intuitive and warrants further discussion. It is easy enough to see that, for two nodes that are correlated unconditionally, that correlation can be “broken” by controlling for a third node. In the case of collision, two nodes that are <em>not</em> correlated when taken by themselves <em>become</em> correlated when we condition on (i.e., learn the value of) a third node, the collider. The reason is in fact quite straightforward once one sees it: if an outcome is a joint function of two inputs, then if we know the outcome, information about one of the inputs can provide information about the other input. For example, if I know that you have brown eyes, then learning that your mother has blue eyes makes me more confident that your father has brown eyes.</p>
<p>Looking back at our democratization DAG in Figure @ref(fig:simpleDAG), <span class="math inline">\(M\)</span> is a collider for <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>, its two inputs. Suppose that we again have the functional equation <span class="math inline">\(M=RE\)</span>. Knowing about redistributive preferences alone provides no information whatsoever about ethnic homogeneity since the two are determined independently of one another. On the other hand, imagine that you already know that there was no mobilization. Now, if you observe that there <em>were</em> redistributive preferences, you can figure out the level of ethnic homogeneity: it must be 0. (And likewise in going from homogeneity to preferences.)</p>
<p>Using these basic principles, conditional independencies can be read off any DAG. We do so by checking every path connecting two nodes of interest and ask whether, along those paths, the flow of information is open or blocked, given any other nodes whose values are already observed. Conditional independence is established when <em>all</em> paths are blocked given what we already know; otherwise, conditional independence is absent.</p>
<!-- ### A simple running example -->
<!-- We can illustrate these core ideas with a simple example of a model of government corruption and survival, one that we will return to in future chapters. -->
<!-- We begin with two binary features of context. Consider, first, that a country may or may not have a free press ($X$). Second, the country's government may or may not be sensitive to public opinion ($S$).^[Government sensitivity here can be thought of as government sophistication (does it take the actions of others into account when making decisions?) or as a matter of preferences (does it have a dominant strategy to engage in corruption?).] Let us then stipulate what follows from these conditions. The government will engage in corruption ($C=1$) unless it is sensitive to public opinion and there is a free press. Moreover, if and only if there is both government corruption and a free press, the press will report on the corruption ($R=1$). Finally, the government will be removed from office ($Y=1$) if it has acted corruptly and this gets reported in the press; otherwise, the government remains in office. -->
<!-- As a set of equations, this simple causal model may be written as follows: -->
<!-- $\begin{array}{ll} -->
<!-- C = 1-X\times S &  \mbox{Whether the government is corrupt}\\ -->
<!-- R = C\times X &  \mbox{Whether the press reports on corruption}\\ -->
<!-- Y = C\times R & \mbox{Whether the government is removed from office} -->
<!-- \end{array}$ -->
<!-- One thing that these equations make clear is that the nodes in our model function in various places as causal-type nodes for one another. For instance, we can see from equation for $C$ that the causal effect of a free press ($X$) on corruption ($C$) depends on whether the government is sensitive to public opinion ($S$): $S$ determines $C$'s response to $X$ (as does $X$ for $S$'s effect on $C$). A similar relationship holds for $C$ and $X$ in their effect on $R$ and for $C$ and $R$ in their effect on $Y$. As we will see below, the model also implies more complex causal-type relationships. We can, further, substitute through the causal processes to write down the functional equation for the outcome in terms of the two initial causal nodes: $Y=(1-S)X$.^[In Boolean notation (but preserving a structural equation interpretation), where $Y$ stands for the occurrence of government removal, $Y= \neg S \land X$; and the function for the outcome "government retained" can be written  $\neg Y = (S\land X) \lor (S\land\neg X) \lor (\neg S \land \neg X)$ or, equivalently, $\neg Y = S + \neg S \neg X$.] -->
<!-- Let us, further, allow the two primary causal nodes---the existence of a free press and the existence of a sensitive government---to vary probabilistically. In particular, we represent the probability of a free press with the population parameter $\lambda^X_1$ and the probability of a sensitive government with the parameter $\lambda^S_1$.  -->
<!-- Note that in this model, only the most "senior" specified nodes, $X$ and $S$, have a stochastic component (i.e., $\lambda^X_1$ and $\lambda^S_1$ lie between 0 and 1). All other endogenous nodes are deterministic functions of other specified nodes (put differently: each node has only a single nodal type). -->
<!-- The corresponding causal diagram for this model is shown in Figure \@ref(fig:running). -->
<!-- In later chapters we will develop this model and use it to illustrate different estimands and different strategies for case level inference. -->
</div>
</div>
<div id="chapter-appendix" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> Chapter Appendix</h2>
<div id="steps-for-constructing-causal-models" class="section level3" number="2.3.1">
<h3 number="2.3.1"><span class="header-section-number">2.3.1</span> Steps for constructing causal models</h3>
<hr />
<p>Box: <strong>Steps for constructing causal models</strong></p>
<ol style="list-style-type: decimal">
<li>Identify a set of variables in a domain of interest. These become the nodes of the model.</li>
</ol>
<ul>
<li>You should specify the range of each node: is it continuous or discrete?</li>
<li>May include <span class="math inline">\(U\)</span> terms representing unspecified, random influences</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Draw a causal graph (DAG) representing beliefs about causal dependencies among these nodes</li>
</ol>
<ul>
<li>Capture direct effects only</li>
<li>Arrows indicate <em>possible</em>, not constant or certain, causal effects</li>
<li>The absence of an arrow between two nodes indicates a belief of <em>no</em> direct causal relationship between them</li>
<li>Ensure that the graph captures all correlations among nodes. This means that either (a) any common cause of two or more nodes is included on the graph (with implications for Step 1) or (b) correlated nodes are connected with a dashed, undirected edge.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Write down one causal function for each endogenous node</li>
</ol>
<ul>
<li>Each node’s function must include all nodes directly pointing into it on the graph</li>
<li>Functions may take any form, as long as each set of possible causal values maps onto a single outcome value</li>
<li>Functions may express arbitrary amounts of uncertainty about causal relations</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>State probabilistic beliefs about the distributions of the exogenous nodes</li>
</ol>
<ul>
<li>How common or likely to do we think different values of the exogenous nodes are?</li>
<li>Are they independently distributed? If in step 2 you drew an undirected edge between nodes then you believe that the connected nodes are not independently distributed.</li>
</ul>
<hr />
</div>
<div id="model-construction-in-code" class="section level3" number="2.3.2">
<h3 number="2.3.2"><span class="header-section-number">2.3.2</span> Model construction in code</h3>
<p>Our <code>gbiqq</code> package provides a set of functions to implement all of these steps concisely for <em>binary</em> models – models in which all nodes are dichotomous.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps 1 and 2 </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We define a model with three binary nodes and specified edges between them:</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">make_model</span>(<span class="st">&quot;X -&gt; M -&gt; Y&quot;</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Unrestricted functional forms are allowed by default, though these can </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># also be reduced. Here we impose monotonicity at each step </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># by removing one type for M and one for Y</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">set_restrictions</span>(model, <span class="at">labels =</span> <span class="fu">list</span>(<span class="at">M =</span> <span class="st">&quot;10&quot;</span>, <span class="at">Y=</span><span class="st">&quot;10&quot;</span>))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># We set priors over the distribution of (remaining) causal types.</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Here we set &quot;jeffreys priors&quot;</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">set_priors</span>(model, <span class="at">distribution =</span> <span class="st">&quot;jeffreys&quot;</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># We now have a model defined as an R object. </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Later we will ask questions of this model and update it using data.</span></span></code></pre></div>
<p>These steps are enough to fully describe a binary causal model. Later in this book we will see how we can ask questions of a model like this but also how to use data to train it.</p>
<!-- If we want to know whether two nodes, $A$ and $C$, are conditionally independent given some set of nodes, $\mathcal B$, we need to find out whether any paths between $A$ and $C$ are "active" given $\mathcal B$. Put slightly differently, the question is whether nodes in $\mathcal{B}$ block information flows from $A$ to $C$---or rather allow, or even create, such flows. This can be assessed as follows. For each possible path between $A$ and $C$, we check whether there are three connected nodes $X, Y, Z$^[Where $X$ and/or $Y$ may be $A$ and/or $B$.] on that path that either: -->
<!-- (a) form a "chain" $X\rightarrow Y \rightarrow Z$ (going either direction) or "fork" $X\leftarrow Y\rightarrow Z$, with $Y \subset \mathcal{B}$,^[For instance, under this criterion, if we have $A\rightarrow W\rightarrow Y \rightarrow B$, and $Y$ is an element of the set $\mathcal{B}$, then this path is not active given $\mathcal{B}$. Similarly, if we have $A \leftarrow X\leftarrow Y\rightarrow Z \rightarrow B$, and $Y$ is in $\mathcal{B}$, then the path is not active given $\mathcal{B}$.] or  -->
<!-- (b) form an "inverted fork" $X \rightarrow Y \leftarrow Z$, with neither $Y$ nor its descendants in $\mathcal C$.^[For instance, if we have $A \rightarrow W \rightarrow Y \leftarrow Z \leftarrow B$, and $Y$ is *not* in $\mathcal{C}$, then the path is not active given $\mathcal{C}$. In other words, "inverted fork" paths are not unconditionally active. Knowing only $A$, in this setup, tells us nothing about $B$, and vice-versa.]  -->
<!-- If either of these conditions holds, then the path is blocked (not active) given $\mathcal C$. In the first case, any possible information flows along the path are *blocked* by a node in $\mathcal C$. In the second case, *no* node in $\mathcal C$ is *creating* an information flow that would not otherwise be present. If there are no active paths, then $A$ and $B$ are conditionally independent given $\mathcal C$. In the graph-analytic language of Pearl and others, $A$ and $B$ are said to be "$d$-separated" by $\mathcal{C}$.^[There are multiple techniques for establishing $d-$separation. Pearl's guide "$d-$separation without tears" appears in an appendix to @pearl2009causality.]   -->
<!-- Thus, in Figure \@ref(fig:simpleDAG), we can readily see that $X$ and $Y$ are conditionally independent given $R$: $X$ and $Y$ are *d-*separated by $R$.  Conversely, $R$ and $\theta^Y$ are unconditionally independent. However, conditioning on $Y$ $d-$*connects* $R$ and $\theta^Y$, generating a dependency between them. If and only if we know the outcome, $Y$, then learning $R$ yields information about $\theta^Y$. To foreshadow a point that we develop further later in the book, this analysis reveals how we can, and cannot, learn empirically about elements of our models. For instance, if $\theta^Y$ is a node of interest but not directly observable, then information on $R$ is unhelpful if we have not observed the outcome, $Y$, but *is* informative if we have. -->
<!-- ###Interventions in causal graphs -->
<!-- A second advantage of causal graphs is that they provide a useful structure for thinking through causal effects. In a causal-model framework, we think of a node's causal effect as being the effect of an imagined *intervention*: a manipulation of some node, $X$, that provides $X$ with a value that is *not* determined by its parents.  In an intervention, it is as if the causal function for $X$ is replaced by the function $X=x$, with $x$ being the constant value to which we have set $X$. If we take $X$ to be binary, to keep things simple, then the causal effect of $X$ on $Y$ is the difference between the value $Y$ would take on under the intervention $X=0$ (which can be written as $do (X)=0$) and the value $Y$ would take on under the intervention $X=1$ ($do(X)=1$).  -->
<!-- As this manipulative account of causation makes clear, analyzing the effect of $X$ requires us we to set aside the "natural causes" of $X$ itself in a particular way. We can readily see how this works graphically by considering a modified version of our free press/government survival model as displayed in Figure \ref{fig:DAGdirect}. As compared with Figure \ref {fig:simpleDAG}, this DAG represents a model in which $X$ has effects on $Y$ both indirectly through $R$ and directly. We might imagine, for instance, that part of the effect of a free press ($X$) on government turnover ($Y$) runs via media reports of official corruption ($R$) while part of the effect runs through a deterrent effect of a free press that reduces graft and thus leaves greater public resources for investment in public goods (neither of which mediating nodes are represented on the graph). -->
<!-- Suppose that we want to estimate the effect of an increase in media reports of corruption, $R$, on government survival, $Y$. We thus want to know the difference between the value that $Y$ would take on if the number of media reports were set at a  high level and the value $Y$ would take on if media reports were set to low. As should be clear from the graph, we cannot estimate this difference by comparing the observed value of $Y$ when media report levels are high to the observed value of $Y$ when media report levels are low. The reason is that $R$ has an ancestor, $X$, that affects $Y$ via a path that does not run through $R$. Thus, the value that $Y$ takes on when $R$ is observed to be high (or low) will be determined not just by $R$ but also by $X$, which is itself systematically correlated with $R$ by being its ancestor. The difference between $Y$'s values at two values of $R$ will thus itself be a combination of $R$'s effect and of $X$'s effect. -->
<!-- Instead, the query, "What is the effect of $R$ on $Y$?", must be conceived of in a way that separates out the effect of $X$ on $R$. We can represent the empirical conditions that we would need to estimate this effect in Figure \ref{fig:DAGdirectmut}. We have "mutilated" the original DAG by removing all arrows pointing into our causal node, $R$ (here, simply the arrow running from $X$ to $R$). This graph represents a world in which $R$ has been manipulated, rather than naturally caused. (Equivalently, it is a world in which $R$ is purely exogenous.) And what the mutilated graph tells us is that, in an empirical situation in which the  dependency of $R$ on $X$ could be removed, $R$'s causal effect on $Y$ *could* be estimated by comparing $Y$'s values at high and low levels of $R$.^[In the formulation used in  @pearl2009causality, an intervention involving an endogenous node $V_i$ can be written as $do(V_i)=v_i'$, or for notational simplicity $\hat{v}_i'$ (meaning $V_i$ is forced to take the particular value $v_i'$). The resulting distribution can be written as a modified version of Equation \@ref(eq:markov): -->
<!-- \begin{equation}  -->
<!-- P(v_1,v_2,\dots v_n|\hat{v}_i) = \prod_{-i}P(v_j|pa_j)\mathbb{1}(v_i = v_i')(\#eq:eqdo) -->
<!-- \end{equation} -->
<!-- where $-i$ indicates that the product is formed over all nodes $V_j$ other than $V_i$, and the indicator function ensures that probability mass is only placed on vectors (or worlds) with $v_i = v_i'$. This new distribution has a graphical interpretation, representing the probability distribution over a graph in which all arrows into $V_i$ are removed.  The difference between Equation \@ref(eq:markov) and \@ref(eq:eqdo) is the difference between an *observed* probability distribution and the effect of an *intervention*. The key differences is that, when we intervene to manipulate a node, we break the link between the node and its "natural" causes.] -->
<!-- It is a separate question how such an empirical situation might be generated. But it is not hard to see from Figure \ref{fig:DAGdirect} that the  dependency of $R$ on $X$ could be removed either via (i) directly manipulating $R$ in a manner orthogonal to $X$ or (ii) controlling for $X$, since any variation in $R$ conditional on $X$ would itself be independent of $X$. Equivalently, using graph-analytic logic, we can also see that conditioning on $X$ blocks the path between $R$ and $Y$ that generates the confound (called a "backdoor"), thus expunging the confounding effect from the observed correlation between $R$ and $Y$. -->
<!-- ```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.5\\textwidth', fig.cap = "\\label{fig:DAGdirect} As compared with Figure \ref {fig:simpleDAG}, this DAG represents a model in which $X$ has effects on $Y$ both indirectly through $R$ and directly. We might imagine, for instance, that part of the effect of a free press ($X$) on government turnover ($Y$) runs via media reports of official corruption ($R$) while part of the effect runs through a deterrent effect of a free press that reduces graft and thus leaves greater public resources for investment in public goods (neither of which mediating nodes are represented on the graph)."} -->
<!-- par(mar=c(1,1,3,1)) -->
<!-- hj_dag(x = c(0, 1, 2), -->
<!--        y = c(2, 3, 2), -->
<!--        names = c("X", "R", "Y"), -->
<!--        arcs = cbind( c(1, 2, 1), -->
<!--                      c(2, 3, 3)), -->
<!--        title = "A DAG with Indirect and Direct Effects", -->
<!--        padding = .4, contraction = .15)  -->
<!-- ``` -->
<!-- ```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.5\\textwidth', fig.cap = "\\label{fig:DAGdirectmut} This DAG represents a 'mutilated' version of the previous graph in which the causes of $R$ have been removed, and thus captures the empirical relations that would be required to hold to estimate the effect of $R$ on $Y$."} -->
<!-- par(mar=c(1,1,3,1)) -->
<!-- hj_dag(x = c(0, 1, 2), -->
<!--        y = c(2, 3, 2), -->
<!--        names = c("X", "R", "Y"), -->
<!--        arcs = cbind( c(2, 1), -->
<!--                      c(3, 3)), -->
<!--        title = "A 'Mutilated' DAG for Estimating the Effect of R on Y", -->
<!--        padding = .4, contraction = .15)  -->
<!-- ``` -->
<!-- Suppose, for instance, that democracy ($D$) causes higher levels of private investment ($I$) and greater public-goods provision ($P$), and that both of these cause faster economic growth ($G$). If we want to know the joint distribution of public-goods provision and democracy, we would use Equation \ref{eqmarkov}, conditioning on the values of the parents of these two nodes. If, however, we want to know what level of growth would be produced by an increase public-goods provision---a causal question---we have to ask  -->
<!-- ```{r, echo = FALSE, fig.width = 11, fig.height = 11.5, fig.align="center", out.width='\\textwidth', fig.cap = "\\label{fig:intervention} The main panel shows a simple causal model. $S$ and $X$ are stochastic, other nodes determined by their parents, as shown in bottom right panel. Other panels show four possible histories that can arise depending on values taken by $S$ and $X$, along with causal relations in each case. The equations for $S$ and $X$ are written with indicator nodes, which take a value of 1 whenever the $u$ value is less than the $\\pi$ value.", fig.align="center", warning = FALSE} -->
<!-- hj_dag(x = c(1, 2, 2, 3), -->
<!--        y = c(1, 2, 0, 1), -->
<!--        names = c("D","I", "P", "G"), -->
<!--        arcs = cbind( c(1, 1, 3, 2), -->
<!--                      c(2, 3, 4, 4)), -->
<!--        add_functions = 0, -->
<!--        contraction = .2 -->
<!--        ) -->
<!-- title("A causal model") -->
<!-- ``` -->
<!-- Not completely following the logic this next paragraph or sure if it is helpful here -->
<!-- So far, although not completely general, the focus on causal DAGs is consistent with most approaches used in qualitative work on process tracing, in qualitative case analysis, and in econometric approaches. Some of these approaches commonly assume simple functional forms but these impositions are not implied by the general approach. For example econometric models often impose linear assumptions---for example in work on linear structural equations. Qualitative case analysis often assume all units are binary and that outcomes are deterministic. Under some representations the latter assumption implies conditional independencies that cannot be read from the graph, and thus violate stability conditions commonly assumed of the probability distributions that graphs are meant to represent (though it is still always that case that one can tell from the graph whenever two sets of nodes are not conditionally independent given some other set). In our running example described below we give an example of such deterministic relations. -->
</div>
<div id="test-yourself-can-you-read-conditional-independence-from-a-graph" class="section level3" number="2.3.3">
<h3 number="2.3.3"><span class="header-section-number">2.3.3</span> Test yourself! Can you read conditional independence from a graph?</h3>
<p>As an exercise, see whether you can identify the relations of conditional independence between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> in Figure .</p>
<div class="figure" style="text-align: center">
<img src="ii_files/figure-html/exercise-1.png" alt="\label{fig:CItest} An exercise: $A$ and $D$ are conditionally independent, given which other node(s)?" width="80%" />
<p class="caption">
(#fig:exercise) An exercise: <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are conditionally independent, given which other node(s)?
</p>
</div>
<p>Are A and D independent:</p>
<ul>
<li>unconditionally?</li>
</ul>
<p>Yes. <span class="math inline">\(B\)</span> is a collider, and information does not flow across a collider if the value of the collider node or its consequences is not known. Since no information can flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>, no information can flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> simply because any such flow would have to run through <span class="math inline">\(C\)</span>.</p>
<ul>
<li>if you condition on <span class="math inline">\(B\)</span>?</li>
</ul>
<p>No. Conditioning on a collider opens the flow of information across the incoming paths. Now, information flows between <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>. And since information flows between <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are now also connected by an unbroken path. While <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> were independent when we conditioned on nothing, they cease to be independent when we condition on <span class="math inline">\(B\)</span>.</p>
<ul>
<li>if you condition on <span class="math inline">\(C\)</span>?</li>
</ul>
<p>Yes. Conditioning on <span class="math inline">\(C\)</span>, in fact, has no effect on the situation. Doing so cuts off <span class="math inline">\(B\)</span> from <span class="math inline">\(D\)</span>, but this is irrelevant to the <span class="math inline">\(A\)</span>-<span class="math inline">\(D\)</span> relationship since the flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> was already blocked at <span class="math inline">\(B\)</span>, an unobserved collider.</p>
<ul>
<li>if you condition on <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>?</li>
</ul>
<p>Yes. Now we are doing two, countervailing things at once. While conditioning on <span class="math inline">\(B\)</span> opens the path connecting <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span>, conditioning on <span class="math inline">\(C\)</span> closes it again, leaving <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> conditionally independent.</p>
<p>Analyzing a causal graph for relations of independence represents one payoff to formally encoding our beliefs about the world in a causal model. We are, in essence, drawing out implications of those beliefs: given what we believe about a set of direct causal relations (the arrows on the graph), what must this logically imply about other dependencies and independencies on the graph, conditional on having observed some particular set of nodes? We show in a later chapter how these implications can be deployed to guide research design, by indicating which parts of a causal system are potentially informative about other parts that may be of interest.</p>
<!--chapter:end:02-causal-models.Rmd-->
</div>
</div>
</div>
<div id="illustratemodels" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Illustrating Causal Models</h1>
<p>Placeholder</p>
<div id="welfare-state-reform-pierson-1994" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Welfare state reform: Pierson (1994)</h2>
</div>
<div id="military-interventions-saunders-2011" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Military Interventions: Saunders (2011)</h2>
</div>
<div id="development-and-democratization-przeworski-and-limongi-1997" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Development and Democratization: Przeworski and Limongi (1997)</h2>
<!--chapter:end:03-illustrating-models.Rmd-->
</div>
</div>
<div id="theory" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Theories as causal models</h1>
<p>Placeholder</p>
<div id="theory-as-a-lower-level-model" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Theory as a “lower-level” model</h2>
</div>
<div id="illustration-of-unpacking-causal-types" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Illustration of unpacking causal types</h2>
<div id="type-disaggregation-in-a-mediation-model" class="section level3" number="4.2.1">
<h3 number="4.2.1"><span class="header-section-number">4.2.1</span> Type disaggregation in a mediation model</h3>
</div>
<div id="type-disaggregation-in-a-moderation-model" class="section level3" number="4.2.2">
<h3 number="4.2.2"><span class="header-section-number">4.2.2</span> Type disaggregation in a moderation model</h3>
</div>
</div>
<div id="rules-for-moving-between-higher--and-lower-level-models" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Rules for moving between higher- and lower-level models</h2>
<div id="moving-down-levels" class="section level3" number="4.3.1">
<h3 number="4.3.1"><span class="header-section-number">4.3.1</span> Moving down levels</h3>
</div>
<div id="moving-up-levels" class="section level3" number="4.3.2">
<h3 number="4.3.2"><span class="header-section-number">4.3.2</span> Moving up levels</h3>
<div id="conditioning-on-nodes" class="section level4" number="4.3.2.1">
<h4 number="4.3.2.1"><span class="header-section-number">4.3.2.1</span> Conditioning on nodes</h4>
</div>
<div id="relation-to-technical-literature" class="section level4" number="4.3.2.2">
<h4 number="4.3.2.2"><span class="header-section-number">4.3.2.2</span> Relation to technical literature</h4>
</div>
</div>
</div>
<div id="conclusion" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> Conclusion</h2>
<div id="quantifying-the-gains-of-a-theory" class="section level3" number="4.4.1">
<h3 number="4.4.1"><span class="header-section-number">4.4.1</span> Quantifying the gains of a theory</h3>
</div>
</div>
<div id="chapter-appendices" class="section level2" number="4.5">
<h2 number="4.5"><span class="header-section-number">4.5</span> Chapter Appendices</h2>
<div id="summary-boxes" class="section level3" number="4.5.1">
<h3 number="4.5.1"><span class="header-section-number">4.5.1</span> Summary Boxes</h3>
</div>
<div id="illustration-of-a-mapping-from-a-game-to-a-dag" class="section level3" number="4.5.2">
<h3 number="4.5.2"><span class="header-section-number">4.5.2</span> Illustration of a Mapping from a Game to a DAG</h3>
<!--chapter:end:04-theory-as-causal-models.Rmd-->
</div>
</div>
</div>
<div id="questions" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Causal Queries</h1>
<p>Placeholder</p>
<div id="case-level-causal-effects" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Case-level causal effects</h2>
</div>
<div id="case-level-causal-attribution" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Case-level causal attribution</h2>
</div>
<div id="case-level-explanation" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Case-level explanation</h2>
</div>
<div id="average-causal-effects" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Average causal effects</h2>
</div>
<div id="causal-paths" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Causal Paths</h2>
<!--chapter:end:05-causal-questions.Rmd-->
</div>
</div>
<div id="bayeschapter" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Bayesian Answers</h1>
<p>Placeholder</p>
<div id="bayes-basics" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> Bayes Basics</h2>
<div id="simple-instances" class="section level3" number="6.1.1">
<h3 number="6.1.1"><span class="header-section-number">6.1.1</span> Simple instances</h3>
</div>
<div id="bayes-rule-for-discrete-hypotheses" class="section level3" number="6.1.2">
<h3 number="6.1.2"><span class="header-section-number">6.1.2</span> Bayes’ Rule for Discrete Hypotheses</h3>
</div>
<div id="the-dirichlet-family-and-bayes-rule-for-continuous-parameters" class="section level3" number="6.1.3">
<h3 number="6.1.3"><span class="header-section-number">6.1.3</span> The Dirichlet family and Bayes’ Rule for Continuous Parameters</h3>
</div>
<div id="moments" class="section level3" number="6.1.4">
<h3 number="6.1.4"><span class="header-section-number">6.1.4</span> Moments</h3>
</div>
<div id="bayes-estimation-in-practice" class="section level3" number="6.1.5">
<h3 number="6.1.5"><span class="header-section-number">6.1.5</span> Bayes estimation in practice</h3>
</div>
</div>
<div id="bayes-applied" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Bayes applied</h2>
<div id="simple-bayesian-process-tracing" class="section level3" number="6.2.1">
<h3 number="6.2.1"><span class="header-section-number">6.2.1</span> Simple Bayesian Process Tracing</h3>
</div>
<div id="a-generalization-bayesian-inference-on-queries" class="section level3" number="6.2.2">
<h3 number="6.2.2"><span class="header-section-number">6.2.2</span> A Generalization: Bayesian Inference on Queries</h3>
</div>
</div>
<div id="three-principles-of-bayesian-updating" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> Three principles of Bayesian updating</h2>
<div id="AppPriors" class="section level3" number="6.3.1">
<h3 number="6.3.1"><span class="header-section-number">6.3.1</span> Priors matter</h3>
</div>
<div id="simultaneous-joint-updating" class="section level3" number="6.3.2">
<h3 number="6.3.2"><span class="header-section-number">6.3.2</span> Simultaneous, joint updating</h3>
</div>
<div id="posteriors-are-independent-of-the-ordering-of-data" class="section level3" number="6.3.3">
<h3 number="6.3.3"><span class="header-section-number">6.3.3</span> Posteriors are independent of the ordering of data</h3>
<!--chapter:end:06-being-Bayesian.Rmd-->
</div>
</div>
</div>
<div id="part-model-based-causal-inference" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Model-Based Causal Inference</h1>
</div>
<div id="pt" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Process Tracing with Causal Models</h1>
<p>Placeholder</p>
<div id="process-tracing-and-causal-models" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Process tracing and causal models</h2>
<div id="the-intuition" class="section level3" number="7.1.1">
<h3 number="7.1.1"><span class="header-section-number">7.1.1</span> The intuition</h3>
</div>
<div id="a-formalization-of-the-general-approach" class="section level3" number="7.1.2">
<h3 number="7.1.2"><span class="header-section-number">7.1.2</span> A formalization of the general approach</h3>
</div>
<div id="illustration-with-code" class="section level3" number="7.1.3">
<h3 number="7.1.3"><span class="header-section-number">7.1.3</span> Illustration with code</h3>
</div>
</div>
<div id="mapping-from-models-to-classic-qualitative-tests" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Mapping from models to classic qualitative tests</h2>
</div>
<div id="principles-of-learning" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Principles of learning</h2>
<div id="a-dag-alone-does-not-get-you-probative-value" class="section level3" number="7.3.1">
<h3 number="7.3.1"><span class="header-section-number">7.3.1</span> A DAG alone does not get you probative value</h3>
</div>
<div id="learning-requires-uncertainty" class="section level3" number="7.3.2">
<h3 number="7.3.2"><span class="header-section-number">7.3.2</span> Learning requires uncertainty</h3>
</div>
<div id="multiple-ways-for-queries-to-be-satisfied" class="section level3" number="7.3.3">
<h3 number="7.3.3"><span class="header-section-number">7.3.3</span> Multiple ways for queries to be satisfied</h3>
</div>
<div id="beware-of-highly-unlikely-queries" class="section level3" number="7.3.4">
<h3 number="7.3.4"><span class="header-section-number">7.3.4</span> Beware of highly unlikely queries</h3>
</div>
<div id="population-level-uncertainty-does-not-alter-case-level-causal-inference" class="section level3" number="7.3.5">
<h3 number="7.3.5"><span class="header-section-number">7.3.5</span> Population-level uncertainty does not alter case-level causal inference</h3>
</div>
<div id="probative-value-requires-d-connection" class="section level3" number="7.3.6">
<h3 number="7.3.6"><span class="header-section-number">7.3.6</span> Probative value requires <span class="math inline">\(d-\)</span>connection</h3>
</div>
<div id="probative-value" class="section level3" number="7.3.7">
<h3 number="7.3.7"><span class="header-section-number">7.3.7</span> Probative value</h3>
<!--chapter:end:07-process-tracing-with-models.Rmd-->
</div>
</div>
</div>
<div id="ptapp" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> Application: Process Tracing with a Causal Model</h1>
<p>Placeholder</p>
<div id="inequality-and-democratization-the-debate" class="section level2" number="8.1">
<h2 number="8.1"><span class="header-section-number">8.1</span> Inequality and Democratization: The Debate</h2>
</div>
<div id="a-structural-causal-model" class="section level2" number="8.2">
<h2 number="8.2"><span class="header-section-number">8.2</span> A Structural Causal Model</h2>
<div id="forming-priors" class="section level3" number="8.2.1">
<h3 number="8.2.1"><span class="header-section-number">8.2.1</span> Forming Priors</h3>
</div>
</div>
<div id="results" class="section level2" number="8.3">
<h2 number="8.3"><span class="header-section-number">8.3</span> Results</h2>
</div>
<div id="pathways" class="section level2" number="8.4">
<h2 number="8.4"><span class="header-section-number">8.4</span> Pathways</h2>
<div id="cases-with-incomplete-data" class="section level3" number="8.4.1">
<h3 number="8.4.1"><span class="header-section-number">8.4.1</span> Cases with incomplete data</h3>
<div id="i0-d0-non-democracy-with-low-inequality" class="section level4" number="8.4.1.1">
<h4 number="8.4.1.1"><span class="header-section-number">8.4.1.1</span> <span class="math inline">\(I=0, D=0\)</span>: Non democracy with low inequality</h4>
</div>
<div id="i1-d0-non-democracy-with-high-inequality" class="section level4" number="8.4.1.2">
<h4 number="8.4.1.2"><span class="header-section-number">8.4.1.2</span> <span class="math inline">\(I=1, D=0\)</span>: Non democracy with high inequality</h4>
</div>
</div>
<div id="inferences-for-cases-with-observed-democratization" class="section level3" number="8.4.2">
<h3 number="8.4.2"><span class="header-section-number">8.4.2</span> Inferences for cases with observed democratization</h3>
<div id="i0-d1-low-inequality-democracies" class="section level4" number="8.4.2.1">
<h4 number="8.4.2.1"><span class="header-section-number">8.4.2.1</span> <span class="math inline">\(I=0, D=1\)</span>: Low inequality democracies</h4>
</div>
<div id="i1-d1-high-inequality-democracies" class="section level4" number="8.4.2.2">
<h4 number="8.4.2.2"><span class="header-section-number">8.4.2.2</span> <span class="math inline">\(I=1, D=1\)</span>: High inequality democracies</h4>
</div>
</div>
</div>
<div id="model-definition-and-inference-in-code" class="section level2" number="8.5">
<h2 number="8.5"><span class="header-section-number">8.5</span> Model definition and inference in code</h2>
</div>
<div id="concluding-thoughts" class="section level2" number="8.6">
<h2 number="8.6"><span class="header-section-number">8.6</span> Concluding thoughts</h2>
<!--chapter:end:08-PT-application.Rmd-->
</div>
</div>
<div id="mixing" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> Integrated inferences</h1>
<p>Placeholder</p>
<div id="sample-inference" class="section level2" number="9.1">
<h2 number="9.1"><span class="header-section-number">9.1</span> Sample inference</h2>
</div>
<div id="from-sample-queries-to-general-processes" class="section level2" number="9.2">
<h2 number="9.2"><span class="header-section-number">9.2</span> From sample queries to general processes</h2>
<div id="set-up" class="section level3" number="9.2.1">
<h3 number="9.2.1"><span class="header-section-number">9.2.1</span> Set up</h3>
</div>
<div id="inference" class="section level3" number="9.2.2">
<h3 number="9.2.2"><span class="header-section-number">9.2.2</span> Inference</h3>
</div>
<div id="wrinkles" class="section level3" number="9.2.3">
<h3 number="9.2.3"><span class="header-section-number">9.2.3</span> Wrinkles</h3>
<div id="unobserved-confounding." class="section level4" number="9.2.3.1">
<h4 number="9.2.3.1"><span class="header-section-number">9.2.3.1</span> Unobserved confounding.</h4>
</div>
<div id="sampling-and-the-likelihood-principle" class="section level4" number="9.2.3.2">
<h4 number="9.2.3.2"><span class="header-section-number">9.2.3.2</span> Sampling and the likelihood principle</h4>
</div>
<div id="case-inference-following-population-updating" class="section level4" number="9.2.3.3">
<h4 number="9.2.3.3"><span class="header-section-number">9.2.3.3</span> Case inference following population updating</h4>
</div>
</div>
</div>
<div id="mixed-methods" class="section level2" number="9.3">
<h2 number="9.3"><span class="header-section-number">9.3</span> Mixed methods</h2>
</div>
<div id="considerations" class="section level2" number="9.4">
<h2 number="9.4"><span class="header-section-number">9.4</span> Considerations</h2>
<div id="probative-value-can-be-derived-from-a-causal-structure-plus-data" class="section level3" number="9.4.1">
<h3 number="9.4.1"><span class="header-section-number">9.4.1</span> Probative value can be derived from a causal structure plus data</h3>
</div>
<div id="learning-without-identification" class="section level3" number="9.4.2">
<h3 number="9.4.2"><span class="header-section-number">9.4.2</span> Learning without identification</h3>
</div>
<div id="beyond-binary-data" class="section level3" number="9.4.3">
<h3 number="9.4.3"><span class="header-section-number">9.4.3</span> Beyond binary data</h3>
</div>
<div id="measurement-error" class="section level3" number="9.4.4">
<h3 number="9.4.4"><span class="header-section-number">9.4.4</span> Measurement error</h3>
</div>
<div id="spillovers" class="section level3" number="9.4.5">
<h3 number="9.4.5"><span class="header-section-number">9.4.5</span> Spillovers</h3>
</div>
<div id="clustering" class="section level3" number="9.4.6">
<h3 number="9.4.6"><span class="header-section-number">9.4.6</span> Clustering</h3>
</div>
<div id="parameteric-models" class="section level3" number="9.4.7">
<h3 number="9.4.7"><span class="header-section-number">9.4.7</span> Parameteric models</h3>
</div>
<div id="prior-databeliefs-channel-the-learning-from-new-data" class="section level3" number="9.4.8">
<h3 number="9.4.8"><span class="header-section-number">9.4.8</span> Prior data/beliefs “channel” the learning from new data</h3>
</div>
</div>
<div id="conclusion-1" class="section level2" number="9.5">
<h2 number="9.5"><span class="header-section-number">9.5</span> Conclusion</h2>
<!--chapter:end:09-mixing-methods.Rmd-->
</div>
</div>
<div id="mixingapp" class="section level1" number="10">
<h1 number="10"><span class="header-section-number">10</span> Mixed-Method Application: Inequality and Democracy Revisited</h1>
<p>Placeholder</p>
<div id="a-trained-model" class="section level2" number="10.1">
<h2 number="10.1"><span class="header-section-number">10.1</span> A trained model</h2>
</div>
<div id="data" class="section level2" number="10.2">
<h2 number="10.2"><span class="header-section-number">10.2</span> Data</h2>
</div>
<div id="inference-1" class="section level2" number="10.3">
<h2 number="10.3"><span class="header-section-number">10.3</span> Inference</h2>
<div id="did-inequality-cause-democracy" class="section level3" number="10.3.1">
<h3 number="10.3.1"><span class="header-section-number">10.3.1</span> Did inequality <em>cause</em> democracy?</h3>
</div>
<div id="did-inequality-prevent-democracy" class="section level3" number="10.3.2">
<h3 number="10.3.2"><span class="header-section-number">10.3.2</span> Did inequality <em>prevent</em> democracy?</h3>
</div>
</div>
<div id="exercises" class="section level2" number="10.4">
<h2 number="10.4"><span class="header-section-number">10.4</span> Exercises</h2>
<!--chapter:end:10-mixed-application.Rmd-->
</div>
</div>
<div id="mm" class="section level1" number="11">
<h1 number="11"><span class="header-section-number">11</span> Mixing models</h1>
<p>Placeholder</p>
<div id="a-jigsaw-puzzle-integrating-across-a-model" class="section level2" number="11.1">
<h2 number="11.1"><span class="header-section-number">11.1</span> A jigsaw puzzle: Integrating across a model</h2>
</div>
<div id="combining-observational-and-experimental-data" class="section level2" number="11.2">
<h2 number="11.2"><span class="header-section-number">11.2</span> Combining observational and experimental data</h2>
</div>
<div id="transportation-of-findings-across-contexts" class="section level2" number="11.3">
<h2 number="11.3"><span class="header-section-number">11.3</span> Transportation of findings across contexts</h2>
</div>
<div id="multilevel-models-meta-analysis" class="section level2" number="11.4">
<h2 number="11.4"><span class="header-section-number">11.4</span> Multilevel models, meta-analysis</h2>
<!--chapter:end:11-fusion.Rmd-->
</div>
</div>
<div id="part-design-choices" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Design Choices</h1>
</div>
<div id="elements" class="section level1" number="12">
<h1 number="12"><span class="header-section-number">12</span> Elements of Design</h1>
<p>Placeholder</p>
<div id="model-inquiry-data-strategy-answer-strategy" class="section level2" number="12.1">
<h2 number="12.1"><span class="header-section-number">12.1</span> Model, inquiry, data strategy, answer strategy</h2>
<div id="defining-a-model" class="section level3" number="12.1.1">
<h3 number="12.1.1"><span class="header-section-number">12.1.1</span> Defining a model</h3>
</div>
</div>
<div id="evaluating-a-design" class="section level2" number="12.2">
<h2 number="12.2"><span class="header-section-number">12.2</span> Evaluating a design</h2>
<div id="expected-error-and-expected-posterior-variance" class="section level3" number="12.2.1">
<h3 number="12.2.1"><span class="header-section-number">12.2.1</span> Expected error and expected posterior variance</h3>
</div>
<div id="illustration" class="section level3" number="12.2.2">
<h3 number="12.2.2"><span class="header-section-number">12.2.2</span> Illustration</h3>
</div>
</div>
<div id="illustration-of-design-decaration-in-code" class="section level2" number="12.3">
<h2 number="12.3"><span class="header-section-number">12.3</span> Illustration of Design Decaration in code</h2>
<!--chapter:end:12-elements-of-design.Rmd-->
</div>
</div>
<div id="clue" class="section level1" number="13">
<h1 number="13"><span class="header-section-number">13</span> Clue Selection as a Decision Problem</h1>
<p>Placeholder</p>
<div id="core-logic" class="section level2" number="13.1">
<h2 number="13.1"><span class="header-section-number">13.1</span> Core logic</h2>
</div>
<div id="a-strategic-approach" class="section level2" number="13.2">
<h2 number="13.2"><span class="header-section-number">13.2</span> A strategic approach</h2>
<div id="clue-selection-with-a-simple-example" class="section level3" number="13.2.1">
<h3 number="13.2.1"><span class="header-section-number">13.2.1</span> Clue selection with a simple example</h3>
</div>
<div id="dependence-on-prior-beliefs" class="section level3" number="13.2.2">
<h3 number="13.2.2"><span class="header-section-number">13.2.2</span> Dependence on prior beliefs</h3>
</div>
<div id="clue-selection-for-the-democratization-model" class="section level3" number="13.2.3">
<h3 number="13.2.3"><span class="header-section-number">13.2.3</span> Clue selection for the democratization model</h3>
</div>
</div>
<div id="dynamic-strategies" class="section level2" number="13.3">
<h2 number="13.3"><span class="header-section-number">13.3</span> Dynamic Strategies</h2>
</div>
<div id="conclusion-2" class="section level2" number="13.4">
<h2 number="13.4"><span class="header-section-number">13.4</span> Conclusion</h2>
<!--chapter:end:13-clue-selection.Rmd-->
</div>
</div>
<div id="caseselection" class="section level1" number="14">
<h1 number="14"><span class="header-section-number">14</span> Mixed methods data strategies</h1>
<p>Placeholder</p>
<div id="case-selection-strategies" class="section level2" number="14.1">
<h2 number="14.1"><span class="header-section-number">14.1</span> Case selection strategies</h2>
<div id="no-general-rules" class="section level3" number="14.1.1">
<h3 number="14.1.1"><span class="header-section-number">14.1.1</span> No general rules</h3>
</div>
<div id="specific-case-walk-through" class="section level3" number="14.1.2">
<h3 number="14.1.2"><span class="header-section-number">14.1.2</span> Specific case walk through</h3>
</div>
<div id="case-selection-from-causal-models-a-simulation-based-approach" class="section level3" number="14.1.3">
<h3 number="14.1.3"><span class="header-section-number">14.1.3</span> Case selection from causal models: a simulation-based approach</h3>
<div id="models-queries-and-strategies" class="section level4" number="14.1.3.1">
<h4 number="14.1.3.1"><span class="header-section-number">14.1.3.1</span> Models, queries, and strategies</h4>
</div>
<div id="results-1" class="section level4" number="14.1.3.2">
<h4 number="14.1.3.2"><span class="header-section-number">14.1.3.2</span> Results</h4>
</div>
<div id="from-the-xy-data-only-chain-model" class="section level4" number="14.1.3.3">
<h4 number="14.1.3.3"><span class="header-section-number">14.1.3.3</span> From the <span class="math inline">\(X,Y\)</span> data only (Chain model)</h4>
</div>
<div id="n1-strategies-chain-model" class="section level4" number="14.1.3.4">
<h4 number="14.1.3.4"><span class="header-section-number">14.1.3.4</span> <span class="math inline">\(N=1\)</span> strategies (Chain model)</h4>
</div>
<div id="n2-strategies-chain-model" class="section level4" number="14.1.3.5">
<h4 number="14.1.3.5"><span class="header-section-number">14.1.3.5</span> <span class="math inline">\(N=2\)</span> Strategies (Chain model)</h4>
</div>
<div id="moderator-models" class="section level4" number="14.1.3.6">
<h4 number="14.1.3.6"><span class="header-section-number">14.1.3.6</span> Moderator models</h4>
</div>
<div id="two-path-models" class="section level4" number="14.1.3.7">
<h4 number="14.1.3.7"><span class="header-section-number">14.1.3.7</span> Two-path models</h4>
</div>
</div>
</div>
<div id="wide-or-deep" class="section level2" number="14.2">
<h2 number="14.2"><span class="header-section-number">14.2</span> Wide or Deep</h2>
<div id="walk-through-of-a-simple-comparison" class="section level3" number="14.2.1">
<h3 number="14.2.1"><span class="header-section-number">14.2.1</span> Walk-through of a simple comparison</h3>
</div>
<div id="results-from-simulations" class="section level3" number="14.2.2">
<h3 number="14.2.2"><span class="header-section-number">14.2.2</span> Results from simulations</h3>
</div>
</div>
<div id="principles" class="section level2" number="14.3">
<h2 number="14.3"><span class="header-section-number">14.3</span> Principles</h2>
<!--chapter:end:14-wideordeep.Rmd-->
</div>
</div>
<div id="part-models-in-question" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Models in Question</h1>
</div>
<div id="justifying" class="section level1" number="15">
<h1 number="15"><span class="header-section-number">15</span> Justifying models</h1>
<p>Placeholder</p>
<div id="nothing-from-nothing" class="section level2" number="15.1">
<h2 number="15.1"><span class="header-section-number">15.1</span> Nothing from nothing</h2>
</div>
<div id="justifying-the-classic-process-tracing-tests" class="section level2" number="15.2">
<h2 number="15.2"><span class="header-section-number">15.2</span> Justifying the classic process tracing tests</h2>
</div>
<div id="justification-from-experimental-designs" class="section level2" number="15.3">
<h2 number="15.3"><span class="header-section-number">15.3</span> Justification from experimental designs</h2>
<div id="mediator" class="section level3" number="15.3.1">
<h3 number="15.3.1"><span class="header-section-number">15.3.1</span> Mediator</h3>
</div>
<div id="moderator" class="section level3" number="15.3.2">
<h3 number="15.3.2"><span class="header-section-number">15.3.2</span> Moderator</h3>
</div>
</div>
<div id="causal-discovery" class="section level2" number="15.4">
<h2 number="15.4"><span class="header-section-number">15.4</span> Causal discovery</h2>
</div>
<div id="exercise" class="section level2" number="15.5">
<h2 number="15.5"><span class="header-section-number">15.5</span> Exercise</h2>
<!--chapter:end:15-Justifying-Models.Rmd-->
</div>
</div>
<div id="evaluation" class="section level1" number="16">
<h1 number="16"><span class="header-section-number">16</span> Evaluating models</h1>
<p>Placeholder</p>
<div id="five-strategies" class="section level2" number="16.1">
<h2 number="16.1"><span class="header-section-number">16.1</span> Five Strategies</h2>
<div id="check-conditional-independence" class="section level3" number="16.1.1">
<h3 number="16.1.1"><span class="header-section-number">16.1.1</span> Check conditional independence</h3>
</div>
<div id="computational-clues" class="section level3" number="16.1.2">
<h3 number="16.1.2"><span class="header-section-number">16.1.2</span> Computational clues</h3>
</div>
<div id="bayesian-p-value-are-the-data-unexpected-given-your-model" class="section level3" number="16.1.3">
<h3 number="16.1.3"><span class="header-section-number">16.1.3</span> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</h3>
</div>
<div id="leave-one-out-loo-cross-validation" class="section level3" number="16.1.4">
<h3 number="16.1.4"><span class="header-section-number">16.1.4</span> Leave-one-out (LOO) cross-validation</h3>
</div>
<div id="sensitivity" class="section level3" number="16.1.5">
<h3 number="16.1.5"><span class="header-section-number">16.1.5</span> Sensitivity</h3>
</div>
</div>
<div id="evaluating-the-democracy-inequality-model" class="section level2" number="16.2">
<h2 number="16.2"><span class="header-section-number">16.2</span> Evaluating the Democracy-Inequality model</h2>
<div id="check-assumptions-of-conditional-independence" class="section level3" number="16.2.1">
<h3 number="16.2.1"><span class="header-section-number">16.2.1</span> Check assumptions of conditional independence</h3>
</div>
<div id="bayesian-p-value" class="section level3" number="16.2.2">
<h3 number="16.2.2"><span class="header-section-number">16.2.2</span> Bayesian <span class="math inline">\(p\)</span>-value</h3>
</div>
<div id="loo-validation" class="section level3" number="16.2.3">
<h3 number="16.2.3"><span class="header-section-number">16.2.3</span> LOO validation</h3>
</div>
<div id="sensitivity-to-priors" class="section level3" number="16.2.4">
<h3 number="16.2.4"><span class="header-section-number">16.2.4</span> Sensitivity to priors</h3>
<!--chapter:end:16-Evaluating-Models5.Rmd-->
</div>
</div>
</div>
<div id="conclusion" class="section level1" number="17">
<h1 number="17"><span class="header-section-number">17</span> Final Words</h1>
<p>Placeholder</p>
<div id="the-benefits" class="section level2" number="17.1">
<h2 number="17.1"><span class="header-section-number">17.1</span> The benefits</h2>
</div>
<div id="the-worries" class="section level2" number="17.2">
<h2 number="17.2"><span class="header-section-number">17.2</span> The worries</h2>
</div>
<div id="the-future" class="section level2" number="17.3">
<h2 number="17.3"><span class="header-section-number">17.3</span> The future</h2>
<!--chapter:end:17-conclusion.Rmd-->
</div>
</div>
<div id="part-appendices" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Appendices</h1>
</div>
<div id="examplesappendix" class="section level1" number="18">
<h1 number="18"><span class="header-section-number">18</span> <code>CausalQueries</code></h1>
<p>Examples of canonical models, together with a guide to the <code>CausalQueries</code> package is provided at:</p>
<p><a href="https://macartan.github.io/causalmodels/" class="uri">https://macartan.github.io/causalmodels/</a></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<!--chapter:end:18-appendix.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-boix2003democracy" class="csl-entry">
Boix, Carles. 2003. <em>Democracy and Redistribution</em>. New York: Cambridge University Press.
</div>
<div id="ref-cartwright1994nature" class="csl-entry">
Cartwright, Nancy, and others. 1994. <span>“Nature’s Capacities.”</span> <em>OUP Catalogue</em>.
</div>
<div id="ref-galles1998axiomatic" class="csl-entry">
Galles, David, and Judea Pearl. 1998. <span>“An Axiomatic Characterization of Causal Counterfactuals.”</span> <em>Foundations of Science</em> 3 (1): 151–82.
</div>
<div id="ref-halpern2005causesa" class="csl-entry">
Halpern, Joseph Y, and Judea Pearl. 2005. <span>“Causes and Explanations: A Structural-Model Approach. Part i: Causes.”</span> <em>The British Journal for the Philosophy of Science</em> 56 (4): 843–87.
</div>
<div id="ref-hernan2006instruments" class="csl-entry">
Hernán, Miguel A, and James M Robins. 2006. <span>“Instruments for Causal Inference: An Epidemiologist’s Dream?”</span> <em>Epidemiology</em> 17 (4): 360–72.
</div>
<div id="ref-hume2000enquiry" class="csl-entry">
Hume, David, and Tom L Beauchamp. 2000. <em>An Enquiry Concerning Human Understanding: A Critical Edition</em>. Vol. 3. Oxford University Press.
</div>
<div id="ref-laplace1901philosophical" class="csl-entry">
Laplace, Pierre-Simon. 1901. <em>A Philosophical Essay on Probabilities</em>. Translated by F.W. Truscott and F.L. Emory. Vol. 166. New York: Cosimo.
</div>
<div id="ref-lewis1973counterfactuals" class="csl-entry">
Lewis, David. 1973. <span>“Counterfactuals and Comparative Possibility.”</span> In <em>Ifs</em>, 57–85. Springer.
</div>
<div id="ref-lewis1986causation" class="csl-entry">
———. 1986. <span>“Causation.”</span> <em>Philosophical Papers</em> 2: 159–213.
</div>
<div id="ref-mahoney2008toward" class="csl-entry">
Mahoney, James. 2008. <span>“Toward a Unified Theory of Causality.”</span> <em>Comparative Political Studies</em> 41 (4-5): 412–36.
</div>
<div id="ref-splawa1990application" class="csl-entry">
Splawa-Neyman, Jerzy, DM Dabrowska, TP Speed, and others. 1990. <span>“On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.”</span> <em>Statistical Science</em> 5 (4): 465–72.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>As nicely put by <span class="citation"><a href="#ref-cartwright1994nature" role="doc-biblioref">Cartwright and others</a> (<a href="#ref-cartwright1994nature" role="doc-biblioref">1994</a>)</span>, no causes in, no causes out, a point we return to more formally later.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The approach is sometimes attributed to David Hume, whose writing contains ideas both about causality as regularity and causality as counterfactual. On the latter, Hume’s key formulation is, “if the first object had not been, the second never had existed” <span class="citation">(<a href="#ref-hume2000enquiry" role="doc-biblioref">Hume and Beauchamp 2000</a>, Section VIII)</span>. More recently, the counterfactual view has been set forth by <span class="citation"><a href="#ref-splawa1990application" role="doc-biblioref">Splawa-Neyman et al.</a> (<a href="#ref-splawa1990application" role="doc-biblioref">1990</a>)</span> and <span class="citation"><a href="#ref-lewis1973counterfactuals" role="doc-biblioref">Lewis</a> (<a href="#ref-lewis1973counterfactuals" role="doc-biblioref">1973</a>)</span>. See also <span class="citation"><a href="#ref-lewis1986causation" role="doc-biblioref">Lewis</a> (<a href="#ref-lewis1986causation" role="doc-biblioref">1986</a>)</span>.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>We noted that we are conditioning on the treatments received by others. If we wanted to describe outcomes as a function of the <em>profile</em> of treatments received by others we would have a more complex types space. The complex type space could be reduced back down to four types again, However, if we invoked the assumption that the treatment or non-treatment of one patient has no effect on the outcomes of other patients—an assumption known as the stable unit treatment value assumption (SUTVA).<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>See  for an early classification of this form. The literature on probabilistic models also refers to such strata as “canonical partitions” or “equivalence classes.”<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Later, we will refer to these as “nodal types.”<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>If we let <span class="math inline">\(\mathcal{R}\)</span> denote a set of ranges for all nodes in the model, we can indicate <span class="math inline">\(X\)</span>’s range, for instance, by writing <span class="math inline">\(\mathcal{R}(X)=\{0,1\}\)</span>. The nodes in a causal model together with their ranges—the triple <span class="math inline">\((\mathcal{U}, \mathcal{V}, \mathcal{R})\)</span>—are sometimes called a , <span class="math inline">\(\mathcal{S}\)</span>.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>The collection of all causal functions in the model can be denoted as <span class="math inline">\(\mathcal{F}\)</span>.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>The set of a node’s parents is required to be minimal in the sense that a node is not included among the parents if, given the other parents, the child does not depend on it in any state that arises with positive probability.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>More formally, a <strong>structural causal model</strong> <em>over</em> signature <span class="math inline">\(\mathcal{S}=&lt;\mathcal{U},\mathcal{V},\mathcal{R}&gt;\)</span> is a pair <span class="math inline">\(&lt;\mathcal{S}, \mathcal{F}&gt;\)</span>, where <span class="math inline">\(\mathcal{F}\)</span> is a set of ordered structural equations containing a function <span class="math inline">\(f_i\)</span> for each element <span class="math inline">\(Y\in \mathcal{V}\)</span>. We say that <span class="math inline">\(\mathcal{F}\)</span> is a set of ordered structural equations if no node is its own descendant and if no element in <span class="math inline">\(\mathcal{U}\)</span> is parent to more than one element of <span class="math inline">\(\mathcal{V}\)</span>. This last condition can be achieved by shifting any parent of multiple children in <span class="math inline">\(\mathcal{U}\)</span> to <span class="math inline">\(\mathcal{V}\)</span>. This definition thus includes an assumption of acyclicity, which is not found in all definitions in the literature.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Thus <span class="math inline">\(P(d|i,e, u_D)\)</span> would defined by this structural model (as a degenerate distribution), but <span class="math inline">\(P(i)\)</span>, <span class="math inline">\(P(e)\)</span>, <span class="math inline">\(P(u_D)\)</span>, and <span class="math inline">\(P(i,e, u_D)\)</span> would not be.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>We assume that the exogenous terms, the elements of <span class="math inline">\(\theta\)</span>, are generated independently of one another. While this is not without loss of generality, it is not as constraining as it might at first appear: any graph in which two exogenous nodes are not independent can be replaced by a graph in which these two terms are listed as endogenous (possibly unobserved) nodes, themselves generated by a third node. Note also that one could envision “incomplete probabilistic causal models” in which researchers claim knowledge regarding distributions over <em>subsets</em> of <span class="math inline">\(\theta\)</span>.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>By “direct” we mean that the <span class="math inline">\(A\)</span> is a parent of <span class="math inline">\(B\)</span>: i.e., the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(B\)</span> is not fully mediated by one or more other nodes in the model.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Readers may recognize this statement as the logic of adjusting for a confound that is a cause of both an explanatory node and a dependent node in order to achieve conditional independence.<a href="#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>In the familial language of causal models, a collider is a child of two or more parents.<a href="#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
