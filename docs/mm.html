<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Mixing models | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Mixing models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Mixing models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mixingapp.html"/>
<link rel="next" href="elements-of-design.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.2</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>10</b> Mixing models</a><ul>
<li class="chapter" data-level="10.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>10.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="10.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>10.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="10.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>10.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="10.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>10.4</b> Multilevel models, meta-analysis</a></li>
<li class="chapter" data-level="10.5" data-path="mm.html"><a href="mm.html#real-multilevel"><i class="fa fa-check"></i><b>10.5</b> Real multilevel</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="11" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>11</b> Elements of Design</a><ul>
<li class="chapter" data-level="11.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>11.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="11.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>11.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>11.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="11.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>11.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="11.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-variance-almost-always-goes-down"><i class="fa fa-check"></i><b>11.2.2</b> Expected variance (almost) always goes down</a></li>
<li class="chapter" data-level="11.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>11.2.3</b> Illustration</a></li>
<li class="chapter" data-level="11.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-loss-functions"><i class="fa fa-check"></i><b>11.2.4</b> Other loss functions</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>11.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>13</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="13.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a></li>
<li class="chapter" data-level="13.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>13.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="13.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>13.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="13.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>13.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>13.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="13.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>13.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="13.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>13.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="13.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>13.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="13.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>13.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="13.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>13.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>14.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>14.2</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>14.3</b> Explorations</a><ul>
<li class="chapter" data-level="14.3.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>14.3.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.4</b> Principles</a><ul>
<li class="chapter" data-level="14.4.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>14.4.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="14.4.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>14.4.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="14.4.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>14.4.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.1</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.2" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.2</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a><ul>
<li class="chapter" data-level="15.4.1" data-path="justifying-models.html"><a href="justifying-models.html#a-model-of-models"><i class="fa fa-check"></i><b>15.4.1</b> A model of models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>17.1</b> General lessons</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>17.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>17.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="17.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>17.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mm" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Mixing models</h1>
<hr />
<p>We provide three examples of situations in which, by combining models, researchers learn more than they could from any single model.</p>
<hr />
<p>In the previous two chapters, we described one form of integration that structural causal models can enable: the systematic combination of (what we typically think of as) qualitative and quantitative evidence for the purposes of drawing population- and case-level causal inferences. One feature of the analyses we have been considering so far is that the integration is essentially “nested.” We are, for instance, integrating quantitative evidence for a large set of cases with qualitative evidence for a <em>subset</em> of those cases. We are, moreover, drawing inferences from the set of cases we observe to a population <em>within which</em> that sample of cases is situated.</p>
<p>In this chapter, we examine how we can use structural causal models to integrate across studies or settings that are, in a sense, more disjointed from one another: across studies that examine different causal relationships altogether; study designs that require different assumptions about exogeneity; and contexts across which the causal quantities of interest may vary.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Integrating across a model</strong> Often, individual studies in a substantive domain examine distinct segments of a broader web of causal relationships. For instance, while one study might examine the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, another might examine the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span>, and yet another might examine the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(K\)</span>. We show in this chapter how we can integrate across such studies in ways that yield learning that we could not achieve by taking each study on its own terms.</p></li>
<li><p><strong>Integrating between experimental and observational studies</strong> One form of multi-method research that has become increasingly common is the use of both observational and experimental methods to study the same basic causal relationships. While an experiment can offer causal identification in a usually local or highly controlled setting, an observational analysis can often shed light on how the same relationships operate “in the wild,” if with greater risk of confounding. Usually, observational and experimental results are presented in parallel, as separate sources of support for a causal claim. We show how, in a causal model setup, we can use experimental and observational data <em>jointly</em> to address questions that cannot be answered when the designs are considered separately.</p></li>
<li><p><strong>Transporting knowledge across contexts</strong> Researchers are sometimes in a situation in which they can identify causal quantities in a particular setting — say, from a randomized controlled trial implemented in a specific local context — but want to know how those inferences travel to other settings. Would the intervention work differently in other countries or regions? As we will explain, with an appropriately specified causal model and the right data from the original context, we can draw inferences about causal relationships in other contexts.</p></li>
</ol>
<p>Before delving into the details of these strategies, we make one key qualification explicit: each of these approaches requires us to believe that setting-, or study-, specific causal model can be nested within a lower level, “encompssing,” model that operates across the multiple settings that we are learning from and want to draw inferences about. Encompassing models, of course, can specifically take heterogeneity across settings into account, for instance by including in the model moderators that condition the effects of interest. But we have to believe that we have indeed captured in the model any ways in which relationships vary across the set of contexts across which we are integrating evidence or transporting inferences.</p>
<p>Put differently, and perhaps more positively, we see social scientists commonly seeking to transport knowledge or combine information informally across studies and settings. Often such efforts are motivated, sometimes implicitly, by an interest in or reliance on general theoretical propositions. The approaches that we describe below force the researcher to be <em>explicit</em> about the underlying causal beliefs that warrant that integration while also ensuring that the integration proceeds in a way that is logically consistent with stated beliefs.</p>
<div id="a-jigsaw-puzzle-integrating-across-a-model" class="section level2">
<h2><span class="header-section-number">10.1</span> A jigsaw puzzle: Integrating across a model</h2>
<p>Generating knowledge about a causal domain often involves cumulating learning across studies that each focus in on some specific part of the domain. For instance, scholars interested in the political economy and democratization might undertake studies focused on the relationship between inequality and mass protests; studies on the role of mass mobilization in generating regime change; pathways other than mass mobilization through which inequality might affect democratization; studies of the role of international sanctions on the likelihood that autocracies will democratize; and studies of the effects of democratization on other things, such as growth or the distribution of resources.</p>
<p>We can think of these studies as each analyzing data on a particular part of a broader, more encompassing causal model. In an informal way, <em>if</em> findings “hold together” in a reasonably intuitive way, we might be able to piece together an impression of the overall relations among variables in this domain. Yet an informal approach becomes more difficult for complex models or data patterns and, more importantly, will leave opportunities for learning unexaploited.</p>
<p>Consider this simple DAG, in which both <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> are causes of <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Z\)</span> also causes <span class="math inline">\(K\)</span>. Now imagine three studies, all conducted in contexts in which we believe this model to hold:</p>
<p><img src="ii_files/figure-html/jigsaw-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li>Study 1 is an RCT in which <span class="math inline">\(X\)</span> is randomized, with data collected on both <span class="math inline">\(Y\)</span> and <span class="math inline">\(K\)</span>. <span class="math inline">\(K\)</span> is collected. <span class="math inline">\(Z\)</span> is not observed.</li>
<li>Study 2 is a factorial experiment, in which <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> are independently randomized, allowing an examination of the joint effects of <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span>. <span class="math inline">\(K\)</span> is not observed.</li>
<li>Study 3 is an experiment randomizing <span class="math inline">\(Z\)</span>, with only <span class="math inline">\(K\)</span> observed as an outcome. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not observed.</li>
</ol>
<p>Now, let’s say that our primary interest is in the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Obviously, Study 1 will, with a sufficiently large sample, perform just fine in estimaing the average treatment effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. However, what if we are interested in a case-oriented query, such as the probability of causation: the probability, say, <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> in a given <span class="math inline">\(X=1, Y=1\)</span> case?</p>
<p>We know that within-case, process-tracing clues can sometimes provide probative value on case-level estimands like the probability of causation, and we have observed <span class="math inline">\(K\)</span> in the Study 3 cases. So what if we combine the <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K\)</span> data?</p>
<!-- AJ: Suggest we flip the study ordering to the X-Y experiment is STudy 1. Makes a more natural progression with the prose. -->
<p>A simple analysis of the graph tells us that <span class="math inline">\(K\)</span> cannot help us learn about <span class="math inline">\(Y\)</span>’s potential outcomes since <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(Z\)</span>, and we have not observed <span class="math inline">\(Z\)</span> in Study 3. We see this confirmed in Table <a href="mm.html#tab:frank1">10.1</a>.</p>
<p>In the first pair of rows, we show the results of analyses in which we have simulated data from the whole model, then updated using the Study 1 observations. We give here the posterior mean on the probability of causation for an <span class="math inline">\(X=Y=1\)</span> case, conditional on each possible value that <span class="math inline">\(K\)</span> might take on. As we can see, our beliefs about the estimand remain unaffected by <span class="math inline">\(K\)</span>’s value, meaning that it contains no information about <span class="math inline">\(X\)</span>’s effect in the case.</p>
<!-- AJ: When we say data on K is not available in S1, do we mean we haven't used K to *update* the model? But we are then simulating what would we would infer if we *did* collect $K$ for a case in S1? This is my read of the code. Or have I misread? Are we imagining a situation in which we simply don't have K at all, so by definition can't learn from K? I've written the text below on the first assumption, so will need changing if that's wrong. -->
<p>We see that the same thing is true for each of the other studies. In study 2, we have not used <span class="math inline">\(K\)</span> to update the model, and so have not learned anything form the data about <span class="math inline">\(K\)</span>’s relationship to the other variables. Thus, we have no foundation on which to ground probative value fo <span class="math inline">\(K\)</span>. In study 3, we understand the <span class="math inline">\(Z,K\)</span> relationship well, but know nothing quantitatively about how <span class="math inline">\(Z\)</span> and <span class="math inline">\(X\)</span> relate to <span class="math inline">\(Y\)</span>. Thus, we have learned nothing from Study 3 about what observing <span class="math inline">\(K\)</span> might tell us about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<table>
<caption><span id="tab:frank1">Table 10.1: </span>The clue <span class="math inline">\(K\)</span> uninformative in all three studies</caption>
<thead>
<tr class="header">
<th align="right">Study</th>
<th align="left">Given</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.652</td>
<td align="right">0.107</td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.640</td>
<td align="right">0.108</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.645</td>
<td align="right">0.138</td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.645</td>
<td align="right">0.137</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.499</td>
<td align="right">0.150</td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.499</td>
<td align="right">0.134</td>
</tr>
</tbody>
</table>
<p>We can do much better, however, if we combine the data and update <em>jointly</em> across all model paramaters. The results are shown in Table <a href="mm.html#tab:frank4">10.2</a>. Updating simultaneously across the studies allows us, in a sense, to bridge across inferences. In particular, inferences from Study 2 make <span class="math inline">\(Z\)</span> informative about <span class="math inline">\(Y\)</span>’s potential outcomes under different values of <span class="math inline">\(X\)</span>. Meanwhile, inferences from the data in Study 3 allow us to use information on <span class="math inline">\(K\)</span> to update on values for <span class="math inline">\(Z\)</span>. As we now see in rows 1 and 2, having updated the model in an integrated fashion, <span class="math inline">\(K\)</span> now <em>is</em> informative about the probability of causation, with our posterior mean on this query changing substantially depending on the value of <span class="math inline">\(K\)</span> that we observe in a case.</p>
<p>Rows 3-4 highlight that the updating works through inferences on <span class="math inline">\(Z\)</span>: we see that if <span class="math inline">\(Z\)</span> is already known (we show this for <span class="math inline">\(Z=1\)</span>, but it holds for <span class="math inline">\(Z=0\)</span> as well), then there are no additional gains from knowledge of <span class="math inline">\(K\)</span>.</p>
<table>
<caption><span id="tab:frank4">Table 10.2: </span>Clue is informative after combining studies linking <span class="math inline">\(K\)</span> to <span class="math inline">\(Z\)</span> and <span class="math inline">\(Z\)</span> to <span class="math inline">\(Y\)</span></caption>
<thead>
<tr class="header">
<th align="left">Given</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.79</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.62</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1 &amp; Z == 1</td>
<td align="right">0.84</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0 &amp; Z == 1</td>
<td align="right">0.84</td>
<td align="right">0.08</td>
</tr>
</tbody>
</table>
<!-- In sum, the collection of studies collectively provides a justification for learning from $K$ when assessing a case level effect of $X$ on $Z$ in study 1.  -->
<!-- AJ: Is something wrong with the study numberings in this next paragraph? -->
<!-- I find the reference to justifying a model confusing here. It's not going to be self-evident to readers how that's what we've just done. It seems like we've *started* with a model and used it. But I'm not 100% clear on what you want to say here. Can you clarify? -->
<p>We devote Chapter 15 to a discussion of how we justify a model. However, we note already that in this example we have an instance in which a researcher (examining a case in study 3) might wish to draw inferences using <span class="math inline">\(K\)</span>, but she does not have anything in study 1 that justifies using <span class="math inline">\(K\)</span> for inference. However with access to studies 2 and 3, and conditional on the overall model, she has a justification for process tracing strategy. The general principle is that weaker commitments to lower level theories —here the causal structure—can justify more fully inferences from more fully specified higher-level theories.</p>
<!-- AJ: Also finding the last sentence above confusing. -->
</div>
<div id="combining-observational-and-experimental-data" class="section level2">
<h2><span class="header-section-number">10.2</span> Combining observational and experimental data</h2>
<p>Experimental studies are often understood as the “gold standard” for causal inference. This is, in particular, because of the ability of a randomized trial (given certain assumptions, such as “no spillovers”) to eliminate sources of confounding. By design, an experiment removes from the situation processes that, in nature, would generate a correlation between selection into treatment and potential outcomes. An experiment thereby allows for an unbiased estimate of the average causal effect of the treatment on the outcome.</p>
<p>At the same time, an interesting weakness of experimental studies is that, by dealing so effectively with selection into treatment, they limit our ability to learn about selection and its implications in the real world. Often, however, we want to know what causal effects would be specifically for units that <em>would</em> in fact take up a treatment in a real-world, non-experimental settings. This kind of problem is studied for example by <span class="citation">Knox et al. (<a href="#ref-knox2019design" role="doc-biblioref">2019</a>)</span>.</p>
<p>Consider, for instance, a policy that would make schooling subsidies available to parents, with the aim of improving educational outcomes for children. How would we know if the policy was effective? A source of confounding in an observational setting might be that those parents who apply for and take up the subsidy might also be those who are investing more in their children’s education in other ways as compared to those parents who do not apply for the subsidy. To eliminate this problem, we might design an experiment in which parents are randomly assigned to receive (or not receive) the subsidy and compare outcomes between children in the treatment and control groups. With a no-spillovers assumption, we can extract the <span class="math inline">\(ATE\)</span> of the receipt of subsidies.</p>
<p>What this experiment cannot tell us, however, is how much the policy will boost educational outcomes outside the experiment. That is because the causal quantity of interest, for answering that question, is <em>not</em> the <span class="math inline">\(ATE\)</span>: it is the average treatment effect for the <em>treated</em> (<span class="math inline">\(ATT\)</span>), given real-world selection effects. That is, the policymaker wants to know what the effect of the subsidy will be for the children of parents who <em>select into</em> treatment. One could imagine the real-world <span class="math inline">\(ATT\)</span> being higher than the <span class="math inline">\(ATE\)</span> if, for instance, those parents who are informed and interested enough to take up the subsidy also put the subsidy to more effective use. One could also imagine the <span class="math inline">\(ATT\)</span> being lower than the <span class="math inline">\(ATE\)</span> is, for instance, there are diminishing marginal returns to educational investments and the self-selecting parents are already investing quite a lot.</p>
<p>Even outside a policy context, we may be interested in the effect of a causal condition <em>where</em> that causal condition emerges. To return to our inequality and democracy example, we may want to know what would have happened to autocracies with low inequality <em>if</em> they had had high inequality – the standard average-treatment effect question. But we might also be interested in knowing how much of a difference high inequality makes <em>in the kinds of cases</em> where high inequality tends to be occur – where the effect could be very different.</p>
<p>With such questions, we are in a sort of bind. The experiment cannot tell us <em>who</em> would naturally select into treatment and what the effects would be for them. Yet an observational study faces the challenge of ruling out confounding. Ideally, we would like to be able to combine the best features of both: use an experiment to deal with confounding and use observational data to learn about those whom nature assigns to treatment.</p>
<p>We can achieve this form of integration with a causal model. We do so by creating a model in which random assignment is nested within a broader set of assignment processes. We plot the model in Figure <a href="mm.html#fig:appcombexpob">10.1</a></p>
<p>At the substantive core of this model is the <span class="math inline">\(X \rightarrow Y\)</span> relationship. However, we give <span class="math inline">\(X\)</span> a parent that is fully exogenous, <span class="math inline">\(Z\)</span>, to capture a random-assignment process. We give <span class="math inline">\(X\)</span> a second parent, <span class="math inline">\(O\)</span>, that is confounded with <span class="math inline">\(Y\)</span>: <span class="math inline">\(O\)</span> here represents the observational scenario. Finally, we include a “switch” variable, <span class="math inline">\(R\)</span>, that determines whether <span class="math inline">\(X\)</span> is randomly assigned or not. So when <span class="math inline">\(R=1\)</span>, <span class="math inline">\(X\)</span> is determined solely by <span class="math inline">\(Z\)</span>, with <span class="math inline">\(X=Z\)</span>. When <span class="math inline">\(R=0\)</span>, we are in an observational setting, and <span class="math inline">\(X\)</span> is determined solely by the confounded <span class="math inline">\(O\)</span>, with <span class="math inline">\(X=O\)</span>.</p>
<p>A few notes on the parameter space. Parameters allow for complete confounding between <span class="math inline">\(O\)</span> and <span class="math inline">\(Y\)</span>, but <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span> are unconfounded. <span class="math inline">\(X\)</span> has only one causal type since its job is to operate as a conveyor belt, simply inheriting the value of <span class="math inline">\(Z\)</span> or <span class="math inline">\(O\)</span>, depending on <span class="math inline">\(R\)</span>.</p>
<p>Note also that this model assumes the exclusion restriction that entering the experimental sample (<span class="math inline">\(R\)</span>) is not related to <span class="math inline">\(Y\)</span> other than through assignment of <span class="math inline">\(X\)</span>.</p>
<div class="figure"><span id="fig:appcombexpob"></span>
<img src="ii_files/figure-html/appcombexpob-1.png" alt="A model that nests an observational and an experimental study. The treatment $X$ either takes on the observational value $O$, or the assigned values $Z$, depending on whether or not the case has been randomized, $R$." width="672" />
<p class="caption">
Figure 10.1: A model that nests an observational and an experimental study. The treatment <span class="math inline">\(X\)</span> either takes on the observational value <span class="math inline">\(O\)</span>, or the assigned values <span class="math inline">\(Z\)</span>, depending on whether or not the case has been randomized, <span class="math inline">\(R\)</span>.
</p>
</div>
<p>Now, let us imagine true parameter values such that <span class="math inline">\(X\)</span> has a <span class="math inline">\(0.2\)</span> average effect on <span class="math inline">\(Y\)</span>. However, the effect is different for those who are selected into treatment in an observational setting: it is positive (<span class="math inline">\(0.6\)</span>) for cases in which <span class="math inline">\(X=1\)</span> under observational assignment, but negative (<span class="math inline">\(-0.2\)</span>) for cases in which <span class="math inline">\(X=0\)</span> under observational assignment. (See appendix for complete specification.)</p>
<p>When we use the model to analyze the data, we will start with flat priors on the causal types.</p>
<p>The implied true values for the estimands of interest, and our priors on those estimands, are displayed in Table <a href="mm.html#tab:fusionestimands">10.3</a>.</p>
<!-- AJ: I think the talk of parameters and priors is less intuitive than it could be in a table and passage like this, though I realize it maps onto CQ argument names. By "parameters" we mean *true* values in the simulation, right? Can we convert to "truth" in the "Using" column? Truth vs. priors seems nicely intuitive. -->
<table>
<caption><span id="tab:fusionestimands">Table 10.3: </span>Estimands in different sites</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">parameters</td>
<td align="right">0.2</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">0.0</td>
<td align="right">0.26</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">R==0</td>
<td align="left">parameters</td>
<td align="right">0.2</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">R==0</td>
<td align="left">priors</td>
<td align="right">0.0</td>
<td align="right">0.26</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">R==1</td>
<td align="left">parameters</td>
<td align="right">0.2</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">R==1</td>
<td align="left">priors</td>
<td align="right">0.0</td>
<td align="right">0.26</td>
</tr>
</tbody>
</table>
<p>Now, we generate data from the model, using the posited “true” parameter values, and then update the model using these data.</p>
<p>We begin by analyzing just the observational data (cases where <span class="math inline">\(R=0\)</span>) and display the results in Table <a href="mm.html#tab:fusiondim">10.4</a>. Recall that the true average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is <span class="math inline">\(0.2\)</span>. Naive analysis of the observational data, taking a simple difference in means between the <span class="math inline">\(X=0\)</span> and <span class="math inline">\(X=1\)</span> cases, yields a strongly upwardly biased estimate of that effect, of 0.0806.</p>
<table>
<caption><span id="tab:fusiondim">Table 10.4: </span>Inferences on the ATE from differences in means</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
<th align="right">CI Lower</th>
<th align="right">CI Upper</th>
<th align="right">DF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X</td>
<td align="right">0.816</td>
<td align="right">0.028</td>
<td align="right">28.93</td>
<td align="right">0</td>
<td align="right">0.76</td>
<td align="right">0.871</td>
<td align="right">189</td>
</tr>
</tbody>
</table>
<p>In contrast, when we use CausalQueries to update on the full causal model and use both the experimental and observational data, we get the much more accurate results shown in Table <a href="mm.html#tab:fusionCQ">10.5</a>. Moving down the rows, we show here the estimate of the unconditional <span class="math inline">\(ATE\)</span>, the estimate for the observational context (<span class="math inline">\(R=0\)</span>), and the estimate for the experimental context (<span class="math inline">\(R=1\)</span>). Unsurprisingly, the estimates are identical across all three settings since, in the model, <span class="math inline">\(R\)</span> is <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(Y\)</span> by <span class="math inline">\(X\)</span>, which is observed. And, as we see, the posterior means are very close to the right answer of <span class="math inline">\(0.2\)</span>.</p>
<table>
<caption><span id="tab:fusionCQ">Table 10.5: </span>Estimates on the ATE for observational (<span class="math inline">\(R=0\)</span>) and experimental (<span class="math inline">\(R=1\)</span>) set.</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.203</td>
<td align="right">0.031</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">R==0</td>
<td align="left">posteriors</td>
<td align="right">0.203</td>
<td align="right">0.031</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">R==1</td>
<td align="left">posteriors</td>
<td align="right">0.203</td>
<td align="right">0.031</td>
</tr>
</tbody>
</table>
<p>Since the model used both the experimental and the observational data, we might wonder from where the leverage derived: did the observational data improve our estimates of the average treatment effect, or do our inferences emerge strictly from the experimental data? In the appendix, we show results when we updating using experimental data only.
Comparing the two sets of results, we find there that we do indeed get a tightening of posterior variance and a more accurate result when we use both the observational and experimental data, but the experimental data alone are quite powerful, as we should expect for an estimate of the <span class="math inline">\(ATE\)</span>. The observational data do not add a great deal to an <span class="math inline">\(ATE\)</span> estimate, and the gains from observational data would be smaller still (and the experimental results even more accurate) if the experimental sample were larger.</p>
<!-- FLAG: Need to create above table in appendix -->
<p>However, what we can learn about uniquely from this model and the combined observational and experimental data is <em>heterogeneity</em> in effects between those that are in treatment and those that are in control <em>in the observational</em> setting. In Table <a href="#combexpobsattatc"><strong>??</strong></a>, we display the results of <span class="math inline">\(ATT\)</span> and <span class="math inline">\(ATC\)</span> queries of the updated model. In the first two rows, we see that, in the experimental setting, the average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is the same on both the treated and control groups, exactly as we would expect under random assignment. In the third row, we see the estimate of <span class="math inline">\(X\)</span>’s average effect for those assigned “by nature” to the control group in the observational setting, extracting a result close to the “true” value of <span class="math inline">\(-0.2\)</span>. The final row shows our estimate of the treatment effect for those who are selected into treatment in the observational setting, again getting close to the answer implied by the underlying data-generating process (<span class="math inline">\(0.6\)</span>).</p>
<table>
<caption><span id="tab:combexpobsattatc">Table 10.6: </span>Effects of <span class="math inline">\(X\)</span> conditional on <span class="math inline">\(X\)</span> for units that were randomly assigned or not. Effects of <span class="math inline">\(X\)</span> do not depend on <span class="math inline">\(X\)</span> in the experimental group, but they do in the observational group becuase of seld selection.</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">R==1 &amp; X==0</td>
<td align="left">posteriors</td>
<td align="right">0.203</td>
<td align="right">0.031</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">R==1 &amp; X==1</td>
<td align="left">posteriors</td>
<td align="right">0.203</td>
<td align="right">0.031</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">R==0 &amp; X==0</td>
<td align="left">posteriors</td>
<td align="right">-0.183</td>
<td align="right">0.027</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">R==0 &amp; X==1</td>
<td align="left">posteriors</td>
<td align="right">0.593</td>
<td align="right">0.048</td>
</tr>
</tbody>
</table>
<p>We can learn nothing about the observational <span class="math inline">\(ATT\)</span> or <span class="math inline">\(ATC\)</span> from the experimental data alone, where there <span class="math inline">\(ATT\)</span> and <span class="math inline">\(ATC\)</span> are the same quantity. And in the observational data alone, we are hobbled by confounding of unknown direction and size. What the mixed model and data, in effect, are able to do is (a) learn about the <span class="math inline">\(ATE\)</span> experimental data, (b) use inferences on the <span class="math inline">\(ATE\)</span> to separate true effects from confounding in the observational data and thus learn about the direction and size of the confounding in those data, and (c) estimate the treatment effect for the <span class="math inline">\(X=0\)</span> group and for the <span class="math inline">\(X=1\)</span> group, respectively, in the observational data <em>using</em> knowledge about confounding in these data. By mixing the experimental and observational data, we can learn about how the treatment has affected those units that, in the “real” world of the observational setting, selected into treatment <em>and</em> about how the treatment <em>would</em> affect those that selected into control.</p>
<p>The numbers in our toy example, while purely notional, can help us see why the observational <span class="math inline">\(ATT\)</span> and <span class="math inline">\(ATC\)</span> might be of great interest to decision makers where strong causal heterogeneity is a possibility. Based on the experimental data alone, we might conclude that the policy that makes <span class="math inline">\(X=1\)</span> available is a good bet, given its positive <span class="math inline">\(ATE\)</span> (assuming, of course, that <span class="math inline">\(Y=1\)</span> is a valued outcome). And, of course, the observational data alone would not allow us to confidently conclude otherwise. What the integrated analysis reveals, however, is that <span class="math inline">\(X\)</span> in fact has a <em>negative</em> mean effect on those who would be most likely to take up the treatment. The strong positive effect for the control strongly shapes the experimental results but will go unrealized in the real world.
In a similar vein, these estimates can aid causal explanation. Seeing the positive <span class="math inline">\(ATE\)</span> might lead us to infer that most of the <span class="math inline">\(X=1, Y=1\)</span> cases we observe in the world are ones in which <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. The observational <span class="math inline">\(ATT\)</span> estimates point in a very different direction, however, indicating that these are cases in which <span class="math inline">\(X\)</span> is least likely to have a positive effect and, thus, where <span class="math inline">\(Y=1\)</span> was most likely generated by some other cause.</p>
<p>We note that the results here relate to the LATE theorem <span class="citation">(Angrist and Imbens <a href="#ref-angrist1995identification" role="doc-biblioref">1995</a>)</span>. Imagine using data only on (a) the experimental group in control and (b) the observational group, some of whom are in treatment. We can conceptualize our design as one in which the observational group are “encouraged” to take up treatment, allowing us to estimate the effect for the “compliers” in the observational setting: those that self-select into treatment. Conversely, we could use data only on (a) the experimental group in treatment and (b) the observational group, some of whom are in control. This is a design in which the observational group are “encouraged” to take the control condition, allowing us to estimate the effect for the “compliers” in this group (those that self select into control).</p>
<!-- AJ: Can't we instead frame the second estimate as the estimate for the never takers? -->
</div>
<div id="transportation-of-findings-across-contexts" class="section level2">
<h2><span class="header-section-number">10.3</span> Transportation of findings across contexts</h2>
<p>In some circumstances, we study the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in one context (a country, region, or time period, for instance) and then want to make inferences about these effects in another context (say, another country, region, or time period). We may face the challenge that effects are heterogeneous, and that conditions that vary across contexts may be related to treatment assignment, to outcomes, and to selection into the sample. For example, we might study the relationship between inequality and democratization in low-income countries and then want to know how those effects travel to middle-income settings. However, the level of income may have implications jointly for the level of inequality and for how likely inequality is to generate regime change, meaning that causal effects uncovered in the first context cannot be assumed to operate in the second context.</p>
<p>This is the problem studied by <span class="citation">Pearl and Bareinboim (<a href="#ref-pearl2014external" role="doc-biblioref">2014</a>)</span>. In particular, <span class="citation">Pearl and Bareinboim (<a href="#ref-pearl2014external" role="doc-biblioref">2014</a>)</span> show for which nodes data are needed in order to “licence” external claims, given a model.</p>
<p>We illustrate with a simple model in which an observable confounder has a different distribution across contexts. In the model drawn in Figure <a href="#extval"><strong>??</strong></a>, <span class="math inline">\(Context\)</span> determines the distribution of the confounder, <span class="math inline">\(W\)</span>. We set a restriction such that the value of <span class="math inline">\(W\)</span> in Context 1 is never less than the value of <span class="math inline">\(W\)</span> in Context 0; our priors are otherwise flat over the remaining nodal types in the model.</p>
<!-- AJ: Macartan, can you interpret the parameter values for the sentence above? Not sure I know how to read the complements and decreasing statements correctly. -->
<!-- AJ: Note I've changed Case to Context everwhere, which I think is better ,more general. -->
<div class="figure"><span id="fig:extval"></span>
<img src="ii_files/figure-html/extval-1.png" alt="Extrapolation when confounders have different distributions across cases." width="672" />
<p class="caption">
Figure 10.2: Extrapolation when confounders have different distributions across cases.
</p>
</div>
<table>
<caption><span id="tab:appev2">Table 10.7: </span>Priors and true values (parameters) for three estimand: the frequency of <span class="math inline">\(W\)</span>, the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, and the effect conditional on <span class="math inline">\(W=1\)</span></caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">priors</td>
<td align="right">0.334</td>
<td align="right">0.237</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">priors</td>
<td align="right">0.666</td>
<td align="right">0.238</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.667</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">priors</td>
<td align="right">0.002</td>
<td align="right">0.140</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">priors</td>
<td align="right">0.003</td>
<td align="right">0.142</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.573</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">priors</td>
<td align="right">0.002</td>
<td align="right">0.174</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">priors</td>
<td align="right">0.002</td>
<td align="right">0.174</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<!-- AJ: Incidence is a confusing label. Can we make Incidence_W or something like that? -->
<p>We show priors and true values for the estimands (drawn from the parameters) in Table <a href="mm.html#tab:appev2">10.7</a>. We see that the incidence of <span class="math inline">\(W=1\)</span> is higher in Context 1 than in Context 0, both in our priors and in the “truth” posited by the assigned parameter values. The “true” <span class="math inline">\(ATE\)</span> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is also higher in Context 1, though this is not reflected in our priors. The average treatment effect conditional on <span class="math inline">\(W\)</span> is the same in both contexts, whether we work from priors or assigned parameter values, as it must be given the model. That is, in this model the <span class="math inline">\(ATE\)</span> varies conditional on <span class="math inline">\(W\)</span> — and it varies conditional <em>only</em> on <span class="math inline">\(W\)</span>.</p>
<!-- incidence in as well as the ATE of $X$ on $Y$ is larger in case 1 than in case 0 (in parameters, though not in priors). However the effect of $X$ on $Y$ conditional on $W$ is the same in both places.  -->
<p>We now update the model using data from one context and then see if we can transport those findings to the other context. Specifically, we update using data on <span class="math inline">\(X, Y,\)</span> and <span class="math inline">\(W\)</span> from Context 0. We then use the updated beliefs to draw inferences about Context 1, using data <em>only</em> on <span class="math inline">\(W\)</span> from Context 1. In Table <a href="#appev3"><strong>??</strong></a>, we show our posteriors on the queries of interest as compared to the truth, given the parameter values.</p>
<table>
<caption><span id="tab:appev3">Table 10.8: </span>Extrapolation when two sites differ on <span class="math inline">\(W\)</span> and <span class="math inline">\(W\)</span> is observable in both contexts</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.336</td>
<td align="right">0.007</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.661</td>
<td align="right">0.007</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.667</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.340</td>
<td align="right">0.011</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.570</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.573</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.810</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.810</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<!-- AJ: Not sure we need the Incidence and CATE rows for this table. -->
<p>By comparing the <span class="math inline">\(ATE\)</span> estimates using our posteriors and the estimates using the assigned parameter values, we see that we have done well in recovering the effects, <em>both</em> for the context we studied (i.e., in which we observed <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>) and for the context we did not study. We can think of the learning here as akin to post-stratification. We have learned from observing <span class="math inline">\(X, Y\)</span>, and <span class="math inline">\(W\)</span> in Context 0 how <span class="math inline">\(X\)</span>’s effect depends on <span class="math inline">\(W\)</span>. Then we use those updated beliefs when confronted with a new value of <span class="math inline">\(W\)</span> in Context 1 to form a belief about <span class="math inline">\(X\)</span>’s effect in this second context. Of course, getting the right answer from this procedure depends, as always, on starting with the correct model.</p>
<p>We can also see, in Table <a href="#appev4"><strong>??</strong></a>, what would have happened if we had attempted to make the extrapolation to Context 1 without data on <span class="math inline">\(W\)</span> in that context. We would get the wrong answer for Context 1, though we would also report greater posterior variance. The higher posterior variance here captures the fact that we know things could be different in Context 1, but we don’t know in what way they are different.</p>
<!-- AJ: This last set of results seems wrong. The estimates using posteriors seem again to be very close to those using parameters, and variances are not higher than in previous table. Seems we're still using info on W in code below?  -->
<!-- Note that we get the CATE right since in the model this is assumed to be the same across cases. -->
<table>
<caption><span id="tab:appev4">Table 10.9: </span>Extrapolation when two contexts differ on <span class="math inline">\(W\)</span> and <span class="math inline">\(W\)</span> is not observable in target context</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.329</td>
<td align="right">0.007</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.675</td>
<td align="right">0.007</td>
</tr>
<tr class="even">
<td align="left">Incidence</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.667</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.319</td>
<td align="right">0.011</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.333</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.572</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.573</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">posteriors</td>
<td align="right">0.811</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==0</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">posteriors</td>
<td align="right">0.811</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">CATE</td>
<td align="left">Case==1</td>
<td align="left">parameters</td>
<td align="right">0.812</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<!-- FLAG: ADD  A SITUATION WITH AN ARROW FROM Case to Y and WHO THAT WE DO NOT HAVE IDENTIFICATION -->
</div>
<div id="multilevel-models-meta-analysis" class="section level2">
<h2><span class="header-section-number">10.4</span> Multilevel models, meta-analysis</h2>
<!-- AJ: Need a better section heading. If we have a good name for this approach, we can also use this when we make comparisons across approaches in next section. -->
<!-- AJ: Transition here needs some work, I think.  -->
<p>A key idea in Bayesian meta-analysis is that when you analyze multiple studies together you learn not only about common processes that give rise to the different results seen in different sites, but you also learn more about each study from seeing the other studies.</p>
<p>A classic setup is provided in GELMAN, which we have access to estimates of effects and uncertainty in eight sites (schools), <span class="math inline">\((b_j, se_j)_{j \in \{1,2,\dots,8\}}\)</span>. We assume that each <span class="math inline">\(b_j\)</span> is a draw from distribution <span class="math inline">\(N(\beta_j, se_j)\)</span> and that each <span class="math inline">\(\beta_j\)</span> is a draw from distribution <span class="math inline">\(N(\beta, \sigma)\)</span>. In that setup we want to learn not just about the superpopulation parameters <span class="math inline">\(\beta, \sigma\)</span>, but also about the study level effects <span class="math inline">\((\beta_j)_{j \in \{1,2,\dots,8\}}\)</span>.</p>
<!-- AJ: Not clear to me that Gelman here is the right way to set up the analysis in this subsection. Doesn't Gelman's setup work more like our setup in the next section, with settings treated as being drawn stochastically from a common distribution at the superpop level? -->
<p>We define a model in which <span class="math inline">\(X\)</span> points into <span class="math inline">\(Y\)</span>, and in which <span class="math inline">\(Setting\)</span> is a third node that also points into <span class="math inline">\(Y\)</span>. Thus <span class="math inline">\(Setting\)</span> can potentially moderate the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. We observe an experiment that takes place in <span class="math inline">\(Setting\)</span> 0 and also in <span class="math inline">\(Setting\)</span> 1. Note that, in this setup, any differences in the distribution of effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> between the two settings can <em>only</em> arise because of <span class="math inline">\(Setting\)</span>. That is, we are here assuming the same causal effects across settings conditional on <span class="math inline">\(Setting\)</span> itself.</p>
<p>We then consider the different conclusions we draw for the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in each setting, depending on whether we pool data across settings and on our priors over how much <span class="math inline">\(Setting\)</span> matters for <span class="math inline">\(X\)</span>’s effects.</p>
<p>We design the simulation so that in <span class="math inline">\(X\)</span>’s true causal effect is stronger in <span class="math inline">\(Setting\)</span> 0 than in <span class="math inline">\(Setting\)</span> 1. We then generate data from these true parameters for each setting, 100 cases for each, and run the analysis in different ways, with results displayed in Table <a href="#settingmatters"><strong>??</strong></a>. In the first two rows, we show <span class="math inline">\(ATE\)</span> posteriors from separate analyses of the data for each setting. We see that we recover an <span class="math inline">\(ATE\)</span> that is higher in <span class="math inline">\(Setting 0\)</span> than in <span class="math inline">\(Setting 1\)</span>, as expected.</p>
<p>In the third row (Integrated flat priors), we use data from both settings to estimate an overall <span class="math inline">\(ATE\)</span>. Moreover, we put equal weight on all possible <span class="math inline">\(Y\)</span> types, i.e., on all possible joint effects of <span class="math inline">\(X\)</span> and <span class="math inline">\(Setting\)</span>, meaning that we provide substantial scope for <span class="math inline">\(Setting\)</span> to moderate <span class="math inline">\(X\)</span>’s effects. As expected, the <span class="math inline">\(ATE\)</span> looking across both settings lies between the <span class="math inline">\(ATE\)</span> for each in the unpooled analyses.</p>
<!-- AJ: Why is the ATE in "Integrated, flat priors" not more centered between the ATE in the first two rows? It's much lower than I'd have expected. Does allowing interactions pull the ATE down in some way? -->
<p>In rows 4 and 5, we then estimate the <span class="math inline">\(ATE\)</span> in each setting separately, again using flat priors that allow for substantial interactions with setting. Differently from the first two rows, however, we are using data from both settings in estimating effects for each setting. Consider what happens we estimate the <span class="math inline">\(ATE\)</span> for <span class="math inline">\(Setting\)</span> 0: we are using our posterior over <span class="math inline">\(Y\)</span>’s nodal type shares to answer this query. Of course, data from <span class="math inline">\(Setting\)</span> 0 itself provides what we might think of as the most context-<em>specific</em> information about the causal effect in that particular setitng. But data from <span class="math inline">\(Setting\)</span> 1, where we also observe <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values, <em>also</em> provides information about those shares, and this additional information drawn from <span class="math inline">\(Setting\)</span> 1 is reflected in the integrated estimate for <span class="math inline">\(Setting\)</span> 0 – and vice versa for the integrated <span class="math inline">\(Setting\)</span> 1 estimate. With the pooling of data, we see that the <span class="math inline">\(ATE\)</span> for each setting…. Also note that the standard deviation of the posterior has shrunk, reflecting the fact that we have brought more data to bear on the question.</p>
<!-- AJ: I don't know how to finish the above sentence because I don't get the lack of convergence -- the lower ATE for Setting 1. Especially since we *do* get the expected convergence with weak interactions priors. -->
<p>Finally, in the last three rows, we set priors such that the moderating effect of <span class="math inline">\(Setting\)</span> is believed to be weak. Here we see that the <span class="math inline">\(ATE\)</span>’s for the two settings converge more strongly, reflecting the influence of our low-heterogeneity priors. Moreover, our uncertainty shrinks further here, reflecting the fact that – if we believe that heterogeneity across settings is low – then we also believe that data from one setting is <em>more</em> informative about the other setting: i.e., we get a bigger boost in statistical power from the pooling under these priors.</p>
<!-- AJ: Why is the overall $ATE$ higher here than with flat priors? Must be that the interactions themselves depress the ATE. Less interaction then means higher ATE?? -->
<table>
<caption><span id="tab:settingmatters">Table 10.10: </span>Inferences from separate analyses and from integrated analysis (meta analysis) given (a) flat priors and (b) expectation of similar effects across studies</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Setting 0</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.43</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td align="left">Setting 1</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.20</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td align="left">Integrated (flat priors)</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.26</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td align="left">Integrated (flat priors)</td>
<td align="left">Setting==0</td>
<td align="left">posteriors</td>
<td align="right">0.36</td>
<td align="right">0.08</td>
</tr>
<tr class="odd">
<td align="left">Integrated (flat priors)</td>
<td align="left">Setting==1</td>
<td align="left">posteriors</td>
<td align="right">0.17</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td align="left">Integrated (weak heterogeneity)</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.29</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td align="left">Integrated (weak heterogeneity)</td>
<td align="left">Setting==0</td>
<td align="left">posteriors</td>
<td align="right">0.32</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td align="left">Integrated (weak heterogeneity)</td>
<td align="left">Setting==1</td>
<td align="left">posteriors</td>
<td align="right">0.26</td>
<td align="right">0.08</td>
</tr>
</tbody>
</table>
<!-- We see in both cases a drop in our estimates for effects in Setting 1 in both cases, relative to the single study case. Where weak heterogeneity is assumed we also see a rise in estimates for Setting 2.  -->
<p>Further, we can use these same updated models to update specifically on the amount of heterogeneity across settings. We operationalize heterogeneity here as the share of units that <em>would</em> respond differently to <span class="math inline">\(X\)</span> if they were in a different setting. In Table XXXX, we compare our prior on this quantity to our posterior. Where we started out with flat priors — allowing for a great deal of heterogeneity — we see that the data bring these beliefs downward. This makes sense given that, under the true data-generating process, the effects in the two settings are only moderately different. Conversely, where we start with a very low prior on heterogeneity, the data lead us to believe there is <em>more</em> heterogeneity than we had initially believed (though, given the strength of the prior that we have used in this example, we can still see its formidable efect on the posterior).</p>
<table>
<caption><span id="tab:unnamed-chunk-12">Table 10.11: </span>Interaction | Flat priors</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">0.628</td>
<td align="right">0.119</td>
</tr>
<tr class="even">
<td align="left">Q 1</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.588</td>
<td align="right">0.122</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-12">Table 10.11: </span>Interaction | Expected homogeneity</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">0.077</td>
<td align="right">0.072</td>
</tr>
<tr class="even">
<td align="left">Q 1</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="right">0.087</td>
<td align="right">0.074</td>
</tr>
</tbody>
</table>
</div>
<div id="real-multilevel" class="section level2">
<h2><span class="header-section-number">10.5</span> Real multilevel</h2>
<!-- AJ: Need a better section heading -->
<p>In the situations we have considered so far, we are learning from and about the particular contexts that we are studying. We are combining experimental data from one setting, for instance, with observational data from another. Or we are using updating from one context to draw an inference about another setting. Our inferences in these setups are limited strictly to the settings at hand, however.</p>
<p>We can take a step further by building a hierarchical model. A hierarchical model allows us to think about the populations in our study sites as themselves drawn from a larger population (“superpopulation”) of settings. And, crucially, it allows us in turn to use data in the study sites to learn about that broader superpopulation of settings.</p>
<!-- AJ: Is "superpopulation" right here and below? -->
<p>For instance, we might be studying the effect of an individual’s relative location in the income scale on their preferences for democracy. We might collect data in a set of 10 countries and estimate the average causal effect of relative income in each of them. We can readily average inferences across these countries or study country-level moderators of the effect to explain differences in effects across the 10 countries. Yet these data from the 10 countries also contain information of a more general sort: they tell us something about the “superpopulation” of settings from which these 10 countries have been “drawn.”</p>
<p>Let’s review how our analytic setup has worked so far. At each node in a causal model, we conceptualize a given case as have a particular nodal type. The case’s nodal type is drawn from a distribution of nodal types in the population of cases from which this case has been drawn. When we do process tracing, we consider that population-level distribution to be a set of fixed shares of nodal types in the population: say, for node <span class="math inline">\(Y\)</span>, we might believe that half the cases in the population are <span class="math inline">\(\lambda^Y_{01}\)</span>, a quarter are <span class="math inline">\(\lambda^Y_{00}\)</span>, and a quarter are <span class="math inline">\(\lambda^Y_{11}\)</span>. We then use data from the case to update on the case’s nodal types (or on the combination of nodal types that correspond to some case-level query), given the population-level shares.</p>
<p>When we engage in population-level inference, we begin with <em>uncertainty</em> about the population-level shares of types, and we express our prior beliefs about those shares as a Dirichlet <em>distribution</em>. So, for instance, our beliefs might be centered around a <span class="math inline">\(\lambda^Y_{01}=0.5, \lambda^Y_{00}=0.25, \lambda^Y_{11}=0.25\)</span> breakdown of shares in the population; and we also express some degree of uncertainty about what the breakdown is. Now, when we analyze data on some number of cases, we can update both on those cases’ types and on our beliefs about the distribution of types in the population – perhaps shifting toward a higher share of <span class="math inline">\(\lambda^Y_{01}\)</span>’s (and with a change in the distribution’s variance).</p>
<p>We can also, as in the last section, build a model in which there are multiple settings, possibly differing on some population-level characteristic. Fundamentally, however, the setup in the last section still involved population-level inference in that we were assuming that the <em>type shares</em> (<span class="math inline">\(\lambda\)</span> values) are the same across settings. The settings might differ in the value of a moderating variable, but they do not differ in the shares of cases that <em>would</em> respond in any given way to the moderator (and other causal conditions). The data allow us to update on what those common, cross-setting type proportions are.</p>
<p>When we build a hierarchical model, each case is still understood as being embedded within a population: our cases might be citizens, say, each embedded within a country. The key difference from population-level inference is that we now conceive of there being <em>multiple</em> populations – say, multiple countries – each drawn from a population of populations, or superpopulation. Now, we think of each population (country) as having its own set of type shares for each node. And we think of each country’s type shares as being drawn from a Dirichlet distribution of type shares (for each node) that lives at the superpopulation level. Moreover, we are <em>uncertain</em> about what that distribution at the superpopulation level <em>is</em>. We uncertain around what type proportions the superpopulation-level distribution is centered, and we are uncertain about how dispersed this distribution is. While the distribution’s central tendency will be related to the mean type shares for countries, its variance will determine the degree of <em>heterogeneity</em> across countries in their type shares.</p>
<p>To summarize, in population-level inference, we express uncertainty about the population’s type shares with a Dirichlet prior, at the population level, on which we update. In the hierarchical setting, we are uncertain both about the population-level type shares and the superpopulation Dirichlet from which each node’s type shares are drawn. We express our uncertainty about each superpopulation Dirichlet by positing a prior distribution over the Dirichlet’s alpha parameters.</p>
<p>Now, when we observe data on citizens within countries, we can update our beliefs about types fora the particular citizens we observe, about type shares in the population of citizens within each country that we study, <em>and</em> on the parameters of the Dirichlet distribution from which population shares have been drawn. In updating on the last of these, we are learning not just about the countries we observe but also about those we do not directly observe.</p>
<!-- AJ: Check that all of the above is right! -->
<!-- AJ: Need something here about how the approach to hierarchical models in Gelman et al is different from or related to how we're operationalizing them. -->
<p>We illustrate with a simulation using a simple <span class="math inline">\(X,Y\)</span> model. We imagine that we are studying the <span class="math inline">\(X \rightarrow Y\)</span> relationship in <code>n</code> countries. Each country has a parameter distribution drawn from common Dirichelets. We start off with flat priors over the alpha arguments of the superpopulation Dirichlets.</p>
<!-- AJ: I am confused by the statement that "Each country has a parameter distribution drawn from  common Dirichelets." I am generally struggling a bit with this bit still, and so may have this point wrong above. I am thinking: we have a set of alphas (Dirichlet parameters) for each *country* -- so we have a prior distribution of shares for each country. And the country-level alphas have been drawn from a common distribution of *alphas* at the superpop level. Is that right? Or is all the randomness at the superpop level, and we're now thinking of each country as having a specific set of shares, and our prior and posterior distributions are ONLY Dirichlet distributions at the superpop level? -->
<!-- MH: No we do not have alphas for each country; each country does and always did have a specific set of shares. This was true before but we represented our prior uncertainty over the specific shares using the Dirichlet. We *still* are uncertain over the shares but now we beliefe there *is* a a Dirichlet distribution from which these are drwan (before the Dirichlet just represented our uncertainty; now it represents the actual data generation process); we just don;t know what the Dirichlet is so we are are uncertain over it (before we did know what the Diriclet is since that just meant we knew what our priors are; now we don;t know what it is because it represents the true dgp). Easiest to think through this focussed only on the distribution of a binary variable X. (a) For each person X is either 0 or 1. (b) in a study the distribution of X is given by p (prob X = 1); in a single country study we want to figure out what p is and we have a prior distribution over possible values of p, using a Beta distribution with parameters a,b.  (c) in a multicountry study we think that there is a different p is every country and we now imagine these are drawn from a beta distribution with parameters a,b; but we don;t know what a and b are. So we put priors over a and b (inverse gamma priors). -->
<!-- AJ: OK, revised text accordingly. -->
<p>We assign a particular true set of superpopulation parameter values that, for the analytic exercise, is treated as unknown and that we would like to recover. In this true world, the probability of assignment to <span class="math inline">\(X=1\)</span> is .4, and the average treatment effect is .1. Using these true parameter values, we simulate <span class="math inline">\(X, Y\)</span> data for <span class="math inline">\(n=8\)</span> countries.</p>
<!-- AJ: I think you'll need to do some elaboration for this step, Macartan. -->
<p><img src="ii_files/figure-html/plotalphas-1.png" width="672" /></p>
<p>In Figure <a href="#fig:plotalphas"><strong>??</strong></a>, we graph our posterior beliefs about the superpopulation parameters. We do this by plotting two alpha parameters against each other at a time. In the first panel, we plot the alphas for <span class="math inline">\(X=0\)</span> and <span class="math inline">\(X=1\)</span>. In the next panel, we plot the alpha’s corresponding to <span class="math inline">\(c\)</span> types against those corresponding to <span class="math inline">\(d\)</span> types. And in the third panel we plot the alpha’s corresponding to <span class="math inline">\(a\)</span> types against those corresponding to <span class="math inline">\(b\)</span> types.</p>
<p>As we can see, each distribution falls roughly along a diagonal. Probability mass located further up the diagonal represents worlds in which the superpopulation Dirichlet distribution of type shares is relatively low in variance. Thus, the more that our posterior beliefs are concentrated toward a graph’s northeast corner, the lower the heterogeneity we have inferred there to be in the relevant type shares across countries. Meanwhile, the dispersion of probability mass <em>away</em> from the diagonal represents greater posterior <em>uncertainty</em> about the heterogeneity across countries, arising from greater variance about the posterior distribution of the alphas.</p>
<p>We can think of a concentration parameter here that is operationalized as the sum of the <span class="math inline">\(\alpha^j\)</span> terms for a node, <span class="math inline">\(j\)</span>, with a higher value representing lower overall heterogeneity.</p>
<!-- This would be 4 for a flat distribution ($(1,1,1,1)$ and should be a lot higher with this example.  -->
<p><img src="ii_files/figure-html/metaplot-1.png" width="672" /></p>
<p>In the Figure <a href="#fig:metaplot"><strong>??</strong></a> we turn to the causal query of interest and show a comparison of three <span class="math inline">\(ATE\)</span> estimates for each country: in blue, we show the unpooled estimate, or the estimate we get for each country using only data from that country; in red, we see the pooled estimates, or the estimate we get for each country using data from <em>all</em> countries to inform that country’s parameter estimates; and in black, we plot the truth as posited for this simulation. As we can see, the pooled estimates are all closer to the center than the unpooled estimates: this is because we are effectively using data from all countries to discount extreme features of the data observed in a given country. Put differently, the pooled data serve the function of a prior when it comes to drawing inferences about a single country: our inference is a compromise between the data from that country and the beliefs we have formed from the pooled data. We can also see that, for most countries, the pooling helps: the regularization provided by the pooling gives us an estimate closer to the truth for most of the settings.</p>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-angrist1995identification">
<p>Angrist, Joshua D, and Guido W Imbens. 1995. “Identification and Estimation of Local Average Treatment Effects.” National Bureau of Economic Research.</p>
</div>
<div id="ref-knox2019design">
<p>Knox, Dean, Teppei Yamamoto, Matthew A Baum, and Adam J Berinsky. 2019. “Design, Identification, and Sensitivity Analysis for Patient Preference Trials.” <em>Journal of the American Statistical Association</em>, 1–27.</p>
</div>
<div id="ref-pearl2014external">
<p>Pearl, Judea, and Elias Bareinboim. 2014. “External Validity: From Do-Calculus to Transportability Across Populations.” <em>Statistical Science</em> 29 (4): 579–95.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mixingapp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="elements-of-design.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
