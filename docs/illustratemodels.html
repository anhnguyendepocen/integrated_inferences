<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Illustrating Causal Models | Illustrating causal models</title>
  <meta name="description" content="Bayesian causal models for integrated inferences." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Illustrating Causal Models | Illustrating causal models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://macartan.github.io/integrated_inferences/" />
  <meta property="og:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />
  <meta property="og:description" content="Bayesian causal models for integrated inferences." />
  <meta name="github-repo" content="macartan/integrated_inferences" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Illustrating Causal Models | Illustrating causal models" />
  
  <meta name="twitter:description" content="Bayesian causal models for integrated inferences." />
  <meta name="twitter:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="models.html"/>
<link rel="next" href="questions.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#counterfactualmodel"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#potential-outcomes"><i class="fa fa-check"></i><b>2.1.1</b> Potential outcomes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#generalization"><i class="fa fa-check"></i><b>2.1.2</b> Generalization</a></li>
<li class="chapter" data-level="2.1.3" data-path="models.html"><a href="models.html#summaries-of-potential-outcomes"><i class="fa fa-check"></i><b>2.1.3</b> Summaries of potential outcomes</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#graphing-models-and-using-graphs"><i class="fa fa-check"></i><b>2.3</b> Graphing models and using graphs</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#graphing"><i class="fa fa-check"></i><b>2.3.1</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.3.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#simplifying-models"><i class="fa fa-check"></i><b>2.3.3</b> Simplifying models</a></li>
<li class="chapter" data-level="2.3.4" data-path="models.html"><a href="models.html#retaining-probabilistic-relations"><i class="fa fa-check"></i><b>2.3.4</b> Retaining probabilistic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#conc2"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.5</b> Chapter Appendix</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.5.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.5.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.5.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.5.3" data-path="models.html"><a href="models.html#rules-for-moving-between-levels"><i class="fa fa-check"></i><b>2.5.3</b> Rules for moving between levels</a></li>
<li class="chapter" data-level="2.5.4" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.5.4</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform"><i class="fa fa-check"></i><b>3.1</b> Welfare state reform</a></li>
<li class="chapter" data-level="3.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions"><i class="fa fa-check"></i><b>3.2</b> Military Interventions</a></li>
<li class="chapter" data-level="3.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization"><i class="fa fa-check"></i><b>3.3</b> Development and Democratization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Queries</a>
<ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#actual-causes"><i class="fa fa-check"></i><b>4.3</b> Actual causes</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>6</b> Theories as causal models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="theory.html"><a href="theory.html#models-as-theories-of"><i class="fa fa-check"></i><b>6.1</b> Models as <em>theories of</em></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="theory.html"><a href="theory.html#implications-of-structural-causal-models"><i class="fa fa-check"></i><b>6.1.1</b> Implications of structural causal models</a></li>
<li class="chapter" data-level="6.1.2" data-path="theory.html"><a href="theory.html#probabilistic-causal-models"><i class="fa fa-check"></i><b>6.1.2</b> Probabilistic causal models</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="theory.html"><a href="theory.html#theorygains"><i class="fa fa-check"></i><b>6.2</b> Gains from theory</a></li>
<li class="chapter" data-level="6.3" data-path="theory.html"><a href="theory.html#formal-theories-and-causal-models"><i class="fa fa-check"></i><b>6.3</b> Formal theories and causal models</a></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="7" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>7</b> Process Tracing with Causal Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>7.1</b> Process tracing and causal models</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>7.1.1</b> The intuition</a></li>
<li class="chapter" data-level="7.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>7.1.2</b> A formalization of the general approach</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pt.html"><a href="pt.html#mapping-from-models-to-classic-qualitative-tests"><i class="fa fa-check"></i><b>7.2</b> Mapping from models to classic qualitative tests</a></li>
<li class="chapter" data-level="7.3" data-path="pt.html"><a href="pt.html#principles-of-learning"><i class="fa fa-check"></i><b>7.3</b> Principles of learning</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-us-probative-value"><i class="fa fa-check"></i><b>7.3.1</b> A DAG alone does not get us probative value</a></li>
<li class="chapter" data-level="7.3.2" data-path="pt.html"><a href="pt.html#learning-requires-uncertainty"><i class="fa fa-check"></i><b>7.3.2</b> Learning requires uncertainty</a></li>
<li class="chapter" data-level="7.3.3" data-path="pt.html"><a href="pt.html#multiple-ways-for-queries-to-be-satisfied"><i class="fa fa-check"></i><b>7.3.3</b> Multiple ways for queries to be satisfied</a></li>
<li class="chapter" data-level="7.3.4" data-path="pt.html"><a href="pt.html#beware-of-highly-unlikely-queries"><i class="fa fa-check"></i><b>7.3.4</b> Beware of highly unlikely queries</a></li>
<li class="chapter" data-level="7.3.5" data-path="pt.html"><a href="pt.html#population-level-uncertainty-does-not-alter-case-level-causal-inference"><i class="fa fa-check"></i><b>7.3.5</b> Population-level uncertainty does not alter case-level causal inference</a></li>
<li class="chapter" data-level="7.3.6" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>7.3.6</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>8</b> Application: Process Tracing with a Causal Model</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>8.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="8.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>8.2</b> A Structural Causal Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>8.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>8.3</b> Results</a></li>
<li class="chapter" data-level="8.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>8.4</b> Pathways</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>8.4.1</b> Inferences for cases with observed democratization</a></li>
<li class="chapter" data-level="8.4.2" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>8.4.2</b> Cases with incomplete data</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>8.5</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>9</b> Integrated inferences</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mixing.html"><a href="mixing.html#sample-inference"><i class="fa fa-check"></i><b>9.1</b> Sample inference</a></li>
<li class="chapter" data-level="9.2" data-path="mixing.html"><a href="mixing.html#from-sample-queries-to-general-processes"><i class="fa fa-check"></i><b>9.2</b> From sample queries to general processes</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="mixing.html"><a href="mixing.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="mixing.html"><a href="mixing.html#inference"><i class="fa fa-check"></i><b>9.2.2</b> Inference</a></li>
<li class="chapter" data-level="9.2.3" data-path="mixing.html"><a href="mixing.html#wrinkles"><i class="fa fa-check"></i><b>9.2.3</b> Wrinkles</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mixing.html"><a href="mixing.html#mixed-methods"><i class="fa fa-check"></i><b>9.3</b> Mixed methods</a></li>
<li class="chapter" data-level="9.4" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>9.4</b> Considerations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="mixing.html"><a href="mixing.html#probative-value-can-be-derived-from-a-causal-structure-plus-data"><i class="fa fa-check"></i><b>9.4.1</b> Probative value can be derived from a causal structure plus data</a></li>
<li class="chapter" data-level="9.4.2" data-path="mixing.html"><a href="mixing.html#learning-without-identification"><i class="fa fa-check"></i><b>9.4.2</b> Learning without identification</a></li>
<li class="chapter" data-level="9.4.3" data-path="mixing.html"><a href="mixing.html#beyond-binary-data"><i class="fa fa-check"></i><b>9.4.3</b> Beyond binary data</a></li>
<li class="chapter" data-level="9.4.4" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>9.4.4</b> Measurement error</a></li>
<li class="chapter" data-level="9.4.5" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>9.4.5</b> Spillovers</a></li>
<li class="chapter" data-level="9.4.6" data-path="mixing.html"><a href="mixing.html#clustering"><i class="fa fa-check"></i><b>9.4.6</b> Clustering</a></li>
<li class="chapter" data-level="9.4.7" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>9.4.7</b> Parameteric models</a></li>
<li class="chapter" data-level="9.4.8" data-path="mixing.html"><a href="mixing.html#prior-databeliefs-channel-the-learning-from-new-data"><i class="fa fa-check"></i><b>9.4.8</b> Prior data/beliefs “channel” the learning from new data</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="mixing.html"><a href="mixing.html#conclusion"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>10</b> Mixed-Method Application: Inequality and Democracy Revisited</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>10.1</b> A trained model</a></li>
<li class="chapter" data-level="10.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="mixingapp.html"><a href="mixingapp.html#inference-1"><i class="fa fa-check"></i><b>10.3</b> Inference</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democratization"><i class="fa fa-check"></i><b>10.3.1</b> Did inequality <em>cause</em> democratization?</a></li>
<li class="chapter" data-level="10.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>10.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="mixingapp.html"><a href="mixingapp.html#from-cases-to-population"><i class="fa fa-check"></i><b>10.4</b> From cases to population</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="mixingapp.html"><a href="mixingapp.html#contribution-to-case-level-inference"><i class="fa fa-check"></i><b>10.4.1</b> Contribution to case-level inference</a></li>
<li class="chapter" data-level="10.4.2" data-path="mixingapp.html"><a href="mixingapp.html#how-much-do-we-get-from-the-model-vs.-the-data"><i class="fa fa-check"></i><b>10.4.2</b> How much do we get from the model vs. the data?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>11</b> Mixing models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>11.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="11.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>11.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="11.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>11.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="11.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>11.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-1"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Mixed methods data strategies</a>
<ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-strategies"><i class="fa fa-check"></i><b>13.1</b> Case selection strategies</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="caseselection.html"><a href="caseselection.html#no-general-rules"><i class="fa fa-check"></i><b>13.1.1</b> No general rules</a></li>
<li class="chapter" data-level="13.1.2" data-path="caseselection.html"><a href="caseselection.html#specific-case-walk-through"><i class="fa fa-check"></i><b>13.1.2</b> Specific case walk through</a></li>
<li class="chapter" data-level="13.1.3" data-path="caseselection.html"><a href="caseselection.html#case-selection-from-causal-models-a-simulation-based-approach"><i class="fa fa-check"></i><b>13.1.3</b> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wideordeep.html"><a href="wideordeep.html"><i class="fa fa-check"></i><b>14</b> Going wide, going deep</a>
<ul>
<li class="chapter" data-level="14.0.1" data-path="wideordeep.html"><a href="wideordeep.html#walk-through-of-a-simple-comparison"><i class="fa fa-check"></i><b>14.0.1</b> Walk-through of a simple comparison</a></li>
<li class="chapter" data-level="14.0.2" data-path="wideordeep.html"><a href="wideordeep.html#a-simulation-based-approach-to-choosing-mixes"><i class="fa fa-check"></i><b>14.0.2</b> A simulation-based approach to choosing mixes</a></li>
<li class="chapter" data-level="14.0.3" data-path="wideordeep.html"><a href="wideordeep.html#factoring-in-the-cost-of-data"><i class="fa fa-check"></i><b>14.0.3</b> Factoring in the cost of data</a></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying.html"><a href="justifying.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="justifying.html"><a href="justifying.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying.html"><a href="justifying.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying.html"><a href="justifying.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="justifying.html"><a href="justifying.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying.html"><a href="justifying.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying.html"><a href="justifying.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
<li class="chapter" data-level="15.5" data-path="justifying.html"><a href="justifying.html#exercise"><i class="fa fa-check"></i><b>15.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.2</b> Bayesian <span class="math inline">\(p-\)</span>value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.3</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.4</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mixing.html"><a href="mixing.html#conclusion"><i class="fa fa-check"></i><b>17</b> Final Words</a>
<ul>
<li class="chapter" data-level="17.1" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>17.1</b> The benefits</a></li>
<li class="chapter" data-level="17.2" data-path="conclusion.html"><a href="conclusion.html#the-worries"><i class="fa fa-check"></i><b>17.2</b> The worries</a></li>
<li class="chapter" data-level="17.3" data-path="conclusion.html"><a href="conclusion.html#the-future"><i class="fa fa-check"></i><b>17.3</b> The future</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/CausalQueries/" target="blank">Uses CausalQueries</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Illustrating causal models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="illustratemodels" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Illustrating Causal Models</h1>
<div class="headerbox">
<div class="center">

</div>
<p>We represent three theoretical arguments as causal models with associated graphs.</p>
</div>
<p><br></p>
<p>In this short chapter, we provide more of a sense of how one can encode prior knowledge in a causal model by asking how we might construct models in light of extant scholarly works. We undertake this exercise by drawing on three well-known publications in comparative politics and international relations: Paul Pierson’s seminal book on welfare-state retrenchment <span class="citation">(<a href="#ref-pierson1994dismantling" role="doc-biblioref">Pierson 1994</a>)</span>; Elizabeth Saunders’ research on leaders’ choice of military intervention strategies <span class="citation">(<a href="#ref-saunders2011leaders" role="doc-biblioref">Saunders 2011</a>)</span>; and Przeworski and Limongi’s work on democratic survival <span class="citation">(<a href="#ref-przeworski1997modernization" role="doc-biblioref">Przeworski and Limongi 1997</a>)</span>, an instructive counterpoint to Boix’s <span class="citation">(<a href="#ref-boix2003democracy" role="doc-biblioref">Boix 2003</a>)</span> argument about a related dependent variable. For each, we represent the causal knowledge that we might plausibly think we take away from the work in question in the form of a causal model.</p>
<p>Readers might represent these knowledge bases differently; our aim here is only to illustrate how causal models are constructed, rather than to defend a particular representation (much less the works in question) as accurate.</p>
<p>For each exercise below, we focus on a specific argument in the literature in order to fix in place a relatively clear set of background causal beliefs and simplify the exposition. We emphasize, however, that <em>in general</em> a causal model should be thought of as a representation of our state of knowledge or beliefs about causal relations within a domain, rather than as a representation of a specific argument. Suppose, for instance, that we are interested in testing a specific argument in which <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> through the mediator <span class="math inline">\(M\)</span>. In constructing a causal model to guide our empirical analysis, we cannot simply draw that argument in DAG form (<span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>) and leave it at that. In line with the principles relating to conditional independence outlined in Chapter <a href="models.html#models">2</a>, we must consult our beliefs about this causal domain in a broader sense. For instance, given what we know about the domain from prior observations or studies, is it plausible that <span class="math inline">\(X\)</span> could affect <span class="math inline">\(Y\)</span> through a pathway that does not go through <span class="math inline">\(M\)</span>? If we believe it is possible, then we must also draw a direct <span class="math inline">\(X \rightarrow Y\)</span> arrow, or our causal model will steer us wrong — even if our primary aim is to examine the pathway through <span class="math inline">\(M\)</span>. Otherwise, our DAG will contain a relation of conditional independence (<span class="math inline">\(X\)</span> being conditionally independent of <span class="math inline">\(Y\)</span> given <span class="math inline">\(M\)</span>) that we do not believe holds. Thus, while we draw on specific works in the illustrations in this chapter, we urge readers to remember that in practice one would want to characterize a broader prior knowledge base in relation to a causal domain in generating a causal model.</p>
<p>We aim to illuminate a number of features of causal models and their construction with these exercises. The examples that we work through variously illustrate how graphs capture beliefs about relations of conditional independence; the potential causal complexity embedded in the causal structures implied by common social-scientific arguments; and the elements of a causal model that cannot be read from a graph. For each work, we discuss both a parametric rendering of the causal functions and a non-parametric formulation built on nodal types.</p>
<div id="welfare-state-reform" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Welfare state reform</h2>
<p>The argument in Pierson’s 1994 book <em>Dismantling the Welfare State?</em> challenged prior notions of post-1980 welfare-state retrenchment in OECD countries as a process driven primarily by socioeconomic pressures (slowed growth, rising unemployment, rising deficits, aging populations) and the rise of market-conservative ideologies (embodied for instance by the ascendance of Thatcher and Reagan). Pierson argues that socioeconomic and ideological forces put retrenchment on the policy agenda, but do not ensure its enactment because retrenchment is a politically perilous process of imposing losses on large segments of the electorate. Governments will only impose such losses if they can do so in ways that allow them avoid blame for doing so—by, for instance, making the losses hard to perceive or the responsibility for them difficult to trace. These blame-avoidance opportunities are themselves conditioned by the particular social-program structures that governments inherit.</p>
<p><!-- $C$=conservative government; $S$=socioeconomic pressures; $P$=program structure; $A$=retrenchment being on the agenda; $B$=blame-avoidance opportunities; $R$=retrenchment; $\theta^R$=random influences on retrenchment --></p>
<!-- ```{r pierson, echo = FALSE, fig.width = 12, fig.height = 7, fig.align="center", out.width='.7\\textwidth', fig.cap = "A graphical representation of Pierson (1994).", warning = FALSE, message = FALSE} -->
<!-- par(mfrow = c(1,1)) -->
<!-- par(mar=c(1,1,3,1)) -->
<!-- hj_dag(x = c(1,2,3,1,1,2,3), -->
<!--        y = c(1,1,2,3,2,2,3), -->
<!--        names = c( -->
<!--          expression(paste("P:\nProgram\nstructure")), -->
<!--          expression(paste("B:\nBlame-avoidance\nopportunity")),   -->
<!--          expression(paste("R:\nRetrenchment")), -->
<!--          expression(paste("C:\nConservative\ngovt")), -->
<!--          expression(paste("S:\nSocioeconomic\npressures")), -->
<!--          expression(paste("A:\nOn Agenda")), -->
<!--          expression(paste(theta^R: "\nRandom influence\n on retrenchment"))), -->
<!--        arcs = cbind( c(1,2, 4,5,6,7), -->
<!--                      c(2,3, 6,6,3,3)), -->
<!--        title = "Welfare-State Rentrenchment (Pierson, 1994)", -->
<!--        add_functions = 0,  -->
<!--        contraction = .16,  -->
<!--        padding = .2 -->
<!-- ) -->
<!-- ``` -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pierson"></span>
<img src="ii_files/figure-html/pierson-1.png" alt="A graphical representation of Pierson (1994)." width=".7\textwidth" />
<p class="caption">
Figure 3.1: A graphical representation of Pierson (1994).
</p>
</div>
<p>While the argument has many more specific features (e.g., different program-structural factors that matter, various potential strategies of blame-avoidance), its essential components can be captured with a relatively simple causal model. We propose such a model in graphical form in Figure <a href="illustratemodels.html#fig:pierson">3.1</a>. Here, the outcome of retrenchment (<span class="math inline">\(R\)</span>) hinges on whether retrenchment makes it onto the agenda (<span class="math inline">\(A\)</span>) and on whether blame-avoidance strategies are available to governments (<span class="math inline">\(B\)</span>). Retrenchment emerges on the policy agenda as a consequence of both socioeconomic developments (<span class="math inline">\(S\)</span>) and the ascendance of ideologically conservative political actors (<span class="math inline">\(C\)</span>). Inherited program structures (<span class="math inline">\(P\)</span>), meanwhile, determine the availability of blame-avoidance strategies. To avoid cluttering the graph, we do not represent the <span class="math inline">\(\theta\)</span> terms, but it is implied that every node on this graph has a <span class="math inline">\(\theta\)</span> node pointing into it.</p>
<p>A few features of this graph warrant attention. As we have discussed, it is the omitted arrows in any causal graph that imply the strongest statements. The graph implies that <span class="math inline">\(C\)</span>, <span class="math inline">\(S\)</span>, and <span class="math inline">\(P\)</span>—which are neither connected along a directed path nor downstream from a common cause—are independent of one another. This implies, for instance, that whether conservatives govern is independent of whether program structures will allow for blame-free retrenchment. Thus, as Pierson argues, a Reagan or Thatcher can come to power but nonetheless run up against an opportunity structure that would make retrenchment politically perilous. Given the absence of bidirectional arrows indicating confounding, the graph similarly implies that the nodal types for all nodes are independent of one another.</p>
<p>Further, this graph represents the belief that any effect of program structures on retrenchment <em>must</em> run through their effects on blame-avoidance opportunities. One could imagine relaxing this restriction by, for instance, drawing an arrow from <span class="math inline">\(P\)</span> to <span class="math inline">\(A\)</span>: program structures might additionally affect retrenchment in other ways, such as by conditioning the fiscal costliness of the welfare state and thus helping to determine whether reform makes it onto the agenda. If the current state of knowledge suggested that program structures could affect retrenchment via a pathway other than blame-avoidance opportunities, then we would indeed want to include a direct <span class="math inline">\(P \rightarrow A\)</span> arrow.</p>
<p>Where two variables <em>are</em> connected by an arrow, moreover, this does not imply that a causal effect will always operate. Consider, for instance, the arrow pointing from <span class="math inline">\(A\)</span> to <span class="math inline">\(R\)</span>. The fact that <span class="math inline">\(A\)</span> sometimes affects <span class="math inline">\(R\)</span> and sometimes does not is, in fact, central to Pierson’s argument: conservatives and socioeconomic pressures forcing retrenchment on the agenda will <em>not</em> generate retrenchment if blame-avoidance opportunities are absent.</p>
<p>The graph also reflects a choice about where to begin. We could, of course, construct a causal account of how conservatives come to power, how socioeconomic pressures arise, or why programs were originally designed as they were. Yet it is perfectly permissible for us to bracket these antecedents and start the model with <span class="math inline">\(C\)</span>, <span class="math inline">\(S\)</span>, and <span class="math inline">\(T\)</span>, as long as we do not believe that these variables have any antecedents in common. If they do have common causes, then this correlation should be captured in the DAG.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p>The DAG itself tells us about the possible direct causal dependencies but is silent on the ranges of and functional relations among the variables. How might we express these? With three endogenous variables, we need three functions indicating how their values are determined. Moreover, every variable pointing directly into another variable must be part of that second variable’s function.</p>
<p>Let us assume that all variables (including the implied <span class="math inline">\(\theta\)</span> terms) are binary, with each condition either absent or present.</p>
<p>One option would be to take a parameteric approach and imagine specific functions connecting parents to children, with <span class="math inline">\(\theta\)</span> terms representing exogenous “noise.” For instance, we can capture quite a lot of Pierson’s theoretical logic with the following quite simple functional equations:</p>
<ul>
<li><span class="math inline">\(A=CS\theta^C\)</span>, capturing the idea that retrenchment makes it on the agenda only if conservatives are in power <em>and</em> socioeconomic pressures are high.</li>
<li><span class="math inline">\(B=P\theta^P\)</span>, implying that blame-avoidance opportunities arise only when program structures take a particular form.</li>
<li><span class="math inline">\(R=AB\theta^R\)</span>, implying that retrenchment will occur only if it is on the agenda and blame-avoidance opportunities are present.</li>
</ul>
<p>In each equation, the <span class="math inline">\(\theta\)</span> term allows for exogenous forces that might block the outcome from occurring. In the last functional equation, for instance, retrenchment will only occur if retrenchment is on the agenda and blame-avoidance opportunities are present, but even if both are present, the effect on retrenchment also hinges on the value of <span class="math inline">\(\theta^R\)</span>. When <span class="math inline">\(\theta^R=1\)</span>, the <span class="math inline">\(AB\)</span> combination has a positive causal effect on retrenchment. When <span class="math inline">\(\theta^R=0\)</span>, <span class="math inline">\(AB\)</span> has no causal effect: retrenchment will not occur regardless of the presence of <span class="math inline">\(AB\)</span>. We can think of <span class="math inline">\(\theta^R\)</span> as capturing a collection of features of a case’s context that might render the case susceptible or not susceptible to an <span class="math inline">\(AB\)</span> causal effect. For instance, Pierson’s analysis suggests that a polity’s institutional structure might widely diffuse veto power such that stakeholders can block reform even when retrenchment is on the agenda and could be pursued without electoral losses. We could think of such a case as having a <span class="math inline">\(\theta^R\)</span> value of 0, implying that <span class="math inline">\(AB\)</span> has no causal effect. A <span class="math inline">\(\theta^R=1\)</span> case, with a positive effect, would be one in which the government has the institutional capacity to enact reforms that it has the political will to pursue.</p>
<p>Alternatively, we could take a non-parameteric approach, as we generally do in the remainder of this book. In a non-parametric setup, each node’s <span class="math inline">\(\theta\)</span> term captures that node’s nodal type. Each value of a <span class="math inline">\(\theta\)</span> term’s range represents a possible way in which the node might respond to its parents. We would define <span class="math inline">\(\theta^A\)</span> as taking on one of 16 values (16 types, given 2 parent nodes); <span class="math inline">\(\theta^B\)</span> as taking on on one of four values; and <span class="math inline">\(\theta^R\)</span> as taking on one of 16 values; with <span class="math inline">\(\theta^C\)</span> and <span class="math inline">\(\theta^S\)</span> each taking on one of two values.</p>
<p>Then choices on the probability distributions fully reflect the ways these variables relate to each other. Note that the parametric argument given above can be thought of as a special case of the non-parametric representation with all probability mass placed on a small set of possible nodal types. Thus the central thrust of Pierson’s argument could then be represented in nodal-type form as:</p>
<ul>
<li><span class="math inline">\(\theta^A=\theta^A_{0001}\)</span></li>
<li><span class="math inline">\(\theta^B=\theta^B_{01}\)</span></li>
<li><span class="math inline">\(\theta^R=\theta^R_{0001}\)</span>.</li>
</ul>
<p>In practice, however we would allow for a richer probability <em>distribution</em> over each <span class="math inline">\(\theta\)</span>, representing beliefs over the assignment process or causal relations operating at each node. Beliefs about the distribution of exogenous conditions would be captured in distributions over the values of <span class="math inline">\(\theta^C, \theta^S\)</span>, and <span class="math inline">\(\theta^P\)</span>. How we handle distributions over <span class="math inline">\(\theta^A, \theta^B\)</span>, and <span class="math inline">\(\theta^R\)</span> depends on the degree of confidence that we want to express in Pierson’s argument. To represent the belief that Pierson’s argument is correct with certainty and operates in uniform, deterministic fashion across units, we would simply have degenerate distributions for <span class="math inline">\(\theta^A, \theta^B\)</span>, and <span class="math inline">\(\theta^R\)</span>, with a probability of 1.0 placed on the respective nodal types shown above. To capture uncertainty about the functional relations on any graph or if we believe that there is some heterogeneity of effects across units we would disperse probability density across types for each <span class="math inline">\(\theta\)</span>. For instance, for <span class="math inline">\(\theta^R\)</span> we might want to put some weight on <span class="math inline">\(\theta^R_{0011}\)</span> (blame-avoidance opportunities alone are enough to generate retrenchment), <span class="math inline">\(\theta^R_{0101}\)</span> (conservative leaders alone are enough), <span class="math inline">\(\theta^R_{0111}\)</span> (either is enough), and <span class="math inline">\(\theta^R_{0000}\)</span> (retrenchment will not happen even when both conditions are present), while perhaps putting greatest weight on <span class="math inline">\(\theta^R_{0001}\)</span>.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a></p>
</div>
<div id="military-interventions" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Military Interventions</h2>
<p><span class="citation"><a href="#ref-saunders2011leaders" role="doc-biblioref">Saunders</a> (<a href="#ref-saunders2011leaders" role="doc-biblioref">2011</a>)</span> asks why, when intervening militarily abroad, do leaders sometimes seek to transform the <em>domestic</em> political institutions of the states they target but sometimes seek only to shape the states’ <em>external</em> behaviors.</p>
<p>Saunders’ central explanatory variable is the nature of leaders’ causal beliefs about security threats. When leaders are “internally focused,” they believe that threats in the international arena derive from the internal characteristics of other states. Leaders who are “externally focused,” by contrast, understand threats as emerging strictly from other states’ foreign and security policies.</p>
<p>These basic worldviews, in turn, affect the cost-benefit calculations leaders make about intervention strategies—in particular, about whether to try to transform the internal institutions of a target state—via two mechanisms. First, an internal focus (as opposed to an external focus) affects leaders’ perceptions of the likely security gains from a transformative intervention strategy. Second, internal vs. external focus affects the kinds of strategic capabilities in which leaders invest over time (do they invest in the kinds of capabilities suited to internal transformation?); and those investments in turn affect the costliness and likelihood of success of alternative intervention strategies. Calculations about the relative costs and benefits of different strategies then shape the choice between a transformative and non-transformative approach to intervention.</p>
<p>At the same time, leaders can only choose a transformative strategy if they decide to intervene at all. The decision about whether to intervene depends, in turn, on at least two kinds of considerations. The first is about fit: a leader is more likely to intervene against a target when the nature of the dispute makes the leader’s preferred strategy appear feasible in a given situation. Second, Saunders allows that forces outside the logic of her main argument might also affect the likelihood of intervention: in particular, leaders may be pushed to intervene by international or domestic audiences.</p>
<p>Figure  depicts the causal dependencies in Saunders’ argument in DAG form (again, with all <span class="math inline">\(\theta\)</span> terms implied). Working from left to right, we see that whether or not leaders are “internally focused” (<span class="math inline">\(F\)</span>) affects the expected net relative benefits of transformation (<span class="math inline">\(B\)</span>), both via a direct pathway and via an indirect pathway running through investments in transformative capacities (<span class="math inline">\(T\)</span>). Characteristics of a given dispute or target state (<span class="math inline">\(D\)</span>) likewise influence the benefits of transformation (<span class="math inline">\(B\)</span>). The decision about whether to intervene (<span class="math inline">\(I\)</span>) is then a function of three factors: internal focus (<span class="math inline">\(F\)</span>), the expected relative net benefits of transformation (<span class="math inline">\(B\)</span>), and audience pressures (<span class="math inline">\(A\)</span>). Finally, the choice of whether to pursue a transformative strategy (<span class="math inline">\(S\)</span>) is a function of whether or not intervention occurs at all (<span class="math inline">\(I\)</span>), and of cost-benefit comparisons between the two strategies (<span class="math inline">\(B\)</span>).</p>
<!-- ```{r saunders, echo = FALSE, fig.width = 12, fig.height = 7, fig.align="center", out.width='.7\\textwidth', fig.cap = "\\label{fig:DAGSaunders} A graphical representation of Saunders' (2011) argument.", warning = FALSE, message = FALSE} -->
<!-- par(mfrow = c(1,1)) -->
<!-- par(mar=c(1,1,3,1)) -->
<!-- hj_dag(x = c(1,2,2,1, 3, 3,3,3.5), -->
<!--        y = c(1,0,2,2, 2, 1,0, .5), -->
<!--        names = c( -->
<!--          expression(paste("C: Causal beliefs")), -->
<!--          expression(paste("P: Preparedness\ninvestment")),   -->
<!--          expression(paste("B: Benefits expected\nfrom transfers")),   -->
<!--          expression(paste("T: Target\ncharacteristics")), -->
<!--          expression(paste("A: Audience pressures")), -->
<!--          expression(paste("I: Intervention")), -->
<!--          expression(paste("S: Intervention strategy")), -->
<!--          expression(paste(U[S]: "Random influence\non strategy"))  -->
<!--          ), -->
<!--        arcs = cbind( c(1,1, 2,1, 4, 3, 3,5,6,8), -->
<!--                      c(2,3, 3,6, 3, 6, 7,6,7,7)), -->
<!--        title = "(b) Military intervention strategies (Saunders, 2011)", -->
<!--        add_functions = 0,  -->
<!--        contraction = .16,  -->
<!--        padding = .2 -->
<!-- ) -->
<!-- ``` -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:saunders"></span>
<img src="ii_files/figure-html/saunders-1.png" alt="\label{fig:DAGSaunders} A graphical representation of Saunders' (2011) argument." width=".7\textwidth" />
<p class="caption">
Figure 3.2:  A graphical representation of Saunders’ (2011) argument.
</p>
</div>
<p>This DAG illustrates how readily causal graphs can depict the multiple pathways through which a given variable might affect another variable, as with the multiple pathways linking <span class="math inline">\(F\)</span> to <span class="math inline">\(I\)</span> and <span class="math inline">\(B\)</span> (and, thus, all of its causes) to <span class="math inline">\(S\)</span>. In fact, this graphical representation of the dependencies in some ways throws the multiplicity of pathways into even sharper relief than does a narrative exposition of the argument. For instance, Saunders draws explicit attention to how causal beliefs operate on expected net benefits via both a direct and indirect pathway, both of which are parts of an indirect pathway from <span class="math inline">\(F\)</span> to the outcomes of interest, <span class="math inline">\(I\)</span> and <span class="math inline">\(S\)</span>. What is a bit easier to miss without formalization is that <span class="math inline">\(F\)</span> also acts <em>directly</em> on the choice to intervene as part of the feasibility logic: when leaders assess whether their generally preferred strategy would be feasible if deployed against a particular target, the generally preferred strategy is itself a product of their causal beliefs. The DAG also makes helpfully explicit that the two main outcomes of interest—the choice about whether to intervene and the choice about how—are not just shaped by some of the same causes but are themselves causally linked, with the latter depending on the former.</p>
<p>Omitted links are also notable. For instance, the lack of an arrow between <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> suggests that features of the dispute that affect feasibility have no effect on audience pressures. If we instead believed there could be other connections—for instance, that audiences take feasibility into account in demanding intervention—then we would want to include a <span class="math inline">\(D \rightarrow A\)</span> arrow.</p>
<p>Turning to variable ranges and functional equations, it is not hard to see how one might readily capture Saunders’ logic in a fairly straightforward set-theoretic manner. All variables except <span class="math inline">\(S\)</span> could be treated as binary with, for instance, <span class="math inline">\(F=1\)</span> representing internally focused causal beliefs, <span class="math inline">\(T=1\)</span> representing investments in transformative capabilities, <span class="math inline">\(B=1\)</span> representing expectations that transformation will be more net beneficial than non-transformation, <span class="math inline">\(D=1\)</span> meaning that a dispute has characteristics that make transformation a feasible strategy, and so on. Although there are two strategies, we in fact need three values for <span class="math inline">\(S\)</span> because it must be defined for all values of the other variables—i.e., it must take on a distinct categorical value if there is no intervention at all. We could then define functions, such as:</p>
<ul>
<li><span class="math inline">\(B=FTD\)</span>, implying that transformation will only be perceived to be net beneficial in a case if and only if the leader has internally focused causal beliefs, the government is prepared for a transformative strategy, and the dispute has characteristics that make transformation feasible.</li>
<li><span class="math inline">\(I=(1-|B-F|)+(1-(1-|B-F|))A\)</span>, implying that intervention can occur under (and only under) either of two alternative sets of conditions: if the generally preferred strategy and the more net-beneficial strategy in a given case are the same (i.e., such that <span class="math inline">\(B-F=0\)</span>) or, when this alignment is absent (i.e., such that <span class="math inline">\(|B-F|=0\)</span>), where audiences pressure a leader to intervene.</li>
</ul>
<p>As illustrated in the Pierson example, in a non-parametric framework, each parametric functional equation represents one nodal type for the relevant <span class="math inline">\(\theta\)</span>. For instance, though we spare the reader the complexities of the corresponding subscript notation, there is a single value of <span class="math inline">\(\theta^B\)</span> under which the conditions <span class="math inline">\(F=1, P=1,\)</span> and <span class="math inline">\(T=1\)</span> generate <span class="math inline">\(B=1\)</span>, and we get <span class="math inline">\(B=0\)</span> otherwise. Likewise, there exists a single value of <span class="math inline">\(\theta^I\)</span> under which <span class="math inline">\(B=1, F=1\)</span> and <span class="math inline">\(B=0, F=0\)</span> produce <span class="math inline">\(I=1\)</span>, for either value of <span class="math inline">\(A\)</span>; and <span class="math inline">\(A\)</span> has a positive effect on <span class="math inline">\(I\)</span> whenever <span class="math inline">\(B \neq F\)</span>. To work with this model, we would specify a probability distribution over all possible nodal types for each node on the graph.</p>
<p>This example also nicely illustrates how much potential causal complexity a moderately intricate argument and causal graph implies. The number of <em>possible</em> nodal types at each node depends on how many parents that node has. Looking at the endogenous nodes here, we have one node with one parent (<span class="math inline">\(T\)</span>), implying 4 nodal types; one node with two parents (<span class="math inline">\(S\)</span>), implying 16 nodal types; and two nodes with 3 parents (<span class="math inline">\(B\)</span> and <span class="math inline">\(I\)</span>), implying 256 nodal types each. If we now conceptualize the set of possible “causal types” as containing all distinct combinations of nodal types—all ways in which a case might behave across all of its nodes (see Chapter <a href="models.html#models">2</a>)—then this graph implies about 4 million different ways in which the values of exogenous nodes (<span class="math inline">\(D\)</span>, <span class="math inline">\(F\)</span>, and <span class="math inline">\(A\)</span>) might jointly produce patterns of outcomes. Saunders’ argument effectively represents one of these 4 million possible sets of relations.</p>
<p>The framework that we outline in this book allows for updating on arguments like Saunders’: we can ask how likely the specific causal type implied by this argument is relative to other causal types. Yet, as we will see, the approach lends itself to a much broader view of causal inquiry. In general, we will use data to update beliefs over <em>all</em> causal types allowed for in a model, and then use these updated beliefs to answer any number of causal questions about relations in the model. For instance, we can use the same data and updated model to ask about the average effect of internal focus on intervention; the relative importance in this effect of the expected-benefits pathway over the direct pathway; about individual steps in the causal chain, such as the effect of expected benefits on choice of strategy; and so on.</p>
</div>
<div id="development-and-democratization" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Development and Democratization</h2>
<p><span class="citation"><a href="#ref-przeworski1997modernization" role="doc-biblioref">Przeworski and Limongi</a> (<a href="#ref-przeworski1997modernization" role="doc-biblioref">1997</a>)</span> argue that democratization occurs for reasons that are, with respect to socioeconomic or macro-structural conditions, largely idiosyncratic; but once a country has democratized, a higher level of economic development makes democracy more likely to survive. Economic development thus affects whether or not a country is a democracy, but only after a democratic transition has occurred, not before. Thus, in their description—and contrary to <span class="citation"><a href="#ref-boix2003democracy" role="doc-biblioref">Boix</a> (<a href="#ref-boix2003democracy" role="doc-biblioref">2003</a>)</span> —democratization is “exogenous”: it is not determined by other variables in the model. The dynamic component of Przeworski and Limongi’s argument—the fact that both the presence of democracy and the causal effect of development on democracy depend on whether a democratic transition occurred at a previous point in time—forces us to think about how to capture over-time processes in a causal model.</p>
<p>We represent Przeworski and Limongi’s argument in the DAG in Figure <a href="illustratemodels.html#fig:DAGPL">3.3</a>. The first thing to note is that we can capture dynamics by considering democracy at different points in time as separate nodes. According to the graph, whether a country is a democracy in a given period (<span class="math inline">\(D_t\)</span>) is a function, jointly, of whether it was a democracy in the previous period (<span class="math inline">\(D_{t-1}\)</span>) and of the level of per capita GDP in the current period (as well as of other unspecified forces <span class="math inline">\(\theta^{D_t}\)</span>, not pictured).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:DAGPL"></span>
<img src="ii_files/figure-html/DAGPL-1.png" alt="A graphical representation of Przeworski and Limongi's argument, where $D_{t-1}$=democracy in the previous period; $GDP_t$=per capita GDP in the current period; $D_t$=democracy in the current period." width=".7\textwidth" />
<p class="caption">
Figure 3.3: A graphical representation of Przeworski and Limongi’s argument, where <span class="math inline">\(D_{t-1}\)</span>=democracy in the previous period; <span class="math inline">\(GDP_t\)</span>=per capita GDP in the current period; <span class="math inline">\(D_t\)</span>=democracy in the current period.
</p>
</div>
<p>Second, the arrow running from <span class="math inline">\(GDP_{t-1}\)</span> to <span class="math inline">\(D_t\)</span> means that <span class="math inline">\(GDP\)</span> <em>may</em> affect democracy, not that it always does. Indeed, Przeworski and Limongi’s argument is that development’s effect depends on a regime’s prior state: GDP matters for whether democracies continue to be democracies, but not for whether autocracies go on to become democracies. The absence of an arrow between <span class="math inline">\(D_{t-1}\)</span> and <span class="math inline">\(GDP_{t-1}\)</span>, however, implies a (possibly incorrect) belief that democracy and <span class="math inline">\(GDP\)</span> in the last period are independent of one another.</p>
<p>Inspection of this figure highlights, we think, a curious feature of this argument. The key claim—that the switch <em>to</em> democracy does not depend on income—is not readable from the graph. The reason is simply that, given this argument, being a non democracy in one period given you were a democracy in a previous period does depend on income. Your state in the second period does depend on income. Specifically there is a <em>counterfactual</em> dependence—income causes a state to be democratic even if it does not cause it to <em>transition to</em> democracy. The effect of income may well be asymmetric depending on whether you start as a democracy or start as an autocracy but this asymmetry has to be be captured by the specification of the functional relations; it is not captured by the graph.</p>
<p>For a parametric representation of this asymmetric relationship we can specify a function in which <span class="math inline">\(GDP\)</span> can reduce the likelihood of a transition <em>away</em> from democracy but does affect the probability of a transition <em>to</em> democracy, which should be exogenously determined. One possible translation of the argument into functional terms is:</p>
<p><span class="math display">\[D_t = \mathbb{1}(\theta^{D_t} + (1-D_{t-1})p + D_{t-1}Y_{t-1}q) &gt; 0)\]</span></p>
<!-- FLAG: Get proper indicator function \mathbb{1} -->
<p>where</p>
<ul>
<li><span class="math inline">\(D_t\)</span> and <span class="math inline">\(D_{t-1}\)</span> are binary, representing current and last-period democracy, respectively</li>
<li><span class="math inline">\(p\)</span> is a parameter representing the probability that an autocracy democratizes</li>
<li><span class="math inline">\(q\)</span> is a parameter representing the probability that a democracy with a GDP of 1 remains democratic</li>
<li><span class="math inline">\(Y_{t-1}\)</span> represents national per capita GDP, scaled to 0-1.</li>
<li><span class="math inline">\(\theta^{D_t}\)</span> represents a random, additional input into democracy</li>
<li>the indicator function, <span class="math inline">\({1}\)</span>, evaluates the inequality and generates a value of <span class="math inline">\(1\)</span> if and only if it is true</li>
</ul>
<p>Unpacking the equation, the likelihood that a country is a democracy in a given period rises and falls with the expression to the left of the inequality operator. This expression itself has two parts, reflecting the difference between the determinants of <em>transitions to</em> democracy (captured by the first part) and the determinants of democratic <em>survival</em> (captured by the second). The first part comes into play—i.e., is non-zero—only for non-democracies. For non-democracies, the expression evaluates simply to <span class="math inline">\(p\)</span>, the exogenous probability of democratization. The second part is non-zero only for democracies, where it evaluates to <span class="math inline">\(q\)</span> times <span class="math inline">\(Y_{t-1}\)</span>: thus, remaining democratic is more likely as national income rises. The inequality is then evaluated by asking whether the expression on the left passes a threshold. Thus, higher values for the expression increase the likelihood of democracy while the randomness of the <span class="math inline">\(\theta^{D_t}\)</span> threshold captures the role of other, idiosyncratic inputs. The mean and variance of <span class="math inline">\(\theta^{D_t}\)</span> capture the overall likelihood of being a democracy as well as the importance of unspecified factors.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> In a model like this it would be natural to seek to estimate parameters <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> as well as trying to understand the distribution of <span class="math inline">\(\theta^{D_t}\)</span>.</p>
<p>We can also represent the asymmetry in the binary set up with causal types that we developed in the last chapter.</p>
<p>Type <span class="math inline">\(\theta^{D_t}_{0001}\)</span> is a type for which the regime type <em>will stay as they are</em> if they are wealthy, but will become authoritarian if they are not wealthy. To be clear, wealth still affects whether or not a state is a democracy, rather than an autocracy, in this period–counterfactually—but wealth does not make a non democracy become a democracy. In other words it causes a case to <em>be</em> a democracy but not to <em>become</em> a democracy. This type can be distinguished from a <span class="math inline">\(\theta^{D_t}_{0011}\)</span> type in which a non democracy becomes a democracy when income is high.</p>
<p>Although we do not engage with dynamic models in this book, it is instructive to think through the implications of a distribution of causal types for a dynamic process. Say we were to imagine that income were constant but that in each period one half of units were of type <span class="math inline">\(\theta^{D_t}_{0001}\)</span>, and one half of type <span class="math inline">\(\theta^{D_t}_{1111}\)</span> (with types drawn afresh each period). Say that in an initial period, half the units were democracies and half had high income and there was no relation between these two features. Then in the next period we would have that
half of cases would be democracies (regardless of income), half of which would be surviving democracies and half new democracies; of the other half, one quarter would be surviving democracies (surviving <em>because of</em> their income), and the other three quarters would be autocracies, one third of which would be “backsliders” because of their poverty. Similar transitions occur in future periods until eventually the wealthy states are all stable democracies and the poorer states transition between democracy and autocracy back and forth randomly each period.</p>
<p>In this approach there are no parameters <span class="math inline">\(p\)</span> or <span class="math inline">\(q\)</span> to be estimated. Rather the focus is entirely on the distribution of nodal types.</p>
<!--    T1  A   D   T2  A   D   T3 -->
<!-- AP 16  8   8   16  8   8   16 -->
<!-- AR 16  8   8   8   4   4   4 -->
<!-- DP 16  8   8   16  8   8   16 -->
<!-- DR 16  0   16  24  0   24  28 -->

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-boix2003democracy" class="csl-entry">
Boix, Carles. 2003. <em>Democracy and Redistribution</em>. New York: Cambridge University Press.
</div>
<div id="ref-pierson1994dismantling" class="csl-entry">
Pierson, Paul. 1994. <em>Dismantling the Welfare State?: Reagan, Thatcher and the Politics of Retrenchment</em>. Cambridge University Press.
</div>
<div id="ref-przeworski1997modernization" class="csl-entry">
Przeworski, Adam, and Fernando Limongi. 1997. <span>“Modernization: Theories and Facts.”</span> <em>World Politics</em> 49 (2): 155–83.
</div>
<div id="ref-saunders2011leaders" class="csl-entry">
Saunders, Elizabeth N. 2011. <em>Leaders at War: How Presidents Shape Military Interventions</em>. Cornell University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="27">
<li id="fn27"><p>In DAG syntax, this correlation can be captured by placing the common cause(s) explicitly on the graph or by drawing a dashed line between the correlated nodes, leaving the source of the correlation unspecified.<a href="illustratemodels.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>In notation that we use later, these beliefs would be represented with a <span class="math inline">\(\lambda^R\)</span> vector.<a href="illustratemodels.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Note how, while the functional equation nails down certain features of the process, it leaves others up for grabs. In particular, the parameters <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are assumed to be constant for all autocracies and for all democracies, respectively, but their values are left unspecified. And one could readily write down a function that left even more openness—by, for instance, including an unknown parameter that translates <span class="math inline">\(y\)</span> into a change in the probability of reversion or allowing for non-linearities, with unknown parameters, in this effect.<a href="illustratemodels.html#fnref29" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="questions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
