<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 Justifying models | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 Justifying models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 Justifying models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="caseselection.html"/>
<link rel="next" href="evaluation.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#exercises"><i class="fa fa-check"></i><b>9.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>10</b> Mixing models</a><ul>
<li class="chapter" data-level="10.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>10.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="10.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>10.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="10.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>10.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="10.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>10.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="11" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>11</b> Elements of Design</a><ul>
<li class="chapter" data-level="11.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>11.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="11.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>11.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>11.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="11.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>11.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="11.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>11.2.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>11.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>13</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="13.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a></li>
<li class="chapter" data-level="13.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>13.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="13.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>13.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="13.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>13.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>13.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="13.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>13.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="13.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>13.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="13.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>13.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="13.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>13.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="13.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>13.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>14.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>14.2</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>14.3</b> Explorations</a><ul>
<li class="chapter" data-level="14.3.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>14.3.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.4</b> Principles</a><ul>
<li class="chapter" data-level="14.4.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>14.4.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="14.4.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>14.4.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="14.4.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>14.4.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
<li class="chapter" data-level="15.5" data-path="justifying-models.html"><a href="justifying-models.html#exercise"><i class="fa fa-check"></i><b>15.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>17.1</b> General lessons</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>17.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>17.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="17.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>17.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="justifying-models" class="section level1">
<h1><span class="header-section-number">Chapter 15</span> Justifying models</h1>
<div class="headerbox">
<div class="center">

</div>
<p>We outline strategies to reduce reliance on unfounded beliefs about the probative value of clues.</p>
</div>
<p><br></p>
<p>The approach we have described to inference always involve updating beliefs given data. But to get off the ground researchers need to be able to state priors on all parameters.</p>
<p>The problem of stating priors for process tracing inferences can be more fundamental than for many Bayesian applications for two reasons. First the beliefs are beliefs over the distribution of individual level effects and not just the beliefs over average effects. This puts us up against the fundamental problem of causal inference <span class="citation">(Holland <a href="#ref-holland1986statistics" role="doc-biblioref">1986</a>)</span>. Second, the beliefs can do a lot of work—especially in small <span class="math inline">\(n\)</span> applications. Indeed for case level queries, inferences might be little more than conditional applications of a model.</p>
<p>We see two broad responses to this problem.</p>
<p>One is <em>emphasize the contingent nature of claims</em>. As we outlined in Chapter 4, some causal models might reasonably reflect actual beliefs about the world—for example one might, be convinced that a treatment was randomly assigned, that there is no interference, and that units are independently sampled from a distribution of types. All of these beliefs may be unwise, of course. But if held, then simple models such as that represented by an <span class="math inline">\(X \rightarrow Y\)</span> DAG is a representation of coarse beliefs about the world and not a model of the world, in the sense of a representation of a simplified world.<a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a> But as we noted in Chapter 4, for an even modestly more complex situation, it seems inevitable that the model being used really is a model and hard to think of as a faithful summary of beliefs.</p>
<p>Recognizing that we are generally dealing with models results in a useful reposing of the question: the question becomes not whether the assumptions are correct but whether the model is useful for some purpose <span class="citation">(Clarke and Primo <a href="#ref-clarke2012model" role="doc-biblioref">2012</a>)</span>. That is the subject of Chapter 15.</p>
<p>A second approach is to justify a process tracing model by claiming exchangeability with units for which we have a lower level model. In a sense, this approach pushes the question down a level, since the lower level model itself needs to be justified. There are two further responses to this concern. One is to justify the lower level model with data or a combination of data and theory. We discuss this approach here. Another is to assess the importance of DAG assumptions – which we address in Chapter 16.</p>
<div id="nothing-from-nothing" class="section level2">
<h2><span class="header-section-number">15.1</span> Nothing from nothing</h2>
<p>We start with a fairly negative result. Many of the models we have looked at—especially for process tracing—have a lot of structure, viz:</p>
<ul>
<li>conditional independence assumptions</li>
<li>no confounding assumptions, and</li>
<li>monotonicity assumptions, or other restrictions</li>
</ul>
<p>What happens if you have none of these? Can access to observational data render clues meaningful for inferences on causal effects?</p>
<p>We show the scope for learning from a mediator for a “good case”—a world in which in fact (though unknown <em>ex ante</em> to the researcher):</p>
<ul>
<li>You have access to large amounts of observational data on <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> and <span class="math inline">\(M\)</span>.</li>
<li>In fact <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> through <span class="math inline">\(M\)</span></li>
<li><span class="math inline">\(X\)</span> is a necessary condition for <span class="math inline">\(M\)</span> and <span class="math inline">\(M\)</span> is a sufficient condition for <span class="math inline">\(Y\)</span> – and so <span class="math inline">\(Y\)</span> is monotonic in <span class="math inline">\(X\)</span> and</li>
<li>There is, in fact, no confounding</li>
</ul>
<p>We imagine inferences are made starting from two types of model. In both we allow all possible links and we impose no restrictions on nodal types. Even though there are only three nodes, this model has 128 causal types (<span class="math inline">\(2\times 4 \times 16\)</span>). In addition:</p>
<ul>
<li><p>In <code>model_1</code> we allow confounding between all pairs of nodes. This results in 127 free parameters.</p></li>
<li><p>In <code>model_2</code> we assume that <span class="math inline">\(X\)</span> is known to be randomized. There are now only 64 free parameters.</p></li>
</ul>
<div class="figure"><span id="fig:unnamed-chunk-18"></span>
<img src="ii_files/figure-html/unnamed-chunk-18-1.png" alt="Two models. The model on the right might be justified if $X$ is known to be randomized." width="672" />
<p class="caption">
Figure 15.1: Two models. The model on the right might be justified if <span class="math inline">\(X\)</span> is known to be randomized.
</p>
</div>
<p>After updating we query the models to see how inferences depend on <span class="math inline">\(M\)</span> like this:</p>
<table>
<caption><span id="tab:unnamed-chunk-19">Table 15.1: </span>Can observation of large N data render mediator <span class="math inline">\(M\)</span> informative for case level inference? Case 1: No knowledge of structure; Case 2: X known to be randomized. Posterior sd in parentheses.</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="left">Case 1</th>
<th align="left">Case 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">posteriors</td>
<td align="left">0.499</td>
<td align="left">0.811</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.156)</td>
<td align="left">(0.029)</td>
</tr>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; M==1 &amp; Y==1</td>
<td align="left">posteriors</td>
<td align="left">0.499</td>
<td align="left">0.828</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.166)</td>
<td align="left">(0.032)</td>
</tr>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; M==0 &amp; Y==1</td>
<td align="left">posteriors</td>
<td align="left">0.5</td>
<td align="left">0.525</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.138)</td>
<td align="left">(0.164)</td>
</tr>
</tbody>
</table>
<p>We find that even with an auspicious monotonic data generating process in which <span class="math inline">\(M\)</span> is a total mediator, <span class="math inline">\(M\)</span> gives no traction on causal inference in Case 1. In contrast it gives considerable leverage in Case 2: <span class="math inline">\(M\)</span> is informative, especially if <span class="math inline">\(M=0\)</span> (in which case we downgrade confidence that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span>), when <span class="math inline">\(X\)</span> is known to be randomized.</p>
<p>This example illustrates the Cartwight idea we pointed to in Chapter 2: no causes in, no causes out <span class="citation">(Cartwright and others <a href="#ref-cartwright1994nature" role="doc-biblioref">1994</a>)</span>. It poses, we think, a challenge to process tracing approaches: observational data alone is not sufficient to generate a justification for process tracing inferences for 3 node problems <em>even when in reality</em> causal structures are simple.</p>
</div>
<div id="justifying-the-classic-process-tracing-tests" class="section level2">
<h2><span class="header-section-number">15.2</span> Justifying the classic process tracing tests</h2>
<p>Now, more positively, we who the possibility of justification of each of the four classical “qualitative tests” described by <span class="citation">Collier (<a href="#ref-collier2011understanding" role="doc-biblioref">2011</a>)</span> and drawing on <span class="citation">Van Evera (<a href="#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span>, at least when treatment assignment is randomized.</p>
<p>Recall the four tests are “smoking gun” tests, “hoop” tests, “doubly decisive” tests, and “straw-in-the-wind” tests. A hoop test is one which, if failed, bodes especially badly for a claim; a smoking gun test is one that bodes well for a hypothesis if passed; a doubly decisive test is strongly conclusive no matter what is found, and a straw-in-the-wind test is suggestive, though not conclusive, either way.</p>
<p>In some treatments (such as <span class="citation">Humphreys and Jacobs (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>), formalization involves specifying a prior that a hypothesis is true and an independent set of beliefs about the probability of seeing some data if the hypothesis is true and if it is false. Then updating proceeds using Bayes’ rule.</p>
<p>This simple approach suffers from two related weaknesses however: first, there is no good reason to expect these probabilities to be independent; second, there is nothing in the set-up to indicate how beliefs around the probative value of clues can be established or justified.</p>
<p>Both of these problems are resolvable if the problem is articulated using fully specified causal models.</p>
<p>We illustrate first by using an idealized example to show that a case level “doubly decisive” test can be justified by population data from factorial designs.</p>
<p>Say we have from observing just <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> that <span class="math inline">\(\Pr(Y=1|X=1) = \Pr(Y=1|X=0) = .5\)</span>. Here we have an average treatment effect of 0. We are interested in a particular case with <span class="math inline">\(X=1, Y=1\)</span> and specifically whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> in that case. The marginal information so far is consistent with a world in which <span class="math inline">\(X\)</span> never affects <span class="math inline">\(Y\)</span> and one in which <span class="math inline">\(X\)</span> always affects <span class="math inline">\(Y\)</span> (sometimes negatively, sometimes positively).</p>
<p>Say now that we had data on <span class="math inline">\(K\)</span> and found (a) that <span class="math inline">\(K=1\)</span> arises with 50% probabilities, and (b) that the marginal distributions of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span> are as follows:</p>
<ul>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 0) = 1\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 0) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 1) = 0\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 1) = .5\)</span></li>
</ul>
<p>In that case we see that in cases in which <span class="math inline">\(K=1\)</span>, <span class="math inline">\(X=0\)</span> is a necessary condition for <span class="math inline">\(Y=1\)</span>. So if <span class="math inline">\(K=1\)</span> then certainly <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> (since, in that case, were <span class="math inline">\(X\)</span> zero then certainly <span class="math inline">\(Y\)</span> would be 0.) On the other hand were <span class="math inline">\(K=0\)</span> then <span class="math inline">\(X=0\)</span> would be a sufficient condition for <span class="math inline">\(Y=1\)</span>, which means that in this case <span class="math inline">\(X=1\)</span> most certainly did <em>not</em> cause <span class="math inline">\(Y=1\)</span>. We have then that if <span class="math inline">\(K=1\)</span> then certainly <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> whereas if <span class="math inline">\(K=0\)</span> then certainly <span class="math inline">\(X=1\)</span> did not cause <span class="math inline">\(Y=1\)</span></p>
<p>This argument demonstrates that it is possible to justify a doubly decisive test on the basis of experimental data—provided your case can be considered exchangeable with cases in the experimental data.</p>
<p>Table <a href="justifying-models.html#tab:tests15">15.2</a> shows how this logic generalizes to different types of tests.</p>
<table>
<caption><span id="tab:tests15">Table 15.2: </span>Known probabilities from a model with <span class="math inline">\(X \rightarrow Y \leftarrow K\)</span> justifying classic test types for clue <span class="math inline">\(K\)</span> given <span class="math inline">\(X=Y=1\)</span>.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">Doubly decisive</th>
<th align="center">Hoop</th>
<th align="center">Smoking gun</th>
<th align="center">Straw in the wind</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\Pr(K = 1)\)</span></td>
<td align="center">0.5</td>
<td align="center">0.9</td>
<td align="center">1</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Pr(Y=1 \vert X=0, K = 0)\)</span></td>
<td align="center">1.0</td>
<td align="center">1</td>
<td align="center">4/9</td>
<td align="center">0.6</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Pr(Y=1 \vert X=1, K = 0)\)</span></td>
<td align="center">0.5</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Pr(Y=1 \vert X=0, K = 1)\)</span></td>
<td align="center">0.0</td>
<td align="center">0.44</td>
<td align="center">0</td>
<td align="center">0.4</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Pr(Y=1 \vert X=1, K = 1)\)</span></td>
<td align="center">0.5</td>
<td align="center">4/9</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Pr(X \text{  causes }Y \vert K=1)\)</span></td>
<td align="center">1.0</td>
<td align="center"></td>
<td align="center">1</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Pr(X \text{  causes }Y \vert K=0)\)</span></td>
<td align="center">0.0</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p><span style="color: orange;">Flag!</span> Put bounds in empty cells.</p>
<p>Note hat some entries in Table <a href="justifying-models.html#tab:tests15">15.2</a> were given as ranges. This reflects that fact that unless we are at edge cases the estimand here is not identified even with infinite experimental data. In practice we expect never to be at these edges. Even still, the procedures given in Chapters XX above let us form posteriors over inferences with finite data.</p>
<p>For the illustration we first make use of a function that generates data from a model with a constrained set of types for <span class="math inline">\(Y\)</span> and a given prior distribution over clue <span class="math inline">\(K\)</span>.</p>
<p>We then use a function that draws inferences, given different values of a clue <span class="math inline">\(K\)</span>, from a model that has been updated using available data. Note that the model that is updated has no constraints on <span class="math inline">\(Y\)</span>, has flat beliefs over the distribution of <span class="math inline">\(K\)</span>, and imposes no assumption that <span class="math inline">\(K\)</span> is informative for how <span class="math inline">\(Y\)</span> reacts to <span class="math inline">\(X\)</span>.</p>
<p>We can now generate posterior beliefs, given <span class="math inline">\(K\)</span>, for different types of tests where the tests are now justified by different types of data, coupled with a common prior causal model.</p>
<p>Results:</p>
<table>
<caption><span id="tab:unnamed-chunk-21">Table 15.3: </span>Classic tests with probative value inferred from (simulated) data</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="left">Doubly decisive</th>
<th align="left">Hoop</th>
<th align="left">Smoking gun</th>
<th align="left">Straw in the Wind</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">-</td>
<td align="left">posteriors</td>
<td align="left">0.489</td>
<td align="left">0.451</td>
<td align="left">0.536</td>
<td align="left">0.469</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.016)</td>
<td align="left">(0.022)</td>
<td align="left">(0.022)</td>
<td align="left">(0.022)</td>
</tr>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">K==0</td>
<td align="left">posteriors</td>
<td align="left">0.009</td>
<td align="left">0.044</td>
<td align="left">0.493</td>
<td align="left">0.301</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.005)</td>
<td align="left">(0.028)</td>
<td align="left">(0.024)</td>
<td align="left">(0.029)</td>
</tr>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">K==1</td>
<td align="left">posteriors</td>
<td align="left">0.976</td>
<td align="left">0.494</td>
<td align="left">0.9</td>
<td align="left">0.637</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">(0.008)</td>
<td align="left">(0.023)</td>
<td align="left">(0.037)</td>
<td align="left">(0.03)</td>
</tr>
</tbody>
</table>
<p>We see that these tests all behave as expected. Importantly, however, the approach to thinking about the tests is quite different to that described in <span class="citation">Collier (<a href="#ref-collier2011understanding" role="doc-biblioref">2011</a>)</span> or <span class="citation">Humphreys and Jacobs (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>. Rather than having a belief about the probative value of a clue, and a prior over a hypothesis, inferences are drawn directly from a causal model that relates a clue to possible causal effects. Critically, with this approach, the inferences made from observing clues can be justified by reference to a more fundamental, agnostic model, that has been updated in light of data. The updated model yields both a prior over the proposition, belief about probative values, and guidance for what conclusions to draw given knowledge of <span class="math inline">\(K\)</span>.</p>
<!-- ## Bounds on probative value -->
<!-- Classic treatments of process tracing make use of Causal Process Observations --- observations that are taken to be indicative of a particular causal process in operation. We introduced in Chapter 5 (as well as in FLAG CITE humphreysjacobs)  quantities such as $\phi_{b}$---the probability that $K=1$ given $X$ caused $Y$ and $X=Y=1$, or $\phi_{d}$-----the probability that $K=1$ given $X$ did not cause $Y$ and $X=Y=1$.  -->
<!-- These accounts do not guide much guidance however regarding where these quantities come from --- given that causal types are unobservable how can one justify a belief about the probability of some observation *given* a causal type. Is it even possible to justify such beliefs? -->
<!-- The grounded approach we described provides an answer to this puzzle. In short, knowledge of the structure of a causal model, together with data on exchangeable units, can be enough to place bounds on possible values of $\phi_{b}, \phi_{d}$.  -->
<!-- We illustrate the basic idea and then review some results in this area. -->
<!-- Imagine a fortunate situation in which (a) it is known that the true causal model has the form $X \rightarrow M \rightarrow Y$ and (b) we have a lot of experimental data on the conditional distribution of $M$ given $X$ and of $Y$ given $M$ for exchangeable units (meaning that we can treat our unit of interest as if it were a draw from this set).  -->
<!-- Let us define: -->
<!-- * $\tau_1 = \Pr(M=1 | X=1) - \Pr(M=1 | X=0)$ -->
<!-- * $\rho_1 = \Pr(M=1 | X=1) - \Pr(M=0 | X=0)$ -->
<!-- * $\tau_2 = \Pr(Y=1 | M=1) - \Pr(Y=1 | M=0)$ -->
<!-- * $\rho_2 = \Pr(Y=1 | M=1) - \Pr(Y=0 | M=0)$ -->
<!-- These are all quantities that can be calculated from the data. The $\tau$s are average treatment effects and the $\rho$s are indicators for how common the $Y=1$ outcome is. -->
<!-- We are interested in the probability of observing $M=1$ given $X=Y=1$: -->
<!-- $$\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + \lambda_{a}^K\lambda_{a}^Y}$$ -->
<!-- Noting that $\tau_j = \lambda_{b_j} - \lambda_{a_j}$: -->
<!-- $$\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + (\lambda_{b}^K-\tau_1)(\lambda_{b}^Y - \tau_2)}$$ -->
<!-- which we can see is decreasing in $\lambda_{b}^j$ (this may seem counterintuitive, but the reason is that with $\tau^j$ fixed, lower $\lambda_{b}^j$ also means lower $\lambda_{a}^j$ which means less ambiguity about *how* $X$ affects $Y$ (i.e. through positive or negative effects on $K$). -->
<!--  <!-- $$\phi_{1} = \frac{\lambda_{b}^Y}{2\lambda_{b}^Y -\tau_2 - \tau_1(\lambda_{b}^Y - \tau_2)/\lambda_{b}}^K$$ -->
<!-- The lowest permissible value of  $\lambda_{b_j}$  is $\tau_j$, yielding $\phi_{b1} = 1$.  -->
<!-- The highest value obtainable by $\lambda_{b_j}$ is when $\lambda_{a_j} = \frac{1-\tau_j+\rho_j}2$ and so $\lambda_{b_j} = \frac{1+\tau_j+\rho_j}2$.  -->
<!-- In this case: -->
<!-- $$\phi_{b1} = \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2) + (1-\tau_1+\rho_1)(1-\tau_2+\rho_2)}= \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau}$$ -->
<!-- And so: -->
<!-- $$\frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau_2} \leq \phi_{b1} \leq 1$$ -->
<!-- These are the bounds on $\phi_{b1}$. We can calculate bounds on $\phi_{d1}$ in a similar way (though of course the bounds on  $\phi_{b1}$ and $\phi_{d1}$ are not independent).  -->
<!-- $$\phi_{d1} = \frac{\lambda_{b}^K\lambda_{d}^Y}{(\lambda_{a}^K + \lambda_{b}^K + \lambda_{c}^K)\lambda_{d}^Y+ \lambda_{c}^K\lambda_{a}^Y}$$ -->
<!-- Figure \@ref(fig:probval1) illustrates how "smoking gun" and "hoop" tests might each be justified with knowledge of $\tau_j, \rho_j$.  -->
<!-- ```{r phis85, echo = FALSE, include = FALSE} -->
<!-- make_phis <- function(model = make_model("X -> M -> Y"),  -->
<!--                         par = c(.5, .5, .3, 0, .6, .1, .1, 0, .6, .3), -->
<!--                         n = 60000){ -->
<!--   data <- simulate_data(model,  -->
<!--                         n = n, -->
<!--                         parameters = par,  -->
<!--                         using = "parameters")  -->
<!--   m1 <- with(data, c(mean(M[X==0]), mean(M[X==1]))) -->
<!--   m1[2] - m1[1]; m1[2] - 1 + m1[1] -->
<!--   m2<- with(data, c(mean(Y[M==0]), mean(Y[M==1]))) -->
<!--   m2[2] - m2[1]; m2[2] - 1 + m2[1] -->
<!--   if(!exists("fit")) fit <- fitted_model() -->
<!--   updated <- CausalQueries(model, data, stan_model = fit) -->
<!--   # check <- rstan::extract(updated$posterior, pars= "lambdas")$lambdas -->
<!--   phi_b_num <- query_distribution(updated, query = "(M==1) & (Y[X=0]==0)", subset = "X==1 & Y==1", using = "posteriors") -->
<!--   phi_b_denom <- query_distribution(updated, query = "(Y[X=0]==0)", subset = "X==1 & Y==1", using = "posteriors") -->
<!--   phi_b <- phi_b_num/phi_b_denom -->
<!--   phi_d_num <- query_distribution(updated, query = "(M==1) & (Y[X=0]==1)", subset = "X==1 & Y==1", using = "posteriors") -->
<!--   phi_d_denom <- query_distribution(updated, query = "(Y[X=0]==1)", subset = "X==1 & Y==1", using = "posteriors") -->
<!--   phi_d <- phi_d_num/phi_d_denom -->
<!--   out <- data.frame(phi_b, phi_d) -->
<!--   out -->
<!--   } -->
<!-- plot_phi <- function(out, main = "bounds"){ -->
<!--     plot(out$phi_d, out$phi_b, xlim = c(0,1), ylim = c(0,1), cex = .5, main = main,  -->
<!--        xlab = expression(phi[d]), ylab = expression(phi[b])) -->
<!--   abline(0,1) -->
<!-- } -->
<!-- ``` -->
<!-- ```{r writephis, include = FALSE} -->
<!-- if(do_diagnosis){ -->
<!--   phis1  <- make_phis(model = make_model("X -> M -> Y"),  -->
<!--                         par = c(.5, .5, .3, 0, .6, .1, .1, 0, .6, .3), -->
<!--                         n = 80000) -->
<!--   write_rds(phis1, "saved/phis_1.rds") -->
<!--   phis2  <- make_phis(model = make_model("X -> M -> Y"),  -->
<!--                         par = c(.5, .5,  -->
<!--                                 .95, 0, 0, .05,  -->
<!--                                 .95, 0, 0, .05), -->
<!--                         n = 80000) -->
<!--   write_rds(phis2, "saved/phis_2.rds") -->
<!-- } -->
<!-- ``` -->
<!-- ```{r plotphis, echo = FALSE} -->
<!-- phis1 <- read_rds("saved/phis_1.rds") -->
<!-- phis2 <- read_rds("saved/phis_2.rds") -->
<!-- par(mfrow = c(1,2)) -->
<!-- plot_phi(phis1, -->
<!--          main = expression(paste("Hoop: ", tau[1], "= .6, ", -->
<!--                                            rho[1], "= -.2, ", -->
<!--                                            tau[2], "= .6, ", -->
<!--                                            rho[2], "= .2")) -->
<!--          ) -->
<!-- plot_phi(phis2, -->
<!--           main = expression(paste("Smoking gun: ",  -->
<!--                                   tau[1], "= 0, ", -->
<!--                                   rho[1], "= -.9, ", -->
<!--                                   tau[2], "= 0, ", -->
<!--                                   rho[2], "= -.9")) -->
<!--          ) -->
<!-- ``` -->
<!-- <!-- plot_bounds(.6, -.2, .6, .2, 20, main = expression(paste("Hoop: ", tau[1], "= .6, ", -->
<!-- <!--                                                             rho[1], "= -.2, ", -->
<!-- <!--                                                             tau[2], "= .6, ", -->
<!-- <!--                                                             rho[2], "= .2"))) -->
<!-- <!-- plot_bounds(0.0, -.9, .0, -.9, 100, main = expression(paste("Smoking gun: ", tau[1], "= 0, ", -->
<!-- <!--                                                             rho[1], "= -.9, ", -->
<!-- <!--                                                             tau[2], "= 0, ", -->
<!-- <!--                                                             rho[2], "= -.9, "))) -->
<!-- <!-- ``` -->
<!-- <!-- ```{r, eval = FALSE, echo = FALSE} -->
<!-- <!-- # An odd one! -->
<!-- <!-- plot_bounds(.02, -.5, -.10, -.5,600) -->
<!-- <!-- ``` -->
<!-- For the smoking gun,  $\phi_{b1}$ is .5 because $\lambda_a^j = \lambda_b^j$ so half of the upper level $b$ types work through a positive effect on $M$ and half through a negative effect on $M$. $\phi_{d1}$, on the other hand, is low here $d$ types mostly arise because of $c$ types in the first step and $a$ types in the second, and hence most commonly with $M=1$.  -->
<!-- Whether the bounds map into useful probative value depends in part on whether causal effects are better identified in the first or the second stage. We can see this in Figure \@ref(fig:probval2). -->
<!-- The key difference between the panels is that $\phi_d$ is constrained to be low in the first panel but not in the second.  -->
<!-- For intuition note that a higher level $d$ type will exhibit $M=1$ if it is formed via $db$, $bd$,or $dd$ and it will exhibit $M=0$ if it is formed via $ca$, $cd$, $ad$. The weak second stage makes it possible that there are no second stage d types, only a and b types. The stronger first stage makes it possible that there are no first stage $c$ types. In that case the higher level d types are formed uniquely of $db$ types -- which always exhibit $M=1$ if $X=1$. -->
<!-- This is not possible however for the data assume in the first panel. In the first panel the the higher value on $\rho_2$ means that there must be at least .25 d types. And the weak first stage means that there must at least .5 a and c types combined. Thus there *must* be a set of cases in which $M$ is not observed even though we have an upper level d type. -->
<!-- ```{r probval2, echo = FALSE, fig.width = 10, fig.cap = "Probative value with different first and second stage relations"} -->
<!-- # par(mfrow = c(1,2)) -->
<!-- #  -->
<!-- # plot_bounds(0, 0, .25, .25, 20, main = expression(paste("Weak first stage: ", tau[1], "= 0, ", -->
<!-- #                                                             rho[1], "= 0, ", -->
<!-- #                                                             tau[2], "= .25 ", -->
<!-- #                                                             rho[2], "= .25"))) -->
<!-- #  -->
<!-- # plot_bounds(.25, .25, 0, 0, 20, main = expression(paste("Weak second stage: ", tau[1], "= .25, ", -->
<!-- #                                                             rho[1], "= .25, ", -->
<!-- #                                                             tau[2], "= 0, ", -->
<!-- #                                                            rho[2], "= 0"))) -->
<!-- if(do_diagnosis){ -->
<!--   phis3  <- make_phis(model = make_model("X -> M -> Y"),  -->
<!--                         par = c(.5, .5,  -->
<!--                                 .25, .25, .25, .25,  -->
<!--                                 .25, 0, .25, .5), -->
<!--                         n = 50000) -->
<!--   write_rds(phis3, "saved/phis_3.rds") -->
<!--   phis4  <- make_phis(model = make_model("X -> M -> Y"),  -->
<!--                         par = c(.5, .5,  -->
<!--                                 .25, 0, .25, .5, -->
<!--                                 .25, .25, .25, .25), -->
<!--                         n = 50000) -->
<!--   write_rds(phis4, "saved/phis_4.rds") -->
<!-- } -->
<!-- phis3 <- read_rds("saved/phis_3.rds") -->
<!-- phis4 <- read_rds("saved/phis_4.rds") -->
<!-- par(mfrow = c(1,2)) -->
<!-- plot_phi(phis3, -->
<!--          main = expression(paste("Hoop: ", tau[1], "= 0, ", -->
<!--                                                             rho[1], "= 0, ", -->
<!--                                                             tau[2], "= .25, ", -->
<!--                                                             rho[2], "= .25"))) -->
<!-- plot_phi(phis4, -->
<!--           main = expression(paste("Smoking gun: ",  -->
<!--                                   tau[1], "= .25, ", -->
<!--                                   rho[1], "= .25, ", -->
<!--                                   tau[2], "= 0, ", -->
<!--                                   rho[2], "= 0, "))) -->
<!-- ``` -->
<!-- In short we emphasize that difficult as it might seem at first it is possible to put relatively tight bounds on probative value for causal types with access to experimental data on exchangeable units.  -->
</div>
<div id="justification-from-experimental-designs" class="section level2">
<h2><span class="header-section-number">15.3</span> Justification from experimental designs</h2>
<p>idea: show inferences given for example parallel designs for mediation</p>
<div id="mediator" class="section level3">
<h3><span class="header-section-number">15.3.1</span> Mediator</h3>
<p>Say now that <em>in addition</em> we know from experimental data, that <span class="math inline">\(K\)</span> mediates the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; indeed we will assume that we have a case of complete mediation, such that, conditional on <span class="math inline">\(K\)</span>, <span class="math inline">\(Y\)</span> does not depend on <span class="math inline">\(X\)</span>.</p>
<p>Say the transition matrices from <span class="math inline">\(X\)</span> to <span class="math inline">\(K\)</span> and <span class="math inline">\(K\)</span> to <span class="math inline">\(Y\)</span> are:</p>
<p><span class="math display">\[P^{xk}=\left( \begin{array}{cc} 1 &amp; 0 \\ 1/2 &amp; 1/2\end{array}\right), P^{ky}=\left( \begin{array}{cc} 1/2 &amp; 1/2 \\ 0 &amp; 1\end{array}\right)\]</span>
Even without observing <span class="math inline">\(K\)</span>, this information is sufficient to place a prior on PC of <span class="math inline">\(p=\frac13\)</span>.</p>
<p>To see this, note that we can calculate:</p>
<ul>
<li><span class="math inline">\(\lambda_a^K =0\)</span>, <span class="math inline">\(\lambda_b^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_d^K = 0\)</span></li>
<li><span class="math inline">\(\lambda_a^Y =0\)</span>, <span class="math inline">\(\lambda_b^Y=\frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^Y=0\)</span>, <span class="math inline">\(\lambda_d^Y=\frac{1}{2}\)</span></li>
</ul>
<p>and so:</p>
<ul>
<li><span class="math inline">\(\lambda_b^u = \lambda_b^K\lambda_b^Y = \frac{1}4\)</span></li>
<li><span class="math inline">\(\lambda_d^u = \lambda_d^Y\)</span></li>
<li><span class="math inline">\(p = \frac{\lambda_b^u}{\lambda_b^u + \lambda_d^u} = \frac{1}3\)</span>.</li>
</ul>
<p>whence:</p>
<ul>
<li><span class="math inline">\(\phi_{b1} = 1\)</span></li>
<li><span class="math inline">\(\phi_{d1} = \lambda_d^K + \lambda_b^K = \frac{1}{2}\)</span></li>
</ul>
<p>More generally we can calculate the lower bound on the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> as the product of the lower bounds that <span class="math inline">\(X\)</span> caused <span class="math inline">\(M\)</span> and that <span class="math inline">\(M\)</span> caused <span class="math inline">\(Y\)</span>, and similarly for the upper bound, using the same formula as before. Signing things so that <span class="math inline">\(\tau^j\geq 0\)</span>, <span class="math inline">\(j \in {1,2}\)</span>:</p>
<p><span class="math display">\[\frac{2\tau_1}{1+\tau_1+\rho_1}\frac{2\tau_2}{1+\tau_2+\rho_2}  \leq PC \leq \frac{1+\tau_1-|\rho_1|}{1+\tau_1+\rho_1}\frac{1+\tau_2-|\rho_2|}{1+\tau_2+\rho_2} \]</span></p>
<p>We have undertaken essentially the same operations as above except that now we are placing bounds on a substantive estimand of interest rather than first placing bounds on probative value of a clue and then turning to Bayes rule to place bounds on the estimand.</p>
</div>
<div id="moderator" class="section level3">
<h3><span class="header-section-number">15.3.2</span> Moderator</h3>
<p>Consider now a situation in which our case is drawn from a set of cases for which <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span> were each randomly assigned. Say then that the transition matrices, conditional on <span class="math inline">\(K\)</span> look as follows:</p>
<p><span class="math display">\[P^{K=0}=\left( \begin{array}{cc} 0 &amp; 1 \\ 0.5 &amp; 0.5 \end{array}\right), P^{K=1}=\left( \begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \end{array}\right)\]</span>
In this case we can now identify PC, even before observing <span class="math inline">\(K\)</span>. If <span class="math inline">\(K=0\)</span>, PC is 0—there are no cases with positive effects in this condition. If <span class="math inline">\(K=1\)</span> PC = 1. We have a prior that <span class="math inline">\(K=1\)</span> of .5 and after observing <span class="math inline">\(X=Y=1\)</span> we raise this to <span class="math inline">\(2/3\)</span>. Thus our prior belief on <span class="math inline">\(PC\)</span> — before seeing <span class="math inline">\(K\)</span>— is <span class="math inline">\(2/3 * 1 + 1/3 * 0 = 2/3\)</span>.</p>
<p>How about <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span>?</p>
<p>Here positive effects only arise when <span class="math inline">\(K=1\)</span> and so <span class="math inline">\(\phi_{b1} = 1\)</span>. <span class="math inline">\(Y=1\)</span> without being cause by <span class="math inline">\(X\)</span> only if <span class="math inline">\(K=0\)</span> and so <span class="math inline">\(\phi_{b0} = 0\)</span>. Thus we have a double decisive clue.</p>
</div>
</div>
<div id="causal-discovery" class="section level2">
<h2><span class="header-section-number">15.4</span> Causal discovery</h2>
<p>The last sections—as well as the core content in chapters 10 and 11 <span style="color: orange;">Flag!</span> showed how higher level models can be justified by reference to lower level models plus data. Even these lower level presupposed beliefs about the basic causal structure. But where does this knowledge come from?</p>
<p>The discovery of causal structure is itself a very large field of inquiry and we cannot do it justice here. For a review see for instance <span class="citation">Glymour, Zhang, and Spirtes (<a href="#ref-glymour2019review" role="doc-biblioref">2019</a>)</span>.</p>
<p>Here we illustrate simply the possibility of casual discovery. We illustrate with three cases in which there is a true—but unknown model—relating <span class="math inline">\(X,M,\)</span> and <span class="math inline">\(Y\)</span> to each other. Critically we assume that there are no unobserved confounding relations (this is a requirement for the “PC” algorithm but not for the “Fast Causal Inference” algorithm). In each case we show the true relationship and the “skeleton” of the model as discovered by a prominent technique that uses a “constraint-based algorithm”— examining whether observed data correlations are consistent with one or other set of conditional independence relations.</p>
<p>In the first model <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> directly and indirectly through <span class="math inline">\(M\)</span>. We simulate data from this model – assuming monotonicity but otherwise a flat distribution on types.</p>
<p>Next we consider the model in which <span class="math inline">\(Y\)</span> has two causes that do not influence each other.</p>
<p>Finally we consider the model in which <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> through <span class="math inline">\(M\)</span> but not directly. Again we impose monotonicity, draw data.</p>
<div class="figure" style="text-align: center"><span id="fig:plots"></span>
<img src="ii_files/figure-html/plots-1.png" alt="(Partially) DAGs from Data: True DAGs in upper row with partially directed graphs in lower row. Circles indicate uncertainty whether a aroow starts or ends at a given point." width="80%" />
<p class="caption">
Figure 15.2: (Partially) DAGs from Data: True DAGs in upper row with partially directed graphs in lower row. Circles indicate uncertainty whether a aroow starts or ends at a given point.
</p>
</div>
<p>In all cases we correctly recover the skeleton. Note that the “o” in the skeleton graphs indicate that we may have an arrow head or an arrow tail. In the first case the skeleton is unrestricted, in the second and third cases the correct restricted skeleton is found. In all cases if we have access to all relevant variables the true graph can be recovered with knowledge of the temporal ordering of variables.</p>
<p>Perhaps the most impressive of these discoveries is the last: here <span class="math inline">\(X\)</span>, <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> are all correlated with each other, but the correct graph is discovered because <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> are not correlated with each other <em>conditional</em> on <span class="math inline">\(M\)</span>.</p>
<p>The second graph is also impressive as here we observe arrow heads in the estimated graphs. Thus even without knowledge of the timing of the variables the algorithm indicate that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are not children of <span class="math inline">\(Y\)</span> — it sees, in essence, data patterns that are distinctive of colliders—<span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> correlated conditional on <span class="math inline">\(Y\)</span> but not otherwise. With that said, if confounding is possible we do not know for sure whether <span class="math inline">\(Y\)</span> is a child of <span class="math inline">\(X_1\)</span> or whether <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span> are confounded.</p>
<p>These examples provide grounds for hope that causal models can be discovered and not simply assumed. In cases in which unobserved confounding is possible the results do not identify a unique causal structure. If all nodes are known and measured however—a tall order for sure—causal structures can be identified from data.</p>
<!-- ### A model of models -->
<!-- In the following mode there is an unknown, $Q$, which determines the relevant causal model.  -->
<!-- If $Q=1$ then we have $A \rightarrow B \rightarrow C2$; if $Q=0$ then $A \rightarrow B \leftarrow C1$. In this case the temporal order of $C1$ and $C2$ is observable, so there is not confusion there; what is not clear however is which is the important node to include in the model.  -->
<!-- ```{r ch14Qornot} -->
<!-- model <- make_model("A -> B -> C2 <- C1 -> B <- Q -> C2") %>% -->
<!--   # These restrictions capture the role of Q in turning parentage on or off  -->
<!--   set_restrictions(c( -->
<!--     "(B[C1=1, Q=1] != B[C1=0, Q=1])", -->
<!--     "(C2[B=1, Q=0] != C2[B=0, Q=0])")) %>% -->
<!--   # These restrictions are for simplification: monotonicity and complementarity  -->
<!--   set_restrictions(c( -->
<!--     "(C2[B=1] < C2[B=0])", -->
<!--     "(C2[C1=1] < C2[C1=0])", -->
<!--     "(B[A=1]  < B[A=0])", -->
<!--     "(B[C1=1] < B[C1=0])", -->
<!--     "((B[A=1, C1=1] - B[A=0, C1=1]) < (B[A=1, C1=0] - B[A=0, C1=0]))")) -->
<!-- model -->
<!-- plot(model) -->
<!-- if(do_diagnosis){ -->
<!--   model_Q0 <- set_parameters(model, node = "Q", alphas = c(1,0)) -->
<!--   model_Q1 <- set_parameters(model, node = "Q", alphas = c(0,1)) -->
<!--   data_0 <- make_data(model_Q0, 100, vars = c("A", "B", "C1", "C2")) -->
<!--   data_1 <- make_data(model_Q1, 100, vars = c("A", "B", "C1", "C2")) -->
<!--   model_Q0 <- update_model(model, data_0) -->
<!--   model_Q1 <- update_model(model, data_1) -->
<!-- Qu0 <- query_model(model_Q0, "Q==1", using = "posteriors") -->
<!-- Qu1 <- query_model(model_Q1, "Q==1", using = "posteriors") -->
<!--   write_rds(list(model_Q0, model_Q1, Qu0, Qu1), "saved/ch14_Qornot.rds") -->
<!-- } -->
<!-- Qornot <- read_rds("saved/ch14_Qornot.rds") -->
<!-- kable(Qornot[[3]]) -->
<!-- kable(Qornot[[4]]) -->
<!-- ``` -->
<!-- [Ideally here however $\lambda^Q$ is either 0 or 1 --- we want to know which world we are in] -->
</div>
<div id="exercise" class="section level2">
<h2><span class="header-section-number">15.5</span> Exercise</h2>
<p>Imagine a model in which in fact <span class="math inline">\(X \rightarrow Y \leftarrow K\)</span> but in which the researcher knows only the temporal ordering of variables. Say in fact that on average <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span> both have strong positive effects on <span class="math inline">\(Y\)</span> with positive interactions. Can access to observational data provide a justification for using <span class="math inline">\(K\)</span> as a clue for the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in an <span class="math inline">\(X=Y=1\)</span> case?</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-cartwright1994nature">
<p>Cartwright, Nancy, and others. 1994. “Nature’s Capacities.” <em>OUP Catalogue</em>.</p>
</div>
<div id="ref-clarke2012model">
<p>Clarke, Kevin A, and David M Primo. 2012. <em>A Model Discipline: Political Science and the Logic of Representations</em>. New York: Oxford University Press.</p>
</div>
<div id="ref-collier2011understanding">
<p>Collier, David. 2011. “Understanding Process Tracing.” <em>PS: Political Science &amp; Politics</em> 44 (04): 823–30.</p>
</div>
<div id="ref-glymour2019review">
<p>Glymour, Clark, Kun Zhang, and Peter Spirtes. 2019. “Review of Causal Discovery Methods Based on Graphical Models.” <em>Frontiers in Genetics</em> 10: 524.</p>
</div>
<div id="ref-holland1986statistics">
<p>Holland, Paul W. 1986. “Statistics and Causal Inference.” <em>Journal of the American Statistical Association</em> 81 (396): 945–60.</p>
</div>
<div id="ref-humphreys2015mixing">
<p>Humphreys, Macartan, and Alan M Jacobs. 2015. “Mixing Methods: A Bayesian Approach.” <em>American Political Science Review</em> 109 (04): 653–73.</p>
</div>
<div id="ref-Van-Evera:1997">
<p>Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="80">
<li id="fn80"><p>Even in this simple case there are ways in which the representation is a model, not least the coding of events as a variable involves a form of modeling.<a href="justifying-models.html#fnref80" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="caseselection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="evaluation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
