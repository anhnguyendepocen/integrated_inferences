<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Justifying models | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Justifying models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Justifying models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="caseselection.html">
<link rel="next" href="evaluation.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#interpretation-of-functional-equations"><i class="fa fa-check"></i><b>2.2.2</b> Interpretation of functional equations</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.3</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.4</b> Conditional independence from DAGs</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.2</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#conditional-independence-alone-does-not-provide-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> Conditional independence alone does not provide probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="10" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>10</b> Elements of Design</a><ul>
<li class="chapter" data-level="10.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>10.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="10.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>10.1.1</b> Defining a model</a></li>
<li class="chapter" data-level="10.1.2" data-path="elements-of-design.html"><a href="elements-of-design.html#choosing-estimands"><i class="fa fa-check"></i><b>10.1.2</b> Choosing estimands</a></li>
<li class="chapter" data-level="10.1.3" data-path="elements-of-design.html"><a href="elements-of-design.html#selecting-a-data-strategy"><i class="fa fa-check"></i><b>10.1.3</b> Selecting a data strategy</a></li>
<li class="chapter" data-level="10.1.4" data-path="elements-of-design.html"><a href="elements-of-design.html#answer-strategy"><i class="fa fa-check"></i><b>10.1.4</b> Answer strategy</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-mixed-method-design"><i class="fa fa-check"></i><b>10.2</b> Evaluating a mixed method design</a><ul>
<li class="chapter" data-level="10.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#other-loss-functions"><i class="fa fa-check"></i><b>10.2.1</b> Other loss functions</a></li>
<li class="chapter" data-level="10.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#other-measures-of-a-gain-from-a-theory"><i class="fa fa-check"></i><b>10.2.2</b> Other measures of a gain from a theory</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-in-code"><i class="fa fa-check"></i><b>10.3</b> Illustration of in code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html"><i class="fa fa-check"></i><b>11</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="11.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#a-strategic-approach"><i class="fa fa-check"></i><b>11.1</b> A strategic approach</a></li>
<li class="chapter" data-level="11.2" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-running-example"><i class="fa fa-check"></i><b>11.2</b> Clue selection for the running example</a><ul>
<li class="chapter" data-level="11.2.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#dynamic-strategies"><i class="fa fa-check"></i><b>11.2.1</b> Dynamic Strategies</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-democracy-model"><i class="fa fa-check"></i><b>11.3</b> Clue selection for the Democracy model</a></li>
<li class="chapter" data-level="11.4" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#conclusion-2"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>12</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="12.1" data-path="wide.html"><a href="wide.html#intuitions-does-a-sufficiently-large-n-always-trump-k"><i class="fa fa-check"></i><b>12.1</b> Intuitions: Does a sufficiently large <span class="math inline">\(N\)</span> always trump <span class="math inline">\(K\)</span>?</a></li>
<li class="chapter" data-level="12.2" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>12.2</b> Evaluating strategies</a></li>
<li class="chapter" data-level="12.3" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>12.3</b> Varieties of mixing</a></li>
<li class="chapter" data-level="12.4" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>12.4</b> Probative value of clues</a></li>
<li class="chapter" data-level="12.5" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>12.5</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="12.6" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>12.6</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="12.7" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>12.7</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>13.1</b> Explorations</a></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#diagnosing-case-selection-strategies-procedure"><i class="fa fa-check"></i><b>13.2</b> Diagnosing case-selection strategies: procedure</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#evaluating-types-of-strategies"><i class="fa fa-check"></i><b>13.3</b> Evaluating types of strategies</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#different-models-different-strategies"><i class="fa fa-check"></i><b>13.4</b> Different models, different strategies</a></li>
<li class="chapter" data-level="13.5" data-path="caseselection.html"><a href="caseselection.html#different-queries-different-strategies"><i class="fa fa-check"></i><b>13.5</b> Different queries, different strategies</a></li>
<li class="chapter" data-level="13.6" data-path="caseselection.html"><a href="caseselection.html#in-code"><i class="fa fa-check"></i><b>13.6</b> In code</a></li>
<li class="chapter" data-level="13.7" data-path="caseselection.html"><a href="caseselection.html#compare-multiple-data-strategies"><i class="fa fa-check"></i><b>13.7</b> Compare multiple data strategies</a></li>
<li class="chapter" data-level="13.8" data-path="caseselection.html"><a href="caseselection.html#experiments"><i class="fa fa-check"></i><b>13.8</b> Experiments</a></li>
<li class="chapter" data-level="13.9" data-path="caseselection.html"><a href="caseselection.html#chapter-appendix-accounting-for-case-selection"><i class="fa fa-check"></i><b>13.9</b> Chapter Appendix: Accounting for case selection</a><ul>
<li class="chapter" data-level="13.9.1" data-path="caseselection.html"><a href="caseselection.html#independent-case-selection-strategy"><i class="fa fa-check"></i><b>13.9.1</b> Independent case selection strategy</a></li>
<li class="chapter" data-level="13.9.2" data-path="caseselection.html"><a href="caseselection.html#conditional-random-case-selection"><i class="fa fa-check"></i><b>13.9.2</b> Conditional random case selection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="14" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>14</b> Justifying models</a><ul>
<li class="chapter" data-level="14.1" data-path="justifying-models.html"><a href="justifying-models.html#bounds-on-probative-value"><i class="fa fa-check"></i><b>14.1</b> Bounds on probative value</a></li>
<li class="chapter" data-level="14.2" data-path="justifying-models.html"><a href="justifying-models.html#the-possibility-of-identification-of-probative-value-from-experimental-data"><i class="fa fa-check"></i><b>14.2</b> The possibility of identification of probative value from experimental data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>14.2.1</b> Mediator</a></li>
<li class="chapter" data-level="14.2.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>14.2.2</b> Moderator</a></li>
<li class="chapter" data-level="14.2.3" data-path="justifying-models.html"><a href="justifying-models.html#case-level-bounds-from-mixed-data"><i class="fa fa-check"></i><b>14.2.3</b> Case level bounds from mixed data</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="justifying-models.html"><a href="justifying-models.html#learning-across-populations"><i class="fa fa-check"></i><b>14.3</b> Learning across populations</a></li>
<li class="chapter" data-level="14.4" data-path="justifying-models.html"><a href="justifying-models.html#different-models-for-different-sites"><i class="fa fa-check"></i><b>14.4</b> Different models for different sites</a><ul>
<li class="chapter" data-level="14.4.1" data-path="justifying-models.html"><a href="justifying-models.html#observational-and-experimental"><i class="fa fa-check"></i><b>14.4.1</b> Observational and experimental</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>14.5</b> Causal discovery</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>15</b> Evaluating models</a><ul>
<li class="chapter" data-level="15.1" data-path="evaluation.html"><a href="evaluation.html#tools-for-evaluating-models"><i class="fa fa-check"></i><b>15.1</b> Tools for evaluating models</a></li>
<li class="chapter" data-level="15.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>15.2</b> Evaluating the Democracy-Inequality model</a></li>
<li class="chapter" data-level="15.3" data-path="evaluation.html"><a href="evaluation.html#prior-check"><i class="fa fa-check"></i><b>15.3</b> Prior check</a></li>
<li class="chapter" data-level="15.4" data-path="evaluation.html"><a href="evaluation.html#monotonic-restrictions"><i class="fa fa-check"></i><b>15.4</b> Monotonic restrictions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>16</b> Final Words</a><ul>
<li class="chapter" data-level="16.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>16.1</b> General lessons</a></li>
<li class="chapter" data-level="16.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>16.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="16.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>16.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="16.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>16.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="17" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>17</b> Analysis of canonical models with <code>gbiqq</code></a><ul>
<li class="chapter" data-level="17.1" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-no-confounding"><i class="fa fa-check"></i><b>17.1</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, no confounding</a></li>
<li class="chapter" data-level="17.2" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-unmodelled-confounding"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with unmodelled confounding</a></li>
<li class="chapter" data-level="17.3" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-confounding-modelled"><i class="fa fa-check"></i><b>17.3</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with confounding modelled</a></li>
<li class="chapter" data-level="17.4" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-mediation-model"><i class="fa fa-check"></i><b>17.4</b> Simple mediation model</a></li>
<li class="chapter" data-level="17.5" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-moderator-model"><i class="fa fa-check"></i><b>17.5</b> Simple moderator model</a></li>
<li class="chapter" data-level="17.6" data-path="examplesappendix.html"><a href="examplesappendix.html#an-iv-model"><i class="fa fa-check"></i><b>17.6</b> An IV model</a></li>
<li class="chapter" data-level="17.7" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-that-allows-application-of-the-frontdoor-criterion"><i class="fa fa-check"></i><b>17.7</b> A model that allows application of the frontdoor criterion</a></li>
<li class="chapter" data-level="17.8" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-with-a-violation-of-sequential-ignorability"><i class="fa fa-check"></i><b>17.8</b> A model with a violation of sequential ignorability</a></li>
<li class="chapter" data-level="17.9" data-path="examplesappendix.html"><a href="examplesappendix.html#learning-from-a-collider"><i class="fa fa-check"></i><b>17.9</b> Learning from a collider</a></li>
<li class="chapter" data-level="17.10" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-mixing-observational-and-experimental-data"><i class="fa fa-check"></i><b>17.10</b> A model mixing observational and experimental data</a></li>
<li class="chapter" data-level="17.11" data-path="examplesappendix.html"><a href="examplesappendix.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>17.11</b> Transportation of findings across contexts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="justifying-models" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Justifying models</h1>
<hr />
<p>We outline strategies to reduce reliance on unfounded beliefs about the probative value of clues.</p>
<hr />
<p>The approach we have described to inference always involve updating beliefs given data. But to get off the ground researchers need to be able to state priors on all parameters. In many applications the problem of stating priors can be more fundamental than for many Bayesian applications for two reasons. First the beliefs are beliefs over the distribution of individual level effects and not just the beliefs over average effects. This puts us up against the fundamental problem of causal inference (Holland cite, Dawid cite FLAG). Second, the beliefs can do a lot of work—especially in small <span class="math inline">\(n\)</span> applications. Indeed for the the process tracing described chapters 6 and 7 [FLAG ADD REFS] the inferences are little more than conditional applications of a model.</p>
<p>We see two broad responses to this problem.</p>
<p>One is emphasize the contingent nature of claims. As we outlined in Chapter 4, some causal models might reasonably reflect actual beliefs about the world—for example one might, be convinced that a treatment was randomly assigned, that there is no interference, and that units are independently sampled from a distribution of types. All of these beliefs may be unwise. But if held, then the simple DAG in chapter 4 (REF) can be taken to represents beliefs about the world rather than a model of the world, in the sense of a simplified representation. But as we noted in Chapter 4, for an even modestly more complex situation, it seems inevitable that the model being used is truly a model and not a faithful summary of beliefs.</p>
<p>Owning the model in this way results in a useful reposing of the question: the question becomes not whether the assumptions are correct but whether the model is useful <span class="citation">(Clarke and Primo <a href="#ref-clarke2012model">2012</a>)</span>. That is the subject of Chapter 15.</p>
<p>Here we focus on more positive steps that might be taken to underpin a model. We highlight first how the type of approach used in Chapters 8 and 9 can be used to justify a process tracing model on the basis of a mixed methods model. These applications presuppose knowledge of a DAG however. There are two further responses to this concern. One is to try to generate the DAG itself from data or a combination of data and theory. We discuss this approach here. Another is to assess the importance of DAG assumptions – which we address in Chapter 15.</p>
<div id="bounds-on-probative-value" class="section level2">
<h2><span class="header-section-number">14.1</span> Bounds on probative value</h2>
<p>Classic treatments of process tracing make use of Causal Process Observations — observations that are taken to be indicative of a particular causal process in operation. We introduced in Chapter 5 (as well as in FLAG CITE humphreysjacobs) quantities such as <span class="math inline">\(\phi_{b}\)</span>—the probability that <span class="math inline">\(K=1\)</span> given <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> and <span class="math inline">\(X=Y=1\)</span>, or <span class="math inline">\(\phi_{d}\)</span>—–the probability that <span class="math inline">\(K=1\)</span> given <span class="math inline">\(X\)</span> did not cause <span class="math inline">\(Y\)</span> and <span class="math inline">\(X=Y=1\)</span>.</p>
<p>These accounts do not guide much guidance however regarding where these quantities come from — given that causal types are unobservable how can one justify a belief about the probability of some observation <em>given</em> a causal type. Is it even possible to justify such beliefs?</p>
<p>The grounded approach we described provides an answer to this puzzle. In short, knowledge of the structure of a causal model, together with data on exchangeable units, can be enough to place bounds on possible values of <span class="math inline">\(\phi_{b}, \phi_{d}\)</span>.</p>
<p>We illustrate the basic idea and then review some results in this area.</p>
<p>Imagine a fortunate situation in which (a) it is known that the true causal model has the form <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> and (b) we have a lot of experimental data on the conditional distribution of <span class="math inline">\(M\)</span> given <span class="math inline">\(X\)</span> and of <span class="math inline">\(Y\)</span> given <span class="math inline">\(M\)</span> for exchangeable units (meaning that we can treat our unit of interest as if it were a draw from this set).</p>
<p>Let us define:</p>
<ul>
<li><span class="math inline">\(\tau_1 = \Pr(M=1 | X=1) - \Pr(M=1 | X=0)\)</span></li>
<li><span class="math inline">\(\rho_1 = \Pr(M=1 | X=1) - \Pr(M=0 | X=0)\)</span></li>
<li><span class="math inline">\(\tau_2 = \Pr(Y=1 | M=1) - \Pr(Y=1 | M=0)\)</span></li>
<li><span class="math inline">\(\rho_2 = \Pr(Y=1 | M=1) - \Pr(Y=0 | M=0)\)</span></li>
</ul>
<p>These are all quantities that can be calculated from the data. The <span class="math inline">\(\tau\)</span>s are average treatment effects and the <span class="math inline">\(\rho\)</span>s are indicators for how common the <span class="math inline">\(Y=1\)</span> outcome is.</p>
<p>We are interested in the probability of observing <span class="math inline">\(M=1\)</span> given <span class="math inline">\(X=Y=1\)</span>:</p>
<p><span class="math display">\[\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + \lambda_{a}^K\lambda_{a}^Y}\]</span></p>
<p>Noting that <span class="math inline">\(\tau_j = \lambda_{b_j} - \lambda_{a_j}\)</span>:</p>
<p><span class="math display">\[\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + (\lambda_{b}^K-\tau_1)(\lambda_{b}^Y - \tau_2)}\]</span>
which we can see is decreasing in <span class="math inline">\(\lambda_{b}^j\)</span> (this may seem counterintuitive, but the reason is that with <span class="math inline">\(\tau^j\)</span> fixed, lower <span class="math inline">\(\lambda_{b}^j\)</span> also means lower <span class="math inline">\(\lambda_{a}^j\)</span> which means less ambiguity about <em>how</em> <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> (i.e. through positive or negative effects on <span class="math inline">\(K\)</span>).</p>
<p><!-- $$\phi_{1} = \frac{\lambda_{b}^Y}{2\lambda_{b}^Y -\tau_2 - \tau_1(\lambda_{b}^Y - \tau_2)/\lambda_{b}}^K$$ --></p>
<p>The lowest permissible value of <span class="math inline">\(\lambda_{b_j}\)</span> is <span class="math inline">\(\tau_j\)</span>, yielding <span class="math inline">\(\phi_{b1} = 1\)</span>.</p>
<p>The highest value obtainable by <span class="math inline">\(\lambda_{b_j}\)</span> is when <span class="math inline">\(\lambda_{a_j} = \frac{1-\tau_j+\rho_j}2\)</span> and so <span class="math inline">\(\lambda_{b_j} = \frac{1+\tau_j+\rho_j}2\)</span>.</p>
<p>In this case:
<span class="math display">\[\phi_{b1} = \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2) + (1-\tau_1+\rho_1)(1-\tau_2+\rho_2)}= \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau}\]</span></p>
<p>And so:</p>
<p><span class="math display">\[\frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau_2} \leq \phi_{b1} \leq 1\]</span></p>
<p>These are the bounds on <span class="math inline">\(\phi_{b1}\)</span>. We can calculate bounds on <span class="math inline">\(\phi_{d1}\)</span> in a similar way (though of course the bounds on <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span> are not independent).</p>
<p><span class="math display">\[\phi_{d1} = \frac{\lambda_{b}^K\lambda_{d}^Y}{(\lambda_{a}^K + \lambda_{b}^K + \lambda_{c}^K)\lambda_{d}^Y+ \lambda_{c}^K\lambda_{a}^Y}\]</span></p>
<p>Figure <a href="#fig:probval1"><strong>??</strong></a> illustrates how “smoking gun” and “hoop” tests might each be justified with knowledge of <span class="math inline">\(\tau_j, \rho_j\)</span>.</p>
<p><img src="ii_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<!-- plot_bounds(.6, -.2, .6, .2, 20, main = expression(paste("Hoop: ", tau[1], "= .6, ", -->
<!--                                                             rho[1], "= -.2, ", -->
<!--                                                             tau[2], "= .6, ", -->
<!--                                                             rho[2], "= .2"))) -->
<!-- plot_bounds(0.0, -.9, .0, -.9, 100, main = expression(paste("Smoking gun: ", tau[1], "= 0, ", -->
<!--                                                             rho[1], "= -.9, ", -->
<!--                                                             tau[2], "= 0, ", -->
<!--                                                             rho[2], "= -.9, "))) -->
<!-- ``` -->
<!-- ```{r, eval = FALSE, echo = FALSE} -->
<!-- # An odd one! -->
<!-- plot_bounds(.02, -.5, -.10, -.5,600) -->
<!-- ``` -->
<p>For the smoking gun, <span class="math inline">\(\phi_{b1}\)</span> is .5 because <span class="math inline">\(\lambda_a^j = \lambda_b^j\)</span> so half of the upper level <span class="math inline">\(b\)</span> types work through a positive effect on <span class="math inline">\(M\)</span> and half through a negative effect on <span class="math inline">\(M\)</span>. <span class="math inline">\(\phi_{d1}\)</span>, on the other hand, is low here <span class="math inline">\(d\)</span> types mostly arise because of <span class="math inline">\(c\)</span> types in the first step and <span class="math inline">\(a\)</span> types in the second, and hence most commonly with <span class="math inline">\(M=1\)</span>.</p>
<p>Whether the bounds map into useful probative value depends in part on whether causal effects are better identified in the first or the second stage. We can see this in Figure <a href="justifying-models.html#fig:probval2">14.1</a>.</p>
<p>The key difference between the panels is that <span class="math inline">\(\phi_d\)</span> is constrained to be low in the first panel but not in the second.</p>
<p>For intuition note that a higher level <span class="math inline">\(d\)</span> type will exhibit <span class="math inline">\(M=1\)</span> if it is formed via <span class="math inline">\(db\)</span>, <span class="math inline">\(bd\)</span>,or <span class="math inline">\(dd\)</span> and it will exhibit <span class="math inline">\(M=0\)</span> if it is formed via <span class="math inline">\(ca\)</span>, <span class="math inline">\(cd\)</span>, <span class="math inline">\(ad\)</span>. The weak second stage makes it possible that there are no second stage d types, only a and b types. The stronger first stage makes it possible that there are no first stage <span class="math inline">\(c\)</span> types. In that case the higher level d types are formed uniquely of <span class="math inline">\(db\)</span> types – which always exhibit <span class="math inline">\(M=1\)</span> if <span class="math inline">\(X=1\)</span>.</p>
<p>This is not possible however for the data assume in the first panel. In the first panel the the higher value on <span class="math inline">\(\rho_2\)</span> means that there must be at least .25 d types. And the weak first stage means that there must at least .5 a and c types combined. Thus there <em>must</em> be a set of cases in which <span class="math inline">\(M\)</span> is not observed even though we have an upper level d type.</p>
<div class="figure"><span id="fig:probval2"></span>
<img src="ii_files/figure-html/probval2-1.png" alt="Probative value with different first and second stage relations" width="960" />
<p class="caption">
Figure 14.1: Probative value with different first and second stage relations
</p>
</div>
<p>In short we emphasize that difficult as it might seem at first it is possible to put relatively tight bounds on probative value for causal types with access to experimental data on exchangeable units.</p>
</div>
<div id="the-possibility-of-identification-of-probative-value-from-experimental-data" class="section level2">
<h2><span class="header-section-number">14.2</span> The possibility of identification of probative value from experimental data</h2>
<p>While it is possible to calculate bounds on probative value, it can be simpler to calculate bounds on estimands directly. These bounds can be justified with reference to background data in the same ways as the bounds on probative value.</p>
<p>Following <span class="citation">Dawid, Humphreys, and Musio (<a href="#ref-dawid2019bounding">2019</a>)</span> we again imagine we had access to infinite experimental data on the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> and we want to know for a case (exchangeable with any other in this population) with <span class="math inline">\(X=Y=1\)</span>, whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Call this the “probability of causation.”</p>
<p>Say we knew the marginal distributions:</p>
<ul>
<li><span class="math inline">\(\Pr(Y=1|X=1) = .75\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0) = .25\)</span></li>
</ul>
<p>The we could represent this knowledge as Markovian transition matrix from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> like this:</p>
<p><span class="math display">\[P=\left( \begin{array}{cc} 0.50 &amp; 0.50 \\ 0.25 &amp; 0.75 \end{array}\right)\]</span></p>
<p>In this case, from results in <span class="citation">Dawid, Musio, and Murtas (<a href="#ref-dawid2017probability">2017</a>)</span>, we can place bounds directly on the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span>, viz:</p>
<p><span class="math display">\[\frac13 \leq PC \leq \frac23 \]</span>
For intuition note that <span class="math inline">\(P\)</span> implies a causal effect of .25 and so the lowest value of <span class="math inline">\(\lambda_b\)</span> consistent with <span class="math inline">\(P\)</span> arises when <span class="math inline">\(\lambda_b = .25\)</span> and <span class="math inline">\(\lambda_a = 0\)</span>, in which case <span class="math inline">\(\lambda_c = .25\)</span> and <span class="math inline">\(\lambda_d = .5\)</span>. In this case <span class="math inline">\(\lambda_b/(\lambda_b+ \lambda_d)=\frac{1}{3}\)</span>. The highest consistent value of <span class="math inline">\(\lambda_b\)</span> arises when <span class="math inline">\(\lambda_b = .5\)</span> and <span class="math inline">\(\lambda_a = .25\)</span>, in which case <span class="math inline">\(\lambda_c = 0\)</span> and <span class="math inline">\(\lambda_d = .25\)</span>. In this case <span class="math inline">\(\lambda_b/(\lambda_b+ \lambda_d)=\frac{2}{3}\)</span>.</p>
<p>Defining <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\rho\)</span> as before, the more general formula for the case with <span class="math inline">\(\rho&gt;0\)</span> is:</p>
<p><span class="math display">\[\frac{2\tau}{1+\tau+\rho} \leq PC \leq \frac{1+\tau-|\rho|}{1+\tau+\rho} \]</span></p>
<p>Say now we have access to auxiliary data <span class="math inline">\(K\)</span> and plan to make inferences based on <span class="math inline">\(K\)</span>.</p>
<p>We will suppose first that <span class="math inline">\(K\)</span> is a mediator, as above, and second that <span class="math inline">\(K\)</span> is a moderator.</p>
<div id="mediator" class="section level3">
<h3><span class="header-section-number">14.2.1</span> Mediator</h3>
<p>Say now that <em>in addition</em> we know from experimental data, that <span class="math inline">\(K\)</span> mediates the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; indeed we will assume that we have a case of complete mediation, such that, conditional on <span class="math inline">\(K\)</span>, <span class="math inline">\(Y\)</span> does not depend on <span class="math inline">\(X\)</span>.</p>
<p>Say the transition matrices from <span class="math inline">\(X\)</span> to <span class="math inline">\(K\)</span> and <span class="math inline">\(K\)</span> to <span class="math inline">\(Y\)</span> are:</p>
<p><span class="math display">\[P^{xk}=\left( \begin{array}{cc} 1 &amp; 0 \\ 1/2 &amp; 1/2\end{array}\right), P^{ky}=\left( \begin{array}{cc} 1/2 &amp; 1/2 \\ 0 &amp; 1\end{array}\right)\]</span>
Even without observing <span class="math inline">\(K\)</span>, this information is sufficient to place a prior on PC of <span class="math inline">\(p=\frac13\)</span>.</p>
<p>To see this, note that we can calculate:</p>
<ul>
<li><span class="math inline">\(\lambda_a^K =0\)</span>, <span class="math inline">\(\lambda_b^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_d^K = 0\)</span></li>
<li><span class="math inline">\(\lambda_a^Y =0\)</span>, <span class="math inline">\(\lambda_b^Y=\frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^Y=0\)</span>, <span class="math inline">\(\lambda_d^Y=\frac{1}{2}\)</span></li>
</ul>
<p>and so:</p>
<ul>
<li><span class="math inline">\(\lambda_b^u = \lambda_b^K\lambda_b^Y = \frac{1}4\)</span></li>
<li><span class="math inline">\(\lambda_d^u = \lambda_d^Y\)</span></li>
<li><span class="math inline">\(p = \frac{\lambda_b^u}{\lambda_b^u + \lambda_d^u} = \frac{1}3\)</span>.</li>
</ul>
<p>whence:</p>
<ul>
<li><span class="math inline">\(\phi_{b1} = 1\)</span></li>
<li><span class="math inline">\(\phi_{d1} = \lambda_d^K + \lambda_b^K = \frac{1}{2}\)</span></li>
</ul>
<p>More generally we can calculate the lower bound on the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> as the product of the lower bounds that <span class="math inline">\(X\)</span> caused <span class="math inline">\(M\)</span> and that <span class="math inline">\(M\)</span> caused <span class="math inline">\(Y\)</span>, and similarly for the upper bound, using the same formula as before. Signing things so that <span class="math inline">\(\tau^j\geq 0\)</span>, <span class="math inline">\(j \in {1,2}\)</span>:</p>
<p><span class="math display">\[\frac{2\tau_1}{1+\tau_1+\rho_1}\frac{2\tau_2}{1+\tau_2+\rho_2}  \leq PC \leq \frac{1+\tau_1-|\rho_1|}{1+\tau_1+\rho_1}\frac{1+\tau_2-|\rho_2|}{1+\tau_2+\rho_2} \]</span></p>
<p>We have undertaken essentially the same operations as above except that now we are placing bounds on a substantive estimand of interest rather than first placing bounds on probative value of a clue and then turning to Bayes rule to place bounds on the estimand.</p>
</div>
<div id="moderator" class="section level3">
<h3><span class="header-section-number">14.2.2</span> Moderator</h3>
<p>Consider now a situation in which our case is drawn from a set of cases for which <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span> were each randomly assigned. Say then that the transition matrices, conditional on <span class="math inline">\(K\)</span> look as follows:</p>
<p><span class="math display">\[P^{K=0}=\left( \begin{array}{cc} 0 &amp; 1 \\ 0.5 &amp; 0.5 \end{array}\right), P^{K=1}=\left( \begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \end{array}\right)\]</span>
In this case we can now identify PC, even before observing <span class="math inline">\(K\)</span>. If <span class="math inline">\(K=0\)</span>, PC is 0—there are no cases with positive effects in this condition. If <span class="math inline">\(K=1\)</span> PC = 1. We have a prior that <span class="math inline">\(K=1\)</span> of .5 and after observing <span class="math inline">\(X=Y=1\)</span> we raise this to <span class="math inline">\(2/3\)</span>. Thus our prior belief on <span class="math inline">\(PC\)</span> — before seeing <span class="math inline">\(K\)</span>— is <span class="math inline">\(2/3 * 1 + 1/3 * 0 = 2/3\)</span>.</p>
<p>How about <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span>?</p>
<p>Here positive effects only arise when <span class="math inline">\(K=1\)</span> and so <span class="math inline">\(\phi_{b1} = 1\)</span>. <span class="math inline">\(Y=1\)</span> without being cause by <span class="math inline">\(X\)</span> only if <span class="math inline">\(K=0\)</span> and so <span class="math inline">\(\phi_{b0} = 0\)</span>. Thus we have a double decisive clue.</p>
</div>
<div id="case-level-bounds-from-mixed-data" class="section level3">
<h3><span class="header-section-number">14.2.3</span> Case level bounds from mixed data</h3>
</div>
</div>
<div id="learning-across-populations" class="section level2">
<h2><span class="header-section-number">14.3</span> Learning across populations</h2>
<p>Now consider strategies to learn about clues from observing patterns in different populations.</p>
<p>We first consider a situation in which we believe the same model holds in multiple sites but in which learning about the model requires combining data about different parts of the model from multiple studies.</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- Z -&gt; K&quot;</span>)</code></pre>
<p><img src="ii_files/figure-html/unnamed-chunk-92-1.png" width="672" /></p>
<p>We imagine we have access to three types of data;</p>
<ol style="list-style-type: decimal">
<li>Study 1 is an experiment looking at the effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, ancillary data on <span class="math inline">\(K\)</span> is collected but <span class="math inline">\(Z\)</span> is not observed</li>
<li>Study 2 is a factorial study examining the joint effects of <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span>, <span class="math inline">\(K\)</span> is not observed</li>
<li>Study 3 is an RCT looking at the relation between <span class="math inline">\(Z\)</span> and <span class="math inline">\(K\)</span>. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not observed.</li>
</ol>
<p>Tables <a href="justifying-models.html#tab:frank1">14.1</a> - <a href="justifying-models.html#tab:frank3">14.3</a> show conditional inferences for the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in <span class="math inline">\(X=Y=1\)</span> cases conditional on <span class="math inline">\(K\)</span> for each study, analyzed individually</p>
<table>
<caption><span id="tab:frank1">Table 14.1: </span>Clue is uninformative in Study 1</caption>
<thead>
<tr class="header">
<th align="left">Subset</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.5</td>
<td align="right">0.153</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.5</td>
<td align="right">0.146</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:frank2">Table 14.2: </span>Clue is also uninformative in Study 2 (factorial)</caption>
<thead>
<tr class="header">
<th align="left">Subset</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.546</td>
<td align="right">0.110</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.546</td>
<td align="right">0.112</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:frank3">Table 14.3: </span>Clue is also uninformative in Study 3 (experiment studying <span class="math inline">\(K\)</span>)</caption>
<thead>
<tr class="header">
<th align="left">Subset</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.5</td>
<td align="right">0.154</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.5</td>
<td align="right">0.152</td>
</tr>
</tbody>
</table>
<p>In no case is <span class="math inline">\(K\)</span> informative. In study 1 data on <span class="math inline">\(K\)</span> is not available, in study 2 it is available but researchers do not know, quantitatively, how it relates to <span class="math inline">\(Z\)</span>. In the third study the <span class="math inline">\(Z,K\)</span> relationship is well understood but the joint relation between <span class="math inline">\(Z,X\)</span>, and <span class="math inline">\(Y\)</span> is not understood.</p>
<p>Table <a href="justifying-models.html#tab:frank4">14.4</a> shows the inferences when the data are combined with joint updating across all parameters.</p>
<table>
<caption><span id="tab:frank4">Table 14.4: </span>Clue is informative after combining studies linking <span class="math inline">\(K\)</span> to <span class="math inline">\(Z\)</span> and <span class="math inline">\(Z\)</span> to <span class="math inline">\(Y\)</span></caption>
<thead>
<tr class="header">
<th align="left">Subset</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1</td>
<td align="right">0.663</td>
<td align="right">0.081</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0</td>
<td align="right">0.519</td>
<td align="right">0.099</td>
</tr>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1 &amp; Z == 1</td>
<td align="right">0.713</td>
<td align="right">0.101</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0 &amp; Z == 1</td>
<td align="right">0.713</td>
<td align="right">0.101</td>
</tr>
<tr class="odd">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 1 &amp; Z == 0</td>
<td align="right">0.509</td>
<td align="right">0.104</td>
</tr>
<tr class="even">
<td align="left">X == 1 &amp; Y == 1 &amp; K == 0 &amp; Z == 0</td>
<td align="right">0.509</td>
<td align="right">0.104</td>
</tr>
</tbody>
</table>
<p>Here fuller understanding of the model lets researchers use information on <span class="math inline">\(Z\)</span> to update on values for <span class="math inline">\(Z\)</span> and in turn update on the likely effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Rows 3-6 highlight that the updating works through inferences on <span class="math inline">\(Z\)</span> and there are no gains when <span class="math inline">\(Z\)</span> is known, as in Study 2.</p>
<p>In this example Studies 2 and 3 can be thought of as helper experiments for Study 1. Study 2 might be thought of as a mechnism study whereas Study 3 is more like a measurement study.</p>
</div>
<div id="different-models-for-different-sites" class="section level2">
<h2><span class="header-section-number">14.4</span> Different models for different sites</h2>
<p>In the last example we assumed that the same model operated in the same wayat all sites. This is a strong assumption, though sometimes justifiable (for instance if sites were randomly allocated across studies).</p>
<p>If the same model does not operate at different sites it might still be possible to update in this way. For this, however, we need to be able to specify <em>how</em> sites differ Consider a problem where the models partially differ across sites: for instance we believe that although treatment effects are different in two sites yet the mechanisms linking treatment to outcomes are the same. As a simple example we might imagine that <span class="math inline">\(X\)</span> is differentially likely to produce <span class="math inline">\(M\)</span> in two sites, but if it does the relation between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> is common across sites.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># In this model you are more likely to have an M=1 type regardless if Y = 1 regardless </span>
<span class="co"># This produces a positive confound</span>

model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X-&gt;M-&gt;Y&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">set_confound</span>(<span class="dt">confound =</span> <span class="kw">list</span>(<span class="dt">M =</span> <span class="st">&quot;(Y[M=1] ==1) &amp; (Y[M=0]==1)&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(.<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">.2</span>, <span class="fl">.7</span>, 
                             <span class="fl">.5</span>, <span class="fl">.5</span>, 
                             <span class="fl">.7</span>, <span class="dv">0</span>, <span class="fl">.2</span>, <span class="fl">.1</span>,
                               <span class="fl">.2</span>, <span class="fl">.2</span>, <span class="fl">.4</span>, <span class="fl">.2</span>))

<span class="kw">plot_dag</span>(model_<span class="dv">1</span>)</code></pre>
<p><img src="ii_files/figure-html/unnamed-chunk-93-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span>(do_diagnosis){
  
  df_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">simulate_data</span>(model_<span class="dv">1</span>, <span class="dt">n =</span> <span class="dv">20000</span>, <span class="dt">using =</span> <span class="st">&quot;parameters&quot;</span>)
  
  posterior_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">gbiqq</span>(model_<span class="dv">1</span>, df_<span class="dv">1</span>, <span class="dt">stan_model =</span> fit)
  
  
  
  <span class="co"># In this model you are more likely to have an M=1 regardless if Y = 1 regardless </span>
  <span class="co"># This produces a negative confound</span>
  model_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X-&gt;M-&gt;Y&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">set_confound</span>(<span class="dt">confound =</span> <span class="kw">list</span>(<span class="dt">M =</span> <span class="st">&quot;(Y[M=1] ==1) &amp; (Y[M=0]==1)&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(.<span class="dv">7</span>, <span class="fl">.1</span>, <span class="fl">.2</span>, <span class="dv">0</span>, 
                               <span class="fl">.5</span>, <span class="fl">.5</span>, 
                                <span class="dv">0</span>, <span class="fl">.1</span>, <span class="fl">.2</span>, <span class="fl">.7</span>,
                               <span class="fl">.2</span>, <span class="fl">.2</span>, <span class="fl">.4</span>, <span class="fl">.2</span>))
  df_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">simulate_data</span>(model_<span class="dv">2</span>, <span class="dt">n =</span> <span class="dv">20000</span>, <span class="dt">using =</span> <span class="st">&quot;parameters&quot;</span>)
  
  posterior_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">gbiqq</span>(model_<span class="dv">2</span>, df_<span class="dv">2</span>, <span class="dt">stan_model =</span> fit)
  
  out1 &lt;-<span class="st"> </span><span class="kw">query_model</span>(posterior_<span class="dv">1</span>, <span class="dt">using=</span><span class="st">&quot;posteriors&quot;</span>, <span class="dt">queries =</span> <span class="kw">list</span>(<span class="st">`</span><span class="dt">X on M</span><span class="st">`</span> =<span class="st"> &quot;M[X=1] - M[X=0]&quot;</span>, <span class="st">`</span><span class="dt">M on Y</span><span class="st">`</span> =<span class="st"> &quot;Y[M=1] - Y[M=0]&quot;</span>))  
  
  out2 &lt;-<span class="st"> </span><span class="kw">query_model</span>(posterior_<span class="dv">2</span>, <span class="dt">using=</span><span class="st">&quot;posteriors&quot;</span>, <span class="dt">queries =</span> <span class="kw">list</span>(<span class="st">`</span><span class="dt">X on M</span><span class="st">`</span> =<span class="st"> &quot;M[X=1] - M[X=0]&quot;</span>, <span class="st">`</span><span class="dt">M on Y</span><span class="st">`</span> =<span class="st"> &quot;Y[M=1] - Y[M=0]&quot;</span>))  
  
  <span class="kw">write_rds</span>(<span class="kw">list</span>(posterior_<span class="dv">1</span>, posterior_<span class="dv">2</span>, out1, out2), <span class="st">&quot;saved/same_mechanism.rds&quot;</span>)
  
  }

same_mechanism &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/same_mechanism.rds&quot;</span>)

<span class="kw">kable</span>(same_mechanism[[<span class="dv">3</span>]])</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Subset</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X on M</td>
<td align="left">All</td>
<td align="left">posteriors</td>
<td align="right">0.204</td>
<td align="right">0.006</td>
</tr>
<tr class="even">
<td align="left">M on Y</td>
<td align="left">All</td>
<td align="left">posteriors</td>
<td align="right">0.239</td>
<td align="right">0.027</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(same_mechanism[[<span class="dv">4</span>]])</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Subset</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X on M</td>
<td align="left">All</td>
<td align="left">posteriors</td>
<td align="right">0.099</td>
<td align="right">0.006</td>
</tr>
<tr class="even">
<td align="left">M on Y</td>
<td align="left">All</td>
<td align="left">posteriors</td>
<td align="right">0.189</td>
<td align="right">0.068</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The marginal effect of X on M will be different in the two cases</span>
<span class="co"># The effect of M on Y is the same however, though it is confounded</span></code></pre>
<p>Under the model there is possibly a difference in the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in the</p>
<div id="observational-and-experimental" class="section level3">
<h3><span class="header-section-number">14.4.1</span> Observational and experimental</h3>
<p>Let us imagine a second case in which one wants to update based on</p>
</div>
</div>
<div id="causal-discovery" class="section level2">
<h2><span class="header-section-number">14.5</span> Causal discovery</h2>
<p>We start with a model with three variables, <span class="math inline">\(X,M,Y\)</span> where <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> directly and indirectly through <span class="math inline">\(M\)</span>. We simulate data from this model – assuming monotonicity but otherwise a flat distribution on types, and then try to recover the structure from this model.</p>
<p>In this case the data structure did not impose restrictions on the skeleton. The true graph can however be recovered with knowledge of the temporal ordering of variables.</p>
<p>Next we consider the model in which X causes Y through M but not directly. In this case we have a restriction — specifically there is no arrow pointing directly from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>. Again we impose monotonicity, draw data, and try to recover the model:</p>
<p>Again we have the correct skeleton and knowledge of timing is enough to recover the graph.</p>
<p>Finally we consider the model in which <span class="math inline">\(Y\)</span> has two causes that do not influence each other. Again we impose monotonicity, draw data, and try to recover the model:</p>
<div class="figure"><span id="fig:unnamed-chunk-98"></span>
<img src="ii_files/figure-html/unnamed-chunk-98-1.png" alt="DAGs from Data" width="480" />
<p class="caption">
Figure 14.2: DAGs from Data
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-clarke2012model">
<p>Clarke, Kevin A, and David M Primo. 2012. <em>A Model Discipline: Political Science and the Logic of Representations</em>. New York: Oxford University Press.</p>
</div>
<div id="ref-dawid2017probability">
<p>Dawid, A Philip, Monica Musio, and Rossella Murtas. 2017. “The Probability of Causation.” <em>Law, Probability and Risk</em> 16 (4): 163–79.</p>
</div>
<div id="ref-dawid2019bounding">
<p>Dawid, Philip, Macartan Humphreys, and Monica Musio. 2019. “Bounding Causes of Effects with Mediators.” <em>arXiv Preprint arXiv:1907.00399</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="caseselection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="evaluation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
