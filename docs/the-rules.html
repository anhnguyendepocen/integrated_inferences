<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 The rules | Integrated Inferences</title>
  <meta name="description" content="Bayesian causal models for integrated inferences." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 The rules | Integrated Inferences" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://macartan.github.io/integrated_inferences/" />
  <meta property="og:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />
  <meta property="og:description" content="Bayesian causal models for integrated inferences." />
  <meta name="github-repo" content="macartan/integrated_inferences" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 The rules | Integrated Inferences" />
  
  <meta name="twitter:description" content="Bayesian causal models for integrated inferences." />
  <meta name="twitter:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="theory.html"/>
<link rel="next" href="pt.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#counterfactualmodel"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#potential-outcomes"><i class="fa fa-check"></i><b>2.1.1</b> Potential outcomes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#generalization"><i class="fa fa-check"></i><b>2.1.2</b> Generalization</a></li>
<li class="chapter" data-level="2.1.3" data-path="models.html"><a href="models.html#summaries-of-potential-outcomes"><i class="fa fa-check"></i><b>2.1.3</b> Summaries of potential outcomes</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#graphing-models-and-using-graphs"><i class="fa fa-check"></i><b>2.3</b> Graphing models and using graphs</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#graphing"><i class="fa fa-check"></i><b>2.3.1</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.3.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#simplifying-models"><i class="fa fa-check"></i><b>2.3.3</b> Simplifying models</a></li>
<li class="chapter" data-level="2.3.4" data-path="models.html"><a href="models.html#retaining-probabilisitic-relations"><i class="fa fa-check"></i><b>2.3.4</b> Retaining probabilisitic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#conc2"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.5</b> Chapter Appendix</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.5.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.5.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.5.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.5.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.5.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform"><i class="fa fa-check"></i><b>3.1</b> Welfare state reform</a></li>
<li class="chapter" data-level="3.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions"><i class="fa fa-check"></i><b>3.2</b> Military Interventions</a></li>
<li class="chapter" data-level="3.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization"><i class="fa fa-check"></i><b>3.3</b> Development and Democratization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Queries</a>
<ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>6</b> Theories as causal models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="theory.html"><a href="theory.html#models-as-theories-of"><i class="fa fa-check"></i><b>6.1</b> Models as <em>theories of</em></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="theory.html"><a href="theory.html#implications-of-structural-causal-models"><i class="fa fa-check"></i><b>6.1.1</b> Implications of structural causal models</a></li>
<li class="chapter" data-level="6.1.2" data-path="theory.html"><a href="theory.html#implications-of-probabilistic-causal-models"><i class="fa fa-check"></i><b>6.1.2</b> Implications of probabilistic causal models</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="theory.html"><a href="theory.html#uses"><i class="fa fa-check"></i><b>6.2</b> Uses</a></li>
<li class="chapter" data-level="6.3" data-path="theory.html"><a href="theory.html#explanation"><i class="fa fa-check"></i><b>6.3</b> Explanation</a></li>
<li class="chapter" data-level="6.4" data-path="theory.html"><a href="theory.html#theoretical-development"><i class="fa fa-check"></i><b>6.4</b> Theoretical development</a></li>
<li class="chapter" data-level="6.5" data-path="theory.html"><a href="theory.html#theories-restructure-error"><i class="fa fa-check"></i><b>6.5</b> Theories restructure error</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-rules.html"><a href="the-rules.html"><i class="fa fa-check"></i><b>7</b> The rules</a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-rules.html"><a href="the-rules.html#mappings-are-not-1-to-1"><i class="fa fa-check"></i><b>7.1</b> Mappings are not 1 to 1</a></li>
<li class="chapter" data-level="7.2" data-path="the-rules.html"><a href="the-rules.html#structural-consistency"><i class="fa fa-check"></i><b>7.2</b> Structural consistency</a></li>
<li class="chapter" data-level="7.3" data-path="the-rules.html"><a href="the-rules.html#from-structure-to-beliefs-about-types"><i class="fa fa-check"></i><b>7.3</b> From structure to beliefs about types</a></li>
<li class="chapter" data-level="7.4" data-path="the-rules.html"><a href="the-rules.html#probabilistic-consistency"><i class="fa fa-check"></i><b>7.4</b> Probabilistic consistency</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="the-rules.html"><a href="the-rules.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>7.4.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="7.4.2" data-path="the-rules.html"><a href="the-rules.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>7.4.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="the-rules.html"><a href="the-rules.html#illustration-of-unpacking-nodal-types"><i class="fa fa-check"></i><b>7.5</b> Illustration of unpacking nodal types</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="the-rules.html"><a href="the-rules.html#implied-consistency-of-priors"><i class="fa fa-check"></i><b>7.5.1</b> Implied consistency of priors</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="the-rules.html"><a href="the-rules.html#conclusion"><i class="fa fa-check"></i><b>7.6</b> Conclusion</a></li>
<li class="chapter" data-level="7.7" data-path="the-rules.html"><a href="the-rules.html#chapter-appendices"><i class="fa fa-check"></i><b>7.7</b> Chapter Appendices</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="the-rules.html"><a href="the-rules.html#summary-boxes"><i class="fa fa-check"></i><b>7.7.1</b> Summary Boxes</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="the-rules.html"><a href="the-rules.html#connections-to-other-writing-on-theory"><i class="fa fa-check"></i><b>7.8</b> Connections to other writing on theory</a></li>
<li class="chapter" data-level="7.9" data-path="the-rules.html"><a href="the-rules.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>7.9</b> Illustration of a Mapping from a Game to a DAG</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="the-rules.html"><a href="the-rules.html#quantifying-the-gains-from-a-theory"><i class="fa fa-check"></i><b>7.9.1</b> Quantifying the gains from a theory</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="8" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>8</b> Process Tracing with Causal Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>8.1</b> Process tracing and causal models</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>8.1.1</b> The intuition</a></li>
<li class="chapter" data-level="8.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>8.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="8.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>8.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="pt.html"><a href="pt.html#mapping-from-models-to-classic-qualitative-tests"><i class="fa fa-check"></i><b>8.2</b> Mapping from models to classic qualitative tests</a></li>
<li class="chapter" data-level="8.3" data-path="pt.html"><a href="pt.html#principles-of-learning"><i class="fa fa-check"></i><b>8.3</b> Principles of learning</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>8.3.1</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="8.3.2" data-path="pt.html"><a href="pt.html#learning-requires-uncertainty"><i class="fa fa-check"></i><b>8.3.2</b> Learning requires uncertainty</a></li>
<li class="chapter" data-level="8.3.3" data-path="pt.html"><a href="pt.html#multiple-ways-for-queries-to-be-satisfied"><i class="fa fa-check"></i><b>8.3.3</b> Multiple ways for queries to be satisfied</a></li>
<li class="chapter" data-level="8.3.4" data-path="pt.html"><a href="pt.html#beware-of-highly-unlikely-queries"><i class="fa fa-check"></i><b>8.3.4</b> Beware of highly unlikely queries</a></li>
<li class="chapter" data-level="8.3.5" data-path="pt.html"><a href="pt.html#population-level-uncertainty-does-not-alter-case-level-causal-inference"><i class="fa fa-check"></i><b>8.3.5</b> Population-level uncertainty does not alter case-level causal inference</a></li>
<li class="chapter" data-level="8.3.6" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>8.3.6</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="8.3.7" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>8.3.7</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>9</b> Application: Process Tracing with a Causal Model</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>9.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="9.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>9.2</b> A Structural Causal Model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>9.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>9.3</b> Results</a></li>
<li class="chapter" data-level="9.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>9.4</b> Pathways</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>9.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="9.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>9.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>9.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="9.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>9.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>10</b> Integrated inferences</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mixing.html"><a href="mixing.html#sample-inference"><i class="fa fa-check"></i><b>10.1</b> Sample inference</a></li>
<li class="chapter" data-level="10.2" data-path="mixing.html"><a href="mixing.html#from-sample-queries-to-general-processes"><i class="fa fa-check"></i><b>10.2</b> From sample queries to general processes</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="mixing.html"><a href="mixing.html#set-up"><i class="fa fa-check"></i><b>10.2.1</b> Set up</a></li>
<li class="chapter" data-level="10.2.2" data-path="mixing.html"><a href="mixing.html#inference"><i class="fa fa-check"></i><b>10.2.2</b> Inference</a></li>
<li class="chapter" data-level="10.2.3" data-path="mixing.html"><a href="mixing.html#wrinkles"><i class="fa fa-check"></i><b>10.2.3</b> Wrinkles</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="mixing.html"><a href="mixing.html#mixed-methods"><i class="fa fa-check"></i><b>10.3</b> Mixed methods</a></li>
<li class="chapter" data-level="10.4" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>10.4</b> Considerations</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="mixing.html"><a href="mixing.html#probative-value-can-be-derived-from-a-causal-structure-plus-data"><i class="fa fa-check"></i><b>10.4.1</b> Probative value can be derived from a causal structure plus data</a></li>
<li class="chapter" data-level="10.4.2" data-path="mixing.html"><a href="mixing.html#learning-without-identification"><i class="fa fa-check"></i><b>10.4.2</b> Learning without identification</a></li>
<li class="chapter" data-level="10.4.3" data-path="mixing.html"><a href="mixing.html#beyond-binary-data"><i class="fa fa-check"></i><b>10.4.3</b> Beyond binary data</a></li>
<li class="chapter" data-level="10.4.4" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>10.4.4</b> Measurement error</a></li>
<li class="chapter" data-level="10.4.5" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>10.4.5</b> Spillovers</a></li>
<li class="chapter" data-level="10.4.6" data-path="mixing.html"><a href="mixing.html#clustering"><i class="fa fa-check"></i><b>10.4.6</b> Clustering</a></li>
<li class="chapter" data-level="10.4.7" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>10.4.7</b> Parameteric models</a></li>
<li class="chapter" data-level="10.4.8" data-path="mixing.html"><a href="mixing.html#prior-databeliefs-channel-the-learning-from-new-data"><i class="fa fa-check"></i><b>10.4.8</b> Prior data/beliefs “channel” the learning from new data</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>10.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>11</b> Mixed-Method Application: Inequality and Democracy Revisited</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>11.1</b> A trained model</a></li>
<li class="chapter" data-level="11.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>11.2</b> Data</a></li>
<li class="chapter" data-level="11.3" data-path="mixingapp.html"><a href="mixingapp.html#inference-1"><i class="fa fa-check"></i><b>11.3</b> Inference</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>11.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="11.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>11.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="mixingapp.html"><a href="mixingapp.html#exercises"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>12</b> Mixing models</a>
<ul>
<li class="chapter" data-level="12.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>12.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="12.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>12.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="12.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>12.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="12.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>12.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="13" data-path="elements.html"><a href="elements.html"><i class="fa fa-check"></i><b>13</b> Elements of Design</a>
<ul>
<li class="chapter" data-level="13.1" data-path="elements.html"><a href="elements.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>13.1</b> Model, inquiry, data strategy, answer strategy</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="elements.html"><a href="elements.html#defining-a-model"><i class="fa fa-check"></i><b>13.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="elements.html"><a href="elements.html#evaluating-a-design"><i class="fa fa-check"></i><b>13.2</b> Evaluating a design</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="elements.html"><a href="elements.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>13.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="13.2.2" data-path="elements.html"><a href="elements.html#illustration"><i class="fa fa-check"></i><b>13.2.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="elements.html"><a href="elements.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>13.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>14</b> Clue Selection as a Decision Problem</a>
<ul>
<li class="chapter" data-level="14.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>14.1</b> Core logic</a></li>
<li class="chapter" data-level="14.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>14.2</b> A strategic approach</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>14.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="14.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>14.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="14.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>14.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>14.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="14.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>14.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>15</b> Mixed methods data strategies</a>
<ul>
<li class="chapter" data-level="15.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-strategies"><i class="fa fa-check"></i><b>15.1</b> Case selection strategies</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="caseselection.html"><a href="caseselection.html#no-general-rules"><i class="fa fa-check"></i><b>15.1.1</b> No general rules</a></li>
<li class="chapter" data-level="15.1.2" data-path="caseselection.html"><a href="caseselection.html#specific-case-walk-through"><i class="fa fa-check"></i><b>15.1.2</b> Specific case walk through</a></li>
<li class="chapter" data-level="15.1.3" data-path="caseselection.html"><a href="caseselection.html#case-selection-from-causal-models-a-simulation-based-approach"><i class="fa fa-check"></i><b>15.1.3</b> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="caseselection.html"><a href="caseselection.html#wide-or-deep"><i class="fa fa-check"></i><b>15.2</b> Wide or Deep</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="caseselection.html"><a href="caseselection.html#walk-through-of-a-simple-comparison"><i class="fa fa-check"></i><b>15.2.1</b> Walk-through of a simple comparison</a></li>
<li class="chapter" data-level="15.2.2" data-path="caseselection.html"><a href="caseselection.html#results-from-simulations"><i class="fa fa-check"></i><b>15.2.2</b> Results from simulations</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>15.3</b> Principles</a></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="16" data-path="justifying.html"><a href="justifying.html"><i class="fa fa-check"></i><b>16</b> Justifying models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="justifying.html"><a href="justifying.html#nothing-from-nothing"><i class="fa fa-check"></i><b>16.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="16.2" data-path="justifying.html"><a href="justifying.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>16.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="16.3" data-path="justifying.html"><a href="justifying.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>16.3</b> Justification from experimental designs</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="justifying.html"><a href="justifying.html#mediator"><i class="fa fa-check"></i><b>16.3.1</b> Mediator</a></li>
<li class="chapter" data-level="16.3.2" data-path="justifying.html"><a href="justifying.html#moderator"><i class="fa fa-check"></i><b>16.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="justifying.html"><a href="justifying.html#causal-discovery"><i class="fa fa-check"></i><b>16.4</b> Causal discovery</a></li>
<li class="chapter" data-level="16.5" data-path="justifying.html"><a href="justifying.html#exercise"><i class="fa fa-check"></i><b>16.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>17</b> Evaluating models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>17.1</b> Five Strategies</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>17.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="17.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>17.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="17.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>17.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="17.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>17.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="17.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>17.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>17.2</b> Evaluating the Democracy-Inequality model</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>17.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="17.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>17.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="17.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>17.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="17.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>17.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="the-rules.html"><a href="the-rules.html#conclusion"><i class="fa fa-check"></i><b>18</b> Final Words</a>
<ul>
<li class="chapter" data-level="18.1" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>18.1</b> The benefits</a></li>
<li class="chapter" data-level="18.2" data-path="conclusion.html"><a href="conclusion.html#the-worries"><i class="fa fa-check"></i><b>18.2</b> The worries</a></li>
<li class="chapter" data-level="18.3" data-path="conclusion.html"><a href="conclusion.html#the-future"><i class="fa fa-check"></i><b>18.3</b> The future</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="19" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>19</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/CausalQueries/" target="blank">Uses CausalQueries</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-rules" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> The rules</h1>
<div id="mappings-are-not-1-to-1" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Mappings are not 1 to 1</h2>
<p>The mappings between higher-level claims and theories may not be one-to-one. A single theory can support multiple higher-level models. Moreover, a single higher-level relation can be supported by multiple, possibly incompatible lower-level theories.</p>
<p>To illustrate, consider two “lower level” theories of democratization:</p>
<ul>
<li>(<span class="math inline">\(L_1\)</span>): <span class="math inline">\(Inequality \rightarrow Democratization \leftarrow Mobilization\)</span><br />
</li>
<li>(<span class="math inline">\(L_2\)</span>): <span class="math inline">\(Inequality \rightarrow Mobilization \rightarrow Democratization\)</span></li>
</ul>
<p>Note how these theories are incompatible with one another. While <span class="math inline">\(Inequality\)</span> and <span class="math inline">\(Democratization\)</span> are independent in <span class="math inline">\(L_1\)</span>, they are causally related in <span class="math inline">\(L_2\)</span>. Moreover, in <span class="math inline">\(L_2\)</span>, <span class="math inline">\(Inequality\)</span> and <span class="math inline">\(Democratization\)</span> are related only through <span class="math inline">\(Mobilization\)</span>, while in <span class="math inline">\(L_1\)</span>, <span class="math inline">\(Democratization\)</span> is directly affected by <span class="math inline">\(Inequality\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Now, consider the following three higher-level claims:</p>
<ul>
<li>(<span class="math inline">\(H_1\)</span>): <span class="math inline">\(Inequality \rightarrow Mobilization\)</span></li>
<li>(<span class="math inline">\(H_2\)</span>): <span class="math inline">\(Inequality \rightarrow Democratization\)</span></li>
<li>(<span class="math inline">\(H_3\)</span>): <span class="math inline">\(Mobilization \rightarrow Democratization\)</span></li>
</ul>
<p><span class="math inline">\(H_1\)</span> can be supported only by one of these theories: only in <span class="math inline">\(L_2\)</span>, and not in <span class="math inline">\(L_1\)</span>, does <span class="math inline">\(Inequality\)</span> cause <span class="math inline">\(Mobilization\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p>However, our other two hypotheses could each rest on <em>both</em> of the lower-level theories, even though those two theories are incompatible with one another. <span class="math inline">\(H_1\)</span> could be derived from (explained by) either theory: though the two theories differ on whether mobilization is a mediator or a moderator, they agree that inequality can affect democratization. Similarly, both theories imply <span class="math inline">\(H_2\)</span>, in which <span class="math inline">\(Mobilization\)</span> affects <span class="math inline">\(Democratization\)</span>, even though the two theories disagree on whether inequality is an antecedent to mobilization or a moderator of its effect.</p>
<p>Thus, multiple theories can usually be proposed to explain any given causal effect, and those theories need not be consistent with <em>each other</em>. When seeking an explanation for, say, <span class="math inline">\(H_1\)</span>, the choice between <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> cannot be dictated by logical mappings between models; it must be drawn from a substantive belief about which set of causal dependencies operates in the world. On the other hand, <span class="math inline">\(L_2\)</span> <em>is</em> logically ruled out as an explanation of <span class="math inline">\(H_3\)</span>.</p>
<p>It is also true that any given theory logically implies multiple <em>higher-level</em> claims about causal relations. <span class="math inline">\(L_2\)</span> implies both <span class="math inline">\(H_2\)</span> and <span class="math inline">\(H_3\)</span>. Note, however, that the multiple higher-level claims that follow from a theory <em>must</em> be compatible with one another.</p>
</div>
<div id="structural-consistency" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Structural consistency</h2>
</div>
<div id="from-structure-to-beliefs-about-types" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> From structure to beliefs about types</h2>
<p>So far we have been discussing the <em>structural</em> components of theories: we have seen how a given causal structure can be justified in terms of a more detailed causal structure. But theories also involve claims about what <em>kinds of effects</em> operate between variables. For instance, the belief that inequality <em>generates</em> democratization, of course, represents a different kind of theory from the belief that inequality <em>prevents</em> democratization, although the two might share a DAG structure. As discussed in Chapter <a href="models.html#models">2</a>, a <em>probabilistic</em> causal model comprises both a causal structure and beliefs about distributions over the exogenous nodes — i.e., in our setup, over a model’s nodal types. In an <span class="math inline">\(I \rightarrow D\)</span> model, for instance, probabilistic beliefs include beliefs about the probability that a given case has the type <span class="math inline">\(\theta^D_{01}\)</span> types and the probability that it has the type <span class="math inline">\(\theta^D_{10}\)</span>. Thus, as we have with structure, we can think about how a set of beliefs about the distribution of nodal types at a higher level can be supported by beliefs about nodal-type distributions in a lower-level model.</p>
<p>For instance, suppose we start with an <span class="math inline">\(I \rightarrow D\)</span> model and the belief that <span class="math inline">\(Pr(\theta^D=\theta^D_{01}) = 0.5\)</span> – i.e., effects are positive <span class="math inline">\(50\%\)</span> of the time. On a structural level, as we have seen, this model could be supported by the model <span class="math inline">\(I \rightarrow M \rightarrow D\)</span>. But what beliefs about causal effects in this lower-level model might support the belief that effects of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span> are positive <span class="math inline">\(50\%\)</span> of the time?</p>
<p>As with structural mappings, we can imagine a whole range of probabilistic beliefs at the lower level that would be consistent with a given higher-level belief. In a <span class="math inline">\(I \rightarrow M \rightarrow D\)</span> model, we can arrive at a positive effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span> either through a combination of the nodal types <span class="math inline">\(\theta_{01}^M\)</span> and <span class="math inline">\(\theta_{01}^{D_{\text lower}}\)</span> (linked positive effects) or of the nodal types <span class="math inline">\(\theta_{10}^M\)</span> and <span class="math inline">\(\theta_{10}^{D_{\text lower}}\)</span> (linked negative effects). So, for instance, a lower-level model in which <span class="math inline">\(Pr(\theta^M=\theta_{01}^M)=0.5\)</span>, <span class="math inline">\(Pr(\theta^{D_{\text lower}}=\theta_{01}^{D_{\text lower}})=0.5\)</span>, <span class="math inline">\(Pr(\theta^M=\theta_{10}^M)=0.5\)</span>, and <span class="math inline">\(Pr(\theta^{D_{\text lower}}=\theta_{10}^{D_{\text lower}})=0.5\)</span> would be consistent with the belief that <span class="math inline">\(Pr(\theta^D=\theta^D_{01}) = 0.5\)</span>. So too, however, would a lower-level model in which <span class="math inline">\(Pr(\theta^M=\theta_{01}^M)=0.707\)</span>, <span class="math inline">\(Pr(\theta^{D_{\text lower}}=\theta_{01}^{D_{\text lower}})=0.707\)</span>, <span class="math inline">\(Pr(\theta^M=\theta_{10}^M)=0\)</span>, and <span class="math inline">\(Pr(\theta^{D_{\text lower}}=\theta_{10}^{D_{\text lower}})=0\)</span> equally implies <span class="math inline">\(Pr(\theta^D=\theta^D_{01}) = 0.5\)</span> in the higher-level model.</p>
<p>Meanwhile, there is a whole range of beliefs about effects in the lower-level model that do not justify the higher-level belief. For instance, any lower-level model in which <span class="math inline">\((Pr(\theta^D=\theta^D_{00}) + Pr(\theta^D=\theta^D_{11})) &gt; 0.5\)</span> is inconsistent with the belief in a 0.5 probability of positive <span class="math inline">\(I \rightarrow D\)</span> effects and cannot serve as a theory of the higher-level model.</p>
<p>We will generally want to think of lower-level models with quite different distributional beliefs as representing different theories, as they will typically capture quite different substantive beliefs about how the world works. We can think of the first lower-level model, above, as one in which inequality can cause democratization via two mechanisms, either by causing mass-mobilization which causes democratizaiton or by preventing mass-mobilization which prevents democratization — while the second model is a theory in which only the former mechanism operates.</p>
</div>
<div id="probabilistic-consistency" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Probabilistic consistency</h2>
<div id="type-disaggregation-in-a-mediation-model" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Type disaggregation in a mediation model</h3>
<!-- We might then wonder *how* inequality might exert its effect on democratization. One possible answer, drawing on our model in Chapter \@ref(models) is that inequality can affect mass-mobilization, which in turn can affect democratization. This explanatory claim is visually represented in Panel (b) of the figure. Here, we can see that any effect of $I$ on $D$ runs through $M$. There are details of this graph that we will delve into later. But for now, it is sufficient to see that we have partly explained variation left unexplained by model (a). Model (b) allows us to say, for instance, that whether inequality has an effect on democratization has to depend on whether inequality has an effect on mobilization. Model (b) thus theorizes, in one important sense, a part of inequality's effect that is left untheorized in model (a).  -->
<p>Whereas Model (a) has nodal types defined for <span class="math inline">\(D\)</span>,<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Model (b) has nodal types defined both for node <span class="math inline">\(M\)</span> and for node <span class="math inline">\(D\)</span>. We thus allow <span class="math inline">\(I\)</span> to have a positive, negative, or no effect on <span class="math inline">\(M\)</span>, with <span class="math inline">\(\theta^M\)</span> taking on four possible values, <span class="math inline">\(\theta_{10}^M,\theta_{01}^M,\theta_{00}^M\)</span>,and <span class="math inline">\(\theta_{11}^M\)</span>. Further, we allow for <span class="math inline">\(M\)</span> to have a positive, negative, or no effect on <span class="math inline">\(D\)</span>, with <span class="math inline">\(\theta^D_{\text{lower}}\)</span>’s possible values again being one of <span class="math inline">\(\theta_{10}^{D_{\text lower}}\)</span>, <span class="math inline">\(\theta_{01}^{D_{\text lower}}\)</span>, <span class="math inline">\(\theta_{00}^{D_{\text lower}}\)</span>, <span class="math inline">\(\theta_{11}^{D_{\text lower}}\)</span>.</p>
<p>We can now think about <em>combinations</em> of nodal types in the lower-level model as mapping onto nodal types in the higher-level model. Table <a href="the-rules.html#tab:highlowmapping">7.1</a> illustrates.</p>
<table>
<caption><span id="tab:highlowmapping">Table 7.1: </span> Mapping from lower-level nodal types on <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span> to higher-level nodal types on <span class="math inline">\(D\)</span>.</caption>
<colgroup>
<col width="15%" />
<col width="21%" />
<col width="21%" />
<col width="21%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(\theta_{10}^{D_{lower}}\)</span></th>
<th align="center"><span class="math inline">\(\theta_{01}^{D_{lower}}\)</span></th>
<th align="center"><span class="math inline">\(\theta_{00}^{D_{lower}}\)</span></th>
<th align="center"><span class="math inline">\(\theta_{11}^{D_{lower}}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta_{10}^{M}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{01}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{10}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta_{01}^{M}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{10}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{01}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta_{00}^{M}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta_{11}^{M}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{00}^{D_{higher}}\)</span></td>
<td align="center"><span class="math inline">\(\theta_{11}^{D_{higher}}\)</span></td>
</tr>
</tbody>
</table>
<p>For instance, in a case in which both <span class="math inline">\(\theta^M=\theta^M_{01}\)</span> (there is a positive effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span>) and <span class="math inline">\(\theta^{D_{\text{lower}}}=\theta_{01}^{D_{lower}}\)</span> (there is a positive effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(D\)</span>), we have a positive effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span>—meaning that, in the <em>higher-level</em> model, <span class="math inline">\(\theta^{D_{higher}}=\theta^{D_{higher}}_{01}\)</span>. Two linked <em>negative</em> effects at the lower level likewise generate a positive effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span>—and so map onto the same higher-level nodal type, <span class="math inline">\(\theta^{D_{higher}}=\theta^{D_{higher}}_{01}\)</span>.</p>
<p>Further, it is easy to see that if there is no causal effect at <em>either</em> the <span class="math inline">\(I \rightarrow M\)</span> step <em>or</em> the <span class="math inline">\(M \rightarrow D\)</span> step, we will have one of the null effect types at the higher level. This is because, in Model (b), <span class="math inline">\(I\)</span> cannot affect <span class="math inline">\(D\)</span> unless there are causal effects at both constituent steps. In other words, in Model (b), <span class="math inline">\(I\)</span> can affect <span class="math inline">\(D\)</span> <em>only</em> through <span class="math inline">\(M\)</span> in this model; there are no direct effects or other pathways permitted.</p>
<p>To foreshadow the discussion in later chapters, these mappings of nodal types between levels are critical. They allow us to draw inferences about causal relations at a lower level and then <em>use</em> those inferences to answer questions posed at a higher level. For instance, if we can learn about the effect of inequality on mass mobilization (a question posed at the lower level), then we can apply that learning to answering a question about whether inequality affects democratization (a higher-level question).</p>
<!-- The lower-level functional equations are formally similar though now each unit's outcome (given $X$) depends on two event probabilities: one that determines type with respect to the effect of $X$ on $K$ ($t_{ij}^{K}$), and one with respect to the effect of $K$ on $Y$ ($u_{ij}^{Y}$): -->
<!-- $$Y(K, u_{ij}^{Y}) = \left\{ \begin{array}{cc}   -->
<!-- i & \text{ if } K=0 \\ j & \text{ if } K=1 \end{array}  \right.$$ -->
<!-- $$K(X, u_{ij}^{K}) = \left\{ \begin{array}{cc}   -->
<!-- i & \text{ if } X=0 \\ j & \text{ if } X=1 \end{array}  \right.$$ -->
<!-- Thus, in the lower-level model, there are sixteen types that derive from the cross product of two independent random terms. -->
<!-- Critically, one can derive the higher-level types from the lower level types, and beliefs about the higher level types from beliefs about the lower level types. For example, using the nomenclature in @humphreys2015mixing: -->
<!-- \begin{eqnarray*} -->
<!-- \text{adverse: }u_{10}^{high} &=& u_{01}^{K}\&u_{10}^{Y} \text{ or } u_{10}^{K}\&u_{01}^{Y} \\ -->
<!-- \text{beneficial: }u_{01}^{high} &=& u_{01}^{K}\&u_{01}^{Y} \text{ or }  u_{10}^{K}\&u_{10}^{Y} \\ -->
<!-- \text{chronic: } u_{00}^{high} &=& u_{00}^{Y} \text{ or }  u_{00}^{K}\&u_{01}^{Y} \text{ or }  u_{11}^{K}\&u_{10}^{Y}\\ -->
<!-- \text{destined: }u_{11}^{high} &=& u_{11}^{Y} \text{ or }  u_{00}^{K}\&u_{10}^{Y} \text{ or }  u_{11}^{K}\&u_{01}^{Y} -->
<!-- \end{eqnarray*} -->
<!-- In the same way, the higher-level probabilities are implied by the lower level probabilities. -->
<!-- \begin{eqnarray*} -->
<!-- \text{adverse: }\lambda_{10}^{high} &=& \lambda_{01}^{K}\lambda_{10}^{Y} + \lambda_{10}^{K}\lambda_{01}^{Y} \\ -->
<!-- \text{beneficial: }\lambda_{01}^{high} &=& \lambda_{01}^{K}\lambda_{01}^{Y} + \lambda_{10}^{K}\lambda_{10}^{Y} \\ -->
<!-- \text{chronic: } \lambda_{00}^{high} &=& \lambda_{00}^{Y} + \lambda_{00}^{K}\lambda_{01}^{Y} + \lambda_{11}^{K}\lambda_{10}^{Y}\\ -->
<!-- \text{destined: }\lambda_{11}^{high} &=& \lambda_{11}^{Y} + \lambda_{00}^{K}\lambda_{10}^{Y} + \lambda_{11}^{K}\lambda_{01}^{Y} -->
<!-- \end{eqnarray*} -->
<!-- Importantly, even without specifying a distribution over $U_K$ or $U_Y^{\text{lower}}$, a lower-level structural model could be informative by restricting the *ranges* of  $U_K$ or $U_Y^{\text{lower}}$. For instance, a lower level theory that imposed a monotonicity condition (no adverse effects) might exclude $t^K_{10}$ and $t^y_{10}$---that is, increasing $X$ never reduces $K$, and increasing $K$ never reduces $Y$.  -->
<!-- We return  to this example below and show how observation  of $K$ can yield inference on causal estimands when  the theory places this kind of a structure on relationships. -->
</div>
<div id="type-disaggregation-in-a-moderation-model" class="section level3" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Type disaggregation in a moderation model</h3>
<p>Alternatively, we might wonder <em>why</em> or under what conditions inequality causes democratization. Our simple claim, in panel (a), allows that <span class="math inline">\(I\)</span> <em>can</em> cause <span class="math inline">\(D\)</span>, but provides no information about the conditions under which it does so. Those conditions are implicitly embedded within <span class="math inline">\(\theta^D\)</span>, where they are left unspecified. We could, however, theorize some of what is left unsaid in in panel (a). We do this in panel (c), where we posit ethnic homogeneity (<span class="math inline">\(E\)</span>) as a moderator of inequality’s effect on democratization. Panel (c) represents a theory of panel (a) in that it can help account for variation in causal effects that is unaccounted for in Model (a).</p>
<p>Put differently, Model (c) gives substantive meaning to an aspect of the phenomenon that is merely residual variation in Model (a). Model (a) provides no account of why inequality has the effects it does, relying fully on <span class="math inline">\(\theta^D\)</span> as a placeholder for this uncertainty. In Model (c), <span class="math inline">\(\theta^D\)</span> plays a more modest role, with the substantive variable of ethnic homogeneity now doing some of the work of determining inequality’s possible effects.</p>
<!-- We note one final possibility. Imagine that we started with the quite *specific* claim that inequality sometimes has a positive effect on democratization and sometimes has no effect (with democratization happening for other reasons). Suppose we believed this claim to be true for some, possibly not well defined, domain of cases.^[This claim could be graphically represented by panel (a), but would involve a more restricted range for $\theta^D$ and simpler functional equation, involving only two types.] Model (c) could serve as a theory of this more specific claim in that Model (c), paired with some data, could explain the claim. In particular, Model (c) paired with the data $E=1$---we are in an ethnically homogeneous context---produces the more specific claim. Here, it is the theory *plus an observation* of context that accounts for the specific claim.  -->
<!-- Similarly, take the functional equation $f_1: Y=X_1X_2$. Coupled with data $X_2=1$, $f_1$ implies the functional equation $f_2: Y=X_1$.  -->
<!-- ### Causal types in lower level models  -->
<!-- We have discussed theorization largely from a graphical perspective, showing how features of causal graphs change (nodes get split, combined, added, or removed) as we move down or up levels. But there is more that happens beneath the surface of a graphical structure when we theorize a claim: the space of causal types itself changes. We walk through how this works for the mediation and moderation theories described above.  -->
<!-- ### Mediation {#medtheory} -->
<!-- We begin with a simple claim: there are two binary variables, $X$ and $Y$, and $X$ may have an effect on $Y$. This claim is represented in Figure \@ref(fig:Highlow)(a) above. In this graph, $X$ is independent of $\theta^Y$, which means that it is as if $X$ is randomly assigned. -->
<!-- We will let $\theta^Y$ be a variable that ranges across our four different causal types, conditioning how $Y$ responds to $X$. While  $a, b, c$, and $d$ were heuristically useful as a way of introducing the  idea of a causal type, things will soon get more complicated, so it will be useful to have more flexible notation. Going forward, we will usually refer to causal types using $\theta$ notation, with subscripts and superscripts used to denote potential outcomes and outcome variables. In our binary $X \rightarrow Y$ setup, we can indicate the causal type governing $Y$'s response with notation of the form $\theta^Y_{ij}$, where $i$ and $j$ represent $Y$'s potential outcomes. Specifically, $i$ represents the value $Y$ takes on when $X=0$, while $j$ represents the value $Y$ takes on when $X=1$.^[The functional equation for $Y$ is then given by:  -->
<!-- $$Y(x, \theta_{ij}^{Y_\text{higher}}) = \left\{ \begin{array}{cc}   -->
<!-- i & \text{ if } x=0 \\ j & \text{ if } x=1 \end{array}  \right.$$] Thus, the translation from $a, b, c$ and $d$ notation is: -->
<!-- * *a*: $\theta_{10}^Y$. A negative effect implies that $Y$ is $1$ when $X=0$ and $0$ when $X=1$. -->
<!-- * *b*: $\theta_{01}^Y$. A positive effect implies that $Y$ is $0$ when $X=0$ and $1$ when $X=1$. -->
<!-- * *c*: $\theta_{00}^Y$. A null "chronic" effect implies that $Y$ is $0$ regardless of $X$'s value. -->
<!-- * *d*: $\theta_{11}^Y$. A null "destined" effect implies that $Y$ is $1$ regardless of $X$'s value. -->
<!-- To be clear, these $\theta_{ij}^Y$ terms are not random variables; they are the four _values_ (types) that the type-variable $\theta^Y$ can take on. -->
<!-- represented with the notation $u_{ij}$: we read the subscripts to mean that a unit of type $u_{ij}$ has outcome $i$ when $X=0$ and $j$ when $X=1$. Then let $u_Y^{higher}$ have a multinomial distribution over the four values of  $u_{ij}$ with event probabilities  $\lambda_{ij}^{higher}$. ; for example, let $u_X\sim \text{Unif}[0,1]$ and $X = \mathbb{1}(u_K<\pi^K)$. -->
<!-- For example if $U_Y^{higher}$ is distributed normally and $Y$ takes on the value 1 if $bX+u_Y^{higher}$ is above some threshold, we have a probit model.  -->
<!-- Now consider a theory that specifies a variable intervening between $X$ and $Y$. This theory is depicted in Figure \@ref(fig:Highlow)(b) above, where $M$ mediates the relationship. We see that there are now two $\theta$ terms, each representing a set of causal types for a different step in the causal chain. While $\theta^Y$ represented $Y$'s response to its parent $X$, $\theta^Y_{\text{lower}}$ represents $Y$'s response to its "new" parent, $M$. We now also need to conceive of a causal type capturing $M$'s response to $X$, and we let $\theta^M$ represent this type.^[This graph assumes no confounding in the mediating relationship either as the two $\theta$ terms and $X$'s assignment are all independent of one another.] -->
<!-- Now consider the alternative lower-level theory in which  $E$ is posited as a second parent of $D$. This graph contains the substantive assumptions that $E$'s value is determined independently of $I$'s, as well as the assumption that $I$ and $E$ are both as-if randomly assigned. -->
<p>In this graph, we again have a <span class="math inline">\(\theta_D^{\text{lower}}\)</span> term, but it is a different object from <span class="math inline">\(\theta_D^{\text{lower}}\)</span> in the mediation graph. In this moderation model, <span class="math inline">\(\theta_D^{\text{lower}}\)</span> is more complex as it determines the mapping from two binary variables into <span class="math inline">\(D\)</span>. <span class="math inline">\(D\)</span>’s nodal type in this setup now represents how a case’s outcome will respond to four different possible combinations of <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> values. Rather than four nodal types for <span class="math inline">\(D\)</span>, we now have 16, as there are 16 possible ways in which one binary variable might respond to two binary parent variables (see Table <a href="#tab:PO16"><strong>??</strong></a> in Chapter <a href="models.html#models">2</a>).</p>
<p>In Table <a href="the-rules.html#tab:PO16b">7.2</a> we give a mapping from a subset of these lower-level types to the higher-level types corresponding to Model (a).</p>
<table>
<caption><span id="tab:PO16b">Table 7.2: </span> Values for <span class="math inline">\(D\)</span> given <span class="math inline">\(E\)</span> and <span class="math inline">\(I\)</span>. With two binary causal variables, there are 16 nodal types: 16 ways in which <span class="math inline">\(D\)</span> depends on <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>. These lower level types map into higher level types for a model in which <span class="math inline">\(D\)</span> depends on <span class="math inline">\(I\)</span> only, as shown in the final column.</caption>
<colgroup>
<col width="20%" />
<col width="10%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Lower Type</th>
<th align="right"><span class="math inline">\(I=0,E=0\)</span></th>
<th align="right"><span class="math inline">\(I=0,E=1\)</span></th>
<th align="center"><span class="math inline">\(I=1,E=0\)</span></th>
<th align="right"><span class="math inline">\(I=1, E=1\)</span></th>
<th align="center">Higher Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^{D}_{0000}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="center">0</td>
<td align="right">0</td>
<td align="center"><span class="math inline">\(\theta^{D}_{00}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^{D}_{0001}\)</span>
<span class="math inline">\(\theta^{D}_{0010}\)</span></td>
<td align="right">0
0</td>
<td align="right">0
0</td>
<td align="center">0
1</td>
<td align="right">1
0</td>
<td align="center"><span class="math inline">\(\theta^{D}_{01}\)</span> if <span class="math inline">\(E=1\)</span>, else <span class="math inline">\(\theta^D_{00}\)</span>
<span class="math inline">\(\theta^D_{00}\)</span> if <span class="math inline">\(E=1\)</span>, else <span class="math inline">\(\theta^D_{01}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^{D}_{0011}\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="center">1</td>
<td align="right">1</td>
<td align="center"><span class="math inline">\(\theta^{D}_{01}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="right"><span class="math inline">\(\vdots\)</span></td>
<td align="right"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="right"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^{D}_{1110}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="center">1</td>
<td align="right">0</td>
<td align="center"><span class="math inline">\(\theta^D_{11}\)</span> if <span class="math inline">\(E=0\)</span>, else <span class="math inline">\(\theta^D_{10}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^{D}_{1111}\)</span></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="center">1</td>
<td align="right">1</td>
<td align="center"><span class="math inline">\(\theta^D_{11}\)</span></td>
</tr>
</tbody>
</table>
<!-- To illustrate, $\theta_Y^{\text{lower}}=$: -->
<!-- * $\theta_{00}^{11}$ means that $I$ has no effect under any value of $E$, and $E$ has a positive effect under any value of $I$.  -->
<!-- * $\theta_{10}^{10}$ implies that $I$ always has a negative effect, and $E$ never has an effect.  -->
<!-- * $\theta_{01}^{11}$ represents one kind of conditional effect: $I$ has a positive effect only when $E=0$, and $E$ has a positive effect only when $I=0$. -->
<p>Importantly we see that the mapping between lower- and higher-level types can depend on the value of the moderator. More generally, since we can think of the value of exogeneous nodes, <span class="math inline">\(E\)</span> and <span class="math inline">\(I\)</span>, as being nodal types for those nodes,<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> we can think of the lower level nodal type as a concatenation of the higher-level nodal types for <span class="math inline">\(E\)</span> and <span class="math inline">\(D\)</span>. Thus, we can think of the the higher-level type as depending uniquely on the fully specified lower level type.</p>
<p>For instance, a case can have type <span class="math inline">\(\theta^D_{01}\)</span> in the higher-level model if it is of type <span class="math inline">\(\theta^D_{0010}\)</span> <em>and</em> c in the lower-level model. This is a case for which <span class="math inline">\(I\)</span> has a positive effect on <span class="math inline">\(D\)</span> when <span class="math inline">\(E=0\)</span> <em>and</em> in which <span class="math inline">\(E\)</span> <em>is in fact</em> 0. On the other hand, the same lower-level <span class="math inline">\(D\)</span> type in combination with <span class="math inline">\(\theta^{E}_1\)</span> maps onto the type <span class="math inline">\(\theta_{10}\)</span> in the higher-level model—a type in which <span class="math inline">\(D\)</span> responds <em>negatively</em> to <span class="math inline">\(I\)</span>.</p>
<p>In later chapters, we represent all lower- to higher-level mappings relevant to a question of interest with the use of “type-reduction” tables that allow one to readily see how inferences drawn at one level inform causal questions posed at another level.</p>
<!-- We let $u_Y^{\text{lower}}$ in this graph denote a multinomial distribution over the sixteen values of  $u_{ij}^{gh}$ with event probabilities  $\lambda_{ij}^{gh}$. -->
<!-- I changed abcd scripts above to ghij and made corresponding (I think) changes below. I don't care what it is but abcd obviously could be confusing in this context. -->
<!-- The sixteen types are illustrated in Table \@ref(tab:types2X) in the appendices. -->
<!-- Again, the types in the higher level mapping are functions of the types in the lower-level mapping. For example,  a unit has type $u_{01}$ in the higher level model if $K=1$ and it is of type $u_{00}^{01},u_{10}^{01},u_{01}^{01}$, or $u_{11}^{01}$, or if $K=0$ and it is of type $\lambda_{01}^{00},\lambda_{01}^{10},\lambda_{01}^{01}$, or $\lambda_{01}^{11}$.  -->
<!-- We write this as: -->
<!-- $$u_{01} =  ((K=1) \land (t^{lower} \in \{u_{00}^{01} \cup u_{10}^{01} \cup  u_{01}^{01} \cup u_{11}^{01} \}) \lor  ((K=0) \land (t^{lower} \in \{\lambda_{01}^{00} \cup \lambda_{01}^{10} \cup \lambda_{01}^{01} \cup \lambda_{01}^{11}\})$$ -->
<!-- In the same way, the probability of type $u_{01}$ can be written in terms of the parameters of the lower-level graph.  Importantly, the parameters of the higher-level distribution  $u_Y^{higher}$ depend on both $u_K$ and $u_Y^{\text{lower}}$. Thus, unlike the mediation case above, the probative value depends on the likelihood of an *observable* event occurring. Specifically, the share of a given higher-level type is given by: -->
<!-- $$\lambda_{ij} = P(u_Y^{higher} = u_{ij}) = \pi^K\left(\lambda_{00}^{gh}+\lambda_{10}^{gh}+\lambda_{01}^{gh}+\lambda_{11}^{gh}\right) -->
<!-- + -->
<!-- (1-\pi^K)\left(\lambda_{ij}^{00}+\lambda_{ij}^{10}+\lambda_{ij}^{01}+\lambda_{ij}^{11}\right)$$ -->
<!-- For example: -->
<!-- $$\lambda_{00} = P(u_Y^{higher} = u_{00}) = \pi^K\left(\lambda_{00}^{00}+\lambda_{10}^{00}+\lambda_{01}^{00}+\lambda_{11}^{00}\right) -->
<!-- + -->
<!-- (1-\pi^K)\left(\lambda_{00}^{00}+\lambda_{00}^{10}+\lambda_{00}^{01}+\lambda_{00}^{11}\right)$$ -->
<!-- Conditional probabilities follow in the usual way. Consider, for instance, the case where it is known that $X=Y=1$ and so the posterior probability of type $u_{01}$ is simply $P(i \in u_{01} | X=Y=1) = \frac{\lambda_{01}}{\lambda_{01}+\lambda_{11}}$. Note that $\pi^x$ does not appear here as this $X$ is orthogonal to $u_Y$. The probability of type $u_{01}$, knowing that $X=Y=1$, can be written in terms of the parameters of the $u$ distributions in the lower-level graph.  -->
<!-- $$P(i \in u_{01} | X=Y=1) = \frac{ -->
<!-- \pi^K\left(\lambda_{00}^{01}+\lambda_{10}^{01}+\lambda_{01}^{01}+\lambda_{11}^{01}\right) -->
<!-- + -->
<!-- (1-\pi^K)\left(\lambda_{01}^{00}+\lambda_{01}^{10}+\lambda_{01}^{01}+\lambda_{01}^{11}\right) -->
<!-- }{ -->
<!-- \sum_{i = 0}^1\left(\pi^K\left(\lambda_{00}^{i1}+\lambda_{10}^{i1}+\lambda_{01}^{i1}+\lambda_{11}^{i1}\right) -->
<!-- + -->
<!-- (1-\pi^K)\left(\lambda_{i1}^{00}+\lambda_{i1}^{10}+\lambda_{i1}^{01}+\lambda_{i1}^{11}\right) -->
<!-- \right)}$$ -->
<!-- We return below to this example and describe how the lower-level model can be used to generate inferences on relations implied by the higher level model.  -->
<!-- ## Rules for moving between higher- and lower-level models -->
<!-- Thinking about models as conditionally nested within one another can be empirically useful. It provides a way of generating empirical leverage on a causal question by plumbing more deeply our background knowledge about a domain of interest. When we more fully specify higher-level claims via a more elaborate, lower-level model, we are a making explicit unspecified conditions on which the higher-level relationships depend. In doing this, we are identifying potentially observable nodes that might be informative about our research question. -->
<!-- As we develop lower-level models to support our claims, or determine which claims are supported by our theories, what kinds of moves are we permitted to make?  -->
</div>
</div>
<div id="illustration-of-unpacking-nodal-types" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Illustration of unpacking nodal types</h2>
<p>We now show more specifically how sets of nodal types in lower-level models map into nodal types in higher-level models.</p>
<p>For concreteness, let us return to our democratization example and consider first the very basic claim that inequality can have an affect on democratization. We represent this simple claim in Figure <a href="the-rules.html#fig:demtheory5">7.1</a>, Panel (a). In this simple model, <span class="math inline">\(I\)</span> may sometimes have an effect on <span class="math inline">\(D\)</span> and sometimes not; and that effect may be positive or negative. <span class="math inline">\(I\)</span>’s effect will, of course, depend on the case’s nodal type on <span class="math inline">\(D\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:demtheory5"></span>
<img src="ii_files/figure-html/demtheory5-1.png" alt="DAG representations of three theories. DAGs only capture claims that one variable causes another, conditional on other variables. Theories (b) and (c) each imply theory (a)." width="80%" />
<p class="caption">
Figure 7.1: DAG representations of three theories. DAGs only capture claims that one variable causes another, conditional on other variables. Theories (b) and (c) each imply theory (a).
</p>
</div>
<p>Next, the figure shows two models that can each <em>explain</em> Model (a), though in different ways. Model (b) answers the explanatory question, “<em>How</em> does inequality affect democratization?” Model (c) answers the explanatory question, “Why does inequality’s effect on democratization vary?” or “Under what conditions does <span class="math inline">\(I\)</span> have a given effect on <span class="math inline">\(D\)</span>?” Both theories provide richer, more interpretable accounts of the phenomenon of interest than the simpler model that they are theorizing.</p>
<p>These lower-level models also imply a set of nodal types that are richer than that implied by (a). Recall that in Chapter <a href="models.html#models">2</a>, we considered the idea that at any node, a nodal type may be conceptualized as a case-specific exogenous disturbance that governs the mapping from input variables to outcome variables. The type node <span class="math inline">\(\theta^D\)</span> can take on the values <span class="math inline">\(\theta^D_{10}, \theta^D_{01}, \theta^D_{00}, \theta^D_{11}\)</span>, and this node can take on different values in different cases. However, differences in <span class="math inline">\(\theta^D\)</span>’s value are left entirely unaccounted for. We are saying nothing about <em>why</em> inequality causes democratization in some places, prevents democratization in other places, and has no effect in still other places.</p>
<p>Let us consider how Models (b) and (c) provide answers to these questions and how these answers map onto these models’ nodal types.</p>
<!-- <!-- To fix this idea going forward, we make a shift in notation and use $\theta$ to indicate that a node is a receptacle for causal types. Thus, $\theta_D$ here captures the case's causal type, or $I$'s causal effect on $D$ for a given case.  -->
<!-- In particular, if we  deploy our four-causal-type function from Chapter \@ref(models) we have:  -->
<!--   * $a$: $\theta^D=\theta^D_{10}$, then $D=1-I$ ($I$ has a negative effect on $D$) -->
<!--   * $b$: $\theta^D=\theta^D_{01}$, then $D=I$ ($I$ has a positive effect on $D$) -->
<!--   * $c$: $\theta^D=\theta^D_{00}$, then $D=0$ ($I$ has no causal effect) -->
<!--   * $d$: $\theta^D=\theta^D_{11}$, then $D=1$ ($I$ has no causal effect) -->
<!-- Knowing $\theta$ tells us how $D$ responds to $I$ and it ignores any heterogeneity between units as long they respond in the same way. For any causal type the model is *consistent* with $I$'s causal effect operating for different reasons for different units, but  -->
<div id="implied-consistency-of-priors" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Implied consistency of priors</h3>
<p>We caution that the mappings of distributional beliefs between levels is not always intuitive. Suppose, for instance, that we begin with no information about causal effects in a model and so want to set flat priors, meaning that we accord equal prior weight to all nodal types at each node. In Model (a), flat priors would mean putting an 0.25 weight on each of the following: positive effects, negative effects, zero effects with <span class="math inline">\(D\)</span> always <span class="math inline">\(0\)</span>, and negative effects with <span class="math inline">\(D\)</span> always <span class="math inline">\(1\)</span>. Now, suppose we engage in the same flat-prior-setting in the lower-level model, Model (b). That is, we put equal weight (i.e., 0.25 across the board) on all nodal types at node <span class="math inline">\(M\)</span> and equal weight (0.25 across the board) on all nodel types at node <span class="math inline">\(D\)</span>. Surprisingly perhaps, setting flat priors at this lower level in fact implies a strong weighting <em>against</em> either positive or negative causal effects at the <em>higher</em> level. Now, we are saying that the probability of a positive effect at the higher level is <span class="math inline">\((0.25 \times 0.25) + (0.25 \times 0.25) = 0.125\)</span>; and likewise for negative effects.</p>
<p>Put simply, the fact that the lower-level model involves more mediating steps between <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span> means that more things have “line up” for an <span class="math inline">\(I \rightarrow D\)</span> effect to emerge — and so causal effects will be rarer under a flat distribution of nodal types in this model than they are in the simpler, higher-level model. Another way to think about this is that simply by spelling out the mediating steps in a causal chain, we can, perhaps indadvertently, generate beliefs that causal effects at the higher level are weaker than we might have thought. We can, of course, set priors at the lower level that would map onto flat priors at the higher level.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Our advice to researchers is, simply, to check for consistency of priors across levels: to ask whether the priors that we set at a lower level imply beliefs at the higher level that we are willing to live with.</p>
</div>
</div>
<div id="conclusion" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Conclusion</h2>
</div>
<div id="chapter-appendices" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Chapter Appendices</h2>
<div id="summary-boxes" class="section level3" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Summary Boxes</h3>
<hr />
<p><strong>BOX 1</strong></p>
<p><strong>Two kinds of theories.</strong></p>
<p>Theories are “lower-level” causal models that explain or provide an account of a “higher-level,” simpler model. There are two forms of theorization:</p>
<ol style="list-style-type: decimal">
<li>The disaggregation of nodes. A single node in a higher-level model can be split into multiple nodes. For instance, for a higher-level model in which <span class="math inline">\(X \rightarrow Y \leftarrow \theta^Y\)</span>:</li>
</ol>
<ul>
<li><em>Mediation</em>: A mediator, <span class="math inline">\(M\)</span>, can be introduced between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, thus splitting <span class="math inline">\(\theta^Y\)</span> into <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^{Y_\text{lower}}\)</span>. The mediation theory thus explains the <span class="math inline">\(X \rightarrow Y\)</span> relationship.</li>
<li><em>Moderation</em>: A component of <span class="math inline">\(\theta^Y\)</span> can be extracted and specified as a substantive variable. This variable is now a substantively conceptualized moderator of the <span class="math inline">\(X \rightarrow Y\)</span> relationship. The moderation theory thus provides a fuller explanation of why <span class="math inline">\(X\)</span> has different effects on <span class="math inline">\(Y\)</span> in different contexts.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Generalization. A feature of context omitted and implicitly held constant in a higher-level model can be explicitly included in the model. The higher-level model is now explained as a special case of a more general set of causal relations.</li>
</ol>
<hr />
</div>
</div>
<div id="connections-to-other-writing-on-theory" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> Connections to other writing on theory</h2>
<p>We close this chapter by considering how the understanding of theory that we work with in this book compares to other prominent understandings of theory.</p>
<p><strong>Theory as tautology.</strong> The claim that the number of Nash equilibria is generically odd in finite games is often understood to be a theoretical claim. Unless there are errors in the derivation of the result, the claim is true in the sense that the conclusions follow from the assumptions. There is no evidence that we could go looking for in the world to assess the claim. The same can be said of the theoretical claims of many formal models in social sciences; they are theoretical deductions of the if-then variety <span class="citation">(<a href="#ref-clarke2012model" role="doc-biblioref">Clarke and Primo 2012</a>)</span>. Theory in this sense is true by tautology. By contrast, theory as we define it in this book refers to claims with <em>empirical</em> content: a theory refers to causal relations in the world that might or might not hold, and is susceptible to empirical testing. The deductive <em>logical</em> relations that hold in a causal model are those of conditional independence, as discussed in Chapter <a href="models.html#models">2</a>: for instance, if <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> only through <span class="math inline">\(M\)</span> in a theory, then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are conditionally independent given some value of <span class="math inline">\(M\)</span>.</p>
<p><strong>Theory as a collection of maps.</strong> According to <span class="citation"><a href="#ref-clarke2012model" role="doc-biblioref">Clarke and Primo</a> (<a href="#ref-clarke2012model" role="doc-biblioref">2012</a>)</span>, building on a semantic view of theory (<span class="citation"><a href="#ref-giere2010explaining" role="doc-biblioref">Giere</a> (<a href="#ref-giere2010explaining" role="doc-biblioref">2010</a>)</span>), a theory is a collection of models, together with a set of hypotheses linking them to the real world. As in our usage, Clarke and Primo see theories and models as very similar objects: for them, a theory is a system of models; for us, a theory is a supporting model. In both frameworks, there is no real difference in kind between models and theories.</p>
<p>Our approach also shares with Clarke and Primo the idea that models are not full and faithful reflections of reality; they are maps designed for a particular purpose. In the case of causal models, the purpose is to capture relationships of independence and possible causal dependence. As we have shown, that is a purpose that allows for the stripping away of detail—though it also forbids certain simplifications (such as any simplification that removes a dependency between variables). Clarke and Primo see models as useful to the extent that they are similar to features of the real world in ways related to the model’s purpose. Along these lines, a causal model will be useful to the extent that it posits relations of independence that are similar to those prevailing in the domain under investigation.</p>
<p><strong>Theory as a testable claim</strong> In the hypothetico-deductive framework, often traced back to <span class="citation"><a href="#ref-popper2014conjectures" role="doc-biblioref">Popper</a> (<a href="#ref-popper2014conjectures" role="doc-biblioref">2002</a>)</span> and highly influential in empirical political science, empirical social science is an activity of theory-<em>testing</em>. Having developed a theory, we then derive from it a set of empirical predictions and then test those predictions against evidence. In <span class="citation"><a href="#ref-clarke2012model" role="doc-biblioref">Clarke and Primo</a> (<a href="#ref-clarke2012model" role="doc-biblioref">2012</a>)</span>, we also seek to confirm theories by developing and testing hypotheses about the similarity of a model or theory to particular features of the world. In both cases, a theory is posited—possibly on the basis of logic or background knowledge—and then assessed. The value (truth or usefulness) of the model itself is the object of inquiry.</p>
<p>In a causal-model framework, theories are always tentative, and we can subject any model or theory to empirical evaluation, a task to which we turn in Chapter <a href="evaluation.html#evaluation">17</a>. However, in the book’s setup, theories are first and foremost <em>expressions of what we already know and don’t know</em> about a given causal domain when inquiry begins. We encode this background knowledge in order to inform research-design choices and draw inferences from the data. Models and theories are thus, in this sense, the world within which inquiry unfolds. Indeed, as we explore in Chapter <a href="questions.html#questions">4</a>, the very questions we ask live within—can be represented as parts of—our theories.</p>
<!-- **Theory as model.** Although @clarke2012model argue for a separation of the ideas of model and theory, it is common for social scientists to use the terms interchangeably to denote an abstract representation of some part of the world that is of interest. For instance, a model may stipulate that outcome $X$ can have a positive effect on $Y$ because $X$ can cause $M$ and $M$ can cause $Y$.  One can read from a model how things work in the context of the model: for instance, if $M$ does not obtain, then under this model, $X$ does not cause $Y$.   One can use a model to make claims about the world only by assuming a mapping from elements in the model to elements in the worlds.  In this sense a  model is best thought of as an object that may or may not be useful [@clarke2012model]; whether the model itself is true or false is, in this usage, not a coherent question.  -->
<!-- **Theory as empirical claim.** In common usage, "a theory of" a phenomenon is a direct claim about the phenomenon, in the world. The claim that natural resources cause conflict is a theoretical claim of this form. The claim is certainly not true by definition, and empirical evidence can be used to assess it. In this claim, the *theory*, as usually understood, is certainly thin; the claim is no more than an empirical proposition, and it possesses no internal logic. Yet, more elaborate collections of empirical propositions are easily constructed. For instance: natural resources cause conflict because they can finance secessionist claims in resource rich areas.^[This latter claim does seem to possess something like a logic; though it does not take much to see that the logic is just a slightly more elaborate set of empirical claims. The outcomes do not follow  *logically* from the causes----there is no logical reason why secessionist claims would cause conflict, but the theory---as a collection of claims---has implications similar to those in the model in the paragraph above: if there are no secessionist claims, then under this theory, natural resources are not causing conflict.] Theory in this sense can certainly be right or wrong. -->
<!-- In this book we take a somewhat idealist position and assume that we are permanently inhabiting a world of models.  -->
<!-- The distinction between the last two accounts is sometimes confusing, and  @clarke2012model make a case for cleaning up the language on this front. In their account, drawing on @giere2010explaining, a theory might be best thought of as a set of models accompanied by hypotheses linking the model to the question of interest in the  world.  -->
<!-- We see our approach to theory as models as following in the spirit of  @clarke2012model and  @giere2010explaining yet also as being consistent with the treatment of models in the literature on probabilistic causal models with which this book is centrally engaged. A nice feature is that it preserves a close associated between theory and explanation and it incorporates naturally the notion of deduction without requiring that models themselves are statements of the  *if-then* variety. -->
<p><strong>Theory as generalization</strong> In another of the many uses of “theory,” political scientists often think of theorization as generalization. For <span class="citation"><a href="#ref-Van-Evera:1997" role="doc-biblioref">Van Evera</a> (<a href="#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span> and <span class="citation"><a href="#ref-przeworski1970logic" role="doc-biblioref">Przeworski and Teune</a> (<a href="#ref-przeworski1970logic" role="doc-biblioref">1970</a>)</span>, for instance, theories are by their nature general statements that we can use to explain specific events. In this view, “Diamond resources caused Sierra Leone’s civil war” is a case-specific explanation; “Natural resource endowments cause civil war” is a theoretical formulation.</p>
<p>In our treatment of theory as a lower-level causal model, however, there is no generic sense in which a theory is more or less general than the higher-level claim that it explains. In this book’s framework, we <em>can</em> theorize by generalizing: when we elaborate a model by building in variation in a factor that was held constant in the higher-level claim, we are making the model more general in scope. If our natural resources claim implicitly applies only to weak states, we can theorize this claim by allowing state strength to vary and articulating how the natural-resource effect hinges on that claim.</p>
<p>However, when we theorize by disaggregating nodes—say, by adding intervening causal steps—we have in fact made a more <em>specific</em> claim. Natural resources may cause civil war under a broad set of circumstances. Natural resources will cause civil war <em>through looting by rebel groups</em> under an almost certainly narrower set of circumstances. Here, the more elaborate argument—the theorization of <em>why</em> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>—is actually a stronger claim, with narrower scope, than the simpler one that it supports.</p>
<p><strong>The value of parsimony</strong> <span class="citation"><a href="#ref-Van-Evera:1997" role="doc-biblioref">Van Evera</a> (<a href="#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span> and <span class="citation"><a href="#ref-przeworski1970logic" role="doc-biblioref">Przeworski and Teune</a> (<a href="#ref-przeworski1970logic" role="doc-biblioref">1970</a>)</span> also express a common view in characterizing <em>parsimony</em> as a quality of good theory. While they recognize that parsimony must often be traded off against other goods, such as accuracy and generality, <em>ceteris paribus</em> a more parsimonious theory—one that uses fewer causal variables to explain variation in a given outcome—is commonly understood to be a better theory.</p>
<p>We do not take issue with the idea that simpler models and explanations are, all else equal, better. But the succeeding chapters also demonstrate a distinctive and important way in which all else will often not be equal when we seek to use theory to guide research design and support causal inference. To foreshadow the argument to come, the elaboration of more detailed, lower-level models can direct us to new opportunities for learning. As we unpack a higher-level claim, we will often be identifying additional features of a phenomenon the observation of which can shed light on causal questions of interest. Moreover, our background beliefs—the prior knowledge on which causal inference must usually rest—are often more informative at lower levels than at higher levels: it will, for instance, often be easier for us express beliefs about causal effects for smaller steps along a causal chain than about an overarching <span class="math inline">\(X \rightarrow Y\)</span> effect.</p>
<p>Making things more complicated, of course, still makes things more complicated. And we should avoid doing so when the payoff is small, as it will sometimes be. But in the pages to come, we will also see a distinct set of benefits that arise from drilling more deeply into our basis of prior knowledge when formulating inferential strategies.</p>
<!-- , with these claims,  perhaps derived or inspired from some model via a statement that the model represents the world faithfully for some purpose.  -->
<!-- The key difference as we see it is between representations of a system, a model, and claims that the model itself represents another system---the world---in some ways. The difference betw  -->
</div>
<div id="illustration-of-a-mapping-from-a-game-to-a-dag" class="section level2" number="7.9">
<h2><span class="header-section-number">7.9</span> Illustration of a Mapping from a Game to a DAG</h2>
<p>Our running example supports a set of higher level models, but it can also be <em>implied</em> by a lower level models. Here we illustrate with an example in which the lower level model is a game theoretic model, together with a solution.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>In Figure <a href="the-rules.html#fig:tree">7.2</a> we show a game in which nature first decides on the type of the media and the politician – is it a media that values reporting on corruption or not? Is the politician one who has a dominant strategy to engage in corruption or one who is sensitive to the risks of media exposure? In the example the payoffs to all players are fully specified, though for illustration we include parameter <span class="math inline">\(b\)</span> in the voter’s payoffs which captures utility gains from sacking a politician that has had a negative story written about them <em>whether or not they actually engaged in corruption</em>. A somewhat less specific, though more easily defended, theory would not specify particular numbers as in the figure, but rather assume ranges on payoffs that have the same strategic implications.</p>
<p>The theory is then the game plus a solution to the game. Here for a solution the theory specifies subgame perfect equilibrium.</p>
<p>In the subgame perfect equilibrium of the game; marked out on the game tree (for the case <span class="math inline">\(b=0\)</span>) the sensitive politicians do not engage in corruption when there is a free press – otherwise they do; a free press writes up any acts of corruption, voters throw out the politician if indeed she is corrupt and this corruption is reported by the press.</p>
<p>As with any structural model, the theory says what will happen but also what <em>would</em> happen if things that should not happen indeed happened.</p>
<div class="figure"><span style="display:block;" id="fig:tree"></span>
<img src="ii_files/figure-html/tree-1.png" alt="\label{fig:tree} A Game Tree. Solid lines represent choices on the (unique) equilibrium path of the subgames starting after nature's move for the case in which  $b=0$." width="1440" />
<p class="caption">
Figure 7.2:  A Game Tree. Solid lines represent choices on the (unique) equilibrium path of the subgames starting after nature’s move for the case in which <span class="math inline">\(b=0\)</span>.
</p>
</div>
<p>To draw this equilibrium as a DAG we include nodes for every action taken, nodes for features that determine the game being played, and the utilities at the end of the game.</p>
<p>If equilibrium claims are justified by claims about the beliefs of actors then these could also appear as nodes. To be clear however these are not required to represent the game or the equilibrium, though they can capture assumed logics underlying the equilibrium choice. For instance a theorist might claim that humans are wired so that whenever they are playing a “Stag Hunt” game they play “defect.” The game and this solution can be represented on a DAG without reference to the beliefs of actors about the action of other players. However, if the <em>justification</em> for the equilibrium involves optimization given the beliefs of other players, a lower level DAG could represent this by having a node for the game description that points to beliefs about the actions of others, that then points to choices. In a game with dominant strategies, in contrast, there would be no arrows from these beliefs to actions.</p>
<p>For our running example, nodes could usefully include the politician’s expectations, since the government’s actions depend on expectations of the actions of others. However, given the game there is no gain from including the media’s expectations of the voter’s actions since in this case the media’s actions do not depend on expectations of the voters actions then these expectations should be included.</p>
<p>In Figure <a href="the-rules.html#fig:gamedag">7.3</a> we provide two examples of DAGs that illustrate lower level models that support our running example.</p>
<p>The upper panel gives a DAG reflecting equilibrium play in the game described in Figure <a href="the-rules.html#fig:tree">7.2</a>. Note that in this game there is an arrow between <span class="math inline">\(C\)</span> and <span class="math inline">\(Y\)</span> even though <span class="math inline">\(Y\)</span> does not depend on <span class="math inline">\(C\)</span> for some values of <span class="math inline">\(b\)</span>—this is because conditional independence requires that two variables are independent for <em>all</em> values of the conditioning set. For simplicity also we mark <span class="math inline">\(S\)</span> and <span class="math inline">\(X\)</span>, along with <span class="math inline">\(b\)</span> as features that affect which subgame is being played—taking the subgames starting after Nature’s move. Note that the government’s expectations of responses by others matters, but the expectations of other players do not matter given this game and solution. Note that the utilities appear twice in a sense. They appear in the subgame node, as they are part of the definition of the game–though here they are the utilities that players expect at each terminal node; when they appear at the end of the DAG they are the utilities that actually arise (in theory at least).</p>
<p>The lower level DAG is very low and much more general, representing the theory that in three player games of complete information, players engage in backwards induction and choose the actions that they expect to maximize utility given their beliefs about the actions of others. The DAG assumes that players know what game is being played (“Game”), though this could also be included for more fundamental justification of behavioral predictions. Each action is taken as a function of the beliefs about the game, the expectations about the actions of others, and knowledge of play to date. The functional equations—not shown—are given by optimization and belief formation assuming optimization by others.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gamedag"></span>
<img src="ii_files/figure-html/gamedag-1.png" alt="\label{fig:gamedag} The upper panel shows a causal graph that describes  relations between nodes suggested by analysis of  the  game  in Figure \ref{fig:tree} and which can imply the causal graph of  Figure \ref{fig:running}. The game itself  (or beliefs about the game) appear as a node, which are in turn determined by exogneous factors.   The lower panel represents a still lower level and more general theory ``players use backwards induction in three step games of complete information.''" width="\textwidth" />
<p class="caption">
Figure 7.3:  The upper panel shows a causal graph that describes relations between nodes suggested by analysis of the game in Figure  and which can imply the causal graph of Figure . The game itself (or beliefs about the game) appear as a node, which are in turn determined by exogneous factors. The lower panel represents a still lower level and more general theory ``players use backwards induction in three step games of complete information.’’
</p>
</div>
<p>These lower level graphs can themselves provide clues for assessing relations in the higher level graphs. For instance, the lower level model might specify that the value of <span class="math inline">\(b\)</span> in the game affects the actions of the government only through their beliefs about the behavior of voters, <span class="math inline">\(E\)</span>. These beliefs may themselves have a stochastic component, <span class="math inline">\(U_E\)</span>. Thus <span class="math inline">\(b\)</span> high might be thought to reduce the effect of media on corruption. For instance if <span class="math inline">\(b \in \mathbb{R}_+\)</span>, we have <span class="math inline">\(C= 1-FG(1-\mathbb{1}(b&gt;1))\)</span>. If <span class="math inline">\(X\)</span> is unobserved and one is interested in whether <span class="math inline">\(S=0\)</span> caused corruption, knowledge of <span class="math inline">\(b\)</span> is informative. It is a root node in the causal estimand. If <span class="math inline">\(b&gt;1\)</span> then <span class="math inline">\(S=0\)</span> did not cause corruption. However if <span class="math inline">\(b\)</span> matters only because of its effect on <span class="math inline">\(E\)</span> then the query depends on <span class="math inline">\(U_E\)</span>. In this case, while knowing <span class="math inline">\(b\)</span> is informative about whether <span class="math inline">\(S=0\)</span> caused <span class="math inline">\(C=1\)</span>, knowing <span class="math inline">\(E\)</span> from the lower level graph is more informative.</p>
<p>Note that the model we have examined here involves no terms for <span class="math inline">\(U_C\)</span>, <span class="math inline">\(U_R\)</span> and <span class="math inline">\(U_Y\)</span>—that is, shocks to outcomes given action. Yet clearly any of these could exist. One could imagine a version of this game with “trembling hands,” such that errors are always made with some small probability, giving rise to a much richer set of predictions. These can be represented in the game tree as moves by nature between actions chosen and outcomes realized. Importantly in a strategic environment such noise could give rise to different types of conditional independence. For instance say that a Free Press only published its report on corruption with probability <span class="math inline">\(\pi^R\)</span>, then with <span class="math inline">\(\pi^R\)</span> high enough the sensitive government might decide it is worth engaging in corruption even if there is a free press; in this case the arrow from <span class="math inline">\(X\)</span> to <span class="math inline">\(C\)</span> would be removed. Interestingly in this case as the error rate rises, <span class="math inline">\(R\)</span> becomes less likely, meaning that the effect of a <span class="math inline">\(S\)</span> on <span class="math inline">\(Y\)</span> becomes gradually weaker (since governments that are not sensitive become more likely to survive) and then drops to 0 as sensitive governments start acting just like nonsensitive governments.</p>
<div id="quantifying-the-gains-from-a-theory" class="section level3" number="7.9.1">
<h3><span class="header-section-number">7.9.1</span> Quantifying the gains from a theory</h3>
<p>We have alluded to the fact that we may want to theorize our models — develop more elaborate, lower-level models to support them — because we can get potentially reap greater inferential leverage from the more elaborate theory. But how much more? For instance, what are the gains from a theory that introduces a node <span class="math inline">\(K\)</span> relative to one that does not include <span class="math inline">\(K\)</span>? What is the value-added of the more elaborate theory?</p>
<p>One approach to assessing the contribution of a theory is to calculate the mean reduction in Bayes risk. Suppose we start with a baseline model with variables in the set <span class="math inline">\(\mathcal W\)</span> and want to answer a query, <span class="math inline">\(Q\)</span>. We can then define the gains from theory as:</p>
<p><span class="math display">\[\text{Gains from theory} = 1- \frac{E_{K|\mathcal W}(Var(Q|K,\mathcal W))}{Var(Q|\mathcal W)}\]</span></p>
<!-- AJ: Have tried to explain what Q and W are, and walk through the intuition behind this formulation. Make sure this is right. Also should the E not be in the denominator too? -->
<p>We can think of the Bayes risk as the inverse of an <span class="math inline">\(R^2\)</span> measure in a regression framework (see also <span class="citation"><a href="#ref-gelman2006bayesian" role="doc-biblioref">Gelman and Pardoe</a> (<a href="#ref-gelman2006bayesian" role="doc-biblioref">2006</a>)</span>): it is the variance in our query given what we have observed. Here we are definining the gains from theory as the degree to which we have reduced that variance by observing <span class="math inline">\(K\)</span> and <span class="math inline">\(\mathcal W\)</span>, relative to just observing <span class="math inline">\(\mathcal W\)</span>.</p>
<p>Another approach is to ask: how much better are our guesses having observed <span class="math inline">\(K\)</span> compared to what we would have guessed before, <em>given</em> what we know having observed <span class="math inline">\(K\)</span>?</p>
<!-- AJ: Needs a sentence here introducing the terminology. Is this our term, expected wisdom? -->
<p>Expected wisdom.</p>
<p><span class="math display">\[Wisdom  = \int(q_0 - q)^2 - (q_k - q)^2 p(q | k)dq\]</span>
This captures how much better off we are with the guess we have made given current data (<span class="math inline">\(q_k\)</span>) compared to the guess we would have made without it (<span class="math inline">\(q_0\)</span>), knowing what we know having observe <span class="math inline">\(K\)</span> (<span class="math inline">\(p(q|k)\)</span>. A modest advantage of this conceptualization is that we can still record gains in learning even if the learning operates such that the posterior variance is larger than the prior variance. Even so, the implications for strategy are the same since wisdom is maximized by a strategy that reduces expected squared error.</p>
<p>Other possible measures of gains from theory might include the simple correlation between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, or entropy-based measures (see <span class="citation"><a href="#ref-zhang2003properties" role="doc-biblioref">Zhang and Srihari</a> (<a href="#ref-zhang2003properties" role="doc-biblioref">2003</a>)</span> for many more possibilities).</p>
<p>For this problem the correlation is given by (see appendix):</p>
<p><span class="math display">\[\rho_{KQ} = \frac{(\phi_b+\phi_d)(1-2p)(p(1-p))^{.5}}{
(p\phi_b+(1-p)\phi_d)(1-(p\phi_b+(1-p)\phi_d)))^{.5}}\]</span></p>
<p>One might also use a measure of “mutual information” from information theory:</p>
<p><span class="math display">\[I(Q,K) = \sum_q \sum_k P(q,k)\log\left(\frac{P(q,k)}{P(q)P(k)}\right)\]</span></p>
<!-- here: -->
<!-- \begin{equation} -->
<!-- \begin{aligned} -->
<!-- I(Q,K) ={} & p\phi_b\log\left(\frac{\phi_b}{p\phi_b+(1-p)\phi_d}\right)+ (1-p)\phi_d\log\left(\frac{\phi_d}{p\phi_b+(1-p)\phi_d}\right) \\ -->
<!--       & +p(1-\phi_b)\log\left(\frac{1-\phi_b}{1-p\phi_b-(1-p)\phi_d}\right)+ -->
<!-- (1-p)(1-\phi_d)\log\left(\frac{1-\phi_d}{1-p\phi_b-(1-p)\phi_d}\right) -->
<!-- \end{aligned} -->
<!-- \end{equation} -->
<p>To express this mutual information as a share of variation explained, we could divide <span class="math inline">\(I(Q,K)\)</span> by the entropy of <span class="math inline">\(Q\)</span>, <span class="math inline">\(H(Q)\)</span> where <span class="math inline">\(H(Q) = -\sum_qP(q)\log(P(q))\)</span>. The resulting ratio can be interpreted as 1 minus the ratio of the entropy of <span class="math inline">\(Q\)</span> conditional (on <span class="math inline">\(K\)</span>) to the unconditional entropy of <span class="math inline">\(Q\)</span>.</p>
<p>For this example, Figure  shows gains as a function of <span class="math inline">\(\phi_b\)</span> given a fixed value of <span class="math inline">\(\phi_d\)</span>. The figure also shows other possible measures of probative value, with, in this case, the reduction in entropy tracking the reduced posterior variance closely.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:probativevalue"></span>
<img src="ii_files/figure-html/probativevalue-1.png" alt="\label{fig:probative_value} The solid line shows gains in precision (reduced posterior variance) for different values of $\phi_b$ given $\phi_d=0.25$ and $p=.5$ for the example given in the text. Additional measures of probative value are also provided including $|\phi_b - \phi_d|$, the correlation of $K$ and $Q$, and the reduction in entropy in $Q$ due to mutual information in $Q$ and $K$." width=".7\textwidth" />
<p class="caption">
Figure 7.4:  The solid line shows gains in precision (reduced posterior variance) for different values of <span class="math inline">\(\phi_b\)</span> given <span class="math inline">\(\phi_d=0.25\)</span> and <span class="math inline">\(p=.5\)</span> for the example given in the text. Additional measures of probative value are also provided including <span class="math inline">\(|\phi_b - \phi_d|\)</span>, the correlation of <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, and the reduction in entropy in <span class="math inline">\(Q\)</span> due to mutual information in <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span>.
</p>
</div>

</div>
</div>
</div>



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-clarke2012model" class="csl-entry">
Clarke, Kevin A, and David M Primo. 2012. <em>A Model Discipline: Political Science and the Logic of Representations</em>. New York: Oxford University Press.
</div>
<div id="ref-dawid2002influence" class="csl-entry">
Dawid, A Philip. 2002. <span>“Influence Diagrams for Causal Modelling and Inference.”</span> <em>International Statistical Review</em> 70 (2): 161–89.
</div>
<div id="ref-gelman2006bayesian" class="csl-entry">
Gelman, Andrew, and Iain Pardoe. 2006. <span>“Bayesian Measures of Explained Variance and Pooling in Multilevel (Hierarchical) Models.”</span> <em>Technometrics</em> 48 (2): 241–51.
</div>
<div id="ref-giere2010explaining" class="csl-entry">
Giere, Ronald N. 2010. <em>Explaining Science: A Cognitive Approach</em>. University of Chicago Press.
</div>
<div id="ref-koller2003multi" class="csl-entry">
Koller, Daphne, and Brian Milch. 2003. <span>“Multi-Agent Influence Diagrams for Representing and Solving Games.”</span> <em>Games and Economic Behavior</em> 45 (1): 181–221.
</div>
<div id="ref-popper2014conjectures" class="csl-entry">
Popper, Karl. 2002. <em>Conjectures and Refutations: The Growth of Scientific Knowledge</em>. New York: Routledge.
</div>
<div id="ref-przeworski1970logic" class="csl-entry">
Przeworski, Adam, and Henry Teune. 1970. <em>The Logic of Comparative Social Inquiry</em>. New York: Wiley-Interscience.
</div>
<div id="ref-Van-Evera:1997" class="csl-entry">
Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.
</div>
<div id="ref-white2009settable" class="csl-entry">
White, Halbert, and Karim Chalak. 2009. <span>“Settable Systems: An Extension of Pearl’s Causal Model with Optimization, Equilibrium, and Learning.”</span> <em>Journal of Machine Learning Research</em> 10 (Aug): 1759–99.
</div>
<div id="ref-zhang2003properties" class="csl-entry">
Zhang, Bin, and Sargur N Srihari. 2003. <span>“Properties of Binary Vector Dissimilarity Measures.”</span> In <em>Proc. JCIS Int’l Conf. Computer Vision, Pattern Recognition, and Image Processing</em>. Vol. 1.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Put differently, these two theories record different relations of conditional independence: in <span class="math inline">\(L_1\)</span>, <span class="math inline">\(Inequality\)</span> and <span class="math inline">\(Mobilization\)</span> are unconditionally independent, but they are not unconditionally independent in <span class="math inline">\(L_2\)</span>. Also, in <span class="math inline">\(L_2\)</span>, <span class="math inline">\(Inequality\)</span> is independent of <span class="math inline">\(Democratization\)</span> conditional on <span class="math inline">\(Mobilization\)</span>; but this is not the case in <span class="math inline">\(L_1\)</span>.<a href="the-rules.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>In addition, a <em>conditional</em> higher-level model <span class="math inline">\(((Inequality \rightarrow Democratization)|Mobilization=1)\)</span> can be supported by model <span class="math inline">\(L_1\)</span> but not by model <span class="math inline">\(L_2\)</span>, where holding <span class="math inline">\(Mobilization\)</span> constant would sever the dependence of <span class="math inline">\(Democratization\)</span> on <span class="math inline">\(Inequality\)</span>.<a href="the-rules.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>All models also have a type defined for node <span class="math inline">\(I\)</span>, but <span class="math inline">\(\theta^I\)</span> is unaffected by the movement between these models.<a href="the-rules.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>In other words, saying <span class="math inline">\(E=1\)</span> in this model is the same as saying <span class="math inline">\(\theta^{E}=\theta^{E}_{1}\)</span>. An exogenous nodes nodal type <em>is</em> the value to which it has been exogenously “assigned.”<a href="the-rules.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Placing roughly 0.35 weight on a positive effect at each mediating step and 0.35 weight on a negative effect at each step implies approximately a 0.25 probability of a positive <span class="math inline">\(I \rightarrow D\)</span> effecta and a 0.25 probability of a negative <span class="math inline">\(I \rightarrow D\)</span> effect.<a href="the-rules.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Such representations have been discussed as multi agent influence diagrams, for example in <span class="citation"><a href="#ref-koller2003multi" role="doc-biblioref">Koller and Milch</a> (<a href="#ref-koller2003multi" role="doc-biblioref">2003</a>)</span> or <span class="citation"><a href="#ref-white2009settable" role="doc-biblioref">White and Chalak</a> (<a href="#ref-white2009settable" role="doc-biblioref">2009</a>)</span> on “settable systems”— an extension of the “influence diagrams” described by <span class="citation"><a href="#ref-dawid2002influence" role="doc-biblioref">Dawid</a> (<a href="#ref-dawid2002influence" role="doc-biblioref">2002</a>)</span>.<a href="the-rules.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pt.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
