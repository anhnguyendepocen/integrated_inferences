<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Going wide and going deep | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Going wide and going deep | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Going wide and going deep | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clue.html"/>
<link rel="next" href="caseselection.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#exercises"><i class="fa fa-check"></i><b>9.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>10</b> Mixing models</a><ul>
<li class="chapter" data-level="10.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>10.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="10.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>10.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="10.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>10.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="10.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>10.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="11" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>11</b> Elements of Design</a><ul>
<li class="chapter" data-level="11.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>11.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="11.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>11.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>11.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="11.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>11.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="11.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>11.2.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>11.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>13</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="13.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a></li>
<li class="chapter" data-level="13.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>13.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="13.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>13.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="13.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>13.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>13.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="13.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>13.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="13.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>13.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="13.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>13.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="13.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>13.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="13.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>13.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>14.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>14.2</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>14.3</b> Explorations</a><ul>
<li class="chapter" data-level="14.3.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>14.3.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.4</b> Principles</a><ul>
<li class="chapter" data-level="14.4.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>14.4.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="14.4.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>14.4.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="14.4.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>14.4.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
<li class="chapter" data-level="15.5" data-path="justifying-models.html"><a href="justifying-models.html#exercise"><i class="fa fa-check"></i><b>15.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>17.1</b> General lessons</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>17.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>17.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="17.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>17.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="wide" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Going wide and going deep</h1>
<div class="headerbox">
<div class="center">

</div>
<p>Researchers often need to choose between collecting data on a greater number of cases or collecting more data within a given set of cases. This is a choice, we might say, between going “wide” and going “deep.” We discuss the tradeoffs and communicate an intuition that clue data, even on a small number of cases, can be informative even when there is <span class="math inline">\(X, Y\)</span> data on a very large number of cases, but only if it provides information that cannot be gathered from <span class="math inline">\(X,Y\)</span> data, such as selection into treatment. Simulations suggest that going deep is especially valuable for observational research, situations with homogeneous treatment effects, and, of course, when clues have strong probative value.</p>
</div>
<p><br></p>
<div id="motivation" class="section level2">
<h2><span class="header-section-number">13.1</span> Motivation</h2>
<p>Let us continue our journey through the space of research-design choices. Suppose, now, that we have identified those clues that will be most informative, given our beliefs about the world. A further question that we face is the quintessential dilemma of <em>mixing</em> methods: what mixture of quantitative and qualitative evidence is optimal? We have, of course, argued in in Chapter (mixing) that the distinction between quantitative and qualitative inference is, in a causal-model framework, without much of a difference. But here we are framing a more precise question: given finite resources, how should we trade off between studying a larger number of cases and drilling down to learn more about some subset of the cases in our sample? How should we decide between going “wide” and going “deep”?</p>
<p>Just as with the selection of clues and cases, how much we should expect to learn from going wide versus going deep will <em>depend</em> on how we think the world works. In this chapter, we separate out two forms that these prior beliefs might take: the structural causal model with which we start the analysis and any data that we have seen at the point of making the wide-versus-deep decision. As we will see, the expected opportunities for learning about different causal estimands depends greatly on both of these.</p>
<p>We examine here both queries commonly associated with extensive, quantitative strategies of analysis (such as average treatment effects) and queries commonly associated with more intensive, qualitative approaches (queries about causal pathways and about causal effects at the case level). The analysis in this chapter makes clear the opportunities for integration across these lines of inquiry. We show that investing in-depth process tracing will sometimes make sense even when one aims to learn about average effects in a population. Likewise, collecting <span class="math inline">\(X, Y\)</span> data can sometimes help us draw inferences that will aid in case-level explanation. Particular kinds of case-level information can teach us about populations, and understanding population-level patterns can help us get individual cases right.</p>
</div>
<div id="developing-some-intuitions" class="section level2">
<h2><span class="header-section-number">13.2</span> Developing some intuitions</h2>
<p>To build up our intuitions about how the optimal mix of strategies might depend on how the world works, let us explore a simple example. We focus here on the question of how much we can learn from drilling deeper, given an initial set of <span class="math inline">\(X,Y\)</span> data and beliefs about the world. To simplify the exposition, we revert here to using our four basic causal types from Chapter (models): <span class="math inline">\(a, b, c, and d\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<!-- e begin by considering the learning that occurs upon observing outcomes from varying numbers of cases given different $XY$ data ranging from small to quite large.  -->
<!-- The goal here is to build up intuitions on how beliefs change given different observations and how this affects posterior variance. We address the question in a very controlled setting in which  -->
<p>Suppose that:</p>
<ul>
<li>a researcher is confronted with <span class="math inline">\(X,Y\)</span> data that exhibits no correlation; observations are balanced across the 4 cells defined by possible combinations of <span class="math inline">\(X, Y\)</span> values.</li>
<li>the researcher can seek information on a highly informative (“doubly decisive”) clue, <span class="math inline">\(K\)</span>, within cases in the <span class="math inline">\(X=Y=1\)</span> cell; thus, we are imagining a scenaior in which the information we will get about the case in question is about as informative about that case as it could possibly be.</li>
<li>although not known in advance, each time the researcher collects a within-case clue, she finds evidence suggesting that the case is a <span class="math inline">\(b\)</span> type.</li>
</ul>
<p>We consider two different data-generating processes:</p>
<p>1 There may be unobserved confounding between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and we have flat priors over this confounding. Put differently, assignment propensities are unknown.</p>
<p>2 There is no confounding; <span class="math inline">\(X\)</span> can be treated as randomly assigned.</p>
<p>We consider what happens as the number of cases on which we collect <span class="math inline">\(K\)</span> increases from 0 to 5. We also consider different amounts of initial <span class="math inline">\(X,Y\)</span> data, considering situations in which we have 5, 10, 50, and 5000 observations in each <span class="math inline">\(X,Y\)</span> cell.</p>
<p>We would expect that seeking a clue in a case—which, in this simulation, always delivers evidence consistent with a positive causal effect in that case—will lead the researcher to believe there are more <span class="math inline">\(b\)</span> types and that there is thus a higher average causal effect. But how strong will these shifts be? And how does the amount of belief change depend on the amount of <span class="math inline">\(X, Y\)</span> data available and the underlying data-generating process? When does the signal from the <span class="math inline">\(X,Y\)</span> data drown out any signal from the <span class="math inline">\(K\)</span> data, and when does <span class="math inline">\(K\)</span> data add value?</p>
<p>Figure  reports answers to these questions. In the top row, we report the average causal effect that we will estimate for different combinations of <span class="math inline">\(X,Y\)</span> and <span class="math inline">\(K\)</span> data. In the bottom row, we show the reductions in uncertainty (posterior variance) that we get with each strategy. On the left, we allow for unobserved confounding, and on the right we have random assignment. Each curve represents a different sample size for which we have <span class="math inline">\(X,Y\)</span> data. The number of cases in which we go “deep,” collecting <span class="math inline">\(K\)</span> data, is represented on the horizontal axis.</p>
<ol style="list-style-type: decimal">
<li>With unobserved confounding, we see clear gains to collecting clues on a greater number of cases across the 1 to 5 range. Collecting clue information on a greater number of cases shifts our beliefs about the average causal effect and reduces our uncertainty about that quantity. Moreover, with unobserved confounding, the value of the clue information is <em>independent</em> of how many <span class="math inline">\(X,Y\)</span> cases there are.</li>
</ol>
<p>What is happening here is that the clues are providing information on assignment propensities, which are informative about the share of each type in each cell. With flat priors over assignment propensities, our beliefs are centered around equal propensities for all types (though we’re also very uncertain about this). Moreover, given equal assignment propensities, the flat data <span class="math inline">\(X,Y\)</span> pattern has us believing that there the average treatment effect is 0 (also with great uncertainty). For every additional <span class="math inline">\(X=1, Y=1\)</span> for which we observe <span class="math inline">\(K=1\)</span>, however, we shift upward our belief about the share of <span class="math inline">\(b\)</span>’s in the cell. We are, thus, now learning about assignment propensities: now it looks like <span class="math inline">\(b\)</span> types were more commonly assigned to <span class="math inline">\(X=1\)</span>, implying that <span class="math inline">\(d\)</span>’s must have been more commonly assigned to <span class="math inline">\(X=0\)</span>. Put differently, we are learning that the flat data pattern has arisen via confounding that is “suppressing” a positive treatment effect.</p>
<p>The value of the clue data, moreover, does not depend on how many <span class="math inline">\(X,Y\)</span> cases we’ve observed because no amount of <span class="math inline">\(X,Y\)</span> data can tell us about <span class="math inline">\(X\)</span>&lt;-&gt;<span class="math inline">\(Y\)</span> confounding. As we see in the bottom-left graph, we end up more certain, the more <span class="math inline">\(X, Y\)</span> data we have. But there’s just as much to be <em>gained</em> from a given amount of clue data whether we’ve started with 5 <span class="math inline">\(X,Y\)</span> cases or 5000.</p>
<ol start="2" style="list-style-type: decimal">
<li>When assignment propensities are known (and so we can treat the data as experimental), the learning from clue data depends heavily on how many <span class="math inline">\(X,Y\)</span> cases we start out with. Where we have a large amount of <span class="math inline">\(X,Y\)</span> data, clue evidence adds little to nothing to our inferences about average treatment effects. There is nothing to be learned from the clues about assignment propensities since these are already known. And, with assignment propensities known, <span class="math inline">\(X,Y\)</span> information alone are sufficient for convergence on the average treatment effect as sample size increases. Clue information shifts beliefs about the types of the particular cases for which clue data is gathered — i.e., for this case-level-estimand — but has almost no effect on estimates of the population estimand.</li>
</ol>
<p>However, we can learn about average effects from clue data when we have few <span class="math inline">\(X,Y\)</span> cases. While we can infer the average causal effect from a known <span class="math inline">\(X,Y\)</span> distribution (and known assignment propensities), we have a lot of uncertainty about that distribution when we only have a handful of <span class="math inline">\(X,Y\)</span> cases. Thus, clue data help us by uniquely providing information about the types of individual cases. It is still only from observing <span class="math inline">\(K=1\)</span> in a case that we can learn that that case is a <span class="math inline">\(b\)</span> type, allowing us to update upwardly on the relative proportions of <span class="math inline">\(b\)</span>’s and <span class="math inline">\(d\)</span>’s. With little other information on the average effect, this pushes our belief about average effects upward.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> And, in the absence of a large amount of of <span class="math inline">\(X,Y\)</span> data, knowing there is one more <span class="math inline">\(b\)</span> and one less <span class="math inline">\(d\)</span> type still benefits from learning</p>
<ol start="3" style="list-style-type: decimal">
<li>Though not visible from the figure, clue data help us learn about a different population-level estimand — the <em>distribution</em> of causal effects in the population — even when we have a large <span class="math inline">\(N\)</span> and known propensities. The same average causal effect could be consistent with a large share of <span class="math inline">\(a\)</span>’s and <span class="math inline">\(b\)</span>’s combined, with few no-effect cases, or with a small share of <span class="math inline">\(a\)</span>’s and <span class="math inline">\(b\)</span>’s combined, with many no-effect cases. In other words, we don’t actually learn from <span class="math inline">\(X,Y\)</span> data about the distribution of types, even with a large <span class="math inline">\(X,Y\)</span> sample and known propensities. But observation of clues identifying <span class="math inline">\(b\)</span> types in the <span class="math inline">\(X=Y=1\)</span> cell, while it does not change estimates of <em>average</em> treatment effects, tells us that there is greater <em>heterogeneity</em> of effects in the population. More <span class="math inline">\(b\)</span> types, holding the average effect constant, means that there must also be more <span class="math inline">\(a\)</span> types. Thus, we have learned that there are more offsetting effects playing out in the population — positive effects alongside negative effects — than we knew before we saw the clue data. In fact, we learn <em>more</em> about heterogeneity from clue data where the average causal effect is already known than where we are highly uncertain about the average effect.</li>
</ol>
<p>FLAG: Can we show the heterogenity point graphically, too? Seems odd to say it’s not visible when we could make it so.</p>
</div>
<div id="diagnosing-mixes" class="section level2">
<h2><span class="header-section-number">13.3</span> Diagnosing mixes</h2>
<p>The stylized example above is intended to help us see how our choices about depth vs. breadth can depend on the process through which we believe the data have been generated. Our more general point is that we can systematically assess different possible mixes of extensiveness and intensiveness given a causal model and any data that have already been observed.</p>
<p>The basic procedure, in <code>gbiqq</code>, is as follows.</p>
<ol style="list-style-type: decimal">
<li><strong>Define a model.</strong> Specify the causal graph (possibly with unobserved confounding), any restrictions on causal effects, and any priors over parameters. We consider five different models:</li>
</ol>
<ul>
<li>One-path model, with a single, mediated path</li>
<li>Two-path model, with a direct and an indirect path</li>
<li>Restricted model, the two-path model with monotonicity restrictions, excluding negative effects at each step</li>
<li>Observed-confound model, in which there is only a direct <span class="math inline">\(X \rightarrow Y\)</span> path and the clue is a confound</li>
<li>Unobserved-confound model, the chain model with unobserved <span class="math inline">\(X\)</span> &lt;-&gt; <span class="math inline">\(Y\)</span> confounding</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Specify the given data.</strong> We imagine starting with a certain amount of <span class="math inline">\(X,Y\)</span> data, from 32 cases, and we vary the pattern in those data.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> The given data patterns we examine are a strong positive <span class="math inline">\(X,Y\)</span> relationship; the absence of any <span class="math inline">\(X,Y\)</span> relationship; a pattern suggestive of <span class="math inline">\(X=1\)</span> being almost sufficient for <span class="math inline">\(Y=1\)</span>; and a pattern suggestive of <span class="math inline">\(X=1\)</span> being almost necessary for <span class="math inline">\(Y=1\)</span>.</p></li>
<li><p><strong>Specify wide and deep data strategies.</strong> In examples below, we assume a baseline set of <span class="math inline">\(X, Y\)</span> data that have already been observed. We pose the wide-vs.-deep question at the margins: how much do we expect to gain from collecting <span class="math inline">\(X,Y\)</span> data for a given number of additional, randomly selected cases, and how much from looking for a clue, <span class="math inline">\(M\)</span>, within a given number of cases in our sample (for which we already have <span class="math inline">\(X,Y\)</span> data)? To simplify the analysis, we assume that clue data are sought on a positive regression line, with half sought in the <span class="math inline">\(X=0, Y=0\)</span> cell and half in the <span class="math inline">\(X=1, Y=1\)</span> cell. A data strategy is defined as a combination of width and depth: adding <span class="math inline">\(X,Y\)</span> data on 0, 2, or 4 cases, and hunting for a clue within 0, 2, or 4 cases.</p></li>
<li><p><strong>Formulate queries.</strong> As our discussion in the last section already suggests, the optimal mix may depend on the causal question we are interested in answering. We assess learning about three distinct causal queries:</p></li>
</ol>
<ul>
<li>Average treatment effect</li>
<li>Probability of positive causation: the probability that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> in an <span class="math inline">\(X=Y=1\)</span> case?</li>
<li>Probability of mediated positive causation: the probability that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> through a particular mechanism — a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> and a positive effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> — in an <span class="math inline">\(X=Y=1\)</span> case.</li>
</ul>
<p>It is worth noting that the second two queries are conditioned on particular <span class="math inline">\(X,Y\)</span> values but that the data strategies we are examining in these analyses do not limit our inquiry to those values. The “wide” component of any strategy is a random draw from the population; and the “deep” componeny involves looking <em>both</em> in the <span class="math inline">\(X=Y=1\)</span> cell <em>and</em> in the <span class="math inline">\(X=Y=0\)</span> cell. Of course, it is not hard to imagine that seeing what is going on in an <span class="math inline">\(X=Y=0\)</span> case could be informative about causal relations in an <span class="math inline">\(X=Y=1\)</span> case.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Diagnose each strategy, conditional on model and given data.</strong> For each strategy, we implement a separate diagnosis under each combination of model and given data, using <code>gbiqq</code>’s <code>diagnose_strategy</code> function. For each strategy, model, and given data pattern, the function:</li>
</ol>
<ul>
<li>identifies all possible new data realizations</li>
<li>calculates the probability of each possible data realization</li>
<li>updates posterior distributions on all parameters for each possible data realization</li>
<li>calculates expected posteriors on all parameters by averaging across posteriors from all possible data-realizations, weighted by their probability of arising</li>
<li>uses the expected posteriors on parameters to generate expected posterior distributions on each of the specified queries.</li>
</ul>
<p>What we are interested in is the expected variance of the posteriors, which tells us how uncertain we expect to be about our estimate after implementing the strategy, given the model and the given data.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> A greater reduction in expected posterior variance implies greater expected learning from the strategy.</p>
<p>The results of these diagnoses are represented in Figures <strong>flag: labels here</strong>. In each figure, we consider learning about all three queries under a single model, with each row of subplots considering a different pattern of given data as the starting point. The “wide” data strategies (collecting <span class="math inline">\(X, Y\)</span> data for an additionl 0, 2, or 4 randomly selected cases) are represented by movement across the columns of subplots; the “deep” strategies (collecting a clue for 0, 2, or 4 <span class="math inline">\(X=Y\)</span> cases within the sample) are represented within each subplot. Within each subplot, we provide the expected posterior variance for a particular level of “width” and given data, providing error bars representing 95 percent of the simulation variability.</p>
<p>We summarize key features of the results, and suggest some intuitions that might explain them, for each model in turn. Whemn referring to unit types, we continue here to use our simpler <span class="math inline">\(a, b, c, d\)</span> notation to help simplfy the discussion. We should also note that the setup of these simulations is, in some sense, generically tilted against breadth in the sense that we always assume that we have collected a moderate amount of <span class="math inline">\(X, Y\)</span> data, and no data on <span class="math inline">\(M\)</span>, prior to making the choice. We are thus likely to be at a steeper point on the “yield curve” when it comes to <span class="math inline">\(M\)</span> data than for <span class="math inline">\(X, Y\)</span> data. This is, of course, mostly an idiosyncratic feature of these particular experiments, rather than a fundamental feature of optimizing across strategies. So we encourage readers to pay more attention to the differences in the relative gains to depth and breadth across models, queries, and given-data patterns rather than to the average relative differences.</p>
<div id="path-model" class="section level3">
<h3><span class="header-section-number">13.3.1</span> 1-path model</h3>
<p><strong><span class="math inline">\(ATE\)</span></strong></p>
<p>One striking feature of the simulations with a 1-path model is how difficult it is to learn about average effects from either additional depth or additional breadth. We see less learning about the <span class="math inline">\(ATE\)</span> than about other queries for all data-mixes examined here.</p>
<p>We learn the most about the <span class="math inline">\(ATE\)</span> when we start with data consistent with a strong treatment effect (regr). If we examine the tradeoffs here, we see that – if we’re going to collect more data on two cases – process tracing two cases already in the sample yields about as much expected gain as expanding the sample by two cases on which we collect only <span class="math inline">\(X, Y\)</span> data. There are hints that the tradeoff shifts slightly as we move to the right: process tracing 4 cases may be marginally better than expanding the <span class="math inline">\(X,Y\)</span> sample by 4 cases. Likewise, a mix of 4-deep and 2-wide looks slightly better than the reverse (4 wide and 2 deep). For both comparisons, however, the apparent differences are well within the simulation error intervals. We do not see clear evidence here of gains from mixing <em>per se</em> – i.e., that we learn more about the ATE from mixing forms of data than from concentrating our efforts on either depth or breadth.</p>
<p>The potential for learning weakens as the given data pattern weakens. The opportunity to learn, from either greater extensive or greater intensive data-collection, is weaker for given data suggestive of necessity or sufficiency (which are, essentially, both moderately strong positive correlations) and essentially disappears when we start with completely flat data. This effect is likely driven by the level of uncertainty that the model plus the given data leave us with. At the extreme, flat priors on the original model plus flat data together make us quite certain that the <span class="math inline">\(ATE\)</span> is 0; this very low uncertainty is evident from the position of the ATE line in the row of graphs for flat given data. This leaves very little expected scope for additional learning.</p>
<p>Suppose, for instance, that we were to collect clue data on two <span class="math inline">\(X=Y=1\)</span> cases that yielded evidence that these cases were likely <span class="math inline">\(b\)</span> types. We would now update our beliefs toward thinking that there are more <span class="math inline">\(b\)</span>’s than <span class="math inline">\(d\)</span>’s in the <span class="math inline">\(X=Y=1\)</span> cell. However, given our high level of certainty that the <span class="math inline">\(ATE=0\)</span>, we would then also upwardly update our beliefs about the share of <span class="math inline">\(a\)</span> types, preserving our original <span class="math inline">\(ATE\)</span> estimate. In principle, observing new <span class="math inline">\(X,Y\)</span> data that deviated from a flat pattern could shift our beliefs about the ATE. But, given current beliefs, we strongly expect <em>not</em> to observe such a data pattern, and so this hypothetical outcome has little effect on the learning we expect to reap from collecting more data.</p>
<p>On the other hand, when we start with flat priors and then observe a strong positive correlation in the given data (regr), such that the priors and given data pull in opposite directions, we bring a more dispersed (new) prior distribution to the design problem. This greater prior uncertainty allows the new data to move our beliefs much more.</p>
<p><strong>ProbPos</strong></p>
<p>When it comes to estimating the probability of causation – is there a positive causal effect in an <span class="math inline">\(X=Y=1\)</span> case? – the tradeoffs shift somewhat. Starting with given data falling along a positive regression line, the gains to going wide appear about the same for the probability of causation as they do for estimating the <span class="math inline">\(ATE\)</span>. However, depth has a distinct advantage in estimating the probability of causation that it did not have for the <span class="math inline">\(ATE\)</span>: the gains to process tracing 2 (or 4) cases are much greater than the gains to collecting <span class="math inline">\(X,Y\)</span> data on an additional 2 (or 4) cases. In fact, we expect to be better off going deep into 2 cases than expanding the sample by 4 cases.</p>
<p>Why might depth be of greater value in assessing the probability of causation than in estimating the <span class="math inline">\(ATE\)</span>? The reason is likely that process tracing helps us estimate the share of types in a manner more directly related to the probability of causation than to the <span class="math inline">\(ATE\)</span>. When we conduct process tracing on an <span class="math inline">\(X=Y\)</span> case, we are learning about the probability that that case is a <span class="math inline">\(b\)</span> type, rather than a <span class="math inline">\(c\)</span> (for <span class="math inline">\(X=Y=0\)</span> cases) or a <span class="math inline">\(d\)</span> (for <span class="math inline">\(X=Y=1\)</span> cases). Whether we are in the <span class="math inline">\(X=Y=0\)</span> cell or the <span class="math inline">\(X=Y=1\)</span> cell, we can then update our beliefs about the share of cases in the <span class="math inline">\(X=Y=1\)</span> that are <span class="math inline">\(b\)</span>’s.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> This is exactly the quantity of interest for the probability of causation question: if I see an <span class="math inline">\(X=Y=1\)</span> case, what are the chances <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> (is it a <span class="math inline">\(b\)</span>?)?</p>
<p>On the other hand, updating on the share of <span class="math inline">\(b\)</span>’s versus <span class="math inline">\(c\)</span>’s and <span class="math inline">\(d\)</span>’s gives us only indirect leverage on the <span class="math inline">\(ATE\)</span> (the share of <span class="math inline">\(b\)</span>’s minus the share in <span class="math inline">\(a\)</span>’s) since it contains no direct information about the share of <span class="math inline">\(a\)</span>’s. If we observe evidence of an additional handful of <span class="math inline">\(b\)</span> cases, any upward shift in our beliefs about the <span class="math inline">\(ATE\)</span> will be constrained by our prior beliefs (given the existing data) about the <span class="math inline">\(ATE\)</span>. Our updating will be some combination of upward movement in the <span class="math inline">\(ATE\)</span> estimate and upward movement in our estimate of the share of <span class="math inline">\(a\)</span>’s (which moderates the change in the <span class="math inline">\(ATE\)</span> estimate).</p>
<p>We also see here evidence of a substitution effect between depth and breadth. As the amount of process-tracing data increases, it appears that the gains to adding <span class="math inline">\(X,Y\)</span> data diminishes.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>As for the <span class="math inline">\(ATE\)</span>, flatter prior data in combination with our initial flat priors also limits learning about the probability of causation, for all kinds of data. We do, however, continue to see an advantage of depth over breadth, regardless of the given data pattern. And we expect slightly more learning from additional data given a “necessity” pattern in the prior data than given a “sufficiency” pattern. This is probably because, given the necessity pattern, we start out with a higher estimate of the probability of causation and more uncertainty.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p><strong>Via_M</strong></p>
<p>What if we want to learn about the probability that, in an <span class="math inline">\(X=Y=1\)</span> case, <span class="math inline">\(X\)</span> had a positive effect on <span class="math inline">\(Y\)</span> through a chain of positive effects running through <span class="math inline">\(M\)</span>? Of course, in this model, if there <em>is</em> an effect in an <span class="math inline">\(X=Y=1\)</span> case, it has to be positive and it has to run through <span class="math inline">\(M\)</span>. So the query reduces here to asking about (a) the probability that there is an effect in an <span class="math inline">\(X=Y=1\)</span> case and (b) the probability that it runs through linked positive effects as opposed to linked negative effects. What can we expect to learn about these questions from going wide as compared to going deep?</p>
<p>If we start with a strong regression pattern, we can expect to reap very large gains from drilling deeper within the current sample, far greater than from expanding the <span class="math inline">\(X,Y\)</span> dataset. The reason is straightforward: while <span class="math inline">\(X,Y\)</span> data alone can speak to one part of the query – the probability of an effect – they are completely silent on the other part – whether the effect operates through linked positive or linked negative effects. Meanwhile, data on <span class="math inline">\(M\)</span> can speak to <em>both</em> parts of the query, informing us about both the causal effect within a case <em>and</em> the mechanism through which it operates.</p>
<p>The gains to increased breadth, on its own, are considerable though they decline rapidly as we obtain clue data. We also see steeply diminishing returns to clue data itself. The sharp reduction in marginal gains on both counts is likely a consequence of our ignorance at the outset. We are starting with given data that provide no information on a key part of the query, allowing for massive early gains to seeing small amounts of relevant data but also steeply diminishing returns. This is a very different situation from the one we are in with the <span class="math inline">\(ATE\)</span> and probability of causation queries, where we have already learned a great deal from the given data.</p>
<p>As the pattern in the given data weakens – becoming less and less consistent with a strong effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> – we again learn less from new data. Interestingly, we still do learn from new data even when flat given data have made us quite certain that there is no average effect. We do not expect to learn here from going wide since <span class="math inline">\(X,Y\)</span> data can only inform us about the overall effect, and we have seen already that (with flat given data) we expect to learn very little from new data about that effect. However, process tracing can still provide unique insight into the pathway through which positive effects in the sample take place. Still, the learning from depth is much more modest here than it is given a strong regression pattern. This is likely because, given flat data, we are much less confident that a given <span class="math inline">\(X=Y\)</span> case <em>has</em> a positive effect.</p>
<p><strong>2-path model</strong></p>
<p><em>Via_M</em></p>
<p>We start with perhaps the most surprising result for the 2-path model: learning about whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>, in an <span class="math inline">\(X=Y=1\)</span> case via linked positive effects through <span class="math inline">\(M\)</span>. Regardless of the given data, we expect to learn extremely little from observing <span class="math inline">\(M\)</span> itself! What makes this so counterintuitive is that observing <span class="math inline">\(M\)</span> seems potentially dispositive: if we see <span class="math inline">\(M=0\)</span> in an <span class="math inline">\(X=Y=1\)</span> case, or <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=Y=0\)</span> case, we know for sure that that case fails to satisfy the query; the opposite observation leaves the query in contention. This divergence in beliefs conditional on the data-realization seems like a setup for potential learning.</p>
<p>Perhaps less surprisingly, we also learn almost nothing about the pathway from additional <span class="math inline">\(X, Y\)</span> observations. Why is this?</p>
<p>The reason is that, under the 2-path model, this query defines a state of affairs that is highly unlikely to begin with. In an <span class="math inline">\(X=1\)</span> case, there is only one combination of nodal types (or unit type) that satisfies the query: we need the types in which <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(M\)</span>; <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (when <span class="math inline">\(X\)</span> is at the value it takes on); and <span class="math inline">\(X\)</span> does <em>not</em> have an effect when <span class="math inline">\(M\)</span> is fixed at 1. The first of these conditions requires <span class="math inline">\(\theta^M_{01}\)</span> while the second and third jointly require <span class="math inline">\(Y^_{0011}\)</span>. With four possible nodal types at <span class="math inline">\(M\)</span>, 16 nodal types at <span class="math inline">\(Y\)</span>, and flat priors across all nodal types, the probability of this particular combination start out as very low; the given <span class="math inline">\(X, Y\)</span> data do little to increase it, regardless of their pattern.
Thus, when we observe <span class="math inline">\(M=0\)</span> in an <span class="math inline">\(X=Y=1\)</span> case, say, while we now know for sure that this case does not satisfy the query, we believed this probability to be very low before we saw the data. Thus, our beliefs about the proportion of cases in the population that satisfy the query hardly budges. If we observe <span class="math inline">\(M=1\)</span> in the case, we can now continue to believe that the query might be satisfied, but that probability still edges up only slightly because there remain a large number of unit types in contention. The data pattern is consistent with all unit types involving a combination of <span class="math inline">\(\theta^M_{01}\)</span> or <span class="math inline">\(\theta^M_{11}\)</span> and any of the 8 <span class="math inline">\(Y\)</span>-types in which <span class="math inline">\(Y=1\)</span> when <span class="math inline">\(X=1\)</span> and <span class="math inline">\(M=1\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> And, again, only one of these 16 unit types satisfies the query.]</p>
<p>To put the point differently, it is very hard to learn from data – even informative data – about a query that is at the outset very unlikely to be true. And how likely a query is to be true will depend both on how few unit types satisfy it and how much weight our priors place on those unit types.</p>
<p><em><span class="math inline">\(ATE\)</span> and ProbPos</em></p>
<p>We see that we can learn about the <span class="math inline">\(ATE\)</span> by collecting additional <span class="math inline">\(X, Y\)</span> data. Indeed, we learn about as much from greater breadth in the 2-path model as we do in the 1-path model, suggesting that learning about average effects from <span class="math inline">\(X, Y\)</span> data is fairly insensitve to the number of causal paths between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in our model. We also can learn about the probability of positive causation in an <span class="math inline">\(X=Y=1\)</span> case from collecting additional <span class="math inline">\(X,Y\)</span> data.</p>
<p>In contrast, we expect to learn almost nothing about the <span class="math inline">\(ATE\)</span> or probability of causation from depth in the 2-path model, a striking contrast from the situation in the 1-path model. The reason is that, in the 2-path model with flat priors, the observation of <span class="math inline">\(M\)</span> will always eliminate a set of causal types balanced around our priors — that is, a set of types over which the <span class="math inline">\(ATE\)</span> is equal to our prior.</p>
<p>To see how this works, for both estimands, let us think this through for the probability of causation since any learning about the <span class="math inline">\(ATE\)</span> from depth must operate through updating on causal effects within the cases examined. Imagine that we start with an <span class="math inline">\(X=Y=1\)</span> case.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> Of the original <span class="math inline">\(16\)</span> nodal types for <span class="math inline">\(Y\)</span> (given that <span class="math inline">\(Y\)</span> has two parents), now only <span class="math inline">\(12\)</span> are consistent with the data. We believe now that the probability that <span class="math inline">\(X\)</span> had a positive effect on <span class="math inline">\(Y\)</span> in this case is 0.5. The causal types in which <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(Y\)</span> have been eliminated. We are left with a set of causal types in which half of the probability is on those with a <span class="math inline">\(0\)</span> effect and half is on those with an effect of <span class="math inline">\(1\)</span>. For instance, there are four causal types in which <span class="math inline">\(M\)</span> is fixed at <span class="math inline">\(0\)</span> and <span class="math inline">\(X\)</span> has a direct positive effect on <span class="math inline">\(Y\)</span>; but there are also four types in which <span class="math inline">\(M\)</span> is fixed at <span class="math inline">\(0\)</span> and <span class="math inline">\(X\)</span> has no effect on <span class="math inline">\(Y\)</span> (whether because any effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> would require either a change in <span class="math inline">\(M\)</span> or <span class="math inline">\(M\)</span>’s value to be <span class="math inline">\(1\)</span>, or because <span class="math inline">\(X\)</span> never affects <span class="math inline">\(Y\)</span>). And the probabilities of the first set sum to an equal value to those of the latter set.</p>
<p>Now, suppose that we look for <span class="math inline">\(M\)</span> and observe <span class="math inline">\(M=1\)</span>. A few things happen.</p>
<p>1 We eliminate a set of causal types containing <span class="math inline">\(Y\)</span>-nodal types in which <span class="math inline">\(Y\)</span> cannot be 1 when <span class="math inline">\(M\)</span> is <span class="math inline">\(1\)</span>. These types are perfectly balanced around our prior of 0.5, however. To loosely illustrate, one pair of eliminated causal types are those involve either <span class="math inline">\(\theta^M_{00}\)</span> or <span class="math inline">\(\theta^M_{10}\)</span>, combined with <span class="math inline">\(\theta^Y_{0100}\)</span>. Both of these types are consistent with <span class="math inline">\(X=Y=1\)</span> but are <em>not</em> consistent with the additional observation of <span class="math inline">\(M=1\)</span>. Under both causal types, <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>: either via a direct effect (with <span class="math inline">\(\theta^M_{00}\)</span>) or a chain of negative effects (with <span class="math inline">\(\theta^M_{10}\)</span>). At the same time, observing <span class="math inline">\(M=1\)</span> also eliminates a pair of causal types in which we <span class="math inline">\(X\)</span> will have <span class="math inline">\(0\)</span> effect on <span class="math inline">\(Y\)</span>: those involving either <span class="math inline">\(\theta^M_{00}\)</span> or <span class="math inline">\(\theta^M_{10}\)</span>, combined with <span class="math inline">\(\theta^Y_{1100}\)</span>. Given the flat priors in our model and the prior observation of <span class="math inline">\(X=Y=1\)</span>, both pairs of causal types have equal prior weights; their elimination thus does not move our beliefs about the probability of causation off of <span class="math inline">\(0.5\)</span>.</p>
<p>2 We also learn about <span class="math inline">\(M\)</span>’s nodal type from observing <span class="math inline">\(M=1\)</span>, and thus eliminate a set of causal types in which <span class="math inline">\(M\)</span> cannot be <span class="math inline">\(1\)</span> when <span class="math inline">\(X=1\)</span>: specifically, <span class="math inline">\(\theta^M_{00}\)</span> and <span class="math inline">\(\theta^M_{10}\)</span>. Yet the eliminative effect is again perfectly balanced around <span class="math inline">\(0.5\)</span>. For instance, seeing <span class="math inline">\(M=1\)</span> eliminates the two causal types in which we have <span class="math inline">\(\theta^Y_{0101}\)</span> and either <span class="math inline">\(\theta^M_{00}\)</span> and <span class="math inline">\(\theta^M_{10}\)</span>. In both of these, <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. Yet seeing <span class="math inline">\(M=1\)</span> likewise eliminates the two causal types containing <span class="math inline">\(\theta^Y_{1111}\)</span> and either <span class="math inline">\(\theta^M_{00}\)</span> and <span class="math inline">\(\theta^M_{10}\)</span> – in both of which <span class="math inline">\(X\)</span> has <span class="math inline">\(0\)</span> effect. And both pairs of types, again, have equal prior weights attached to them.</p>
<p>To put the point more intuitively, our model contains too little information to make <span class="math inline">\(M\)</span> informative about <span class="math inline">\(X \rightarrow Y\)</span> effects. Any observation of <span class="math inline">\(M\)</span> is equally consistent with a positive effect and with no effect; and given flat priors across these two possibilities, there is no possibility to update on either estimand.</p>
<p>Overall, then, if we start with a 2-path model, embedding in the model no beliefs beyond the causal linkages, our prior beliefs do not contain sufficient information to lend probative value to observation of a potential mediator, at least for the three queries examined here.</p>
<p><strong>2-path model with restrictions</strong></p>
<p>Now, suppose that we have information about the possible direction of causal effects and impose restrictions on the nodel types accordingly. In particular, imagine that we believe negative direct effects to be impossible. We would then want to set restrictions to exclude nodal types that imply a negative effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span>; a negative effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> at any value of <span class="math inline">\(M\)</span>; and a negative effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> at any value of <span class="math inline">\(X\)</span>. How much can we learn now from depth or additional breadth?</p>
<p><em>Via-M</em></p>
<p>We appear to learn virtually nothing about our pathway query from additional <span class="math inline">\(X, Y\)</span> cases. On the other hand, we learn far more about the pathway query from within-case analysis in the restricted model than we did in the unrestricted model. The key reason is that the restrictions now substantially boost the prior probability of the query being true. While ruling out negative direct effects eliminates one nodal type at <span class="math inline">\(M\)</span> (<span class="math inline">\(\theta^M_{10}\)</span>), it eliminates 10 of the 16 nodal types at <span class="math inline">\(Y\)</span> (all but <span class="math inline">\(\theta^Y_{0000}\)</span>, <span class="math inline">\(\theta^Y_{0001}\)</span>, <span class="math inline">\(\theta^Y_{0101}\)</span>, <span class="math inline">\(\theta^Y_{0011}\)</span>, <span class="math inline">\(\theta^Y_{0111}\)</span>, <span class="math inline">\(\theta^Y_{1111}\)</span>. Observing <span class="math inline">\(X=Y=1\)</span> (the kind of case in which we are posing the query) eliminates <span class="math inline">\(\theta^Y_{0000}\)</span>.</p>
<p>With the causal-type space so dramatically reduced, the causal types that <em>satisfy</em> the query now have a substantially higher prior probability. Thus, when we find evidence, say, that a given case does not satisfy the query (observing <span class="math inline">\(M=0\)</span>), there is far more scope (as compared to under the unrestricted model) for our beliefs about the share of cases satisfying the query to shift downward. Likewise, evidence consistent with the query (<span class="math inline">\(M=1\)</span>) has more of an upward impact on beliefs when we start with a prior further from 0.</p>
<p><em>ProbPos and <span class="math inline">\(ATE\)</span></em></p>
<p>Expected learning from breadth about the probability of causation and the <span class="math inline">\(ATE\)</span> does not look very different in the restricted than in the unrestricted model: we can still learn about both from enlarging our <span class="math inline">\(X, Y\)</span> sample.</p>
<p>More significantly, the restrictions now make it possible for us to learn about causal effects from observing <span class="math inline">\(M\)</span> within cases in our sample. Under the restricted model, we now will think it is a little more likely that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in an <span class="math inline">\(X=Y=1\)</span> case if we observe <span class="math inline">\(M=0\)</span> and a little less likely if we observe <span class="math inline">\(M=1\)</span>. It is difficult to formulate a simple story aabout how this updating operates. Indeed, most readers’ intuitions (as did ours) likely run in the <em>opposite</em> direction, expecting <span class="math inline">\(M=1\)</span> to generate a higher probability of positive causation than <span class="math inline">\(M=0\)</span>. If causal effects cannot be negative, then isn’t <span class="math inline">\(M=1\)</span> more consistent than <span class="math inline">\(M=0\)</span> with <span class="math inline">\(X=1\)</span> causing <span class="math inline">\(Y=1\)</span>? This setup is, in fact, a good example of how difficult it can be to informally reason our way through inference for even fairly simple models.</p>
<p>One aspect of the setup that our intuitions might miss is the difference between how a model affects our <em>prior beliefs</em> on a query and how the model conditions <em>learning</em> from new evidence. It <em>is</em> the case that our restricted model implies a higher probability of positive causation <em>before</em> we see <span class="math inline">\(M\)</span> than does our unrestricted model. For instance, the prior probability of positive causation in an <span class="math inline">\(X=Y=1\)</span> case in the unrestricted 2-path model is 0.5 (assuming no given data); in the restricted model, that prior probability is 0.6. The restricted model is thus a world in which positive causation in an <span class="math inline">\(X=Y=1\)</span> case is in general more likely. However, <em>conditional</em> on being in that world, observing <span class="math inline">\(M=1\)</span> is actually less consistent with positive causation than is <span class="math inline">\(M=0\)</span>.</p>
<p>Each realization of <span class="math inline">\(M\)</span> actually pushes our beliefs in two directions. When we observe <span class="math inline">\(M=1\)</span>, there is one set of implications that pushes in the direction of a higher probability of causation. One way to think about this is that, before knowing <span class="math inline">\(M\)</span>’s value, we were unsure whether the nodal types <span class="math inline">\(\theta^Y_{0001}\)</span> or <span class="math inline">\(\theta^Y_{0011}\)</span> were consistent with the observations we had already made of <span class="math inline">\(X=Y=1\)</span>. That is because these types are <em>only</em> consistent with <span class="math inline">\(X=Y=1\)</span> if <span class="math inline">\(M=1\)</span>. Knowing that <span class="math inline">\(M=1\)</span> thus boosts the probability that a case is of one of these two types (relative to the other 3 possible <span class="math inline">\(Y\)</span>-types, <span class="math inline">\(\theta^Y_{0101}\)</span>, <span class="math inline">\(\theta^Y_{0111}\)</span>, <span class="math inline">\(\theta^Y_{1111}\)</span>). And it happens that these two types are also the types with a higher average probability of causation as compared to the other 3 <span class="math inline">\(Y\)</span>-types that were consistent with <span class="math inline">\(X=Y=1\)</span>.</p>
<p>Meanwhile, observing <span class="math inline">\(M=1\)</span> also eliminates any expected effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> <em>if</em> the <span class="math inline">\(Y-type\)</span> is <span class="math inline">\(\theta^Y_{0111}\)</span>. The reason can be straightforwardly read off this type: when the <span class="math inline">\(Y\)</span> type is <span class="math inline">\(\theta^Y_{0111}\)</span>, <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(Y\)</span> <em>only</em> at <span class="math inline">\(M=0\)</span>.</p>
<p>On net, this downward effect is larger than the upward effect, leading to a net reduction in the posterior probability of causation. Likewise, seeing <span class="math inline">\(M=0\)</span> eliminates <span class="math inline">\(Y\)</span> types with a high expected effect but boosts the probability of causation for <span class="math inline">\(\theta^Y_{0111}\)</span>, with the net result of increasing our posterior probability of causation.</p>
<p>In sum, the restrictions placed on the model generate the unevenness in weights across types that give us a foothold for learning from the clue. When observing <span class="math inline">\(M\)</span> eliminates some types and changes the probability of causation for others, the effects do not simply cancel out, as they do in the unrestricted model.</p>
<p>Note that learning from <span class="math inline">\(M\)</span> about the <span class="math inline">\(ATE\)</span> is also made possible by the restrictions since this learning flows from learning about causation at the case level. However, learning about the <span class="math inline">\(ATE\)</span> is going to be attenuated compared to learning about the probability of positive causation because, as discussed above, learning about the <span class="math inline">\(ATE\)</span> from within-case evidence is more indirect than is learning about the probability of positive causation.</p>
<p>For the <span class="math inline">\(ATE\)</span>, then the expected gains to learning from a given amount of breadth (two more <span class="math inline">\(X, Y\)</span> cases) are greater than the expected gains from an equivalent amount of depth (observing <span class="math inline">\(M\)</span> within 2 cases), even after we have already observed <span class="math inline">\(X, Y\)</span> data for 32 cases. For the probability of positive causation, the breadth/depth tradeoff looks roughly balanced at this point.</p>
<p><strong>Model with observable confound</strong></p>
<p>Now we turn to an unrestricted model in which <span class="math inline">\(M\)</span> affects both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, operating as an observable confound for their relationship. What can we learn by observing a confound in this model?</p>
<p><em>Via_M</em></p>
<p>The simplest takeaway is that we can learn nothing about our pathway query, for the simple reason that we have no uncertainty about it, given the model on its own. Under this model, there is no possibility for <span class="math inline">\(X\)</span> to exert a positive effect on <span class="math inline">\(Y\)</span> <em>through</em> <span class="math inline">\(M\)</span> since <span class="math inline">\(M\)</span> is not positioned as a mediator between these two variables. Data cannot make us any more certain of this!</p>
<p><em><span class="math inline">\(ATE\)</span> and <span class="math inline">\(ProbPos\)</span></em></p>
<p>We can see that we can learn about both the <span class="math inline">\(ATE\)</span> and <span class="math inline">\(ProbPos\)</span> both from additional <span class="math inline">\(X, Y\)</span> data and from observing <span class="math inline">\(M\)</span> within our sample. Despite the possibility of a confound, <span class="math inline">\(X,Y\)</span> data are still informative insofar as <span class="math inline">\(X=1, Y=0\)</span> and <span class="math inline">\(X=0, Y=1\)</span> observations are both inconsistent with a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>Full set of analyses</p>
<p>Graph full set</p>
<p>How does this approach guide researchers in making choices about research designs?</p>
<p>We address this question with a focus on characterizing the kind of learning that emerges from gathering different sorts of data—such , <em>under different research conditions</em>. We report the results here of simulation-based experiments designed to tell us under what research conditions different mixes of methods can be expected to yield more accurate inferences. We also discuss, at a high level, the implications of the framework for strategies of qualitative case-selection.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="wide.html#cb1-1"></a>model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- K&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1-2"><a href="wide.html#cb1-2"></a><span class="st">  </span><span class="kw">set_restrictions</span>(<span class="st">&quot;(Y[X=0, K=1]==1) | (Y[X=0, K=0]==0)&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb1-3"><a href="wide.html#cb1-3"></a><span class="st">  </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">.99</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>))</span></code></pre></div>
<p>We see that prior beliefs are for a 0 average effect which rises to approximately .5 for cases in which <span class="math inline">\(K=1\)</span> is observed and falls to -.5 for cases in which <span class="math inline">\(K=0\)</span> is observed.</p>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">-0.008</td>
<td align="right">0.338</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.503</td>
<td align="right">0.222</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.500</td>
<td align="right">0.227</td>
</tr>
</tbody>
</table>
<p>We see little difference in the prior on estimands. Despite this an important difference is that the model that allows for confounding also allows for updating on confounding, which the simple model does not.</p>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">-0.007</td>
<td align="right">0.342</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.505</td>
<td align="right">0.222</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.495</td>
<td align="right">0.223</td>
</tr>
</tbody>
</table>
<p>We now examine inferences given different data strategies:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="wide.html#cb2-1"></a><span class="cf">if</span>(do_diagnosis){</span>
<span id="cb2-2"><a href="wide.html#cb2-2"></a>  wd_<span class="dv">1</span>_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">wide_or_deep</span>(model, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb2-3"><a href="wide.html#cb2-3"></a>  <span class="kw">write_rds</span>( wd_<span class="dv">1</span>_<span class="dv">2</span>, <span class="st">&quot;saved/wd_1_2.rds&quot;</span>)</span>
<span id="cb2-4"><a href="wide.html#cb2-4"></a>}</span>
<span id="cb2-5"><a href="wide.html#cb2-5"></a></span>
<span id="cb2-6"><a href="wide.html#cb2-6"></a>wd_<span class="dv">1</span>_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wd_1_2.rds&quot;</span>)</span>
<span id="cb2-7"><a href="wide.html#cb2-7"></a></span>
<span id="cb2-8"><a href="wide.html#cb2-8"></a></span>
<span id="cb2-9"><a href="wide.html#cb2-9"></a>wd_sim &lt;-<span class="st"> </span><span class="cf">function</span>(model, n_K, n_fold) {</span>
<span id="cb2-10"><a href="wide.html#cb2-10"></a>  </span>
<span id="cb2-11"><a href="wide.html#cb2-11"></a>    df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">X =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">Y =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">K =</span> <span class="ot">NA</span>) <span class="op">%&gt;%</span></span>
<span id="cb2-12"><a href="wide.html#cb2-12"></a><span class="st">      </span><span class="kw">slice</span>(<span class="kw">rep</span>(<span class="kw">row_number</span>(), n_fold))</span>
<span id="cb2-13"><a href="wide.html#cb2-13"></a>    df &lt;-<span class="st"> </span><span class="kw">mutate</span>(df, <span class="dt">K =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_K), <span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">n</span>()<span class="op">-</span>n_K)))</span>
<span id="cb2-14"><a href="wide.html#cb2-14"></a>    </span>
<span id="cb2-15"><a href="wide.html#cb2-15"></a>    given &lt;-<span class="st">  </span><span class="kw">collapse_data</span>(df, model)</span>
<span id="cb2-16"><a href="wide.html#cb2-16"></a></span>
<span id="cb2-17"><a href="wide.html#cb2-17"></a>    updated &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">gbiqq</span>(model, <span class="dt">data =</span> df, <span class="dt">stan_model =</span> fit)</span>
<span id="cb2-18"><a href="wide.html#cb2-18"></a>    <span class="kw">query_model</span>(updated, </span>
<span id="cb2-19"><a href="wide.html#cb2-19"></a>                  <span class="dt">queries =</span> <span class="kw">list</span>(<span class="dt">ATE =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span>), </span>
<span id="cb2-20"><a href="wide.html#cb2-20"></a>                  <span class="dt">using =</span> <span class="st">&quot;posteriors&quot;</span>)</span>
<span id="cb2-21"><a href="wide.html#cb2-21"></a>  </span>
<span id="cb2-22"><a href="wide.html#cb2-22"></a>}</span>
<span id="cb2-23"><a href="wide.html#cb2-23"></a></span>
<span id="cb2-24"><a href="wide.html#cb2-24"></a><span class="cf">if</span>(do_diagnosis){</span>
<span id="cb2-25"><a href="wide.html#cb2-25"></a>  <span class="cf">if</span>(<span class="op">!</span><span class="kw">exists</span>(<span class="st">&quot;fit&quot;</span>)) fit &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">fitted_model</span>()</span>
<span id="cb2-26"><a href="wide.html#cb2-26"></a>  out &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">8</span>), <span class="cf">function</span>(n_K) {<span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">20</span>), <span class="cf">function</span>(k) <span class="kw">wd_sim</span>(model, n_K, k))})</span>
<span id="cb2-27"><a href="wide.html#cb2-27"></a>  <span class="kw">write_rds</span>(out, <span class="st">&quot;saved/wide_or_deep_XMY.rds&quot;</span>)</span>
<span id="cb2-28"><a href="wide.html#cb2-28"></a>  }</span>
<span id="cb2-29"><a href="wide.html#cb2-29"></a></span>
<span id="cb2-30"><a href="wide.html#cb2-30"></a>wd &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wide_or_deep_XMY.rds&quot;</span>)</span>
<span id="cb2-31"><a href="wide.html#cb2-31"></a>wd &lt;-<span class="st"> </span><span class="kw">t</span>(wd[<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">9</span>,<span class="dv">14</span>), ])</span>
<span id="cb2-32"><a href="wide.html#cb2-32"></a><span class="kw">rownames</span>(wd) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Clues on 4 cases&quot;</span>, <span class="st">&quot;Clues on 8 cases&quot;</span>)</span>
<span id="cb2-33"><a href="wide.html#cb2-33"></a><span class="kw">colnames</span>(wd) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;N=8&quot;</span>, <span class="st">&quot;N=40&quot;</span>, <span class="st">&quot;N=80&quot;</span>)</span>
<span id="cb2-34"><a href="wide.html#cb2-34"></a><span class="kw">kable</span>((wd))</span>
<span id="cb2-35"><a href="wide.html#cb2-35"></a></span>
<span id="cb2-36"><a href="wide.html#cb2-36"></a><span class="cf">if</span>(do_diagnosis){</span>
<span id="cb2-37"><a href="wide.html#cb2-37"></a>  <span class="cf">if</span>(<span class="op">!</span><span class="kw">exists</span>(<span class="st">&quot;fit&quot;</span>)) fit &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">fitted_model</span>()</span>
<span id="cb2-38"><a href="wide.html#cb2-38"></a>  out &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">8</span>), <span class="cf">function</span>(n_K) {<span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">20</span>), <span class="cf">function</span>(k) <span class="kw">wd_sim</span>(model_confound, n_K, k))})</span>
<span id="cb2-39"><a href="wide.html#cb2-39"></a>  <span class="kw">write_rds</span>(out, <span class="st">&quot;saved/wide_or_deep_XMY2.rds&quot;</span>)</span>
<span id="cb2-40"><a href="wide.html#cb2-40"></a>  }</span>
<span id="cb2-41"><a href="wide.html#cb2-41"></a></span>
<span id="cb2-42"><a href="wide.html#cb2-42"></a>wd2 &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wide_or_deep_XMY2.rds&quot;</span>)</span>
<span id="cb2-43"><a href="wide.html#cb2-43"></a>wd2 &lt;-<span class="st"> </span><span class="kw">t</span>(wd2[<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">9</span>,<span class="dv">14</span>), ])</span>
<span id="cb2-44"><a href="wide.html#cb2-44"></a><span class="kw">rownames</span>(wd2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Clues on 4 cases&quot;</span>, <span class="st">&quot;Clues on 8 cases&quot;</span>)</span>
<span id="cb2-45"><a href="wide.html#cb2-45"></a><span class="kw">colnames</span>(wd2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;N=8&quot;</span>, <span class="st">&quot;N=40&quot;</span>, <span class="st">&quot;N=80&quot;</span>)</span>
<span id="cb2-46"><a href="wide.html#cb2-46"></a><span class="kw">kable</span>((wd2))</span></code></pre></div>
</div>
</div>
<div id="evaluating-strategies" class="section level2">
<h2><span class="header-section-number">13.4</span> Evaluating strategies</h2>
<p>As a metric of the returns from different research strategies we calculate the <em>expected</em> inaccuracy in the estimation of the average treatment effect, as given by:</p>
<p><span class="math display">\[\mathcal{L}=\mathbb{E}_\theta(\mathbb{E}_{\mathcal{D}|\theta}(\tau(\theta)-\hat{\tau}(\mathcal{D}))^2) \]</span></p>
<p>where <span class="math inline">\(\tau(\theta)\)</span> is the value of <span class="math inline">\(\lambda_b-\lambda_a\)</span> (the average treatment effect) given <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\hat{\tau}(\mathcal{D})\)</span> is the <em>estimate</em> of this treatment effect (the mean posterior value) that is generated following some realization of data <span class="math inline">\(\mathcal{D}\)</span>. Thus, if some <span class="math inline">\(\theta\)</span> characterized the true state of the world, then <span class="math inline">\(\mathbb{E}_{\mathcal{D}|\theta}(\tau^\theta-\hat{\tau})^2\)</span> is the expected error in estimation of the causal effect given different realizations of the data, <span class="math inline">\(\mathcal{D}\)</span>, that could obtain in this state of the world. <span class="math inline">\(\mathcal{L}\)</span> is then the expected value of these errors given prior beliefs over possible values of <span class="math inline">\(\theta\)</span>.</p>
<p>Note that, while we focus on errors on estimated average causal effects, similar exercises could assess how cross- and within-case observations distinctively contribute to other estimands | including the causal explanations for individual cases and the validity of causal theories | as well as to learning about inferential assumptions themselves (assignment and clue probabilities).
For all simulations, prior distributions are drawn with parameters as described in the Supplementary Materials (, Table <a href="#tab:sims"><strong>??</strong></a>). Priors on the type distribution are drawn from a Dirichlet distribution; priors for each of the <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\phi\)</span> values are drawn independently from Beta distributions. We note that, while by construction priors on each parameter are independent, this will not generally be the case for posterior distributions. In most cases we simulate the prior distribution using 5200 draws of each parameter. For most experiments we then systematically vary the prior distribution for one parameter of the research situation between two extreme positions. We then calculate the expected posterior from each possible data realization and, in turn, the expected loss in estimates of treatment effects for a range of levels of investment in qualitative and quantitative evidence.</p>
<p>A few further features of the experiments below are worth noting. First, our illustrations focus on learning about population-level causal effects; however, the model can yield results about the benefits of alternative research designs for estimating a wide range of other quantities of interest, such as case-specific causal explanations or clue probabilities. Second, while we focus on the search for a <em>single</em> clue in each case, the analysis can be extended to the case of an arbitrarily large set of clues. Third, in many of these experiments, the probative values are set at doubly decisive levels for all <span class="math inline">\(\phi\)</span> parameters, and thus focus on the very optimistic case of maximally informative process tracing. Fourth, we illustrate tradeoffs at low levels of <span class="math inline">\(n\)</span>, but the model can be employed to make choices for arbitrarily large numbers of cases. Finally, we note that some results may be sensitive to the choice of priors. The results below should thus be understood as an illustration of the utility of the BIQQ framework for guiding research choices, rather than as a set of more general prescriptive design rules.</p>
</div>
<div id="varieties" class="section level2">
<h2><span class="header-section-number">13.5</span> Varieties of mixing</h2>
<p>What are the marginal gains from additional pieces of correlational and process-tracing evidence for the accuracy of causal estimates? Figure  displays results, plotting the errors associated with different mixes of correlational and process data.</p>
<ul>
<li><strong>Qualitative and quantitative data can act as partial substitutes for assessing causal effects</strong>.</li>
<li><strong>The <em>relative</em> marginal gains from going wider and going deeper vary with the study design</strong>.</li>
<li><strong>Optimal strategies might involve going deep in a subsample of cases only.</strong></li>
</ul>

<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">strategy</th>
<th align="left">Query</th>
<th align="left">Subset</th>
<th align="right">estimand</th>
<th align="right">estimates</th>
<th align="right">MSE</th>
<th align="right">post_var</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">estimands_database</td>
<td align="left">Prior</td>
<td align="left">Q 1</td>
<td align="left">All</td>
<td align="right">0.135</td>
<td align="right">0.134</td>
<td align="right">0.024</td>
<td align="right">0.017</td>
</tr>
<tr class="even">
<td align="left">estimands_database1</td>
<td align="left">A_online</td>
<td align="left">Q 1</td>
<td align="left">All</td>
<td align="right">0.135</td>
<td align="right">0.141</td>
<td align="right">0.018</td>
<td align="right">0.016</td>
</tr>
<tr class="odd">
<td align="left">estimands_database2</td>
<td align="left">B_offline</td>
<td align="left">Q 1</td>
<td align="left">All</td>
<td align="right">0.135</td>
<td align="right">0.136</td>
<td align="right">0.024</td>
<td align="right">0.017</td>
</tr>
<tr class="even">
<td align="left">estimands_database3</td>
<td align="left">C_X1Y1</td>
<td align="left">Q 1</td>
<td align="left">All</td>
<td align="right">0.135</td>
<td align="right">0.136</td>
<td align="right">0.020</td>
<td align="right">0.016</td>
</tr>
<tr class="odd">
<td align="left">estimands_database4</td>
<td align="left">D_random</td>
<td align="left">Q 1</td>
<td align="left">All</td>
<td align="right">0.135</td>
<td align="right">0.138</td>
<td align="right">0.020</td>
<td align="right">0.016</td>
</tr>
</tbody>
</table>
</div>
<div id="probative-value-of-clues" class="section level2">
<h2><span class="header-section-number">13.6</span> Probative value of clues</h2>
</div>
<div id="effect-heterogeneity" class="section level2">
<h2><span class="header-section-number">13.7</span> Effect Heterogeneity</h2>
</div>
<div id="uncertainty-regarding-assignment-processes" class="section level2">
<h2><span class="header-section-number">13.8</span> Uncertainty Regarding Assignment Processes</h2>
</div>
<div id="uncertainty-regarding-the-probative-value-of-clues" class="section level2">
<h2><span class="header-section-number">13.9</span> Uncertainty regarding the probative value of clues</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For this illustration, we just need to keep track of <span class="math inline">\(b\)</span> (positive effect), <span class="math inline">\(a\)</span> (negative effect), and <span class="math inline">\(d\)</span> (no effect, <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>).<a href="wide.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>We also, by implication, update upwardly on the share of <span class="math inline">\(a\)</span>’s relative to <span class="math inline">\(d\)</span>’s in the <span class="math inline">\(X=0, Y=1\)</span> cell; but the direct learning about the <span class="math inline">\(X=1, Y=1\)</span> cell will be sharper than the indirect learning about the <span class="math inline">\(a\)</span>’s, generating a net increase in the estimated average causal effect.<a href="wide.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>We need to start with some given data to imagine strategies that involve going “deep” without going “wide”; that is we have to already have some cases within which additional data can be collected.<a href="wide.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>While we also might expect the posterior mean to change depending on what data-realization we encounter, the <em>expected</em> posterior will be equal to the prior mean since any beliefs about what we are most likely to find are already reflected in the prior.<a href="wide.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Since the model assumes exogenous assignment of <span class="math inline">\(X\)</span>, the updating for the two cells will in fact be identical.<a href="wide.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>This does not seem to simply be a function of generic diminishing returns to data as the gains appear linear within a given type of data.<a href="wide.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>The necessity pattern has fewer <span class="math inline">\(X=0, Y=1\)</span> cases than does the sufficiency pattern, implying a lower likelihood that an <span class="math inline">\(X=Y=1\)</span> case <em>would</em> still have <span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X\)</span> were 0.<a href="wide.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Specifically: <span class="math inline">\(\theta^Y_{0001}\)</span>, <span class="math inline">\(\theta^Y_{1001}\)</span>, <span class="math inline">\(\theta^Y_{0101}\)</span>, <span class="math inline">\(\theta^Y_{1101}\)</span>, <span class="math inline">\(\theta^Y_{0011}\)</span>, <span class="math inline">\(\theta^Y_{1011}\)</span>, <span class="math inline">\(\theta^Y_{0111}\)</span>, or <span class="math inline">\(\theta^Y_{1111}\)</span>.<a href="wide.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>To simplify, we set aside the given data in this illustration.<a href="wide.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clue.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="caseselection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
