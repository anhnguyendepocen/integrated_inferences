<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Going wide and going deep | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Going wide and going deep | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Going wide and going deep | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clue.html"/>
<link rel="next" href="caseselection.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#interpretation-of-functional-equations"><i class="fa fa-check"></i><b>2.2.2</b> Interpretation of functional equations</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.3</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.4</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.5" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.5</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.2</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#conditional-independence-alone-does-not-provide-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> Conditional independence alone does not provide probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="10" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>10</b> Elements of Design</a><ul>
<li class="chapter" data-level="10.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>10.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="10.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>10.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>10.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="10.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>10.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="10.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-variance-almost-always-goes-down"><i class="fa fa-check"></i><b>10.2.2</b> Expected variance (almost) always goes down</a></li>
<li class="chapter" data-level="10.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>10.2.3</b> Illustration</a></li>
<li class="chapter" data-level="10.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-loss-functions"><i class="fa fa-check"></i><b>10.2.4</b> Other loss functions</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>10.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>11</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="11.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>11.1</b> Core logic</a></li>
<li class="chapter" data-level="11.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>11.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="11.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>11.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="11.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>11.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="11.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>11.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>11.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="11.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>12</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="12.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>12.1</b> Motivation</a></li>
<li class="chapter" data-level="12.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>12.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="12.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>12.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="12.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>12.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>12.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="12.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>12.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="12.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>12.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="12.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>12.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="12.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>12.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="12.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>12.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>13.1</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>13.2</b> Explorations</a><ul>
<li class="chapter" data-level="13.2.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>13.2.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>13.3</b> Principles</a><ul>
<li class="chapter" data-level="13.3.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>13.3.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="13.3.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>13.3.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="13.3.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>13.3.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="14" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>14</b> Justifying models</a><ul>
<li class="chapter" data-level="14.1" data-path="justifying-models.html"><a href="justifying-models.html#bounds-on-probative-value"><i class="fa fa-check"></i><b>14.1</b> Bounds on probative value</a></li>
<li class="chapter" data-level="14.2" data-path="justifying-models.html"><a href="justifying-models.html#the-possibility-of-identification-of-probative-value-from-experimental-data"><i class="fa fa-check"></i><b>14.2</b> The possibility of identification of probative value from experimental data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>14.2.1</b> Mediator</a></li>
<li class="chapter" data-level="14.2.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>14.2.2</b> Moderator</a></li>
<li class="chapter" data-level="14.2.3" data-path="justifying-models.html"><a href="justifying-models.html#case-level-bounds-from-mixed-data"><i class="fa fa-check"></i><b>14.2.3</b> Case level bounds from mixed data</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="justifying-models.html"><a href="justifying-models.html#learning-across-populations"><i class="fa fa-check"></i><b>14.3</b> Learning across populations</a></li>
<li class="chapter" data-level="14.4" data-path="justifying-models.html"><a href="justifying-models.html#different-models-for-different-sites"><i class="fa fa-check"></i><b>14.4</b> Different models for different sites</a><ul>
<li class="chapter" data-level="14.4.1" data-path="justifying-models.html"><a href="justifying-models.html#observational-and-experimental"><i class="fa fa-check"></i><b>14.4.1</b> Observational and experimental</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>14.5</b> Causal discovery</a><ul>
<li class="chapter" data-level="14.5.1" data-path="justifying-models.html"><a href="justifying-models.html#a-model-of-models"><i class="fa fa-check"></i><b>14.5.1</b> A model of models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>15</b> Evaluating models</a><ul>
<li class="chapter" data-level="15.1" data-path="evaluation.html"><a href="evaluation.html#inferences-when-you-dont-buy-your-priors"><i class="fa fa-check"></i><b>15.1</b> Inferences when you don;t buy your priors</a></li>
<li class="chapter" data-level="15.2" data-path="evaluation.html"><a href="evaluation.html#tools-for-evaluating-models"><i class="fa fa-check"></i><b>15.2</b> Tools for evaluating models</a><ul>
<li class="chapter" data-level="15.2.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independencies"><i class="fa fa-check"></i><b>15.2.1</b> Check conditional independencies</a></li>
<li class="chapter" data-level="15.2.2" data-path="evaluation.html"><a href="evaluation.html#check-confounding-assumptions"><i class="fa fa-check"></i><b>15.2.2</b> Check confounding assumptions</a></li>
<li class="chapter" data-level="15.2.3" data-path="evaluation.html"><a href="evaluation.html#check-prior-dependence"><i class="fa fa-check"></i><b>15.2.3</b> Check prior dependence</a></li>
<li class="chapter" data-level="15.2.4" data-path="evaluation.html"><a href="evaluation.html#check-fit"><i class="fa fa-check"></i><b>15.2.4</b> Check fit</a></li>
<li class="chapter" data-level="15.2.5" data-path="evaluation.html"><a href="evaluation.html#assess-likelihoods-under-different-models"><i class="fa fa-check"></i><b>15.2.5</b> Assess likelihoods under different models</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>15.3</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="15.3.1" data-path="evaluation.html"><a href="evaluation.html#prior-check"><i class="fa fa-check"></i><b>15.3.1</b> Prior check</a></li>
<li class="chapter" data-level="15.3.2" data-path="evaluation.html"><a href="evaluation.html#monotonic-restrictions"><i class="fa fa-check"></i><b>15.3.2</b> Monotonic restrictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>16</b> Final Words</a><ul>
<li class="chapter" data-level="16.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>16.1</b> General lessons</a></li>
<li class="chapter" data-level="16.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>16.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="16.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>16.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="16.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>16.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="17" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>17</b> <code>gbiqq</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="wide" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Going wide and going deep</h1>
<hr />
<p>Researchers often need to choose between collecting data on a greater number of cases or collecting more data within a given set of cases. This is a choice, we might say, between going “wide” and going “deep.” We discuss the tradeoffs and communicate an intuition that clue data, even on a small number of cases, can be informative even when there is <span class="math inline">\(X, Y\)</span> data on a very large number of cases, but only if it provides information that cannot be gathered from <span class="math inline">\(X,Y\)</span> data, such as selection into treatment. Simulations suggest that going deep is especially valuable for observational research, situations with homogeneous treatment effects, and, of course, when clues have strong probative value.</p>
<hr />
<div id="motivation" class="section level2">
<h2><span class="header-section-number">12.1</span> Motivation</h2>
<p>Let us continue our journey through the space of research-design choices. Suppose, now, that we have identified those clues that will be most informative, given our beliefs about the world. A further question that we face is the quintessential dilemma of <em>mixing</em> methods: what mixture of quantitative and qualitative evidence is optimal? We have, of course, argued in in Chapter (mixing) that the distinction between quantitative and qualitative inference is, in a causal-model framework, without much of a difference. But here we are framing a more precise question: given finite resources, how should we trade off between studying a larger number of cases and drilling down to learn more about some subset of the cases in our sample? How should we decide between going “wide” and going “deep”?</p>
<p>Just as with the selection of clues and cases, how much we should expect to learn from going wide versus going deep will <em>depend</em> on how we think the world works. In this chapter, we separate out two forms that these prior beliefs might take: the structural causal model with which we start the analysis and any data that we have seen at the point of making the wide-versus-deep decision. As we will see, the expected opportunities for learning about different causal estimands depends greatly on both of these.</p>
<p>We examine here both queries commonly associated with extensive, quantitative strategies of analysis (such as average treatment effects) and queries commonly associated with more intensive, qualitative approaches (queries about causal pathways and about causal effects at the case level). The analysis in this chapter makes clear the opportunities for integration across these lines of inquiry. We show that investing in-depth process tracing will sometimes make sense even when one aims to learn about average effects in a population. Likewise, collecting <span class="math inline">\(X, Y\)</span> data can sometimes help us draw inferences that will aid in case-level explanation. Particular kinds of case-level information can teach us about populations, and understanding population-level patterns can help us get individual cases right.</p>
</div>
<div id="developing-some-intuitions" class="section level2">
<h2><span class="header-section-number">12.2</span> Developing some intuitions</h2>
<p>To build up our intuitions about how the optimal mix of strategies might depend on how the world works, let us explore a simple example. We focus here on the question of how much we can learn from drilling deeper, given an initial set of <span class="math inline">\(X,Y\)</span> data and beliefs about the world. To simplify the exposition, we revert here to using our four basic causal types from Chapter (models): <span class="math inline">\(a, b, c, and d\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<!-- e begin by considering the learning that occurs upon observing outcomes from varying numbers of cases given different $XY$ data ranging from small to quite large.  -->
<!-- The goal here is to build up intuitions on how beliefs change given different observations and how this affects posterior variance. We address the question in a very controlled setting in which  -->
<p>Suppose that:</p>
<ul>
<li>a researcher is confronted with <span class="math inline">\(X,Y\)</span> data that exhibits no correlation; observations are balanced across the 4 cells defined by possible combinations of <span class="math inline">\(X, Y\)</span> values.</li>
<li>the researcher can seek information on a highly informative (“doubly decisive”) clue, <span class="math inline">\(K\)</span>, within cases in the <span class="math inline">\(X=Y=1\)</span> cell; thus, we are imagining a scenaior in which the information we will get about the case in question is about as informative about that case as it could possibly be.</li>
<li>although not known in advance, each time the researcher collects a within-case clue, she finds evidence suggesting that the case is a <span class="math inline">\(b\)</span> type.</li>
</ul>
<p>We consider two different data-generating processes:</p>
<p>1 There may be unobserved confounding between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and we have flat priors over this confounding. Put differently, assignment propensities are unknown.</p>
<p>2 There is no confounding; <span class="math inline">\(X\)</span> can be treated as randomly assigned.</p>
<p>We consider what happens as the number of cases on which we collect <span class="math inline">\(K\)</span> increases from 0 to 5. We also consider different amounts of initial <span class="math inline">\(X,Y\)</span> data, considering situations in which we have 5, 10, 50, and 5000 observations in each <span class="math inline">\(X,Y\)</span> cell.</p>
<p>We would expect that seeking a clue in a case—which, in this simulation, always delivers evidence consistent with a positive causal effect in that case—will lead the researcher to believe there are more <span class="math inline">\(b\)</span> types and that there is thus a higher average causal effect. But how strong will these shifts be? And how does the amount of belief change depend on the amount of <span class="math inline">\(X, Y\)</span> data available and the underlying data-generating process? When does the signal from the <span class="math inline">\(X,Y\)</span> data drown out any signal from the <span class="math inline">\(K\)</span> data, and when does <span class="math inline">\(K\)</span> data add value?</p>
<p>Figure  reports answers to these questions. In the top row, we report the average causal effect that we will estimate for different combinations of <span class="math inline">\(X,Y\)</span> and <span class="math inline">\(K\)</span> data. In the bottom row, we show the reductions in uncertainty (posterior variance) that we get with each strategy. On the left, we allow for unobserved confounding, and on the right we have random assignment. Each curve represents a different sample size for which we have <span class="math inline">\(X,Y\)</span> data. The number of cases in which we go “deep,” collecting <span class="math inline">\(K\)</span> data, is represented on the horizontal axis.</p>
<ol style="list-style-type: decimal">
<li>With unobserved confounding, we see clear gains to collecting clues on a greater number of cases across the 1 to 5 range. Collecting clue information on a greater number of cases shifts our beliefs about the average causal effect and reduces our uncertainty about that quantity. Moreover, with unobserved confounding, the value of the clue information is <em>independent</em> of how many <span class="math inline">\(X,Y\)</span> cases there are.</li>
</ol>
<p>What is happening here is that the clues are providing information on assignment propensities, which are informative about the share of each type in each cell. With flat priors over assignment propensities, our beliefs are centered around equal propensities for all types (though we’re also very uncertain about this). Moreover, given equal assignment propensities, the flat data <span class="math inline">\(X,Y\)</span> pattern has us believing that there the average treatment effect is 0 (also with great uncertainty). For every additional <span class="math inline">\(X=1, Y=1\)</span> for which we observe <span class="math inline">\(K=1\)</span>, however, we shift upward our belief about the share of <span class="math inline">\(b\)</span>’s in the cell. We are, thus, now learning about assignment propensities: now it looks like <span class="math inline">\(b\)</span> types were more commonly assigned to <span class="math inline">\(X=1\)</span>, implying that <span class="math inline">\(d\)</span>’s must have been more commonly assigned to <span class="math inline">\(X=0\)</span>. Put differently, we are learning that the flat data pattern has arisen via confounding that is “suppressing” a positive treatment effect.</p>
<p>The value of the clue data, moreover, does not depend on how many <span class="math inline">\(X,Y\)</span> cases we’ve observed because no amount of <span class="math inline">\(X,Y\)</span> data can tell us about <span class="math inline">\(X\)</span>&lt;-&gt;<span class="math inline">\(Y\)</span> confounding. As we see in the bottom-left graph, we end up more certain, the more <span class="math inline">\(X, Y\)</span> data we have. But there’s just as much to be <em>gained</em> from a given amount of clue data whether we’ve started with 5 <span class="math inline">\(X,Y\)</span> cases or 5000.</p>
<ol start="2" style="list-style-type: decimal">
<li>When assignment propensities are known (and so we can treat the data as experimental), the learning from clue data depends heavily on how many <span class="math inline">\(X,Y\)</span> cases we start out with. Where we have a large amount of <span class="math inline">\(X,Y\)</span> data, clue evidence adds little to nothing to our inferences about average treatment effects. There is nothing to be learned from the clues about assignment propensities since these are already known. And, with assignment propensities known, <span class="math inline">\(X,Y\)</span> information alone are sufficient for convergence on the average treatment effect as sample size increases. Clue information shifts beliefs about the types of the particular cases for which clue data is gathered — i.e., for this case-level-estimand — but has almost no effect on estimates of the population estimand.</li>
</ol>
<p>However, we can learn about average effects from clue data when we have few <span class="math inline">\(X,Y\)</span> cases. While we can infer the average causal effect from a known <span class="math inline">\(X,Y\)</span> distribution (and known assignment propensities), we have a lot of uncertainty about that distribution when we only have a handful of <span class="math inline">\(X,Y\)</span> cases. Thus, clue data help us by uniquely providing information about the types of individual cases. It is still only from observing <span class="math inline">\(K=1\)</span> in a case that we can learn that that case is a <span class="math inline">\(b\)</span> type, allowing us to update upwardly on the relative proportions of <span class="math inline">\(b\)</span>’s and <span class="math inline">\(d\)</span>’s. With little other information on the average effect, this pushes our belief about average effects upward.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> And, in the absence of a large amount of of <span class="math inline">\(X,Y\)</span> data, knowing there is one more <span class="math inline">\(b\)</span> and one less <span class="math inline">\(d\)</span> type still benefits from learning</p>
<ol start="3" style="list-style-type: decimal">
<li>Though not visible from the figure, clue data help us learn about a different population-level estimand — the <em>distribution</em> of causal effects in the population — even when we have a large <span class="math inline">\(N\)</span> and known propensities. The same average causal effect could be consistent with a large share of <span class="math inline">\(a\)</span>’s and <span class="math inline">\(b\)</span>’s combined, with few no-effect cases, or with a small share of <span class="math inline">\(a\)</span>’s and <span class="math inline">\(b\)</span>’s combined, with many no-effect cases. In other words, we don’t actually learn from <span class="math inline">\(X,Y\)</span> data about the distribution of types, even with a large <span class="math inline">\(X,Y\)</span> sample and known propensities. But observation of clues identifying <span class="math inline">\(b\)</span> types in the <span class="math inline">\(X=Y=1\)</span> cell, while it does not change estimates of <em>average</em> treatment effects, tells us that there is greater <em>heterogeneity</em> of effects in the population. More <span class="math inline">\(b\)</span> types, holding the average effect constant, means that there must also be more <span class="math inline">\(a\)</span> types. Thus, we have learned that there are more offsetting effects playing out in the population — positive effects alongside negative effects — than we knew before we saw the clue data. In fact, we learn <em>more</em> about heterogeneity from clue data where the average causal effect is already known than where we are highly uncertain about the average effect.</li>
</ol>
<p>FLAG: Can we show the heterogenity point graphically, too? Seems odd to say it’s not visible when we could make it so.</p>
</div>
<div id="diagnosing-mixes" class="section level2">
<h2><span class="header-section-number">12.3</span> Diagnosing mixes</h2>
<p>The stylized example above is intended to help us see how our choices about depth vs. breadth can depend on the process through which we believe the data have been generated. Our more general point is that we can systematically assess different possible mixes of extensiveness and intensiveness given a causal model and any data that have already been observed.</p>
<p>The basic procedure, in <code>gbiqq</code>, is as follows.</p>
<ol style="list-style-type: decimal">
<li><strong>Define a model.</strong> Specify the causal graph (possibly with unobserved confounding), any restrictions on causal effects, and any priors over parameters. We consider five different models:</li>
</ol>
<ul>
<li>One-path model, with a single, mediated path</li>
<li>Two-path model, with a direct and an indirect path</li>
<li>Restricted model, the two-path model with monotonicity restrictions, excluding negative effects at each step</li>
<li>Observed-confound model, in which there is only a direct <span class="math inline">\(X \rightarrow Y\)</span> path and the clue is a confound</li>
<li>Unobserved-confound model, the chain model with unobserved <span class="math inline">\(X\)</span> &lt;-&gt; <span class="math inline">\(Y\)</span> confounding</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Specify the given data.</strong> We imagine starting with a certain amount of <span class="math inline">\(X,Y\)</span> data, from 32 cases, and we vary the pattern in those data.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> The given data patterns we examine are a strong positive <span class="math inline">\(X,Y\)</span> relationship; the absence of any <span class="math inline">\(X,Y\)</span> relationship; a pattern suggestive of <span class="math inline">\(X=1\)</span> being almost sufficient for <span class="math inline">\(Y=1\)</span>; and a pattern suggestive of <span class="math inline">\(X=1\)</span> being almost necessary for <span class="math inline">\(Y=1\)</span>.</p></li>
<li><p><strong>Specify wide and deep data strategies.</strong> In examples below, we assume a baseline set of <span class="math inline">\(X, Y\)</span> data that have already been observed. We pose the wide-vs.-deep question at the margins: how much do we expect to gain from collecting <span class="math inline">\(X,Y\)</span> data for a given number of additional, randomly selected cases, and how much from looking for a clue, <span class="math inline">\(M\)</span>, within a given number of cases in our sample (for which we already have <span class="math inline">\(X,Y\)</span> data)? To simplify the analysis, we assume that clue data are sought on a positive regression line, with half sought in the <span class="math inline">\(X=0, Y=0\)</span> cell and half in the <span class="math inline">\(X=1, Y=1\)</span> cell. A data strategy is defined as a combination of width and depth: adding <span class="math inline">\(X,Y\)</span> data on 0, 2, or 4 cases, and hunting for a clue within 0, 2, or 4 cases.</p></li>
<li><p><strong>Formulate queries.</strong> As our discussion in the last section already suggests, the optimal mix may depend on the causal question we are interested in answering. We assess learning about three distinct causal queries:</p></li>
</ol>
<ul>
<li>Average treatment effect</li>
<li>Probability of positive causation: the probability that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> in an <span class="math inline">\(X=Y=1\)</span> case?</li>
<li>Probability of mediated positive causation: the probability that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> through a particular mechanism — a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> and a positive effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> — in an <span class="math inline">\(X=Y=1\)</span> case.</li>
</ul>
<p>It is worth noting that the second two queries are conditioned on particular <span class="math inline">\(X,Y\)</span> values but that the data strategies we are examining in these analyses do not limit our inquiry to those values. The “wide” component of any strategy is a random draw from the population; and the “deep” componeny involves looking <em>both</em> in the <span class="math inline">\(X=Y=1\)</span> cell <em>and</em> in the <span class="math inline">\(X=Y=0\)</span> cell. Of course, it is not hard to imagine that seeing what is going on in an <span class="math inline">\(X=Y=0\)</span> case could be informative about causal relations in an <span class="math inline">\(X=Y=1\)</span> case.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Diagnose each strategy, conditional on model and given data.</strong> For each strategy, we implement a separate diagnosis under each combination of model and given data, using <code>gbiqq</code>’s <code>diagnose_strategy</code> function. For each strategy, model, and given data pattern, the function:</li>
</ol>
<ul>
<li>identifies all possible new data realizations</li>
<li>calculates the probability of each possible data realization</li>
<li>updates posterior distributions on all parameters for each possible data realization</li>
<li>calculates expected posteriors on all parameters by averaging across posteriors from all possible data-realizations, weighted by their probability of arising</li>
<li>uses the expected posteriors on parameters to generate expected posterior distributions on each of the specified queries.</li>
</ul>
<p>What we are interested in is the expected variance of the posteriors, which tells us how uncertain we expect to be about our estimate after implementing the strategy, given the model and the given data.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> A greater reduction in expected posterior variance implies greater expected learning from the strategy.</p>
<p>The results of these diagnoses are represented in Figures <strong>flag: labels here</strong>. In each figure, we consider learning about all three queries under a single model, with each row of subplots considering a different pattern of given data as the starting point. The “wide” data strategies (collecting <span class="math inline">\(X, Y\)</span> data for an additionl 0, 2, or 4 randomly selected cases) are represented by movement across the columns of subplots; the “deep” strategies (collecting a clue for 0, 2, or 4 <span class="math inline">\(X=Y\)</span> cases within the sample) are represented within each subplot. Within each subplot, we provide the expected posterior variance for a particular level of “width” and given data, providing error bars representing 95 percent of the simulation variability.</p>
<p>We summarize key features of the results, and suggest some intuitions that might explain them, for each model in turn. Whemn referring to unit types, we continue here to use our simpler <span class="math inline">\(a, b, c, d\)</span> notation to help simplfy the discussion. We should also note that the setup of these simulations is, in some sense, generically tilted against breadth in the sense that we always assume that we have collected a moderate amount of <span class="math inline">\(X, Y\)</span> data, and no data on <span class="math inline">\(M\)</span>, prior to making the choice. We are thus likely to be at a steeper point on the “yield curve” when it comes to <span class="math inline">\(M\)</span> data than for <span class="math inline">\(X, Y\)</span> data. This is, of course, mostly an idiosyncratic feature of these particular experiments, rather than a fundamental feature of optimizing across strategies. So we encourage readers to pay more attention to the differences in the relative gains to depth and breadth across models, queries, and given-data patterns rather than to the average relative differences.</p>
<div id="path-model" class="section level3">
<h3><span class="header-section-number">12.3.1</span> 1-path model</h3>
<p><strong><span class="math inline">\(ATE\)</span></strong></p>
<p>One striking feature of the simulations with a 1-path model is how difficult it is to learn about average effects from either additional depth or additional breadth. We see less learning about the <span class="math inline">\(ATE\)</span> than about other queries for all data-mixes examined here.</p>
<p>We learn the most about the <span class="math inline">\(ATE\)</span> when we start with data consistent with a strong treatment effect (regr). If we examine the tradeoffs here, we see that – if we’re going to collect more data on two cases – process tracing two cases already in the sample yields about as much expected gain as expanding the sample by two cases on which we collect only <span class="math inline">\(X, Y\)</span> data. There are hints that the tradeoff shifts slightly as we move to the right: process tracing 4 cases may be marginally better than expanding the <span class="math inline">\(X,Y\)</span> sample by 4 cases. Likewise, a mix of 4-deep and 2-wide looks slightly better than the reverse (4 wide and 2 deep). For both comparisons, however, the apparent difference are well within the simulation error bars. We do not see clear evidence here of gains from mixing <em>per se</em> – i.e., that we learn more about the ATE from mixing forms of data than from concentrating our efforts on either depth or breadth.</p>
<p>The potential for learning weakens as the given data pattern weakens. The opportunity to learn, from either greater extensive or greater intensive data-collection, is weaker for given data suggestive of necessity or sufficiency (which are, essentially, both moderately strong positive correlations) and essentially disappears when we start with completely flat data. This effect is likely driven by the level of uncertainty that the model plus the given data leave us with. At the extreme, flat priors on the original model plus flat data together make us quite certain that the <span class="math inline">\(ATE\)</span> is 0; this very low uncertainty is evident from the position of the ATE line in the row of graphs for flat given data. This leaves very little expected scope for additional learning.</p>
<p>Suppose, for instance, that we were to collect clue data on two <span class="math inline">\(X=Y=1\)</span> cases that yielded evidence that these cases were likely <span class="math inline">\(b\)</span> types. We would now update our beliefs toward thinking that there are more <span class="math inline">\(b\)</span>’s than <span class="math inline">\(d\)</span>’s in the <span class="math inline">\(X=Y=1\)</span> cell. However, given our high level of certainty that the <span class="math inline">\(ATE=0\)</span>, we would then also upwardly update our beliefs about the share of <span class="math inline">\(a\)</span> types, preserving our original <span class="math inline">\(ATE\)</span> estimate. In principle, observing new <span class="math inline">\(X,Y\)</span> data that deviated from a flat pattern could shift our beliefs about the ATE. But, given current beliefs, we strongly expect <em>not</em> to observe such a data pattern, and so this hypothetical outcome has little effect on the learning we expect to reap from collecting more data.</p>
<p>On the other hand, when we start with flat priors and then observe a strong positive correlation in the given data (regr), such that the priors and given data pull in opposite directions, we bring a more dispersed posterior distribution to the design problem. This greater uncertainty allows the new data to move our beliefs much more.</p>
<p><strong>ProbPos</strong></p>
<p>When it comes to estimating the probability of causation – is there a positive causal effect in an <span class="math inline">\(X=Y=1\)</span> case? – the tradeoffs shift somewhat. Starting with given data falling along a positive regression line, the gains to going wide appear about the same for the probability of causation as they do for estimating the <span class="math inline">\(ATE\)</span>. However, depth has a distinct advantage in estimating the probability of causation that it did not have for the <span class="math inline">\(ATE\)</span>: the gains to process tracing 2 (or 4) cases are much greater than the gains to collecting <span class="math inline">\(X,Y\)</span> data on an additional 2 (or 4) cases. In fact, we expect to be better off going deep into 2 cases than expanding the sample by 4 cases.</p>
<p>Why might depth be of greater value in assessing the probability of causation than in estimating the <span class="math inline">\(ATE\)</span>? The reason is likely that process tracing helps us estimate the share of types in a manner more directly related to the probability of causation than to the <span class="math inline">\(ATE\)</span>. When we conduct process tracing on an <span class="math inline">\(X=Y\)</span> case, we are learning about the probability that that case is a <span class="math inline">\(b\)</span> type, rather than an <span class="math inline">\(c\)</span> (for <span class="math inline">\(X=Y=0\)</span> cases) or a <span class="math inline">\(d\)</span> (for <span class="math inline">\(X=Y=1\)</span> cases). Whether we are in the <span class="math inline">\(X=Y=0\)</span> cell or the <span class="math inline">\(X=Y=1\)</span> cell, we can then update our beliefs about the share of cases in the <span class="math inline">\(X=Y=1\)</span> that are <span class="math inline">\(b\)</span>’s.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> This is exactly the quantity of interest for the probability of causation question: if I see an <span class="math inline">\(X=Y=1\)</span> case, what are the chances <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> (is it a <span class="math inline">\(b\)</span>?)?</p>
<p>On the other hand, updating on the share of <span class="math inline">\(b\)</span>’s versus <span class="math inline">\(c\)</span>’s and <span class="math inline">\(d\)</span>’s gives us only indirect leverage on the <span class="math inline">\(ATE\)</span> (the share of <span class="math inline">\(b\)</span>’s minus the share in <span class="math inline">\(a\)</span>’s) since it contains no direct information about the share of <span class="math inline">\(a\)</span>’s. If we observe evidence of an additional handful of <span class="math inline">\(b\)</span> cases, any upward shift in our beliefs about the <span class="math inline">\(ATE\)</span> will be constrained by our prior beliefs (given the existing data) about the <span class="math inline">\(ATE\)</span>. Our updating will be some combination of upward movement in the <span class="math inline">\(ATE\)</span> estimate and upward movement in our estimate of the share of <span class="math inline">\(a\)</span>’s (which moderates the change in the <span class="math inline">\(ATE\)</span> estimate).</p>
<p>We also see here hints of substitution effects between depth and breadth. As the amount of process-tracing data increases, it appears that the gains to adding <span class="math inline">\(X,Y\)</span> data diminishes.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p>As for the <span class="math inline">\(ATE\)</span>, flatter prior data in combination with our initial flat priors also limits learning about the probability of causation, for all kinds of data. We do, however, continue to see an advantage of depth over breadth, regardless of the given data pattern. And we expect slightly more learning from additional data given a “necessity” pattern in the prior data than given a “sufficiency” pattern. This is probably because, given the necessity pattern, we start out with a higher estimate of the probability of causation and more uncertainty.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<p><strong>Via_M</strong></p>
<p>What if we want to learn about the probability that, in an <span class="math inline">\(X=Y=1\)</span> case, <span class="math inline">\(X\)</span> had a positive effect on <span class="math inline">\(Y\)</span> through a chain of positive effects running through <span class="math inline">\(M\)</span>? Of course, in this model, if there <em>is</em> an effect in an <span class="math inline">\(X=Y=1\)</span> case, it has to be positive and it has to run through <span class="math inline">\(M\)</span>. So the query reduces here to asking about (a) the probability that there is an effect in an <span class="math inline">\(X=Y=1\)</span> case and (b) the probability that it runs through linked positive effects as opposed to linked negative effects. What can we expect to learn about these questions from going wide as compared to going deep?</p>
<p>If we start with a strong regression pattern, we can expect to reap very large gains from drilling deeper within the current sample, far greater than from expanding the <span class="math inline">\(X,Y\)</span> dataset. The reason is straightforward: while <span class="math inline">\(X,Y\)</span> data alone can speak to one part of the query – the probability of an effect – they are completely silent on the other part – whether the effect operates through linked positive or linked negative effects. Meanwhile, data on <span class="math inline">\(M\)</span> can speak to <em>both</em> parts of the query, informing us about both the causal effect within a case <em>and</em> the mechanism through which it operates.</p>
<p>The gains to increased breadth, on its own, are considerable though they decline rapidly as we obtain clue data. We also see steeply diminishing returns to clue data itself. The sharp reduction in marginal gains on both counts is likely a consequence of our ignorance at the outset. We are starting with given data that provide no information on a key part of the query, allowing for massive early gains to seeing small amounts of relevant data but also steeply diminishing returns. This is a very different situation from the one we are in with the <span class="math inline">\(ATE\)</span> and probability of causation queries, where we have already learned a great deal from the given data.</p>
<p>As the pattern in the given data weakens – becoming less and less consistent with a strong effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> – we again learn less from new data. Interestingly, we still do learn from new data even when flat given data have made us quite certain that there is no average effect. We do not expect to learn here from going wide since <span class="math inline">\(X,Y\)</span> data can only inform us about the overall effect, and we have seen already that (with flat given data) we expect to learn very little from new data about that effect. However, process tracing can still provide unique insight into the pathway through which positive effects in the sample take place. Still, the learning from depth is much more modest here than it is given a strong regression pattern. This is likely because, given flat data, we are much less confident that a given <span class="math inline">\(X=Y\)</span> case <em>has</em> a positive effect.</p>
<p><strong>2-path mode</strong></p>
<p>Big takeaway: it’s very hard to learn from clues with a 2-path model with flat priors. Whatever you learn about the mediated path doesn’t tell you anything about the direct path.</p>
<p><em>ATE</em></p>
<p>Regr: W is about as valuable here as it is for 1-path model. D is useless.</p>
<p>As with 1-path model, much less little learning about ATE from W given necs, suff, or flat data (in order of diminishing learning opportunities). D still useless.</p>
<p><em>ProbPos</em></p>
<p>Regr: Very similar to 1-path model: Learning from W is similar to, though a bit less than, for ATE. No learning from D.</p>
<p>No detectable learning from W or D from other data patterns (because of weaker X,Y patterns).</p>
<p><em>Via_M</em></p>
<p>Most surprising results are here: in contrast to 1-path model, the learning about pathway is almost undetectable here, from D or from W. Why??? Suppose you see a set of M=1’s in X=Y=1 cases. Isn’t that evidence for X having a positive effect on M, M having a positive effect on Y, and X having a positive effect on Y that depends on this chain of effects? As compared to seeing a mix of M=0’s and M=1’s or a bunch of M=0’s? Seems like there should definitely still be learning from D here.</p>
<p><strong>2-path restricted model</strong></p>
<p><em>ATE</em></p>
<p>D is no more helpful here because you’ve still got the other path that M doesn’t tell you anything about.</p>
<p>Learning from clues is hard because you don’t have any prior on whether M=0 or M=1 is more consistent with a b type. Could be linked positive effects or linked negative effects. However, when you see, say, a pattern of multiple M=1’s in X=1, Y=1 cases, which cannot be a types, this shifts you toward the joint beliefs that b types operate via linked <em>positive</em> effects and that there are more b types in this cell.</p>
<p>Full set of analyses</p>
<p>Graph full set</p>
<p>How does this approach guide researchers in making choices about research designs?</p>
<p>We address this question with a focus on characterizing the kind of learning that emerges from gathering different sorts of data—such , <em>under different research conditions</em>. We report the results here of simulation-based experiments designed to tell us under what research conditions different mixes of methods can be expected to yield more accurate inferences. We also discuss, at a high level, the implications of the framework for strategies of qualitative case-selection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- K&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_restrictions</span>(<span class="st">&quot;(Y[X=0, K=1]==1) | (Y[X=0, K=0]==0)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(<span class="fl">0.01</span>, .<span class="dv">99</span>, .<span class="dv">5</span>, .<span class="dv">5</span>, .<span class="dv">25</span>, .<span class="dv">25</span>, .<span class="dv">25</span>, .<span class="dv">25</span>))</code></pre></div>
<p>We see that prior beliefs are for a 0 average effect which rises to approximately .5 for cases in which <span class="math inline">\(K=1\)</span> is observed and falls to -.5 for cases in which <span class="math inline">\(K=0\)</span> is observed.</p>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">-0.004</td>
<td align="right">0.338</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.496</td>
<td align="right">0.223</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.499</td>
<td align="right">0.226</td>
</tr>
</tbody>
</table>
<p>We see little difference in the prior on estimands. Despite this an important difference is that the model that allows for confounding also allows for updating on confounding, which the simple model does not.</p>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">-</td>
<td align="left">priors</td>
<td align="right">-0.001</td>
<td align="right">0.345</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.504</td>
<td align="right">0.221</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.504</td>
<td align="right">0.221</td>
</tr>
</tbody>
</table>
<p>We now examine inferences given different data strategies:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span>(do_diagnosis){
  wd_1_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">wide_or_deep</span>(model, <span class="dv">1</span>, <span class="dv">2</span>)
  <span class="kw">write_rds</span>( wd_1_<span class="dv">2</span>, <span class="st">&quot;saved/wd_1_2.rds&quot;</span>)
}

wd_1_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wd_1_2.rds&quot;</span>)


wd_sim &lt;-<span class="st"> </span><span class="cf">function</span>(model, n_K, n_fold) {
  
    df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">X =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">Y =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">K =</span> <span class="ot">NA</span>) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">slice</span>(<span class="kw">rep</span>(<span class="kw">row_number</span>(), n_fold))
    df &lt;-<span class="st"> </span><span class="kw">mutate</span>(df, <span class="dt">K =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_K), <span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">n</span>()<span class="op">-</span>n_K)))
    
    given &lt;-<span class="st">  </span><span class="kw">collapse_data</span>(df, model)

    updated &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">gbiqq</span>(model, <span class="dt">data =</span> df, <span class="dt">stan_model =</span> fit)
    <span class="kw">query_model</span>(updated, 
                  <span class="dt">queries =</span> <span class="kw">list</span>(<span class="dt">ATE =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span>), 
                  <span class="dt">using =</span> <span class="st">&quot;posteriors&quot;</span>)
  
}

<span class="cf">if</span>(do_diagnosis){
  <span class="cf">if</span>(<span class="op">!</span><span class="kw">exists</span>(<span class="st">&quot;fit&quot;</span>)) fit &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">fitted_model</span>()
  out &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">8</span>), <span class="cf">function</span>(n_K) {<span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">20</span>), <span class="cf">function</span>(k) <span class="kw">wd_sim</span>(model, n_K, k))})
  <span class="kw">write_rds</span>(out, <span class="st">&quot;saved/wide_or_deep_XMY.rds&quot;</span>)
  }

wd &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wide_or_deep_XMY.rds&quot;</span>)
wd &lt;-<span class="st"> </span><span class="kw">t</span>(wd[<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">9</span>,<span class="dv">14</span>), ])
<span class="kw">rownames</span>(wd) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Clues on 4 cases&quot;</span>, <span class="st">&quot;Clues on 8 cases&quot;</span>)
<span class="kw">colnames</span>(wd) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;N=8&quot;</span>, <span class="st">&quot;N=40&quot;</span>, <span class="st">&quot;N=80&quot;</span>)
<span class="kw">kable</span>((wd))

<span class="cf">if</span>(do_diagnosis){
  <span class="cf">if</span>(<span class="op">!</span><span class="kw">exists</span>(<span class="st">&quot;fit&quot;</span>)) fit &lt;-<span class="st"> </span>gbiqq<span class="op">::</span><span class="kw">fitted_model</span>()
  out &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">8</span>), <span class="cf">function</span>(n_K) {<span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">20</span>), <span class="cf">function</span>(k) <span class="kw">wd_sim</span>(model_confound, n_K, k))})
  <span class="kw">write_rds</span>(out, <span class="st">&quot;saved/wide_or_deep_XMY2.rds&quot;</span>)
  }

wd2 &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="st">&quot;saved/wide_or_deep_XMY2.rds&quot;</span>)
wd2 &lt;-<span class="st"> </span><span class="kw">t</span>(wd2[<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">9</span>,<span class="dv">14</span>), ])
<span class="kw">rownames</span>(wd2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Clues on 4 cases&quot;</span>, <span class="st">&quot;Clues on 8 cases&quot;</span>)
<span class="kw">colnames</span>(wd2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;N=8&quot;</span>, <span class="st">&quot;N=40&quot;</span>, <span class="st">&quot;N=80&quot;</span>)
<span class="kw">kable</span>((wd2))</code></pre></div>
</div>
</div>
<div id="evaluating-strategies" class="section level2">
<h2><span class="header-section-number">12.4</span> Evaluating strategies</h2>
<p>As a metric of the returns from different research strategies we calculate the <em>expected</em> inaccuracy in the estimation of the average treatment effect, as given by:</p>
<p><span class="math display">\[\mathcal{L}=\mathbb{E}_\theta(\mathbb{E}_{\mathcal{D}|\theta}(\tau(\theta)-\hat{\tau}(\mathcal{D}))^2) \]</span></p>
<p>where <span class="math inline">\(\tau(\theta)\)</span> is the value of <span class="math inline">\(\lambda_b-\lambda_a\)</span> (the average treatment effect) given <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\hat{\tau}(\mathcal{D})\)</span> is the <em>estimate</em> of this treatment effect (the mean posterior value) that is generated following some realization of data <span class="math inline">\(\mathcal{D}\)</span>. Thus, if some <span class="math inline">\(\theta\)</span> characterized the true state of the world, then <span class="math inline">\(\mathbb{E}_{\mathcal{D}|\theta}(\tau^\theta-\hat{\tau})^2\)</span> is the expected error in estimation of the causal effect given different realizations of the data, <span class="math inline">\(\mathcal{D}\)</span>, that could obtain in this state of the world. <span class="math inline">\(\mathcal{L}\)</span> is then the expected value of these errors given prior beliefs over possible values of <span class="math inline">\(\theta\)</span>.</p>
<p>Note that, while we focus on errors on estimated average causal effects, similar exercises could assess how cross- and within-case observations distinctively contribute to other estimands | including the causal explanations for individual cases and the validity of causal theories | as well as to learning about inferential assumptions themselves (assignment and clue probabilities). For all simulations, prior distributions are drawn with parameters as described in the Supplementary Materials (, Table <a href="#tab:sims"><strong>??</strong></a>). Priors on the type distribution are drawn from a Dirichlet distribution; priors for each of the <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\phi\)</span> values are drawn independently from Beta distributions. We note that, while by construction priors on each parameter are independent, this will not generally be the case for posterior distributions. In most cases we simulate the prior distribution using 5200 draws of each parameter. For most experiments we then systematically vary the prior distribution for one parameter of the research situation between two extreme positions. We then calculate the expected posterior from each possible data realization and, in turn, the expected loss in estimates of treatment effects for a range of levels of investment in qualitative and quantitative evidence.</p>
<p>A few further features of the experiments below are worth noting. First, our illustrations focus on learning about population-level causal effects; however, the model can yield results about the benefits of alternative research designs for estimating a wide range of other quantities of interest, such as case-specific causal explanations or clue probabilities. Second, while we focus on the search for a <em>single</em> clue in each case, the analysis can be extended to the case of an arbitrarily large set of clues. Third, in many of these experiments, the probative values are set at doubly decisive levels for all <span class="math inline">\(\phi\)</span> parameters, and thus focus on the very optimistic case of maximally informative process tracing. Fourth, we illustrate tradeoffs at low levels of <span class="math inline">\(n\)</span>, but the model can be employed to make choices for arbitrarily large numbers of cases. Finally, we note that some results may be sensitive to the choice of priors. The results below should thus be understood as an illustration of the utility of the BIQQ framework for guiding research choices, rather than as a set of more general prescriptive design rules.</p>
</div>
<div id="varieties" class="section level2">
<h2><span class="header-section-number">12.5</span> Varieties of mixing</h2>
<p>What are the marginal gains from additional pieces of correlational and process-tracing evidence for the accuracy of causal estimates? Figure  displays results, plotting the errors associated with different mixes of correlational and process data.</p>
<ul>
<li><strong>Qualitative and quantitative data can act as partial substitutes for assessing causal effects</strong>.</li>
<li><strong>The <em>relative</em> marginal gains from going wider and going deeper vary with the study design</strong>.</li>
<li><strong>Optimal strategies might involve going deep in a subsample of cases only.</strong></li>
</ul>

<table>
<thead>
<tr class="header">
<th>strategy Query Su</th>
<th>bset esti</th>
<th>mand e</th>
<th>stimates</th>
<th align="right">MSE p</th>
<th align="left">ost_var</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>estimands_database</td>
<td>Prior</td>
<td>Q 1</td>
<td>All</td>
<td align="right">0.135</td>
<td align="left">0.134</td>
<td>0.024</td>
<td>0.017</td>
</tr>
<tr class="even">
<td>estimands_database1</td>
<td>A_online</td>
<td>Q 1</td>
<td>All</td>
<td align="right">0.135</td>
<td align="left">0.141</td>
<td>0.018</td>
<td>0.016</td>
</tr>
<tr class="odd">
<td>estimands_database2</td>
<td>B_offline</td>
<td>Q 1</td>
<td>All</td>
<td align="right">0.135</td>
<td align="left">0.136</td>
<td>0.024</td>
<td>0.017</td>
</tr>
<tr class="even">
<td>estimands_database3</td>
<td>C_X1Y1</td>
<td>Q 1</td>
<td>All</td>
<td align="right">0.135</td>
<td align="left">0.136</td>
<td>0.020</td>
<td>0.016</td>
</tr>
<tr class="odd">
<td>estimands_database4</td>
<td>D_random</td>
<td>Q 1</td>
<td>All</td>
<td align="right">0.135</td>
<td align="left">0.138</td>
<td>0.020</td>
<td>0.016</td>
</tr>
</tbody>
</table>
</div>
<div id="probative-value-of-clues" class="section level2">
<h2><span class="header-section-number">12.6</span> Probative value of clues</h2>
</div>
<div id="effect-heterogeneity" class="section level2">
<h2><span class="header-section-number">12.7</span> Effect Heterogeneity</h2>
</div>
<div id="uncertainty-regarding-assignment-processes" class="section level2">
<h2><span class="header-section-number">12.8</span> Uncertainty Regarding Assignment Processes</h2>
</div>
<div id="uncertainty-regarding-the-probative-value-of-clues" class="section level2">
<h2><span class="header-section-number">12.9</span> Uncertainty regarding the probative value of clues</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For this illustration, we just need to keep track of <span class="math inline">\(b\)</span> (positive effect), <span class="math inline">\(a\)</span> (negative effect), and <span class="math inline">\(d\)</span> (no effect, <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>).<a href="wide.html#fnref1">↩</a></p></li>
<li id="fn2"><p>We also, by implication, update upwardly on the share of <span class="math inline">\(a\)</span>’s relative to <span class="math inline">\(d\)</span>’s in the <span class="math inline">\(X=0, Y=1\)</span> cell; but the direct learning about the <span class="math inline">\(X=1, Y=1\)</span> cell will be sharper than the indirect learning about the <span class="math inline">\(a\)</span>’s, generating a net increase in the estimated average causal effect.<a href="wide.html#fnref2">↩</a></p></li>
<li id="fn3"><p>We need to start with some given data to imagine strategies that involve going “deep” without going “wide”; that is we have to already have some cases within which additional data can be collected.<a href="wide.html#fnref3">↩</a></p></li>
<li id="fn4"><p>While we also might expect the posterior mean to change depending on what data-realization we encounter, the <em>expected</em> posterior will be equal to the prior mean since any beliefs about what we are most likely to find are already reflected in the prior.<a href="wide.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Since the model assumes exogenous assignment of <span class="math inline">\(X\)</span>, the updating for the two cells will in fact be identical.<a href="wide.html#fnref5">↩</a></p></li>
<li id="fn6"><p>This does not seem to simply be a function of generic diminishing returns to data as the gains appear linear within a given type of data.<a href="wide.html#fnref6">↩</a></p></li>
<li id="fn7"><p>The necessity pattern has fewer <span class="math inline">\(X=0, Y=1\)</span> cases than does the sufficiency pattern, implying a lower likelihood that an <span class="math inline">\(X=Y=1\)</span> case <em>would</em> still have <span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X\)</span> were 0.<a href="wide.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clue.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="caseselection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
