<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Going wide and going deep | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Going wide and going deep | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Going wide and going deep | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clue-selection-as-a-decision-problem.html">
<link rel="next" href="caseselection.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Integrands</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-centrality-of-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Centrality of Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.1</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.2</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.2</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#features-of-causal-models"><i class="fa fa-check"></i><b>2.2.1</b> Features of causal models</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.3</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#causal-models-from-the-literature"><i class="fa fa-check"></i><b>2.3</b> Causal models from the literature</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#pierson-on-dismantling-the-welfare-state"><i class="fa fa-check"></i><b>2.3.1</b> Pierson on dismantling the welfare state</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4</b> Steps for constructing causal models</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#abstract-procedure"><i class="fa fa-check"></i><b>2.4.1</b> Abstract procedure</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#inequalitytheory"><i class="fa fa-check"></i><b>3.1</b> Two theories of inequality’s effects on democratization</a><ul>
<li class="chapter" data-level="3.1.1" data-path="theory.html"><a href="theory.html#theory-as-causal-functions"><i class="fa fa-check"></i><b>3.1.1</b> Theory as causal functions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.2</b> Theory as a “lower-level” model</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#disggregating-nodes"><i class="fa fa-check"></i><b>3.2.1</b> Disggregating nodes</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#generalizing-a-model"><i class="fa fa-check"></i><b>3.2.2</b> Generalizing a model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#mappings-are-not-one-to-one"><i class="fa fa-check"></i><b>3.3.1</b> Mappings are not one-to-one</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#permissible-moves-across-levels"><i class="fa fa-check"></i><b>3.3.2</b> Permissible moves across levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#beneath-the-graph-causal-types-in-lower-level-models"><i class="fa fa-check"></i><b>3.4</b> Beneath the Graph: Causal Types in Lower-Level Models</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#medtheory"><i class="fa fa-check"></i><b>3.4.1</b> Mediation as Theory</a></li>
<li class="chapter" data-level="3.4.2" data-path="theory.html"><a href="theory.html#modtheory"><i class="fa fa-check"></i><b>3.4.2</b> Moderation as Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
<li class="chapter" data-level="3.6" data-path="theory.html"><a href="theory.html#appendix-illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.6</b> Appendix: Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#causal-queries"><i class="fa fa-check"></i><b>4.1</b> Causal queries</a><ul>
<li class="chapter" data-level="4.1.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.1.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.1.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.1.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.1.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.1.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.1.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.1.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.1.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#illustration-with-the-running-example"><i class="fa fa-check"></i><b>4.2</b> Illustration with the Running Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> Bayes’ Rule for Continuous Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-correlational-inference"><i class="fa fa-check"></i><b>5.2.2</b> Bayesian correlational inference</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.3</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneoues-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneoues, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="clues.html"><a href="clues.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="clues.html"><a href="clues.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="clues.html"><a href="clues.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="clues.html"><a href="clues.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="clues.html"><a href="clues.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="clues.html"><a href="clues.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clues.html"><a href="clues.html#conditional-independence-alone-does-not-provide-probative-value"><i class="fa fa-check"></i><b>6.2.1</b> Conditional independence alone does not provide probative value</a></li>
<li class="chapter" data-level="6.2.2" data-path="clues.html"><a href="clues.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.2</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.3" data-path="clues.html"><a href="clues.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.3</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.4" data-path="clues.html"><a href="clues.html#probative-value"><i class="fa fa-check"></i><b>6.2.4</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a><ul>
<li class="chapter" data-level="7.3.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.3.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.3.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.3.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.4</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.5" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.5</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#the-parameter-matrix"><i class="fa fa-check"></i><b>8.2.1</b> The parameter matrix</a></li>
<li class="chapter" data-level="8.2.2" data-path="mixing.html"><a href="mixing.html#the-ambiguity-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The ambiguity matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="mixing.html"><a href="mixing.html#likelihood"><i class="fa fa-check"></i><b>8.2.3</b> Likelihood</a></li>
<li class="chapter" data-level="8.2.4" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.4</b> Estimation</a></li>
<li class="chapter" data-level="8.2.5" data-path="mixing.html"><a href="mixing.html#mixed-data"><i class="fa fa-check"></i><b>8.2.5</b> Mixed data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.5</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="10" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>10</b> Elements of Design</a><ul>
<li class="chapter" data-level="10.1" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-process-tracing-design"><i class="fa fa-check"></i><b>10.1</b> Declaring a process tracing design</a><ul>
<li class="chapter" data-level="10.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#steps"><i class="fa fa-check"></i><b>10.1.1</b> Steps</a></li>
<li class="chapter" data-level="10.1.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-in-code"><i class="fa fa-check"></i><b>10.1.2</b> Illustration in code</a></li>
<li class="chapter" data-level="10.1.3" data-path="elements-of-design.html"><a href="elements-of-design.html#diagnosands-evaluating-a-model"><i class="fa fa-check"></i><b>10.1.3</b> Diagnosands: Evaluating a model</a></li>
<li class="chapter" data-level="10.1.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-measures-of-a-gain-from-a-theory"><i class="fa fa-check"></i><b>10.1.4</b> Other measures of a gain from a theory</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-mixed-methods-design"><i class="fa fa-check"></i><b>10.2</b> Declaring a mixed methods design</a><ul>
<li class="chapter" data-level="10.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model"><i class="fa fa-check"></i><b>10.2.1</b> Model</a></li>
<li class="chapter" data-level="10.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#data-strategies"><i class="fa fa-check"></i><b>10.2.2</b> Data strategies</a></li>
<li class="chapter" data-level="10.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#estimands"><i class="fa fa-check"></i><b>10.2.3</b> Estimands</a></li>
<li class="chapter" data-level="10.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#answer-strategies"><i class="fa fa-check"></i><b>10.2.4</b> Answer Strategies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html"><i class="fa fa-check"></i><b>11</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="11.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#a-strategic-approach"><i class="fa fa-check"></i><b>11.1</b> A strategic approach</a></li>
<li class="chapter" data-level="11.2" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-running-example"><i class="fa fa-check"></i><b>11.2</b> Clue selection for the running example</a><ul>
<li class="chapter" data-level="11.2.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#dynamic-strategies"><i class="fa fa-check"></i><b>11.2.1</b> Dynamic Strategies</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-democracy-model"><i class="fa fa-check"></i><b>11.3</b> Clue selection for the Democracy model</a></li>
<li class="chapter" data-level="11.4" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#conclusion-2"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>12</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="12.1" data-path="wide.html"><a href="wide.html#intuitions-does-a-sufficiently-large-n-always-trump-k"><i class="fa fa-check"></i><b>12.1</b> Intuitions: Does a sufficiently large <span class="math inline">\(N\)</span> always trump <span class="math inline">\(K\)</span>?</a></li>
<li class="chapter" data-level="12.2" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>12.2</b> Evaluating strategies</a></li>
<li class="chapter" data-level="12.3" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>12.3</b> Varieties of mixing</a></li>
<li class="chapter" data-level="12.4" data-path="wide.html"><a href="wide.html#AppSimNotes"><i class="fa fa-check"></i><b>12.4</b> Notes on Simulations</a><ul>
<li class="chapter" data-level="12.4.1" data-path="wide.html"><a href="wide.html#AppE1"><i class="fa fa-check"></i><b>12.4.1</b> Probative values</a></li>
<li class="chapter" data-level="12.4.2" data-path="wide.html"><a href="wide.html#AppE2"><i class="fa fa-check"></i><b>12.4.2</b> Effect heterogeneity</a></li>
<li class="chapter" data-level="12.4.3" data-path="wide.html"><a href="wide.html#AppE3"><i class="fa fa-check"></i><b>12.4.3</b> Uncertainty about assignment processes</a></li>
<li class="chapter" data-level="12.4.4" data-path="wide.html"><a href="wide.html#AppE4"><i class="fa fa-check"></i><b>12.4.4</b> Uncertainty regarding the probative value of clues</a></li>
<li class="chapter" data-level="12.4.5" data-path="wide.html"><a href="wide.html#details-on-simulation-experiments"><i class="fa fa-check"></i><b>12.4.5</b> Details on simulation experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>13.1</b> Explorations</a><ul>
<li class="chapter" data-level="13.1.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>13.1.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#in-code"><i class="fa fa-check"></i><b>13.2</b> In code</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#compare-multiple-data-strategies"><i class="fa fa-check"></i><b>13.3</b> Compare multiple data strategies</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#experiments"><i class="fa fa-check"></i><b>13.4</b> Experiments</a></li>
<li class="chapter" data-level="13.5" data-path="caseselection.html"><a href="caseselection.html#chapter-appendix-accounting-for-case-selection"><i class="fa fa-check"></i><b>13.5</b> Chapter Appendix: Accounting for case selection</a><ul>
<li class="chapter" data-level="13.5.1" data-path="caseselection.html"><a href="caseselection.html#independent-case-selection-strategy"><i class="fa fa-check"></i><b>13.5.1</b> Independent case selection strategy</a></li>
<li class="chapter" data-level="13.5.2" data-path="caseselection.html"><a href="caseselection.html#conditional-random-case-selection"><i class="fa fa-check"></i><b>13.5.2</b> Conditional random case selection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="14" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html"><i class="fa fa-check"></i><b>14</b> Where does probative value come from?</a><ul>
<li class="chapter" data-level="14.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#causal-discovery"><i class="fa fa-check"></i><b>14.1</b> Causal discovery</a></li>
<li class="chapter" data-level="14.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#the-possibility-of-identification-of-probative-value-from-experimental-data"><i class="fa fa-check"></i><b>14.2</b> The possibility of identification of probative value from experimental data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#moderator"><i class="fa fa-check"></i><b>14.2.1</b> Moderator</a></li>
<li class="chapter" data-level="14.2.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#mediator"><i class="fa fa-check"></i><b>14.2.2</b> Mediator</a></li>
<li class="chapter" data-level="14.2.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#generally-not-so-easy"><i class="fa fa-check"></i><b>14.2.3</b> Generally not so easy</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#bounds-on-causes-of-effects"><i class="fa fa-check"></i><b>14.3</b> Bounds on causes of effects</a></li>
<li class="chapter" data-level="14.4" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#qualitative-beliefs-and-sensitivity-analyses"><i class="fa fa-check"></i><b>14.4</b> Qualitative beliefs and Sensitivity Analyses</a></li>
<li class="chapter" data-level="14.5" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#conditional-claims"><i class="fa fa-check"></i><b>14.5</b> Conditional claims</a></li>
<li class="chapter" data-level="14.6" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-about-parameters-within-a-model"><i class="fa fa-check"></i><b>14.6</b> Learning about parameters within a model</a></li>
<li class="chapter" data-level="14.7" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-from-observational-and-experimental-mixtures"><i class="fa fa-check"></i><b>14.7</b> Learning from observational and experimental mixtures</a></li>
<li class="chapter" data-level="14.8" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-across-populations"><i class="fa fa-check"></i><b>14.8</b> Learning across populations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>15</b> Robustness and Model-Evaluation</a><ul>
<li class="chapter" data-level="15.1" data-path="evaluation.html"><a href="evaluation.html#tools-for-evaluating-models"><i class="fa fa-check"></i><b>15.1</b> Tools for evaluating models</a></li>
<li class="chapter" data-level="15.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>15.2</b> Evaluating the Democracy-Inequality model</a></li>
<li class="chapter" data-level="15.3" data-path="evaluation.html"><a href="evaluation.html#prior-check"><i class="fa fa-check"></i><b>15.3</b> Prior check</a></li>
<li class="chapter" data-level="15.4" data-path="evaluation.html"><a href="evaluation.html#monotonic-restrictions"><i class="fa fa-check"></i><b>15.4</b> Monotonic restrictions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>16</b> Final Words</a><ul>
<li class="chapter" data-level="16.1" data-path="final-words.html"><a href="final-words.html#some-conclusions"><i class="fa fa-check"></i><b>16.1</b> Some conclusions</a></li>
<li class="chapter" data-level="16.2" data-path="final-words.html"><a href="final-words.html#words-of-warning"><i class="fa fa-check"></i><b>16.2</b> Words of warning</a></li>
<li class="chapter" data-level="16.3" data-path="final-words.html"><a href="final-words.html#general-and-specific-knowledge"><i class="fa fa-check"></i><b>16.3</b> General and specific knowledge</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="17" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>17</b> Analysis of canonical models with <code>gbiqq</code></a><ul>
<li class="chapter" data-level="17.1" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-no-confounding"><i class="fa fa-check"></i><b>17.1</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, no confounding</a></li>
<li class="chapter" data-level="17.2" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-unmodelled-confounding"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with unmodelled confounding</a></li>
<li class="chapter" data-level="17.3" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-confounding-modelled"><i class="fa fa-check"></i><b>17.3</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with confounding modelled</a></li>
<li class="chapter" data-level="17.4" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-mediation-model"><i class="fa fa-check"></i><b>17.4</b> Simple mediation model</a></li>
<li class="chapter" data-level="17.5" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-moderator-model"><i class="fa fa-check"></i><b>17.5</b> Simple moderator model</a></li>
<li class="chapter" data-level="17.6" data-path="examplesappendix.html"><a href="examplesappendix.html#an-iv-model"><i class="fa fa-check"></i><b>17.6</b> An IV model</a></li>
<li class="chapter" data-level="17.7" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-that-allows-application-of-the-frontdoor-criterion"><i class="fa fa-check"></i><b>17.7</b> A model that allows application of the frontdoor criterion</a></li>
<li class="chapter" data-level="17.8" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-with-a-violation-of-sequential-ignorability"><i class="fa fa-check"></i><b>17.8</b> A model with a violation of sequential ignorability</a></li>
<li class="chapter" data-level="17.9" data-path="examplesappendix.html"><a href="examplesappendix.html#learning-from-a-collider"><i class="fa fa-check"></i><b>17.9</b> Learning from a collider</a></li>
<li class="chapter" data-level="17.10" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-mixing-observational-and-experimental-data"><i class="fa fa-check"></i><b>17.10</b> A model mixing observational and experimental data</a></li>
<li class="chapter" data-level="17.11" data-path="examplesappendix.html"><a href="examplesappendix.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>17.11</b> Transportation of findings across contexts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="wide" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Going wide and going deep</h1>
<hr />
<p>Researchers often need to choose between collecting data on more cases or collecting more data within cases. We discuss the tradeoffs and communicate an intuition that clue data, even on a small number of cases, can be informative even when there is <span class="math inline">\(X, Y\)</span> data on a very large number of cases, but only if it provides information that cannot be gathered from <span class="math inline">\(X,Y\)</span> data, such as selection into treatment. Simulations suggest that going deep is especially valuable for observational research, situations with homogeneous treatment effects, and, of course, when there is strong probative value.</p>
<hr />
<p>How does this approach guide researchers in making choices about research designs?</p>
<p>We address this question with a focus on characterizing the kind of learning that emerges from different combinations of investment in the collection of correlational as compared with process-tracing data <em>under different research conditions</em>. We report the results here of simulation-based experiments designed to tell us under what research conditions different mixes of methods can be expected to yield more accurate inferences. We also discuss, at a high level, the implications of the framework for strategies of qualitative case-selection.</p>
<div id="intuitions-does-a-sufficiently-large-n-always-trump-k" class="section level2">
<h2><span class="header-section-number">12.1</span> Intuitions: Does a sufficiently large <span class="math inline">\(N\)</span> always trump <span class="math inline">\(K\)</span>?</h2>
<p>We begin by considering the learning that occurs upon observing outcomes from varying numbers of cases given different <span class="math inline">\(XY\)</span> data ranging from small to quite large.</p>
<p>The goal here is to build up intuitions on how beliefs change given different observations and hw this affects posterior variance. We address the question is a very controlled setting in which</p>
<ul>
<li>a researcher is confronted with balanced <span class="math inline">\(X,Y\)</span> data that exhibits no correlation</li>
<li>the researcher can seek a doubly decisive clue on cases in the <span class="math inline">\(X=Y=1\)</span> cell</li>
<li>though not known in advance, it turns out that each time the researcher finds evidence suggesting that the case in question is a <span class="math inline">\(b\)</span> type</li>
<li>the selection probabilities are either unknown or known with near certainty</li>
</ul>
<p>In this case, we can expect that seeing evidence of <span class="math inline">\(b\)</span> types will shift the researcher to increase her beliefs on the average causal effect. But how strong will these shifts be and how does this depend on the amount of XY data available? Does the signal from the <span class="math inline">\(XY\)</span> data drown out any signal from the <span class="math inline">\(K\)</span> data?</p>
<p>Intuitions to answer these questions can be gathered from the simulations reported in Figure . For these simulations we varied the size of the <span class="math inline">\(XY\)</span> data from 5 observations in each cell to 5000. The key features of the simulations are:</p>
<ol style="list-style-type: decimal">
<li><p>When assignment propensities are unknown—as for example with observational data—the clue information shifts beliefs independent of how many <span class="math inline">\(XY\)</span> cases there are. The key insight is that the clue information provides inforation on assignment propensities which are informative about the share of each type in each cell and these shares determine treatment effects no matter how large or small the cells are.</p></li>
<li><p>When assignment propensities are known with large data there is a lot of learning over the distribution of types in a population (at least up to differences in types rather than the distribution of fundamental types). Clue information shifts beliefs about the types of the particular cases for which clue data is gathered but has almost no effect on estimates of the population estimand.</p></li>
<li><p>Not visible from the figure however: in the case with large <span class="math inline">\(N\)</span> and known propensities, observation on many <span class="math inline">\(b\)</span> types in the <span class="math inline">\(X=Y=1\)</span> cell, while not changing estimates of <em>average</em> treatment effects (<span class="math inline">\(\lambda_b- \lambda_s\)</span>) does affect beliefs on <em>heterogneity</em>, because the data is more consistent with a world with many <span class="math inline">\(a\)</span>s and <span class="math inline">\(b\)</span>s than one with many <span class="math inline">\(c\)</span>s and <span class="math inline">\(d\)</span>s. For example if there were 10,000 data points in each <span class="math inline">\(X,Y\)</span> and clue information on 20 cases in the <span class="math inline">\(X=Y=1\)</span> cell suggest that these are all <span class="math inline">\(b\)</span> types, then the conclusion would be that 95% of the cases are <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> types, in equal proportion.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- K&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_restrictions</span>(<span class="dt">causal_type_restrict =</span> <span class="st">&quot;(Y[X=0, K=1]==1) | (Y[X=0, K=0]==0)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">.999</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Subset</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">All</td>
<td align="left">parameters</td>
<td align="right">0.499</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">parameters</td>
<td align="right">0.500</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">parameters</td>
<td align="right">-0.500</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">All</td>
<td align="left">priors</td>
<td align="right">-0.001</td>
<td align="right">0.347</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.506</td>
<td align="right">0.222</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.501</td>
<td align="right">0.223</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">N=8</th>
<th align="left">N=40</th>
<th align="left">N=80</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Clues on 4 cases</td>
<td align="left">0.377</td>
<td align="left">0.454</td>
<td align="left">0.477</td>
</tr>
<tr class="even">
<td>Clues on 8 cases</td>
<td align="left">0.399</td>
<td align="left">0.461</td>
<td align="left">0.479</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r">model_confound &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- K&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_restrictions</span>(<span class="dt">causal_type_restrict =</span> <span class="st">&quot;(Y[X=0, K=1]==1) | (Y[X=0, K=0]==0)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_parameters</span>(<span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">.999</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.25</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_confound</span>(<span class="kw">list</span>(<span class="dt">X =</span> <span class="st">&quot;(Y[X=1]==1)&quot;</span>))

<span class="kw">draw_parameters</span>(model_confound)</code></pre>
<pre><code>##  X-1.X0  X-1.X1    K.K0    K.K1    X.X0    X.X1 
## 0.03846 0.96154 0.12116 0.87884 0.82736 0.17264 
## Y.Y1000 Y.Y1010 Y.Y1001 Y.Y1011 
## 0.16355 0.01472 0.06361 0.75812</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(<span class="kw">rbind</span>(
  <span class="kw">query_model</span>(model_confound, <span class="dt">queries =</span> <span class="kw">list</span>(<span class="dt">ATE =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span>), <span class="dt">using =</span> <span class="st">&quot;parameters&quot;</span>, 
              <span class="dt">subsets =</span> <span class="kw">list</span>(<span class="ot">TRUE</span>, <span class="st">&quot;K==1&quot;</span>, <span class="st">&quot;K==0&quot;</span>)),
  <span class="kw">query_model</span>(model_confound, <span class="dt">queries =</span> <span class="kw">list</span>(<span class="dt">ATE =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span>), <span class="dt">using =</span> <span class="st">&quot;priors&quot;</span>, 
              <span class="dt">subsets =</span> <span class="kw">list</span>(<span class="ot">TRUE</span>, <span class="st">&quot;K==1&quot;</span>, <span class="st">&quot;K==0&quot;</span>), <span class="dt">n_draws =</span> <span class="dv">2</span>)
  ))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Subset</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">All</td>
<td align="left">parameters</td>
<td align="right">0.499</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">parameters</td>
<td align="right">0.500</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">parameters</td>
<td align="right">-0.500</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">All</td>
<td align="left">priors</td>
<td align="right">0.028</td>
<td align="right">0.161</td>
</tr>
<tr class="odd">
<td align="left">ATE</td>
<td align="left">K==1</td>
<td align="left">priors</td>
<td align="right">0.648</td>
<td align="right">0.121</td>
</tr>
<tr class="even">
<td align="left">ATE</td>
<td align="left">K==0</td>
<td align="left">priors</td>
<td align="right">-0.500</td>
<td align="right">0.442</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>(<span class="kw">get_types</span>(model_confound, <span class="dt">query =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span>, <span class="dt">join_by =</span> <span class="st">&quot;|&quot;</span>)<span class="op">$</span>types)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">N=8</th>
<th align="left">N=40</th>
<th align="left">N=80</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Clues on 4 cases</td>
<td align="left">0.372</td>
<td align="left">0.451</td>
<td align="left">0.468</td>
</tr>
<tr class="even">
<td>Clues on 8 cases</td>
<td align="left">0.403</td>
<td align="left">0.457</td>
<td align="left">0.474</td>
</tr>
</tbody>
</table>
</div>
<div id="evaluating-strategies" class="section level2">
<h2><span class="header-section-number">12.2</span> Evaluating strategies</h2>
<p>As a metric of the returns from different research strategies we calculate the <em>expected</em> inaccuracy in the estimation of the average treatment effect, as given in equation .
<span class="math display">\[\begin{equation}
\mathcal{L}=\mathbb{E}_\theta(\mathbb{E}_{\mathcal{D}|\theta}(\tau(\theta)-\hat{\tau}(\mathcal{D}))^2) 
\label{Loss}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\tau(\theta)\)</span> is the value of <span class="math inline">\(\lambda_b-\lambda_a\)</span> (the average treatment effect) given <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\hat{\tau}(\mathcal{D})\)</span> is the <em>estimate</em> of this treatment effect (the mean posterior value) that is generated following some realization of data <span class="math inline">\(\mathcal{D}\)</span>. Thus, if some <span class="math inline">\(\theta\)</span> characterized the true state of the world, then <span class="math inline">\(\mathbb{E}_{\mathcal{D}|\theta}(\tau^\theta-\hat{\tau})^2\)</span> is the expected error in estimation of the causal effect given different realizations of the data, <span class="math inline">\(\mathcal{D}\)</span>, that could obtain in this state of the world. <span class="math inline">\(\mathcal{L}\)</span> is then the expected value of these errors given prior beliefs over possible values of <span class="math inline">\(\theta\)</span>.</p>
<p>Note that, while we focus on errors on estimated average causal effects, similar exercises could assess how cross- and within-case observations distinctively contribute to other estimands | including the causal explanations for individual cases and the validity of causal theories | as well as to learning about inferential assumptions themselves (assignment and clue probabilities).
For all simulations, prior distributions are drawn with parameters as described in the Supplementary Materials (, Table <a href="wide.html#tab:sims">12.1</a>). Priors on the type distribution are drawn from a Dirichlet distribution; priors for each of the <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\phi\)</span> values are drawn independently from Beta distributions. We note that, while by construction priors on each parameter are independent, this will not generally be the case for posterior distributions. In most cases we simulate the prior distribution using 5200 draws of each parameter. For most experiments we then systematically vary the prior distribution for one parameter of the research situation between two extreme positions. We then calculate the expected posterior from each possible data realization and, in turn, the expected loss in estimates of treatment effects for a range of levels of investment in qualitative and quantitative evidence.</p>
<p>A few further features of the experiments below are worth noting. First, our illustrations focus on learning about population-level causal effects; however, the model can yield results about the benefits of alternative research designs for estimating a wide range of other quantities of interest, such as case-specific causal explanations or clue probabilities. Second, while we focus on the search for a <em>single</em> clue in each case, the analysis can be extended to the case of an arbitrarily large set of clues. Third, in many of these experiments, the probative values are set at doubly decisive levels for all <span class="math inline">\(\phi\)</span> parameters, and thus focus on the very optimistic case of maximally informative process tracing. Fourth, we illustrate tradeoffs at low levels of <span class="math inline">\(n\)</span>, but the model can be employed to make choices for arbitrarily large numbers of cases. Finally, we note that some results may be sensitive to the choice of priors. The results below should thus be understood as an illustration of the utility of the BIQQ framework for guiding research choices, rather than as a set of more general prescriptive design rules.</p>
</div>
<div id="varieties" class="section level2">
<h2><span class="header-section-number">12.3</span> Varieties of mixing</h2>
<p>What are the marginal gains from additional pieces of correlational and process-tracing evidence for the accuracy of causal estimates? Figure  displays the results, plotting the errors associated with different mixes of correlational and process data. Each dot represents a single possible research design, with the <span class="math inline">\(x\)</span>-axis charting the total the number of cases examined. For all cases, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> data are collected. The shading of the dots in each column then represents the proportion of cases for which process-tracing is also carried out. An unshaded dot is a design in which <em>only</em> correlational data has been collected for all cases; a black dot is a design in which the process-tracing clue is sought in <em>all</em> cases; and shades of grey, as they darken, indicate process tracing for increasing shares of cases. For <span class="math inline">\(n\leq 4\)</span> we report results for all designs; for <span class="math inline">\(n&gt;4\)</span> we report only results when within case information is sought for all, half, or none of the cases.</p>
<p>We see first from the graph that, as one would expect, moving from lower-<span class="math inline">\(n\)</span> to higher-<span class="math inline">\(n\)</span> designs reduces the expected error of estimates. Further, both adding a correlational case and doing process tracing on an additional case improve accuracy. The figure also suggests that there are diminishing marginal returns to both types of data: in particular the grey point reflecting 50% process tracing is generally well below the mid point of the white and black dots, and converges toward the black dot (100% process tracing) as sample size increases. Other, less obvious results also emerge, including:</p>



<p>More generally, we would expect that the optimal level of mixing depends on the context|on features of the research situation that affect the problem and available tools of inference. In the next subsections, we report results from experiments in which we vary the researcher’s priors about (a.) the probative value of clues, (b.) heterogeneity of treatment effects (c.) uncertainty regarding assignment processes, and (d.) uncertainty regarding the probative value of clues. In all cases we report the expected loss for the design in question, as given in Equation . %</p>

<p>If clues have no probative value| in the sense that priors over <span class="math inline">\(\phi_{jx}\)</span> do not depend on type, <span class="math inline">\(j\)</span>, then gathering data on clues does not affect inference. Probative value does not get picked up during analysis, it must be imported. Less clear, however, is the extent to which gains in inference depend on the degree of probative value, defined here as in Section  (see footnote ). Our simulation evidence from full BIQQ estimation (Figure ) suggests that in some ranges at least the gains are also convex, that is <em>increasingly</em> more is learned as the gaps between pairs such as <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span> increases. The top left panel of Figure  shows an example of these convex gains, showing expected losses for settings where there is not probative value, where all tests are doubly decisive, and a case half way between these extremes.</p>


<p>We might expect that the optimal research design for estimating average treatment effects would depend on how <em>heterogeneous</em> the true causal effects are in the population. If we believe that effects are strongly homogeneous, then confidence that one case is affected by treatment provides a great deal of information about population treatment effects. However, if effects are believed to be highly heterogeneous, then knowing that one case is affected by treatment provides less information regarding effects on different cases.</p>
<p>Heterogeneity can be conceptualized in different ways. Here we define heterogeneity as increasing in the amount of <em>variance</em> in causal effects across cases in the population. In the binary environment, for any <span class="math inline">\(\tau \in [0,1]\)</span>, maximum effect heterogeneity is obtained when <span class="math inline">\(\lambda_a=(1-\tau)/2\)</span> and <span class="math inline">\(\lambda_b=(1+\tau)/2\)</span>: i.e., when all cases have either a positive or negative treatment effect, with no destined or chronic cases. For a positive treatment effect, maximum homogeneity occurs when <span class="math inline">\(a=0, b=\tau\)</span>, with the remaining share <span class="math inline">\(1-\tau\)</span> consisting of types <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>.<a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a> There are two very different ways to have an average treatment effect of 0: there may be no treatment effect for any case (maximal homogeneity), or there is a positive effect for half the cases and a negative effect for the other half (maximal heterogeneity).<br />
%Here there is no variance in causal effects across cases.</p>
<p>Using this conceptualization of heterogeneity, our simulation results confirm that higher heterogeneity increases the marginal value of going ‘’wide’’ rather than ‘’deep.’’ At low levels of heterogeneity, there are considerable gains to collecting clues on cases at a given sample size; but the gains to process tracing diminish and then disappear as heterogeneity rises (see Supplementary Materials, ).</p>
<p>%Above, why is homogeneity defined only for a=0? Also, I don’t understand why maximal homogeneity isn’t a, b, c, or d = 1. How does learning about one case tell you so much more about the population under the definition of homogeneity above?
% that’s homogeneity of type, but not of treatment effect; e.g. all c is no more homogeneous than half a and half b. the second het analysis looks at a case like this though</p>

<p>Here we examine the implications of uncertainty over treatment assignment (confounding).</p>
<p>Any differences in assignment probabilities that are <em>known</em> are built into our priors in a Bayesian setting and do not produce biases (just as known confounds can be controlled for in a standard regression model). However, <em>uncertainty</em> about assignment processes still generates higher variance in posterior estimates . % where variance of the prior distribution of bias is infinite. In this case, they show that it is optimal to place resources in strategies that have no uncertainty around sources of bias—such as in experimental data collection rather than observational data collection. Similarly, authors in the process tracing tradition have argued that a key feature of process tracing is its capacity to detect reverse causation, omitted variables, and other confounding processes (e.g., .
In the BIQQ framework, however, clues provide discriminatory leverage on case types that is <em>independent</em> of assignment probabilities: with strong probative value, <span class="math inline">\(b\)</span> and <span class="math inline">\(d\)</span> type treated units can be told apart thus eliminating the identification problem that certainty over assignment processes helps to solve.<br />
%How does the level of uncertainty about assignment affect the optimal design mix?
In our simulations (bottom left panel of Figure ), we find that greater uncertainty over assignment processes indeed results in greater errors for correlational analysis | most obviously for higher <span class="math inline">\(n\)</span>. However, for the parameter space we examine (and given strong assumptions on the probative value of clues), uncertainty about assignment does not reduce accuracy for mixed methods analysis. %Mixed methods analysis, that is, appears more robust to violations of the ignorability assumption.
(See Supplementary Materials, .)</p>

<p>%The critical assumption for drawing inferences from clues is that researchers know the likelihood of clues being present as a function of type: that is, that we know the likelihood with which a given piece of process-based evidence should be observed if a given causal effect is truly present. This is clearly a strong assumption. %, dependent on identifying both the right theoretical logic for each causal effect and the ways in which that logic would make itself observable in within-case data.
%In this sense, process tracing rests on a set of assumptions that may be just as uncertain as the assumption of particular (conditional) assignment probabilities made in observational quantitative research.
As with assignment probabilities, researchers may be uncertain regarding the probative value of clues for discriminating between types. How much does this uncertainty matter for the relative gains to qualitative evidence?</p>
<p>Surprisingly, our simulations suggest that uncertainty over the probative values of clues is unimportant for expected errors (see Supplementary Materials, ). Our experiment fixes the expected probative value of a clue and allows for variance around that expected value. Informally, we are thus comparing a situation in which one believes that a clue has moderate probative value to one in which one believes that it may have strong probative value or it may have none at all.</p>
<p>To be clear, this analysis does <em>not</em> imply that there is no penalty to being <em>wrong</em> about the probative value of clues. %If a researcher is convinced that a clue has more probative value than it actually has, then the researcher will draw the wrong inferences.
The result suggests rather, that having more, rather than less, <em>uncertainty</em> about that probative value may be relatively inconsequential for the choice of research strategy.</p>
</div>
<div id="AppSimNotes" class="section level2">
<h2><span class="header-section-number">12.4</span> Notes on Simulations</h2>
<p>Here we provide statistical details and some further interpretation for the paper’s simulations assessing the benefits of different designs conditional on different priors regarding the probative value of clues, the heterogeneity of causal effects, uncertainty regarding assignment probabilities, and uncertainty regarding the probative value of clues. Table <a href="wide.html#tab:sims">12.1</a> provides details on all parameters used in simulations and Table  provides detail on the number of runs, iterations, and related information used in the estimation.</p>
<div id="AppE1" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Probative values</h3>
<p>For these simulations we simultaneously vary the probative value for tests for all <span class="math inline">\(X,Y\)</span> combinations. Specifically, we vary the differences between <span class="math inline">\(\phi_{b0}\)</span> and <span class="math inline">\(\phi_{c0}\)</span> (for <span class="math inline">\(X=Y=0\)</span> cases), between <span class="math inline">\(\phi_{a0}\)</span> and <span class="math inline">\(\phi_{d0}\)</span> (for <span class="math inline">\(X=0, Y=1\)</span> cases); between <span class="math inline">\(\phi_{a1}\)</span> and <span class="math inline">\(\phi_{c1}\)</span> (for <span class="math inline">\(X=1, Y=0\)</span> cases); and between <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span> (for <span class="math inline">\(X=Y=1\)</span> cases). For each <span class="math inline">\(X,Y\)</span> combination, we compare the relevant <span class="math inline">\(\phi\)</span> pairs across values of <span class="math inline">\((.5,.5)\)</span> (no probative value), <span class="math inline">\((.25,.75)\)</span> (middling probative value) and <span class="math inline">\((0.01,0.99)\)</span> (strong probative value). Using the definition of probative value (PV) we provide (Section , see footnote ), these correspond to cases with probative value of 0, .5, and close to 1 respectively.</p>
</div>
<div id="AppE2" class="section level3">
<h3><span class="header-section-number">12.4.2</span> Effect heterogeneity</h3>
<p>We note that heterogeneity makes going ‘’wide’’ relatively more beneficial for two reasons. First, when all cases are affected either positively or negatively, all of the information needed to identify types is provided by information on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. If <span class="math inline">\(X=Y\)</span> then a case was (or could have been) positively affected; if <span class="math inline">\(X \ne Y\)</span> then a case was (or could have been) negatively affected. In this extreme case of maximal heterogeneity, causal process information provides no additional inferential gains. Where there is high homogeneity, on the other hand, the core difficulty is distinguishing <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> types, from <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> types. Then, the information contained in clues may provide greater benefits (see Table ). Second, the more heterogeneous effects are across cases, the less we learn about <em>population-level</em> causal effects by getting an individual case right. Thus, again, we would expect greater relative gains to more extensive analysis as heterogeneity increases.</p>
</div>
<div id="AppE3" class="section level3">
<h3><span class="header-section-number">12.4.3</span> Uncertainty about assignment processes</h3>
<p>Note that in our binary setup, infinite bias cannot arise, and the harm done by uncertainty over selection processes can be more moderate. In this set of simulations, the expected value of <span class="math inline">\(\pi_j\)</span> is fixed at <span class="math inline">\(0.5\)</span> and we vary the variance in <span class="math inline">\(\pi_j\)</span> between 0 and a maximum of 0.289.</p>
</div>
<div id="AppE4" class="section level3">
<h3><span class="header-section-number">12.4.4</span> Uncertainty regarding the probative value of clues</h3>
<p>In this experiment, the expected probability that a clue will be observed is set to 0.75 if one hypothesis is right, and 0.25 if the alternative hypothesis is correct. The simulations vary from a situation in which those probabilities are known with certainty (uncertainty low) to a situation in which the researcher admits the possibility of many possible values of <span class="math inline">\(\phi\)</span> (uncertainty set to its maximum of 0.25). Uncertainty is simultaneously varied for all pairs of <span class="math inline">\(\phi\)</span> values (see ). The displayed results suggest that uncertainty about the probative value of clues plays little role in the assessment of optimal strategies. Fixing the penumbra of uncertainty around a given expected <span class="math inline">\(\phi\)</span> value allows for the possibility that the clue may have weak probative value, but also that it may have exceptionally strong probative value. The effects of these possibilities appear to wash out when we update beliefs about causal effects upon observation of the clue (or its absence).</p>
</div>
<div id="details-on-simulation-experiments" class="section level3">
<h3><span class="header-section-number">12.4.5</span> Details on simulation experiments</h3>
<!-- \begin{table}[htbp]
  \centering
    \begin{tabular}{ccc|c|ccc|ccc|ccc|ccc}
          &       &       & 1: m or n & \multicolumn{3}{|c|}{2:  Probative Value} & \multicolumn{3}{|c|}{3: Effect Heterogeneity} & \multicolumn{3}{|c|}{4: Assignment Uncertainty} & \multicolumn{3}{c}{5: Clue Uncertainty}  \\
\hline
    $\theta$ & Dist & arg   &       & Low     & $\rightarrow$ & High     & Low      & $\rightarrow$ & High     & Low     & $\rightarrow$ & High     & Low     & $\rightarrow$ & High \\ \hline 
    $\lambda_a$ & Dirichlet& $\alpha_a$   & 1  & 0.20  & $\rightarrow$ & 0.20       & 0.10  & $\rightarrow$ & **2.00**  & 1  & $\rightarrow$ & 1  & 1  & $\rightarrow$ & 1 \\
    $\lambda_b$      &       & $\alpha_b$ & 1  & 0.20  & $\rightarrow$ & 0.20   & 02.10  & $\rightarrow$ & **4.00**   & 1  & $\rightarrow$ & 1  & 1  & $\rightarrow$ & 1 \\
    $\lambda_c$      &       & $\alpha_c$ & 1  & 0.20  & $\rightarrow$ & 0.20   & 02.00  & $\rightarrow$ & **0.10**   & 1  & $\rightarrow$ & 1  & 1  & $\rightarrow$ & 1 \\
    $\lambda_d$      &       & $\alpha_d$ & 1  & 0.20  & $\rightarrow$ & 0.20   & 02.00     & $\rightarrow$ & **0.10**   & 1  & $\rightarrow$ & 1  & 1  & $\rightarrow$ & 1 \\
    \hline
    $\pi_a$  & Beta  & $\mu$    & 0.50   & 0.50   & $\rightarrow$ & 0.50                 & 0.50  & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50 \\
          &       & $\sigma$    & 0.10 & 0.10 & $\rightarrow$ & 0.10 & 0.10             & $\rightarrow$ & 0.10   & 0.01 & $\rightarrow$ & **0.289** & 0.10 & $\rightarrow$ & 0.10\\ \hline
    $\pi_b$  & Beta  & $\mu$    & 0.50   & 0.50   & $\rightarrow$ & 0.50        & 0.50   &  $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50 \\
          &       & $\sigma$    & 0.10 & 0.10 & $\rightarrow$ & 0.10 & 0.10 &           $\rightarrow$ & 0.10 & 0.01 & $\rightarrow$ & **0.289** & 0.10 & $\rightarrow$ & 0.10 \\ \hline
    $\pi_c$  & Beta  & $\mu$    & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50               & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50 \\
          &       & $\sigma$    & 0.10 & 0.10 & $\rightarrow$ & 0.10 & 0.10             & $\rightarrow$ & 0.10 & 0.01 & $\rightarrow$ & **0.289** & 0.10 & $\rightarrow$ & 0.10 \\ \hline
    $\pi_d$  & Beta  & $\mu$    & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50               & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50   & 0.50   & $\rightarrow$ & 0.50 \\
          &       & $\sigma$    & 0.10 & 0.10 & $\rightarrow$ & 0.10 & 0.10             & $\rightarrow$ & 0.10 & 0.01 & $\rightarrow$ & **0.289** & 0.10 & $\rightarrow$ & 0.10 \\
\hline
    $\phi_{a0}$ & Beta  & $\mu$     & 0.01  & 0.50  & $\rightarrow$ & **0.01**      & 0.01  & $\rightarrow$ & 0.01  & 0.01  & $\rightarrow$ & 0.01  & 0.01  & $\rightarrow$ & 0.25 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{a1}$ & Beta  & $\mu$     & 0.99  & 0.50  & $\rightarrow$ & **0.99**      & 0.99  & $\rightarrow$ & 0.99  & 0.99  & $\rightarrow$ & 0.99  & 0.75  & $\rightarrow$ & 0.75 \\
          &       & $\sigma$      & 0.01 & 0.01 & $\rightarrow$ & 0.01          & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{b0} $& Beta  & $\mu$     & 0.01  & 0.50  & $\rightarrow$ & **0.01**      & 0.01  & $\rightarrow$ & 0.01  & 0.01  & $\rightarrow$ & 0.01  & 0.25  & $\rightarrow$ & 0.25 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{b1}$ & Beta  & $\mu$     & 0.99  & 0.50  & $\rightarrow$ & **0.99**      & 0.99  & $\rightarrow$ & 0.99  & 0.99  & $\rightarrow$ & 0.99  & 0.75  & $\rightarrow$ & 0.75 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{c0}$ & Beta  & $\mu$     & 0.99  & 0.50  & $\rightarrow$ & **0.99**      & 0.99  & $\rightarrow$ & 0.99  & 0.99  & $\rightarrow$ & 0.99  & 0.75  & $\rightarrow$ & 0.75 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{c1}$ & Beta  & $\mu$     & 0.01  & 0.50  & $\rightarrow$ & **0.01**      & 0.01  & $\rightarrow$ & 0.01  & 0.01  & $\rightarrow$ & 0.01  & 0.25  & $\rightarrow$ & 0.25 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\\hline
    $\phi_{d0}$ & Beta  & $\mu$     & 0.99  & 0.50  & $\rightarrow$ & **0.99**      & 0.99  & $\rightarrow$ & 0.99  & 0.99  & $\rightarrow$ & 0.99  & 0.75  & $\rightarrow$ & 0.75 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\ \hline
    $\phi_{d1}$& Beta  & $\mu$      & 0.01  & 0.50  & $\rightarrow$ & **0.01**      & 0.01  & $\rightarrow$ & 0.01  & 0.01  & $\rightarrow$ & 0.01  & 0.25  & $\rightarrow$ & 0.25 \\
          &       & $\sigma$    & 0.01 & 0.01 & $\rightarrow$ & 0.01            & 0.01 & $\rightarrow$ & 0.01 & 0.01 & $\rightarrow$ & 0.01 & 0.001 & $\rightarrow$ & **0.25** \\
\hline
    \end{tabular}%
  \caption{Simulation parameters. Each column details parameters used to generate prior distributions for one of the simulations below. The prior distribution for the full parameter vector is formed from independent draws from Beta distributions for all probabilities and the Dirichlet distribution for shares. Note that the mean and standard deviation parameterization we provide for Beta distributions can be mapped directly to the more standard $\alpha, \beta$ parameterization. 
 }
  \label{sims}%
\end{table}% -->
<table>
<caption><span id="tab:sims">Table 12.1: </span>Simulation parameters. Each column details parameters used to generate prior distributions for one of the simulations below. The prior distribution for the full parameter vector is formed from independent draws from Beta distributions for all probabilities and the Dirichlet distribution for shares. Note that the mean and standard deviation parameterization we provide for Beta distributions can be mapped directly to the more standard <span class="math inline">\(\alpha, \beta\)</span> parameterization</caption>
<colgroup>
<col width="5%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="7%" />
<col width="5%" />
<col width="5%" />
<col width="9%" />
<col width="5%" />
<col width="5%" />
<col width="10%" />
<col width="5%" />
<col width="5%" />
<col width="8%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><br />
<span class="math inline">\(\theta\)</span></th>
<th align="center"><br />
Dist</th>
<th align="center"><br />
arg</th>
<th>1: m or n\</th>
<th align="center">2: Probative Value<br />
Low</th>
<th align="center"><br />
<span class="math inline">\(\rightarrow\)</span></th>
<th align="center"><br />
High</th>
<th align="center">3: Effect Heterogeneity<br />
Low</th>
<th><span class="math inline">\(\rightarrow\)</span></th>
<th align="center">High</th>
<th align="center">4: Assignment Uncertainty<br />
Low</th>
<th><span class="math inline">\(\rightarrow\)</span></th>
<th align="center">High</th>
<th align="center">5: Clue Uncertainty<br />
Low</th>
<th align="right"><span class="math inline">\(\rightarrow\)</span></th>
<th align="center">High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda_a\)</span></td>
<td align="center">Dirichlet</td>
<td align="center"><span class="math inline">\(\alpha_a\)</span></td>
<td>1<br />
</td>
<td align="center">0.20<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.20<br />
</td>
<td align="center">0.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>2.00</strong></td>
<td align="center">1<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
<td align="center">1<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda_b\)</span></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\alpha_b\)</span></td>
<td>1<br />
</td>
<td align="center">0.20<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.20<br />
</td>
<td align="center">02.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>4.00</strong></td>
<td align="center">1<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
<td align="center">1<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda_c\)</span></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\alpha_c\)</span></td>
<td>1<br />
</td>
<td align="center">0.20<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.20<br />
</td>
<td align="center">02.00<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.10</strong></td>
<td align="center">1<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
<td align="center">1<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda_d\)</span></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\alpha_d\)</span></td>
<td>1<br />
</td>
<td align="center">0.20<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.20<br />
</td>
<td align="center">02.00<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.10</strong></td>
<td align="center">1<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
<td align="center">1<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="center">1<br />
</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\pi_a\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
<strong>0.289</strong></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\pi_b\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
<strong>0.289</strong></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\pi_c\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
<strong>0.289</strong></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\pi_d\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.10<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
<strong>0.289</strong></td>
<td align="center">0.50<br />
0.10<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.50<br />
0.10<br />
</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\phi_{a0}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.01<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.01</strong>
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.01<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.25<br />
<strong>0.25</strong></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\phi_{a1}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.99<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.99</strong>
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.75<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.75<br />
<strong>0.25</strong></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\phi_{b0}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.01<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.01</strong>
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.25<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.25<br />
<strong>0.25</strong></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\phi_{b1}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.99<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.99</strong>
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.75<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.75<br />
<strong>0.25</strong></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\phi_{c0}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.99<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.99</strong>
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.75<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.75<br />
<strong>0.25</strong></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\phi_{c1}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.01<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.01</strong>
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.25<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.25<br />
<strong>0.25</strong></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\phi_{d0}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.99<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.99</strong>
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.99<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.99<br />
0.01<br />
</td>
<td align="center">0.75<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.75<br />
<strong>0.25</strong></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\phi_{d1}\)</span></td>
<td align="center">Beta</td>
<td align="center"><span class="math inline">\(\mu\)</span>
<span class="math inline">\(\sigma\)</span></td>
<td>0.01<br />
0.01<br />
</td>
<td align="center">0.50<br />
0.01<br />
</td>
<td align="center"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center"><strong>0.01</strong>
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.01<br />
0.01<br />
</td>
<td><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.01<br />
0.01<br />
</td>
<td align="center">0.25<br />
0.001<br />
</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span>
<span class="math inline">\(\rightarrow\)</span></td>
<td align="center">0.25<br />
<strong>0.25</strong></td>
</tr>
</tbody>
</table>




</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="81">
<li id="fn81"><p>For negative treatment effects, homogeneity is maximized with <span class="math inline">\(\lambda_b=0\)</span>.<a href="wide.html#fnref81" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clue-selection-as-a-decision-problem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="caseselection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
