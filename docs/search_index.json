[
["caseselection.html", "Chapter 14 Mixed methods data strategies 14.1 Case selection strategies 14.2 Wide or Deep 14.3 Principles", " Chapter 14 Mixed methods data strategies With a causal model in hand, together with priors over parameters, we can assess in advance what conclusions we will draw from different observations and assess what kinds of observations are most worth seeking. We draw out the implications of this idea for case selection. We then turn to the problem of choosing between going “wide” and going “deep.” We discuss the tradeoffs and communicate an intuition that clue data, even on a small number of cases, can be informative even when there is \\(X, Y\\) data on a very large number of cases, but only if it provides information that cannot be gathered from \\(X,Y\\) data, such as selection into treatment. Simulations suggest that going deep is especially valuable for observational research, situations with homogeneous treatment effects, and, of course, when clues have strong probative value. A critical decision for scholars employing mixed methods is to determine when and where to look deep and when to look wide. We address this question if two steps, first addressing the problem of case selection and second the question of qualitative/quantitative mixing. 14.1 Case selection strategies A host of different strategies have been proposed for selecting cases for in-depth study based on the observed values of \\(X\\), \\(Y\\) data. Perhaps the most common strategy is to select cases in which \\(X=1\\) and \\(Y=1\\) and look to see whether in fact \\(X\\) caused \\(Y\\) in the case in question (using some more or less formal strategy for inferring causality from within-case evidence). But many other strategies have been proposed, including strategies to select cases “on the regression line” or, for some purposes, cases “off the regression line” (e.g., Lieberman (2005)). Some scholars suggest ensuring variation in \\(X\\) (most prominently, King, Keohane, and Verba (1994)), while others have proposed various kinds of matching strategies. Some have pointed to the advantages of random sampling of cases, either stratified or unstratified by values on \\(X\\) or \\(Y\\) (Fearon and Laitin (2008), Herron and Quinn (2016)). Which cases we should choose will likely depend on the purposes to which we want to put them. A matching strategy for instance—selecting cases that are comparable on many features but that differ on \\(X\\)—replicates at a small scale the kind of inference done by matching estimators with large-\\(n\\) data. The strategy draws leverage from \\(X,Y\\) variation rather than from within-case information beyond what is available in the measurement of \\(X\\) and \\(Y\\). (FLAG: Citations needed.) Other treatments seek to use qualitative information to check assumptions made in \\(X, Y\\) analysis: for example, is the measurement of \\(X\\) and \\(Y\\) reliable in critical cases? (FLAG: Citations needed) For such questions with limited resources, it might make sense to focus on cases for which validation plausibly makes a difference to the \\(X,Y\\) inferences: for example influential cases that have unusually extreme values on \\(X\\) and \\(Y\\).1 Similar arguments are made for checking assumptions on selection processes, though we consider this a more complex desideratum since this requires making case level causal inferences and not simply measurement claims. A third purpose is to use a case to generate alternative or richer theories of causal processes, as in Lieberman’s “model-building” mode of “nested analysis” (Lieberman (2005)). Here it may be cases off the regression line that are of interest. Weller and Barnes (CITE article) on case selection focus on (a) X/Y relations and (b) whether the cases are useful for hypothesis generation. In what follows, we focus on a simpler goal: given existing \\(X, Y\\) data for a set of cases and a given clue (or set of clues) that we can go looking for in the intensive analysis of some subset of these cases, for which cases would process tracing yield the greatest learning about the population-level causal effect of \\(X\\) on \\(Y\\)? The basic insight of this chapter is simple enough: the optimal strategy for case selection for a model-based analysis are a function of the model we start with and the query we seek to address, just as we saw for the optimal clue-selection strategy in Chapter ??. Using this strategy yields guidance that is consistent with some common advice but at odds with other advice. The main principles that emerge from the analysis can be summarized as: go where the probative value is, and sample from \\(X\\) and \\(Y\\) values in proportion to their occurrence in the population, invest in collections of cases that provide complementary learning. Beyond these general principles, other patterns are more complex and thus more difficult to neatly summarize. The most general message of this chapter is about the general approach: that is, that we can use a causal model to tell us what kinds of cases are likely to yield the greatest learning, given the model and a strategy of inference. We provide a tool for researchers to undertake this analysis, at least for simple problems with \\(X, Y, K\\) data. Most closely related to our analysis in this chapter is the contribution of Herron and Quinn (2016), who build on Seawright and Gerring (2008). While Seawright and Gerring provide a taxonomy of approaches to case selection, they do not provide a strategy for assessing the relative merits of these different approaches. As we do, Herron and Quinn (2016) focus on a situation with binary \\(X,Y\\) data and assess the gains from learning about causal type in a set of cases (interestingly in their treatment causal type, \\(Z_i\\) is called a confounder rather than being an estimand of direct interest; in our setup, confounding as normally understood arises because of different probabilities of different causal types of being assigned to “treatment”, or an \\(X=1\\) value). Herron and Quinn (2016) assume that in any given case selected for analysis a qualitative researcher is able to infer the causal type perfectly. Our setup differs from that in Herron and Quinn (2016) in a few ways. Herron and Quinn (2016) paramaterize differently, though this difference is not important.2 Perhaps the most important difference between our analysis and that in Herron and Quinn (2016) is that we connect the inference strategy to process-tracing approaches. Whereas Herron and Quinn (2016) assume that causal types can be read directly, we assume that these are inferred imperfectly from evidence and we endogenize the informativeness of the evidence to features of the inquirys. Moreover, not only can we have uncertainty about the probative value of clues, but researchers can learn about the probative value of clues by examining cases. Here we assume that the case selection decision is made after observing the \\(XY\\) distribution and we explore a range of different possible contingency tables. In Herron and Quinn (2016) the distribution from which the contingency tables are drawn is fixed, though set to exhibit an expected observed difference in means (though not necessarily a true treatment effect) of 0.2. They assume large \\(XY\\) data sets (with 10,000) units and case selection strategies ranging from 1 to 20 cases. Another important difference, is that in many of their analyses, Herron and Quinn (2016) take the perspective of an outside analyst who knows the true treatment effect; they then assess the expected bias generated by a research strategy over the possible data realizations. We, instead, take the perspective of a researcher who has beliefs about the true treatment effect that correspond to their priors, and for whom there is therefore no expected bias. This has consequences also for the assessment of expected posterior variance, as in our analyses the expectation of the variance is taken with respect to the researcher’s beliefs about the world, rather than being made conditional on some specific world (ATE). We think that this setup is addressed to the question that a researcher must answer when deciding on a strategy: given what they know now, what will produce the greatest reduction in uncertainty (the lowest expected posterior variance)? Finally, we proceed somewhat differently in our identification of strategies from Herron and Quinn: rather than pre-specifying particular sets of strategies (operationalizations of those identified by Seawright and Gerring (2008)) and evaluating them, we define a strategy as the particular distribution over \\(XY\\) cells to be examined and proceed to examine every possible strategy given a choice of a certain number of cases in which to conduct process tracing. We thus let the clusters of strategies—those strategies that perform similarly—emerge from the analysis rather than being privileged by past conceptualizations of case-selection strategies. Despite these various differences, our results will agree in key ways with those in Herron and Quinn (2016). 14.1.1 No general rules Case selection is about choosing in which cases to make observations. We obviously want to look for evidence in cases where that evidence is likely to be most informative. And the informativeness of a case depends, in turn, on our model and our query. Although it might be tempting to seek general case-selection rules of the form “examine cases in which \\(X=1\\) and \\(Y=1\\)” or “ignore cases in which \\(X=0\\) and \\(Y=1\\),” it is easily demonstrated that which cases will be (in expectation) more informative depends on models and queries. Suppose we have observed \\(X\\) and \\(Y\\) values for a set of random draw of cases from a population. Suppose further that we know, for this population, that: \\(X \\rightarrow Y \\leftarrow K\\) \\(\\Pr(Y=1|X=0, K = 0) = 1\\) \\(\\Pr(Y=1|X=1, K = 0) = .5\\) \\(\\Pr(Y=1|X=0, K = 1) = 0\\) \\(\\Pr(Y=1|X=1, K = 1) = .9\\) One way to read this set of statements is that \\(X\\)’s causal effect on \\(Y\\) varies with \\(K\\). We do not know, however how common \\(K\\) is. Thus we do not know either the average effect of \\(X\\) or the probability that \\(X\\) caused \\(Y\\) in a case with particular \\(X, Y\\) values. What do the above statements tell us about \\(K\\)’s informativeness? The beliefs above imply that if, \\(X=Y=1\\), then \\(K\\) is a “doubly decisive” clue for assessing whether, in a given case, \\(X\\) causes \\(Y\\). In particular, we see that for an \\(X=Y=1\\) case, observing \\(K=1\\) implies that \\(X\\) caused \\(Y\\): this is because, otherwise, \\(Y\\) would have been 0. We also see that \\(K=0\\), in an \\(X=1, Y=1\\) case implies that \\(X\\) did not cause \\(Y\\) since \\(Y\\) would have still been 1 even if \\(X\\) were 0. So an \\(X=Y=1\\) case would be a highly informative place to go looking for \\(K\\). However, if we had a case in which \\(X=Y=0\\), then learning \\(K\\) would be entirely uninformative for the case. In particular, we already know that \\(K=1\\) in this case as the statements above exclude the possibiltiy of a case in which \\(X=Y=0\\) and \\(K=0\\). So there would be nothing gained by “looking” to see what \\(K\\)’s value is in the case. Moreover, this knowledge is not enough to tell us whether \\(X=0\\) caused \\(Y=0\\). For the same reason, we can learn nothing from \\(K\\) in an \\(X=0, Y=1\\) case since we know that \\(K=0\\) in such a case. On the other hand, if we chose an \\(X=1, Y=0\\), then \\(K\\) would again be doubly decisive, with \\(K=0\\) implying that \\(X=1\\) caused \\(Y=0\\), and \\(K=1\\) implying that \\(X=1\\) did not cause \\(Y=0\\). We have chosen extreme values for this illustration — our beliefs could, of course, allow for gradations of informativeness, rather than all-or-nothing identification — but the larger point is that beliefs about the way world work can have a powerful effect on the kind of case in which learning is possible. And note that in this example, there is nothing special about where a case lies relative to a (notional) regression line: informativeness in this setup happens to depend on \\(X\\)’s value entirely. But, again, this is a particular feature of this particular set of beliefs about the world. Suppose, now, that we were interested in a population estimand: the average effect of \\(X\\) on \\(Y\\). We can see that this is equal to \\(\\Pr(K=1)\\times.9 + (1-\\Pr(K-0))\\times(-.5)) = 1.4\\times Pr(K=1)-.5\\). To estimate this estimand, we need only determnine the prevalence of \\(K=1\\) in the population. It might seem that this means that it is irrelevant what type of case we choose: why not use pure random sampling to determine \\(K\\)’s prevalence. As noted above, however, we have more information about the likely value of \\(K\\) in some kinds of cases than in others. Thus, for this population-level estimand as well, selecting an \\(X=1\\) case will be informative while selecting an \\(X=0\\) case will not be informative. At the same time, not all \\(X=1\\) cases are equally informative. Should we choose an \\(X=1\\) case in which \\(Y=1\\) or one in which \\(Y=0\\)? In both types of case, \\(K\\) is doubly decisive for the probability of causation in the case. However, the two kinds of cases are differentially informative about \\(K\\)’s prevalence in the population. For an \\(X=1, Y=1\\) case, we think it moderately likely that \\(K=1\\) (specifically, assuming a prior of \\(\\Pr(K=1)\\) we think \\(\\Pr(K=1 | X=1, Y=1) = \\frac{.9}{.9+.5}=.64\\)). For an \\(X=1, Y=0\\) case, we think \\(K=1\\) is quite unlikely (\\(\\Pr(K=1 | X=1, Y=0) = \\frac{.1}{.5+.1}=.17\\)). In other words, we are much more uncertain about the value of \\(K\\) in the \\(X=Y=1\\) case than in the \\(X=1, Y=0\\) case. In this setup, we would thus expect to learn more about the average treatment effect by choosing to observe \\(K\\) in an on-the-diagonal case than in an off-the-diagonal case. FLAG: What does “assuming a prior of \\(\\Pr(K=1)\\)” add to above paragraph? Specifically, let \\(\\kappa\\) denote \\(\\Pr(K=1)\\). Suppose that we begin thinking it equally likely that \\(\\kappa=\\kappa^H = .5\\) and \\(\\kappa=\\kappa^L=0\\). Suppose, further, that the distribution of \\(X\\) is such that, for any randomly drawn case, \\(\\Pr(X=1) = .5\\). We then observe one case with \\(X=1, Y=1\\) and another with \\(X=1, Y=0\\). From that information alone, we can update over \\(\\kappa\\). Specifically, conditioning on \\(X=1\\), when we observe the data pattern, \\(D\\), in which \\(Y=0\\) in one case and \\(Y=1\\) in the other, the posterior on \\(\\kappa\\) is: \\[p(\\kappa = \\kappa^L|D) = \\frac{p(D|\\kappa^H)}{p(D|\\kappa^H)+p(D|\\kappa^L)}=\\frac{.5}{.5 + .25\\times(2\\times.5\\times.5 + 2\\times.9\\times.1 + 2\\times(.9\\times.5 +.1\\times.5))}\\] FLAG: Is the above expression not missing the prior? FLAG: I am not sure what we’re trying to get out of this expression, so unsure how to tie this up. In summary, under the stipulated beliefs about the world, we can learn most about the population \\(ATE\\) by selecting an \\(X=Y=1\\) for study. We can also learn about the case-level effect in such a case as well as in an \\(X=1, Y=0\\) case. If we are interested in the case level estimand for any \\(X=0\\) case, then there are no gains from any case-selection strategy since we know \\(K\\)’s value based on \\(X\\) and \\(Y\\)’s value. FLAG: AJ: Check my rewrite of last statement. There is nothing preferable in general about an \\(X=1\\) case. Under a different set of beliefs about the world, we would expect to learn more in an \\(X=Y=0\\) than in an \\(X=Y=1\\) case. Suppose, for instance, that we have a model in which: \\(X \\rightarrow Y \\leftarrow K\\) \\(\\Pr(Y=1|X=0, K = 0) = .5\\) \\(\\Pr(Y=1|X=1, K = 0) = 0\\) \\(\\Pr(Y=1|X=0, K = 1) = .5\\) \\(\\Pr(Y=1|X=1, K = 1) = 1\\) In this world, we learn nothing from observing a case in which \\(X=Y=1\\)—since we already know that \\(K=1\\). In contrast, if \\(X=Y=0\\), then if we learn that \\(K=1\\), we know that, were \\(X=1\\), \\(Y\\) would have been 1; and if instead we observe \\(K=0\\), we know that \\(Y\\) would have (still) been 0 if \\(X\\) were 1. Now, \\(K\\) is doubly decisive for an \\(X=Y=0\\) case but unhelpful for an \\(X=Y=1\\) case. The two off-diagonal cases may also be different in the opportunities for learning that they present. Suppose that you knew that: \\(X \\rightarrow Y \\leftarrow K\\) \\(\\Pr(Y=1|X=0, K = 0) = 0\\) \\(\\Pr(Y=1|X=1, K = 0) = .5\\) \\(\\Pr(Y=1|X=0, K = 1) = 1\\) \\(\\Pr(Y=1|X=1, K = 1) = .5\\) For an \\(X=1, Y=0\\) case, if you observe \\(K=1\\) you know that if \\(X\\) were 0, \\(Y\\) would have been 1; but if \\(K=0\\), you know that if \\(X\\) were 0, \\(Y\\) would still have been 0. In that case \\(K\\), would be doubly decisive for \\(X=1\\) causing \\(Y=0\\). But in an \\(X=0, Y=1\\), we already know \\(K=0\\) before we go looking. Say instead that you knew that: \\(X \\rightarrow Y \\leftarrow K\\) \\(\\Pr(Y=1|X=0, K = 0) = .5\\) \\(\\Pr(Y=1|X=1, K = 0) = 0\\) \\(\\Pr(Y=1|X=0, K = 1) = .5\\) \\(\\Pr(Y=1|X=1, K = 1) = 1\\) It may be better to select a case that is not “like” the cases you want to make inferences about. FLAG: Not getting the point here. How is this different from the setup two up from here? 14.1.2 Specific case walk through FLAG: AJ: I don’t think this section helps. It basically walks through the chain model results, which we’re already doing in the next section. And it uses a different set of strategies, which will just be confusing. The one thing maybe that’s added here is the table showing the possible data. We could perhaps generate one for illustrative purposes for the four strategies we consider in the sims section. Consider a situation in which one has access to \\(X,Y\\) data on just six cases of the form: event count X0Y0 2 X1Y0 1 X0Y1 1 X1Y1 2 We want to examine data on \\(M\\) for two of these cases and are wondering about what strategy we should use to select the cases. We are considering three strategies: Strategy \\(A\\) chooses two cases on the regression line, one in the \\(X=Y=0\\) cell and one in the \\(X=Y=1\\) cell Strategy \\(B\\) chooses off the regression line, one in the \\(X=1, Y=0\\) cell and one in the \\(X=0, Y=1\\) cell Strategy \\(C\\) selects jointly on the independent and dependent variables, choosing two cases with \\(X=1, Y = 1\\). Different strategies yield different possible types of data. Each one of these is likely to arise with a different probability and is associated with a different inference. Drawing on the prior beliefs embedded in a causal model, we can thus assess the expected posterior variance associated with each strategy. For each of these possible strategies we can assess the posterior that we would obtain for each type of data we might observe. The data possibilities, probabilities of each, and inferences given each, are shown in Table 14.1. Table 14.1: Each column shows a possible distribution of data that can be generated from a given strategy. We calculate the probability of each data possibility, given the data seen so far, and the posterior variance associated with each one. event A1 A2 A3 A4 B1 B2 B3 B4 C1 C2 C3 X0M0Y0 1 0 1 0 0 0 0 0 0 0 0 X0M0Y1 0 0 0 0 1 0 1 0 0 0 0 X0M1Y0 0 1 0 1 0 0 0 0 0 0 0 X0M1Y1 0 0 0 0 0 1 0 1 0 0 0 X0Y0 1 1 1 1 2 2 2 2 2 2 2 X0Y1 1 1 1 1 0 0 0 0 1 1 1 X1M0Y0 0 0 0 0 1 1 0 0 0 0 0 X1M0Y1 1 1 0 0 0 0 0 0 2 1 0 X1M1Y0 0 0 0 0 0 0 1 1 0 0 0 X1M1Y1 0 0 1 1 0 0 0 0 0 1 2 X1Y0 1 1 1 1 0 0 0 0 1 1 1 X1Y1 1 1 1 1 2 2 2 2 0 0 0 Probability 0.171 0.03 0.625 0.174 0.27 0.231 0.23 0.268 0.09 0.242 0.668 Posterior mean 0.078 0.041 0.171 0.078 0.128 0.141 0.143 0.131 0.046 0.089 0.161 Posterior variance 0.006 0.002 0.029 0.006 0.016 0.02 0.02 0.017 0.002 0.008 0.026 Each of the first two strategies generates one of four different data patterns. The third data strategy generates up to three data patterns. None of these data patterns overlap across strategies. From the calculated probability of each data type, given the data seen so far, and the posterior variance given each data realization, the implied expected variance is easily calculated. These are summarized below: Strategy Variance Online 0.015 Offline 0.017 X=1, Y=1 0.015 In this example, we see that we would expect to be better off—in the sense of having less posterior uncertainty—by focusing her process-tracing efforts where a greater share of the population of cases lies: on the regression line. Why is this? For intuition consider first the case with flat prior data: if we examine two cases in different quadrants on the diagonal (one \\(X=Y=0\\) case and one \\(X=Y=1\\) case) : if we find that \\(M\\) is the same in the two cases then we increase our belief that \\(X\\) has no effect at all on \\(Y\\) and reduce our confidence that \\(X\\) had a positive or a negative effect on \\(Y\\). Since we are looking on the regression line however, our confidence that \\(X\\) had a positive effect on \\(Y\\) is more strongly reduced, producing a posterior centered on a small negative effect. Conversely if we see that \\(M\\) is different in the two cases, then we have a correlation of the same sign between both \\(X\\) and \\(M\\) and between \\(M\\) and \\(Y\\) cases. We increase our confidence that \\(X\\) mattered for \\(Y\\) in general an din particular that it had a positive effect, resulting in a posterior centered on a small positive ATE. if we examine two cases in different quadrants off the diagonal (one \\(X=0, Y=1\\) case and one \\(X=1, Y=0\\) case) : if we find that \\(M\\) is the same in the two cases then we increase our belief that \\(X\\) has no effect at all on \\(Y\\) and reduce our confidence that \\(X\\) had a negative effect \\(Y\\) (producing a posterior centered on a small positive effect). Conversely if we see that \\(M\\) is different in the two cases, then we have a correlation (of different signs) between both \\(X\\) and \\(M\\) and between \\(M\\) and \\(Y\\) cases. We increase our confidence that \\(X\\) mattered for \\(Y\\) in general and in particular that it had a negative effect, resulting in a posterior centered on a small negative ATE. If we examine data conditioning on the value of \\(X\\) but with variation on \\(Y\\) (for instance \\(X=1, Y=0\\) and \\(X=1, Y=1\\)) data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in \\(M\\) is more consistent with \\(M\\) being responsive to \\(X\\) and thus the chances that \\(X\\) matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged. FLAG work though intuition more If we examine data conditioning on the value of \\(Y\\) but with variation on \\(X\\) (for instance \\(X=0, Y=1\\) and \\(X=1, Y=1\\)) data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in \\(M\\) is more consistent with \\(M\\) being responsive to \\(X\\) and thus the chances that \\(X\\) matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged. For correlated data similar logics apply, but the effects are stronger for evidence on the regression line. The reason is that given correlated data we believe there are more units with positive effects than negative effects. When we find evidence against causal relations on the regression line that reduces our confidence for types with positive effects more than for types with negative effects and teh difference between teh shares with positive effects and negative eeffects smaller due to the fact that the beliefs in the shares with negative effects is not so strongly reduced. Wehen we find evidence for causal relations this magnifies teh difference between beliefs in shares positive and shares negatives; these effects are magnified however since our confidence for the positive effects change more than for the negative effects, since we are examining cases on the regression line. Conversely when examining cases of teh regression line, the two forces offset each other. 14.1.3 Case selection from causal models: a simulation-based approach 14.1.3.1 Procedure We turn now to a more general approach for deriving case-selection guidance from a causal model, given the causal query we wish to address and any data that we have already observed. This approach can be implemented using CausalQueries together with CQTools. We imagine a situation in which we have already observed some data (the values of some nodes from the causal model in some set of cases) and must now decide in which cases we should gather additional data. To simplify the setup, we will be assuming that we are considering gathering additional observations in cases for which we already have some data. In other words, we are deciding which cases to investigate more deeply. (This is distinct from the question of “wide vs. deep”, where we might decide to observe cases we have not yet seen at all.) The general intuition of the case-selection approach that we develop here is that we can use our causal model and any previously observed data to estimate what observations we are more or less likely to make under a given case-selection strategy, and then figure out how far off from the (under the model) true estimand we can expect to be under the strategy, given whatever causal question we seek to answer. We proceed as follows: DAG. We start, as always, with a DAG representing our beliefs about which variables we believe to be direct causes of other variables. For the current illustrations, we consider two different DAGS: a simple mediation (or “chain”) model, \\(X \\rightarrow M \\rightarrow Y\\), and a two-path model, \\(X \\rightarrow M \\rightarrow Y \\leftarrow X\\). Priors. As when conducting mixed-method inference, we can set qualitative restrictions and/or differential quantitative weights on the (possibly conditional) nodal types in the model. We can also indicate our uncertainty over the latter, by setting the \\(\\alpha\\) parameters of the relevant Dirichlet distributions. For the current example, we start by setting flat priors over all nodal types and assume no unobserved confounding. Given data. If we have already made observations of any of the model’s nodes in some set of cases, we can use this information to condition our strategy for searching for further information. For instance, if we have observed \\(X\\)’s and \\(Y\\)’s value in a set of cases, we might select cases for process tracing based on their values of \\(X\\) and/or \\(Y\\). And, importantly, what we have already observed in the cases will affect the inferences we will draw when we observe additional data, including how informative a particular new observation is likely to be. For the present examples, we assume that we have already observed \\(X\\) and \\(Y\\) in a set of cases and found a positive correlation. Query. We define our query. This could, for instance, be the share of cases in the population in which \\(X\\) has a positive effect on \\(Y\\), or it might be \\(X\\)’s average effect on \\(Y\\). We can use the general procedure to identify case-selection strategies for any causal query that can be defined on a DAG. And, importantly, the optimal case-selection strategy may depend on the query. For instance, the best case-selection strategy for estimating the average causal effect of \\(X\\) on \\(Y\\) may not be the same as the best strategy for figuring out for what proportion of the population \\(X\\) has a positive effect on \\(Y\\). In the example below, we focus on a set of conditional queries, asking what the effect of \\(X\\) on \\(Y\\) is in cases with different \\(X\\), \\(Y\\), and \\(M\\) values. FLAG: MAke sure above query definition lines up with what we end up doing. Define one or more strategies. A strategy is defined, generically, as the search for data on a given set of nodes, in a given number of cases that are randomly selected conditional on some information we already have about potential cases. Let us assume here that our strategy will involve uncovering \\(M\\)’s value in 1 or 2 cases. What we are wondering is how to choose this one or two cases for deeper analysis. For illustrative purposes, we focus in on four possible strategies, conditional on the \\(X\\) and \\(Y\\) values that we already know: 1 examine \\(M\\) in 1 \\(X=Y=1\\) case; 2 examine \\(M\\) in 1 \\(X=1, Y=0\\) case; 3 examine \\(M\\) in 2 cases, an \\(X=Y=1\\) and an \\(X=Y=0\\); and 4 examine \\(M\\) in 2 cases, an \\(X=1, Y=0\\) and an \\(X=0, Y=1\\). In light of the positive \\(X,Y\\) correlation already observed, we can think of strategies 1 and 3 as “on-the-regression line” strategies, while strategies 2 and 4 are “off-the-regression line” strategies. Possible data. For each strategy, there are multiple possible sets of data that we could end up observing. In particular, the data we could end up with will be the \\(X,Y\\) patterns we have already observed plus some pattern of \\(M\\) observations. Thus, for instance, for strategy 1, we could end up observing the initial \\(X,Y\\) pattern plus \\(M=0\\) in one of the \\(X=1, Y=1\\) cases, or the initial \\(X,Y\\) pattern plus \\(M=1\\) in one of the \\(X=1, Y=1\\) cases. For strategy 3, we could observe four possible combinations of \\(M\\) values, with \\(M\\) being 0 or 1 in each of the cases. Probability of the data. We now calculate a probability of each possible data realization, given the model and the data that we have already observed. In practice, we do this in CQtools via simulation. Starting with the model together with our priors, we update our beliefs about \\(\\lambda\\) based on the previously observed data. This posterior now represents our prior for the purposes of the process tracing. In the present example, we are using the already-observed \\(X,Y\\) correlation to update our beliefs about causal-type share allocations in the population, having seen the \\(X,Y\\) data only. We then use this posterior to draw a series of \\(\\lambda\\) values. Given that the ambiguity matrix gives us the mapping from causal types to data realizations, we can calculate for each \\(lambda\\) draw the probability of each data possibility given that particular \\(\\lambda\\) and the strategy. We then average across repeated \\(\\lambda\\) draws. Since \\(\\lambda\\)’s are being drawn from our prior, we are automatically weighting more heavily those \\(\\lambda\\)’s that we believe to be most likely. Posterior on estimate given the data. For each data possibility, we can then use CQtools to ask what inference we would get from each data possibility, given whatever query we seek to answer, as well as the variance of that posterior. Examining the inferences from possible data-realizations, as we do below, can help us understand how the learning unfolds for different strategies. Expected posterior variance under each strategy. The quantity of ultimate interest is the posterior variance that we expect to end up with under each strategy. Calculating this expectation is now elementary as we have both the posterior variance arising from each data possibility and the probability of each data possibility (given our prior beliefs and the data already observed). The expected posterior variance is simply an average of the posterior variances under each data possibility, weighted by the probability of each data possibility. We can think of the expected gains from a strategy as the expected reduction in posterior variance arising from that strategy. 14.1.3.2 Results For our analyses we imagine that we have previously observed a positive \\(X,Y\\) correlation in 6 cases: with 4 cases on the regression line, 2 cases off. Now we see what can happen for different queries when we implement each of the seven different case-selection strategies given five different background models and three primary queries. The primary queries we are interested in are: what is the \\(ATE\\) for the population? what is the probability that \\(Y=1\\) is due to \\(X=1\\) for a randomly drawn case among those with \\(X=1, Y=1\\) what is the probability that \\(Y=1\\) is due to \\(X=0\\) for a randomly drawn case among those with \\(X=0, Y=1\\) In the figure, each column represents a single model. Each row represents a query. Within a graph, we plot the inference on the query for all data-realization possibilities for, in turn: no new data: beliefs are based on the \\(X,Y\\) data only two \\(N=1\\) strategies (one in which data on \\(M\\) is sought in the \\(X=1, Y=0\\) cell and one in which it is sought in the \\(X=1, Y=1\\) cell) an on the regression line straetgy: with data sought in one \\(X=1, Y=1\\) case and one \\(X=0, Y=0\\) case an off the regression line straetgy: with data sought in one \\(X=0, Y=1\\) case and one \\(X=1, Y=0\\) case an on-on strategy with data on \\(M\\) sought for two cases in teh \\(X=1, Y=1\\) cell a strategy in which we look at two cases in which treatment was given with \\(X\\) fixed at 1; one with \\(Y=0\\) and one with \\(Y=1\\) a strategy in which we look at two cases in which a postive outcome was observed, with \\(Y\\) fixed at 1; one with \\(X=0\\) and one with \\(X=1\\) These are all “pure” strategies in hte sense that the number of units for which data on \\(M\\) is sought in each cell is fixed. One could also imagine random strategies in which a reearcher choses at radnom which cells to look. For example if they choose one point at random, they are randomly chooseing between one point on the regression ine and one off it. The performance of the strategy will be wa waiting average of tehe pure strateigs over which they are randomizing. The main results are shown in Figure 14.1 and Figure 14.2, we examine the informativeness of different process-tracing case-selection strategies by looking at the inferences we would draw for a set of queries depending on what we observe when we delve into the cases. For each strategy we figure out (a) all the possible data realizations (b) what inferences would be made from each (c) how likely these are each to arise and (d) what is the implied expected reduction in variance from each strategy. Figure 14.1 shows (a)-(c), with shading used to show (c). Figure 14.2 shows (d). These figures are close connected of course, with a higher dispersion of estimates in Figure 14.1 implying a greater reduction in variance in Figure 14.2. Figure 14.1: Inferences given observations Figure 14.2: Reduction in variance on ATE and PC given strategies Figure 14.3 we show the reduction in variance for otehr estimands, notably the effects of \\(X\\) on \\(M\\), the effects of \\(M\\) on \\(Y\\) and the direct and indirect effects. We include these to help with interpretation of teh main results but they also usefully demonstrate the applicability of the procedure to different types of queries we might be concerned with. Figure 14.3: Reduction in variance, other estimands 14.1.3.3 From the \\(X,Y\\) data (Chain model) We turn first to the chain model. Before examining inferences from data, it is worth noting what a chain model with flat priors implies about the queries of interest. We start out believing that, for the \\(X \\rightarrow M\\) relationship, the population is evenly divided across the four types, \\(\\theta^M_{00}, \\theta^M_{01}, \\theta^M_{10}, \\theta^M_{11}\\) (so 0.25 share of each). Likewise for \\(\\theta^Y\\) in relation to the \\(M \\rightarrow Y\\) relationship. We can get a positive \\(X,Y\\) effect from a causal type involving \\(\\theta^M_{01}\\) and \\(\\theta^Y_{01}\\) or from a causal type involving \\(\\theta^M_{10}\\) and \\(\\theta^Y_{10}\\). Each of those causal types has a 0.125 probability, implying a 0.25 share of positive effects. A mirror-image of that logic gets us to a 0.25 share of negative effects, with the remaining 0.5 of the population comprising causal types that yield null effects (involving either a null effect at one or both steps in the chain). Thus, the average effect of \\(X\\) on \\(Y\\), given nothing but the model, is 0. Moreover, for an \\(X=1, Y=1\\) case, the probability of a (positive) causal effect is also 0.25, as it is for a negative effect in an \\(X=0, Y=1\\) case. Now, we introduce data. In the \\(N=0\\) column of each graph, we see our inferences from the initial set of 6 \\(X,Y\\) observations. In this model, as there is no confounding, a positive \\(X,Y\\) correlation is evidence of a higher relative share of cases in which \\(X\\) has a positive effect on \\(Y\\). This implies a positive treatment effect as well as a greater than 0.25 chance of causation for an \\(X=1, Y=1\\) case since the \\(X,Y\\) pattern suggests that there are more cases where \\(X\\) has a positive effect on \\(Y\\) than there are cases in which \\(Y\\) is fixed at 1. Notably, however, our beliefs for an \\(X=0, Y=1\\) case are unaffected by observing the positive correlation. To return for a moment to our handy \\(a,b,c,d\\) typology, the reason is that the positive \\(X,Y\\) correlation affects our beliefs about the share of \\(b\\) types relative to \\(a,c,\\) and \\(d\\) types (with reference to the overall \\(X \\rightarrow Y\\) effect), but it is uninformative about the relative shares of \\(a\\) vs. \\(d\\) types, the two types in contention for an \\(X=0, Y=1\\) case. In the \\(X,Y\\) data, the \\(X=0, Y=1\\) case is equally likely to be an \\(a\\) or a \\(d\\), which is exactly what our prior belief was about a random \\(X=0, Y=1\\) case.3 FLAG: Stuff above on N=0 needs adjustment once we’ve figured out how the XY correlation affects things. 14.1.3.4 \\(N=1\\) strategies (Chain model) Now, what can we learn by selecting a single case for process tracing, that is, the observation of the additional clue, \\(M\\) in one of the 6 cases on which we already have \\(X,Y\\) data? We can see along the \\(N=1\\) vertical in each graph how our beliefs shift for each query depending on what value of \\(M\\) we observe for two case-selection strategies: selecting a case on the regression line (an \\(X=Y=1\\) case) or selecting a case off the regression line (an \\(X=1, Y=0\\) case). The lesson here is a simple one: under this model, an \\(N=1\\) strategy delivers no learning about the \\(ATE\\) or probability of causation, regardless of which type of case we choose. We see essentially only 1 point plotted for \\(N=1\\) for all queries because the inference is the same regardless of strategy and realized value of \\(M\\). To see why, let’s first consider the on-the-line strategy. Not having observed \\(M\\) previously, we still have flat priors over the nodal types governing \\(X\\)’s effect on \\(M\\) and \\(M\\)’s effect on \\(Y\\). That is to say, we still have no idea whether \\(X\\)’s positive effect on \\(Y\\) (where present) more commonly operates through a chain of positive effects or a chain of negative effects. Thus, the observation of, say, \\(M=1\\) in an \\(X=1, Y=1\\) case is equally consistent with a positive \\(X \\rightarrow Y\\) (to the extent that effect operates via linked positive effects) and with no \\(X \\rightarrow Y\\) effect (to the extent positive effects operate through linked negative effects). Observing \\(M=1\\) in an \\(X=1, Y=1\\) case therefore tells us nothing about the causal effect in that case and, thus, nothing about the average effect either. Similarly, we have no idea whether \\(X\\)’s negative effect on \\(Y\\) (where present) operates through a positive-negative chain or a negative-positive chain, making \\(M=1\\) or \\(M=0\\) in an \\(X=1, Y=0\\) case both equally consistent with a negative or null \\(X \\rightarrow Y\\) effect, yielding no information about causation in the case. By a similar logic, observing \\(M=1\\) in the \\(X=1, Y=1\\) case is uninformative about negative effects in an \\(X=0, Y=1\\) case, and observing \\(M=1\\) in an \\(X=1, Y=0\\) case tells us nothing about positive effects in an \\(X=1, Y=1\\) case. 14.1.3.5 \\(N=2\\) Strategies (Chain model) Next, we consider the process tracing of two of our cases. Now, because we are observing \\(M\\) in two cases, we can learn from the variation in \\(M\\) across these cases—or, more specifically, from its covariation with \\(X\\) aand with \\(Y\\). In other words, there is a critical difference between process tracing one case and process tracing two cases. When we only process trace one case in a setup like this one, we do not learn about causal effects in the cases we process-trace because we have no information about intermediate causal effects (e.g., whether they are more likely positive or negative). In contrast, if we observe \\(M\\) in two or more cases, we do learn about causal effects for those cases because of the leverage provided by observing covariation between the process-tracing clue and other variables. In each chain-model graph, we show the potential shifts in our beliefs from four stragies: examine two on-the-line cases, an \\(X=Y=0\\) case and an \\(X=Y=1\\) case; examine two off-the line cases, one \\(X=1, Y=0\\) case and one \\(X=0, Y=1\\) case; select on \\(X\\) by examining two \\(X=1\\) cases; and select on \\(Y\\) by examining two \\(Y=1\\) cases. We plot four points for each strategy (for each query), representing the inference we would draw from four possible realizations of \\(M\\). In most analyses, the the inferences are essentially the same for pairs of data-realizations, so only two dots are apparent.4 While unlabelled, the higher dot represents the inference we would draw if \\(M\\) varies with \\(X\\); the lower dot represents the inference we would draw if \\(M=1\\) in both cases. Let’s consider the on-the-line strategy first. Consider what we infer if we observe \\(M\\) covary positively with \\(X\\) in these cases. What we are seeing, then, is that \\(M=0\\) in the \\(X=Y=0\\) case, and \\(M=1\\) in the \\(X=Y=1\\) case. Seeing that the mediator covaries across cases with both the cause and the outcome is evidence of a causal effect of \\(X\\) on \\(Y\\). Since the observed pattern of covariation is consistent with a positive \\(X \\rightarrow Y\\) effect (via linked positive effects), our belief about the average effect of \\(X\\) on \\(Y\\) goes up. For the same reason, so too does our belief about the probability of causation in an \\(X=1, Y=1\\) case. Now, supppose we we observe \\(M=1\\) in both on-the-line cases. This data-realization represents clear evidence against positive effects. We have observed that \\(M\\) is unresponsive to changes in \\(X\\), and that \\(Y\\) varies without \\(M\\) varying—null effects at both stages of the chain. Now we see that our posterior on the \\(AT\\) drops to about \\(0\\). We also see a sharp downward movement in the probability of causation for an \\(X=1, Y=1\\) case, representing our updated belief that there are few positive effects. Moving across the graphs, we also see that process-tracing the on-the-line cases yields leverage on causal effects in an off-the-line case. In particular, finding evidence consistent with positive effects in those cases leads us to update in favor of negative effects as well, while finding \\(M=1\\) in both cases leads to a downard shift in the probability of negative causation. Why is this? Our answer is somewhat speculative, but we think there are two things going on. One is simply that the correlations between \\(M\\) and \\(X\\) and between \\(M\\) and \\(Y\\) across the two process-traced cases constitutes evidence of effects, period, at the intervening steps—a necessary condition for any \\(X \\rightarrow Y\\) effect, positive or negative. So, for an \\(X=0, Y=1\\) case, a stronger belief that \\(X\\) has some effect on \\(M\\) and that \\(M\\) has some effect on \\(Y\\) implies a stronger belief in a negative \\(X \\rightarrow Y\\) effect. The second thing that is probably going on is constraint imposed by prior beliefs. Having seen the \\(X,Y\\) data, we have previously formed a belief that the average effect of \\(X\\) on \\(Y\\) is about 0.05. When we find evidence in favor of positive effects, we update to a set of beliefs that are a compromise between the new data and prior beliefs. On the one hand, we upwardly update on the \\(ATE\\). On the other hand, our beliefs are constrained from moving too far away from an \\(ATE\\) of 0.05. Recall that, in a binary setting, the average effect in a population is the share of cases with positive effects minus the share with negative effects. Thus, the conservative influence of our priors means that, as we upwardly update on positive effects, we also upwardly update our beliefs about the prevalence of negative effects, though not by as much. The result is that our beliefs about the \\(ATE\\) do not shift as much as they would if we had had flat priors going into the process tracing. By more deeply anchoring our beliefs about average effects, then, the prior \\(X,Y\\) evidence means that any evidence in favor of positive effects also constitutes evidence in favor of negative effects. To put this point another way, while we learn directly about positive effects from process-tracing the on-the-line cases since these are cases in which positive effects can possible occur. But we then learn indirectly about negative effects from these cases via the prior-imposed constraint on the average effect. We also consider an off-the-line \\(N=2\\) strategy, selecting for process tracing one \\(X=1, Y=0\\) case and one \\(X=0, Y=1\\) case. Again, the two basic data-realizations we consider are that \\(M\\) varies with \\(X\\) across the two cases (higher point) or that \\(M\\) is constant in both cases (lower point). One thing we can observe immediately is that we get less leverage from this strategy if we are interested in either the \\(ATE\\) or positive effects. In the graphs for both the \\(ATE\\) and probability of causation in an \\(X=1, Y=1\\) case, the difference in our posterior beliefs between the two data-realizations is smaller for this strategy than it is for the two data-realizations of the on-the-line strategy. However, we learn more from the off-the-line strategy about the probability of negative causation. Unpacking this further, we know that we can learn directly about negative \\(X \\rightarrow Y\\) effects through process-tracing off-the-line cases. If we see \\(M\\) covary positively with \\(X\\) across these two cases—which also means covarying negatively with \\(Y\\)—we have found evidence in favor of the operation of negative \\(X \\rightarrow Y\\) effects. Hence the upward movement in our posterior on the probability of negative causation. We also upwardly update our posterior on positive effects in an \\(X=1, Y=1\\) case, though by a smaller amount. Again, some of this movement is likely attributable to the constraint imposed by the prior generated from the \\(X,Y\\) data; and some of this updating is likely attributable to the fact that we have found evidence against null intermediate effects. If on the other hand we observe \\(M=1\\) in both off-the-line cases, we have found evidence against the operation of negative effects. Hence the the strong downward movement of our posterior on the probability of negative causation. Likewise, we see (weaker) upward movement in our posterior on the \\(ATE\\) and, for reasons discussed earlier, in our posterior on positive effects. In sum, an off-the-line strategy generates “direct” learning about negative effects and indirect, weaker learning about positive effects. The remaining puzzle is why the learning about the \\(ATE\\) from the off-the-line strategy is weaker than under the on-the-line strategy. This is at first glance puzzling in that the two strategies generate symmetrical opportunities to observe an \\(M\\) pattern that is consistent or inconsistent with causal effects. We believe there are two reasons, both relating to where the direct and indirect learning falls. The first, more mechanical reason is that we start, given the \\(X,Y\\) data, with a higher and higher-variance posterior on the prevalence of positive effects as compared to negative effects. So there is simply more scope for the data to influence our beliefs about positive effects, and the on-the-line cases are those in which we can learn “directly” about positive effects. In support of this view, note how much bigger the swing in beliefs, conditional on the data pattern, we see for the probability of positive causation than for the probability of negative causation. The second reason is prevalence: given the \\(X,Y\\) correlation, we believe that there are more cases out there that potentially contain positive effects than there are cases that potentially contain negative effects. Thus, whatever it is we learn about positive effects is going to have a bigger impact on our beliefs about the population as a whole than is whatever we learn about negative effects. Since on-the-line case yield the most direct learning about positive effects, they are therefore the most informative about the population. Note, importantly, that this finding is consistent with recommendations in the literature to investigate on-the-line cases (Lieberman 2005, @goertz2017multimethod),5 but for a very different reason. Lieberman and Goertz emphasize the importance of examining cases where the theorized mechanism connecting \\(X\\) to \\(Y\\) might potentially play out, arguing that this would be in the set of cases that conform to theory in their \\(X,Y\\) values. We would emphasize that, in the causal-model framework, one can learn about both overall effects and intermediate effects from off-the-line cases. The reason why on-the-line cases is simply that they are more representative about the universe about which we aim to learn (assuming we want to learn about the population from which the \\(X,Y\\) pattern is drawn). Finally, we consider case-selection strategies that holds the value of \\(X\\) or the value of \\(Y\\) constant, while seeking variation on the other variable. The \\(X=1\\) strategy selects one \\(X=1, Y=0\\) case and one \\(X=1, Y=1\\) case. The \\(Y=1\\) strategy selects one \\(X=0, Y=1\\) case and one \\(X=1, Y=1\\) case. Across queries, we see that these two strategies generate roughly equivalent opportunities for learning. Interestingly, we also see that these strategies generates significantly less learning than selecting on both \\(X\\) and \\(Y\\), whether on-the-line or off-the-line. Why? When we select on-the-line or off-the-line, we are building in variation in both \\(X\\) and \\(Y\\) across the cases. In contrast, when we select on a value for \\(X\\) or a value for \\(Y\\), while letting the other variable vary, we are building in variation in only one variable. This means that the “signal” we get from the \\(M\\) pattern is likely to be more ambiguous across the cases we end up with. For instance, if we examine an \\(X=1, Y=1\\) case and an \\(X=1, Y=0\\) case, suppose we observe \\(M=1\\) in both cases. That \\(M\\) pattern is consistent with \\(X\\) having an effect on \\(M\\), but inconsistent with \\(M\\) have an effect on \\(Y\\). And what if, instead, we observe \\(M=1\\) in the first case and \\(M=0\\) in the second case? Then we have evidence of an \\(M \\rightarrow Y\\) effect but not of an \\(X \\rightarrow M\\) effect. In both scenarios, there is no strong implication for the higher-level \\(X \\rightarrow Y\\) causal queries we are interested in. This finding is particularly interesting in light of canonical advice in the qualitative methods literature. King, Keohane, and Verba (1994) advise selecting for variation on the explanatory variable and, as a second-best approach, on the dependent variable. And they warn sternly against selection for variation on both at the same time. But note what happens if we follow their advice. Suppose we decide to select for variation on \\(X\\), ignoring \\(Y\\). We might end up with a pair of informative on-the-line or off-the-line cases. But we might just as easily (depending on the joint \\(X,Y\\) distributon in the population) end up with a fairly uninformative \\(X=0, Y=1\\), \\(X=1, Y=1\\) pair. King, Keohane, and Verba’s advice makes sense if all we are interested in is examining covariation between \\(X\\) and the \\(Y\\): then we can learn from forcing \\(X\\) to vary and letting \\(Y\\)’s values fall where they may. However, seeking leverage from a mediator is a different affair. As our simulations indicate, for at least some common causal structures, we actually stand to learn the most from observing that mediator when we choose to examine it across a set of cases selected for variation in both \\(X\\) and \\(Y\\). 14.1.3.6 Moderator models What if \\(M\\) appears in the model as a moderator, rather than a mediator, of \\(X\\)’s effect on \\(Y\\): \\(X \\rightarrow Y \\leftarrow M\\)? We can think of the learning from examining a moderator as deriving from the fact that a moderator is an alternative potential cause. So, for instance, if we see \\(M\\) constant while \\(Y\\) varies, or vice versa, this is evidence against \\(M\\)’s effect and, in turn, for \\(X\\)’s effect on \\(Y\\). The relative patterns across strategies are quite similar to those in the chain model — for similar reasons, we think—though the learning opportunities are more muted. They are likely more muted essentially because of the issue of degrees of freedom: with two causes, it takes more cases to achieve the same degree of leverage. 14.1.3.7 Two-path models Case-selection strategies depend on the model. To see this, consider the results of the same analysis conducted for a two-path model in which \\(X\\) can have both an indirect effect on \\(Y\\) via \\(M\\) and a direct effect on \\(Y\\). We first examine a version with flat priors over all nodal types and then a version in which we impose some monotonicity restrictions. In the two-path row of graphs, we see the results of the case-selection exercise for a two-path model with flat priors. The takeaway here is simple: it does not matter what kind of case(s) we choose for process-tracing because nothing can be learned from observing \\(M\\) under almost any strategy. We certainly learn about \\(X \\rightarrow Y\\) effects from the \\(X,Y\\) data, reflected in the positive \\(ATE\\) for \\(N=0\\). But, after that, adding observations of \\(M\\) yields no change in beliefs, under any strategy. The reason, we think, is the combination of the double pathway and uninformtativeness of priors about intermediate effects. We go in with a flat distribution across nodal types \\(\\theta^M\\) and nodal types \\(\\theta^Y\\). We then acquire some information on the \\(X \\rightarrow Y\\) effect from the \\(X,Y\\) data, but those effects are equally consistent with all possible pathways—direct, indirect, or combined. Suppose we then find evidence that cuts against the operation of the indirect pathway: \\(M=1\\) is observed in two on-the-line cases with different \\(X\\) values. So we downgrade the probability of \\(\\theta^M_{01}\\) relative to \\(\\theta^M_{11}\\). However, we are still able to preserve our prior on the effect of \\(X\\) on \\(Y\\) by updating our beliefs about \\(\\theta^Y\\) in a manner that places greater weight on direct effects. To put the point differently: high flexibility in our lower-level beliefs impedes learning about higher-level quantities from observations at the lower level. This is true regardless of which quadrants we select our cases from. The situation changes considerably, however, if we come in with informative beliefs at the lower level. In the restricted-two-path set of graphs, we see results for a two-path model in which we have imposed stronger beliefs about the direction of causation at the lower level, ruling out negative \\(X \\rightarrow M\\) and negative \\(M \\rightarrow Y\\) effects. Now we see that we can learn from all of the strategies. Perhaps most striking is that we can learn even just from \\(N=1\\) strategies in this model. Observing \\(M=0\\) in an \\(X=1, Y=1\\) case decisively rules out the indirect pathway as a mechanism of causation, thus making a positive effect overall less likely in the case than if we observed \\(M=1\\). We also see that our \\(N=2\\) strategies are all informative. They are generally more weakly than for the chain model, reflecting the fact that we are still getting some countervailing updating of beliefs about the direct pathway. But the restrictions make \\(M\\) sufficiently informative – our beliefs about causation along the indirect pathway can shift by a sufficient magnitude – that the updating about the direct pathway cannot fully offset it. So evidence for (against) the operation of the indirect pathway registers, on net, as evidence for (against) the operation of a total \\(X \\rightarrow Y\\) effect. We also observe here asymmetries in the learning that we do not see in the other models. That is, our beliefs move further in absolute-value terms from the baseline given by the pure \\(X,Y\\) data depending on what we find. This asymmetry is driven by the asymmetry of the restrictions. In excluding intermediate negative effects along the indirect path, we have made the search for \\(M=1\\) a “hoop” test for the operation of this path: it might be operating if \\(M=1\\) (generating a small upward shift in the causal estimand) but is certainly not operating if \\(M=0\\) (generating a larger downward shift). Another interesting result is that, under these restrictions, it is the off-the-line strategy that holds the potential for the biggest swings in inferences. We believe that the reason relates, again, to the assymetry introduced by the restrictions. In an off-the-line pair of cases, we know that the indirect path cannot be fully operating: any \\(X \\rightarrow Y\\) effect here must be negative, but the restrictions only allow for a positive indirect effect. Another way to put this is that an off-the-line case is one in which we start out with the lowest prior on the mediating effects along the indirect path: it’s the kind of case in which we least expect an effect of \\(X\\) on \\(M\\) or an effect of \\(M\\) on \\(Y\\). This creates an opportunity for an especially strong “surprise”: in particular, if we observe \\(X=0, M=0, Y=1\\) and \\(X=1, M=1, Y=0\\) in the two off-the-line cases, we have found evidence in favor of one of the two intermediate effects, the \\(X \\rightarrow M\\) effect. Now, this pattern also constitutes evidence against the operation of an \\(M \\rightarrow Y\\) effect; but as we have said, we did not particularly expect to find such an effect in off-the-line cases, so this negative finding does not affect our beliefs much. So we see a large boost in our belief about the average effect of \\(X\\) on \\(M\\), a small drop on the estimated average effect of \\(M\\) on \\(Y\\), a considerable boost in our belief in the average indirect effect of \\(X\\) on \\(Y\\), and a concomitant upward shift in our beliefs about the \\(ATE\\). Observing \\(M\\) vary in the opposite direction across the two off-the-line cases — so positively varying with \\(Y\\) but not \\(X\\) — generates strong downward movement in our beliefs about the indirect effect and the \\(ATE\\). It seems that the hit to the \\(X \\rightarrow M\\) effect matters more for the indirect (and total) effect than does the boost to the \\(M \\rightarrow Y\\) effect. Looking on the line, in the restricted two-path model, also yields opportunities to learn, but weaker ones. If we see \\(M\\) vary in concert with \\(X\\) and \\(Y\\) across the one-the-line cases, we certainly shift our beliefs in indirect effects and the \\(ATE\\) upward. But the shift is smaller than in the off-the-line comparison because these are cases in which we started out with a stronger expectation that the indirect path would be operating and, in turn, that \\(M\\) would covary with \\(X\\) and \\(Y\\). There is simply less opportunity for surprise. FLAG: Incorporate as needed above and below any implications of Jeffreys priors. 14.2 Wide or Deep We continue our journey through the space of research-design choices. Suppose, now, that we have identified those clues that will be most informative, given our beliefs about the world. A further question that we face is the quintessential dilemma of mixing methods: what mixture of quantitative and qualitative evidence is optimal? We have, of course, argued in in Chapter (mixing) that the distinction between quantitative and qualitative inference is, in a causal-model framework, without much of a difference. But here we are framing a more precise question: given finite resources, how should we trade off between studying a larger number of cases and drilling down to learn more about some subset of the cases in our sample? How should we decide between going “wide” and going “deep”? Just as with the selection of clues and cases, how much we should expect to learn from going wide versus going deep will depend on how we think the world works. In this chapter, we separate out two forms that these prior beliefs might take: the structural causal model with which we start the analysis and any data that we have seen at the point of making the wide-versus-deep decision. As we will see, the expected opportunities for learning about different causal estimands depends greatly on both of these. We examine here both queries commonly associated with extensive, quantitative strategies of analysis (such as average treatment effects) and queries commonly associated with more intensive, qualitative approaches (queries about causal pathways and about causal effects at the case level). The analysis in this chapter makes clear the opportunities for integration across these lines of inquiry. We show that investing in-depth process tracing will sometimes make sense even when one aims to learn about average effects in a population. Likewise, collecting \\(X, Y\\) data can sometimes help us draw inferences that will aid in case-level explanation. Particular kinds of case-level information can teach us about populations, and understanding population-level patterns can help us get individual cases right. 14.2.1 Specific case walk through To build up our intuitions about how the optimal mix of strategies might depend on how the world works, let us explore a simple example. We focus here on the question of how much we can learn from drilling deeper, given an initial set of \\(X,Y\\) data and beliefs about the world. Imagine a world in which we have lots of data on \\(X\\) and \\(Y\\) (2000 observations) and we see \\(X\\) and \\(Y\\) are perfectly correlated. We might be tempted to infer that \\(X\\) causes \\(Y\\) surely. If \\(X\\) were randomly assigned then we might be able to justify that inference. Say however that our data is observational and in particular we were aware of an observed confound (gender say) that might determine both \\(X\\) and \\(Y\\), then what are we to infer? In that case the effect of \\(X\\) on \\(Y\\) is not identified. As shown by Manski (1995), different priors could support beliefs anywhere between 0 and 1. From Pearl (2009) we know that if the right model is \\(X \\rightarrow Y \\leftarrow M \\rightarrow X\\) then if we had data on \\(M\\) the effect of \\(X\\) on \\(Y\\) would be identified. We could essentially find the effect of \\(X\\) on \\(Y\\) for men and women and take the average effect. Say though that we had a choice between gathering a lot more data on \\(X\\) and \\(Y\\) or gathering a little data on \\(M\\) for a subset of cases—just 20 in this illustration. Which should we do? Is 20 cases enough to probe the causal model to see whether the correlation between \\(X\\) and \\(Y\\) is spurious or not? We get an intuition for the answer by imagining the inferences we might draw in 3 extreme cases and compare these to the base case. Figure 14.4 illustrates. The figures are generated by forming a model with \\(X\\rightarrow Y \\leftarrow M \\rightarrow Y\\) strong priors that \\(\\Pr(M=1)=0.5\\) and flat priors otherwise. Thus in our priors we think that \\(M\\) is equally likely to be a 0 or 1 but do not make assumptions about how it is related to \\(X\\) and \\(Y\\). We then update the model with the base data and then with the base data combined with three types of additional data. Figure 14.4: Posteriors on the ATE given different wide or deep data patterns. The first panel in Figure 14.4 shows our posterior distributions over the average effect from observation of the base data: 2000 cases with \\(X\\) and \\(Y\\) perfectly correlated. The distribution is quite wide given that the data is perfectly correlated. The reason is that the posterior includes our uncertainty over the nature of confounding. Our estimate for the ATE is 0.86 but with posterior standard deviation of 0.1519. We have positive weight on all positive value of the ATE. The second panel shows inferences in the case in which we have twice as many data points and the new points also display a perfect \\(X,Y\\) correlation—like the first set. We coudldn’t imagine data that more strongly confirms a positive relation. The main thing to note here however is that investing in gathering data on 2000 additional points does not help us very much. Our estimate for the ATE is 0.88 but with posterior standard deviation of 0.1497. So the changes are slight. The third panel shows inferences in the case in which we again keep the number of cases fixed but now examine data on \\(M\\) for 20 cases. In this example we imagine that \\(M\\) is uncorrelated with both \\(X\\) and \\(Y\\). Our estimate for the ATE is 0.98 but with posterior standard deviation of 0.004. The few cases we have are enough to convince us that the \\(X,Y\\) relationship is not spurious. Note also that the same confidence can not be generated simply by updating on the 20 datapoints for which we have full \\(X\\), \\(M\\), \\(Y\\) data—were we to use only the subset with complete data our estimate for the ATE is 0.26 but a large posterior standard deviation of 0.1218. The fourth panel shows inferences in the case in which we keep the number of cases fixed but now examine data on \\(M\\) for 20 cases. In this example we imagine that \\(M\\) is also perfectly correlated with \\(X\\) and \\(Y\\). Our estimate for the ATE is 0.79 but with posterior standard deviation of 0.1632. The lessons in this example are quite stark: in some settings, such as when there is confounding, going wide can stop aiding inference. More data of the same form does not change beliefs. However, going deep—even if only in a few cases—can add more valuable and help us figure out whether the patterns we are seeing in the wide data reflect real relations or not. 14.2.2 Results from simulations The results in the last section were striking but they depended upon particular realizations of the data under each strategy. When selecting strategies we do not know of course how the data will look. Our problem becomes, as in the previous section, one of figuring out the expected posterior variance from different strategies. Figure 14.5: Distributions of posterior variances from many simulated datasets Table 14.2: Expected posterior variance on the ATE wide_n deep_n expected 800 0 0.0056 800 100 0.0039 1600 0 0.0053 1600 100 0.0035 Figure 14.5 shows the distribution of posterior variances we might obtain from many possible data draws, where each data draw is based on our current beliefs about the world. In this example we compare strategies with 800 and 1600 data points on \\(X\\) and \\(Y\\) and with 0 and 100 data points on \\(M\\). We see here that the expected variance is lower when new data on \\(M\\) is sought — more data on \\(X\\) and \\(Y\\) does not add much in expectation. This is consistent with the analysis above with the important difference that hte strategy we use here does not depend on the specification of a particular dataset but can be applied to any model, with any query, and any prior data. We explore strategies for a range of models and present the results in a compact form in Figure ??. Figure 14.6: Expected posterior variance over multiple models with multiple data strategies. 14.3 Principles Qualitative and quantitative data can act as partial substitutes for assessing causal effects. The relative marginal gains from going wider and going deeper vary with the study design. Optimal strategies might involve going deep in a subsample of cases only. References "]
]
