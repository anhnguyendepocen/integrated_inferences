[["justifying-models.html", "Chapter 15 Justifying models 15.1 Nothing from nothing 15.2 Justifying the classic process tracing tests 15.3 Justification from experimental designs 15.4 Causal discovery 15.5 Exercise", " Chapter 15 Justifying models We outline strategies to reduce reliance on unfounded beliefs about the probative value of clues. The approach we have described to inference always involve updating beliefs given data. But to get off the ground researchers need to be able to state priors on all parameters. The problem of stating priors for process tracing inferences can be more fundamental than for many Bayesian applications for two reasons. First the beliefs are beliefs over the distribution of individual level effects and not just the beliefs over average effects. This puts us up against the fundamental problem of causal inference (Holland 1986). Second, the beliefs can do a lot of workespecially in small \\(n\\) applications. Indeed for case level queries, inferences might be little more than conditional applications of a model. We see two broad responses to this problem. One is emphasize the contingent nature of claims. As we outlined in Chapter 4, some causal models might reasonably reflect actual beliefs about the worldfor example one might, be convinced that a treatment was randomly assigned, that there is no interference, and that units are independently sampled from a distribution of types. All of these beliefs may be unwise, of course. But if held, then simple models such as that represented by an \\(X \\rightarrow Y\\) DAG is a representation of coarse beliefs about the world and not a model of the world, in the sense of a representation of a simplified world.1 But as we noted in Chapter 4, for an even modestly more complex situation, it seems inevitable that the model being used really is a model and hard to think of as a faithful summary of beliefs. Recognizing that we are generally dealing with models results in a useful reposing of the question: the question becomes not whether the assumptions are correct but whether the model is useful for some purpose (Clarke and Primo 2012). That is the subject of Chapter 15. A second approach is to justify a process tracing model by claiming exchangeability with units for which we have a lower level model. In a sense, this approach pushes the question down a level, since the lower level model itself needs to be justified. There are two further responses to this concern. One is to justify the lower level model with data or a combination of data and theory. We discuss this approach here. Another is to assess the importance of DAG assumptions  which we address in Chapter 16. 15.1 Nothing from nothing We start with a fairly negative result. Many of the models we have looked atespecially for process tracinghave a lot of structure, viz: conditional independence assumptions no confounding assumptions, and monotonicity assumptions, or other restrictions What happens if you have none of these? Can access to observational data render clues meaningful for inferences on causal effects? We show the scope for learning from a mediator for a good casea world in which in fact (though unknown ex ante to the researcher): You have access to large amounts of observational data on \\(X\\), \\(Y\\) and \\(M\\). In fact \\(X\\) causes \\(Y\\) through \\(M\\) \\(X\\) is a necessary condition for \\(M\\) and \\(M\\) is a sufficient condition for \\(Y\\)  and so \\(Y\\) is monotonic in \\(X\\) and There is, in fact, no confounding We imagine inferences are made starting from two types of model. In both we allow all possible links and we impose no restrictions on nodal types. Even though there are only three nodes, this model has 128 causal types (\\(2\\times 4 \\times 16\\)). In addition: In model_1 we allow confounding between all pairs of nodes. This results in 127 free parameters. In model_2 we assume that \\(X\\) is known to be randomized. There are now only 64 free parameters. Figure 15.1: Two models. The model on the right might be justified if \\(X\\) is known to be randomized. After updating we query the models to see how inferences depend on \\(M\\) like this: Table 15.1: Can observation of large N data render mediator \\(M\\) informative for case level inference? Case 1: No knowledge of structure; Case 2: X known to be randomized. Posterior sd in parentheses. Query Given Using Case 1 Case 2 Q 1 X==1 &amp; Y==1 posteriors 0.499 0.811 (0.156) (0.029) Q 1 X==1 &amp; M==1 &amp; Y==1 posteriors 0.499 0.828 (0.166) (0.032) Q 1 X==1 &amp; M==0 &amp; Y==1 posteriors 0.5 0.525 (0.138) (0.164) We find that even with an auspicious monotonic data generating process in which \\(M\\) is a total mediator, \\(M\\) gives no traction on causal inference in Case 1. In contrast it gives considerable leverage in Case 2: \\(M\\) is informative, especially if \\(M=0\\) (in which case we downgrade confidence that \\(X\\) caused \\(Y\\)), when \\(X\\) is known to be randomized. This example illustrates the Cartwight idea we pointed to in Chapter 2: no causes in, no causes out (Cartwright and others 1994). It poses, we think, a challenge to process tracing approaches: observational data alone is not sufficient to generate a justification for process tracing inferences for 3 node problems even when in reality causal structures are simple. 15.2 Justifying the classic process tracing tests Now, more positively, we who the possibility of justification of each of the four classical qualitative tests described by Collier (2011) and drawing on Van Evera (1997), at least when treatment assignment is randomized. Recall the four tests are smoking gun tests, hoop tests, doubly decisive tests, and straw-in-the-wind tests. A hoop test is one which, if failed, bodes especially badly for a claim; a smoking gun test is one that bodes well for a hypothesis if passed; a doubly decisive test is strongly conclusive no matter what is found, and a straw-in-the-wind test is suggestive, though not conclusive, either way. In some treatments (such as Humphreys and Jacobs (2015)), formalization involves specifying a prior that a hypothesis is true and an independent set of beliefs about the probability of seeing some data if the hypothesis is true and if it is false. Then updating proceeds using Bayes rule. This simple approach suffers from two related weaknesses however: first, there is no good reason to expect these probabilities to be independent; second, there is nothing in the set-up to indicate how beliefs around the probative value of clues can be established or justified. Both of these problems are resolvable if the problem is articulated using fully specified causal models. We illustrate first by using an idealized example to show that a case level doubly decisive test can be justified by population data from factorial designs. Say we have from observing just \\(X\\) and \\(Y\\) that \\(\\Pr(Y=1|X=1) = \\Pr(Y=1|X=0) = .5\\). Here we have an average treatment effect of 0. We are interested in a particular case with \\(X=1, Y=1\\) and specifically whether \\(X=1\\) caused \\(Y=1\\) in that case. The marginal information so far is consistent with a world in which \\(X\\) never affects \\(Y\\) and one in which \\(X\\) always affects \\(Y\\) (sometimes negatively, sometimes positively). Say now that we had data on \\(K\\) and found (a) that \\(K=1\\) arises with 50% probabilities, and (b) that the marginal distributions of \\(Y\\) given \\(X\\) and \\(K\\) are as follows: \\(\\Pr(Y=1|X=0, K = 0) = 1\\) \\(\\Pr(Y=1|X=1, K = 0) = .5\\) \\(\\Pr(Y=1|X=0, K = 1) = 0\\) \\(\\Pr(Y=1|X=1, K = 1) = .5\\) In that case we see that in cases in which \\(K=1\\), \\(X=0\\) is a necessary condition for \\(Y=1\\). So if \\(K=1\\) then certainly \\(X=1\\) caused \\(Y=1\\) (since, in that case, were \\(X\\) zero then certainly \\(Y\\) would be 0.) On the other hand were \\(K=0\\) then \\(X=0\\) would be a sufficient condition for \\(Y=1\\), which means that in this case \\(X=1\\) most certainly did not cause \\(Y=1\\). We have then that if \\(K=1\\) then certainly \\(X=1\\) caused \\(Y=1\\) whereas if \\(K=0\\) then certainly \\(X=1\\) did not cause \\(Y=1\\) This argument demonstrates that it is possible to justify a doubly decisive test on the basis of experimental dataprovided your case can be considered exchangeable with cases in the experimental data. Table 15.2 shows how this logic generalizes to different types of tests. Table 15.2: Known probabilities from a model with \\(X \\rightarrow Y \\leftarrow K\\) justifying classic test types for clue \\(K\\) given \\(X=Y=1\\). Doubly decisive Hoop Smoking gun Straw in the wind \\(\\Pr(K = 1)\\) 0.5 0.9 1 0.5 \\(\\Pr(Y=1 \\vert X=0, K = 0)\\) 1.0 1 4/9 0.6 \\(\\Pr(Y=1 \\vert X=1, K = 0)\\) 0.5 0.5 0.5 0.5 \\(\\Pr(Y=1 \\vert X=0, K = 1)\\) 0.0 0.44 0 0.4 \\(\\Pr(Y=1 \\vert X=1, K = 1)\\) 0.5 4/9 0.5 0.5 \\(\\Pr(X \\text{ causes }Y \\vert K=1)\\) 1.0 1 \\(\\Pr(X \\text{ causes }Y \\vert K=0)\\) 0.0 0 Flag! Put bounds in empty cells. Note hat some entries in Table 15.2 were given as ranges. This reflects that fact that unless we are at edge cases the estimand here is not identified even with infinite experimental data. In practice we expect never to be at these edges. Even still, the procedures given in Chapters XX above let us form posteriors over inferences with finite data. For the illustration we first make use of a function that generates data from a model with a constrained set of types for \\(Y\\) and a given prior distribution over clue \\(K\\). We then use a function that draws inferences, given different values of a clue \\(K\\), from a model that has been updated using available data. Note that the model that is updated has no constraints on \\(Y\\), has flat beliefs over the distribution of \\(K\\), and imposes no assumption that \\(K\\) is informative for how \\(Y\\) reacts to \\(X\\). We can now generate posterior beliefs, given \\(K\\), for different types of tests where the tests are now justified by different types of data, coupled with a common prior causal model. Results: Table 15.3: Classic tests with probative value inferred from (simulated) data Query Given Using Doubly decisive Hoop Smoking gun Straw in the Wind Q 1 - posteriors 0.489 0.451 0.536 0.469 (0.016) (0.022) (0.022) (0.022) Q 1 K==0 posteriors 0.009 0.044 0.493 0.301 (0.005) (0.028) (0.024) (0.029) Q 1 K==1 posteriors 0.976 0.494 0.9 0.637 (0.008) (0.023) (0.037) (0.03) We see that these tests all behave as expected. Importantly, however, the approach to thinking about the tests is quite different to that described in Collier (2011) or Humphreys and Jacobs (2015). Rather than having a belief about the probative value of a clue, and a prior over a hypothesis, inferences are drawn directly from a causal model that relates a clue to possible causal effects. Critically, with this approach, the inferences made from observing clues can be justified by reference to a more fundamental, agnostic model, that has been updated in light of data. The updated model yields both a prior over the proposition, belief about probative values, and guidance for what conclusions to draw given knowledge of \\(K\\). 15.3 Justification from experimental designs idea: show inferences given for example parallel designs for mediation 15.3.1 Mediator Say now that in addition we know from experimental data, that \\(K\\) mediates the relationship between \\(X\\) and \\(Y\\); indeed we will assume that we have a case of complete mediation, such that, conditional on \\(K\\), \\(Y\\) does not depend on \\(X\\). Say the transition matrices from \\(X\\) to \\(K\\) and \\(K\\) to \\(Y\\) are: \\[P^{xk}=\\left( \\begin{array}{cc} 1 &amp; 0 \\\\ 1/2 &amp; 1/2\\end{array}\\right), P^{ky}=\\left( \\begin{array}{cc} 1/2 &amp; 1/2 \\\\ 0 &amp; 1\\end{array}\\right)\\] Even without observing \\(K\\), this information is sufficient to place a prior on PC of \\(p=\\frac13\\). To see this, note that we can calculate: \\(\\lambda_a^K =0\\), \\(\\lambda_b^K = \\frac{1}{2}\\), \\(\\lambda_c^K = \\frac{1}{2}\\), \\(\\lambda_d^K = 0\\) \\(\\lambda_a^Y =0\\), \\(\\lambda_b^Y=\\frac{1}{2}\\), \\(\\lambda_c^Y=0\\), \\(\\lambda_d^Y=\\frac{1}{2}\\) and so: \\(\\lambda_b^u = \\lambda_b^K\\lambda_b^Y = \\frac{1}4\\) \\(\\lambda_d^u = \\lambda_d^Y\\) \\(p = \\frac{\\lambda_b^u}{\\lambda_b^u + \\lambda_d^u} = \\frac{1}3\\). whence: \\(\\phi_{b1} = 1\\) \\(\\phi_{d1} = \\lambda_d^K + \\lambda_b^K = \\frac{1}{2}\\) More generally we can calculate the lower bound on the probability that \\(X\\) caused \\(Y\\) as the product of the lower bounds that \\(X\\) caused \\(M\\) and that \\(M\\) caused \\(Y\\), and similarly for the upper bound, using the same formula as before. Signing things so that \\(\\tau^j\\geq 0\\), \\(j \\in {1,2}\\): \\[\\frac{2\\tau_1}{1+\\tau_1+\\rho_1}\\frac{2\\tau_2}{1+\\tau_2+\\rho_2} \\leq PC \\leq \\frac{1+\\tau_1-|\\rho_1|}{1+\\tau_1+\\rho_1}\\frac{1+\\tau_2-|\\rho_2|}{1+\\tau_2+\\rho_2} \\] We have undertaken essentially the same operations as above except that now we are placing bounds on a substantive estimand of interest rather than first placing bounds on probative value of a clue and then turning to Bayes rule to place bounds on the estimand. 15.3.2 Moderator Consider now a situation in which our case is drawn from a set of cases for which \\(X\\) and \\(K\\) were each randomly assigned. Say then that the transition matrices, conditional on \\(K\\) look as follows: \\[P^{K=0}=\\left( \\begin{array}{cc} 0 &amp; 1 \\\\ 0.5 &amp; 0.5 \\end{array}\\right), P^{K=1}=\\left( \\begin{array}{cc} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{array}\\right)\\] In this case we can now identify PC, even before observing \\(K\\). If \\(K=0\\), PC is 0there are no cases with positive effects in this condition. If \\(K=1\\) PC = 1. We have a prior that \\(K=1\\) of .5 and after observing \\(X=Y=1\\) we raise this to \\(2/3\\). Thus our prior belief on \\(PC\\)  before seeing \\(K\\) is \\(2/3 * 1 + 1/3 * 0 = 2/3\\). How about \\(\\phi_{b1}\\) and \\(\\phi_{d1}\\)? Here positive effects only arise when \\(K=1\\) and so \\(\\phi_{b1} = 1\\). \\(Y=1\\) without being cause by \\(X\\) only if \\(K=0\\) and so \\(\\phi_{b0} = 0\\). Thus we have a double decisive clue. 15.4 Causal discovery The last sectionsas well as the core content in chapters 10 and 11 Flag! showed how higher level models can be justified by reference to lower level models plus data. Even these lower level presupposed beliefs about the basic causal structure. But where does this knowledge come from? The discovery of causal structure is itself a very large field of inquiry and we cannot do it justice here. For a review see for instance Glymour, Zhang, and Spirtes (2019). Here we illustrate simply the possibility of casual discovery. We illustrate with three cases in which there is a truebut unknown modelrelating \\(X,M,\\) and \\(Y\\) to each other. Critically we assume that there are no unobserved confounding relations (this is a requirement for the PC algorithm but not for the Fast Causal Inference algorithm). In each case we show the true relationship and the skeleton of the model as discovered by a prominent technique that uses a constraint-based algorithm examining whether observed data correlations are consistent with one or other set of conditional independence relations. In the first model \\(X\\) affects \\(Y\\) directly and indirectly through \\(M\\). We simulate data from this model  assuming monotonicity but otherwise a flat distribution on types. Next we consider the model in which \\(Y\\) has two causes that do not influence each other. Finally we consider the model in which \\(X\\) causes \\(Y\\) through \\(M\\) but not directly. Again we impose monotonicity, draw data. Figure 15.2: (Partially) DAGs from Data: True DAGs in upper row with partially directed graphs in lower row. Circles indicate uncertainty whether a aroow starts or ends at a given point. In all cases we correctly recover the skeleton. Note that the o in the skeleton graphs indicate that we may have an arrow head or an arrow tail. In the first case the skeleton is unrestricted, in the second and third cases the correct restricted skeleton is found. In all cases if we have access to all relevant variables the true graph can be recovered with knowledge of the temporal ordering of variables. Perhaps the most impressive of these discoveries is the last: here \\(X\\), \\(M\\) and \\(Y\\) are all correlated with each other, but the correct graph is discovered because \\(X\\) and \\(M\\) are not correlated with each other conditional on \\(M\\). The second graph is also impressive as here we observe arrow heads in the estimated graphs. Thus even without knowledge of the timing of the variables the algorithm indicate that \\(X_1\\) and \\(X_2\\) are not children of \\(Y\\)  it sees, in essence, data patterns that are distinctive of colliders\\(X_1\\), \\(X_2\\) correlated conditional on \\(Y\\) but not otherwise. With that said, if confounding is possible we do not know for sure whether \\(Y\\) is a child of \\(X_1\\) or whether \\(Y\\) and \\(X_1\\) are confounded. These examples provide grounds for hope that causal models can be discovered and not simply assumed. In cases in which unobserved confounding is possible the results do not identify a unique causal structure. If all nodes are known and measured howevera tall order for surecausal structures can be identified from data. 15.5 Exercise Imagine a model in which in fact \\(X \\rightarrow Y \\leftarrow K\\) but in which the researcher knows only the temporal ordering of variables. Say in fact that on average \\(X\\) and \\(K\\) both have strong positive effects on \\(Y\\) with positive interactions. Can access to observational data provide a justification for using \\(K\\) as a clue for the effect of \\(X\\) on \\(Y\\) in an \\(X=Y=1\\) case? References "]]
