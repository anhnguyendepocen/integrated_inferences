[["final-words.html", "Chapter 17 Final Words 17.1 The benefits 17.2 The worries 17.3 The future", " Chapter 17 Final Words The central idea of this book is that we can usefully learn about the world by combining new evidence with prior causal models to produce updated models of how the world works. When asking specific questionssuch as whether this caused that or whether one or other channel is importantwe look up answers in our updated model of causal processes rather than seeking to the question directly from data. This way of thinking about learning is very different to many standard approaches in the social sciences. It promises benefits, but it also comes with risks. We try to describe both in this closing chapter. The approach stands in particularly stark contrast to the design based approach to causal inference, which has gained prominence in recent years. Design based approaches have shown that it is possible to greatly diminish the role of background assumptions for some research questions and contexts. This is a remarkable achievement that has put the testing of some hypotheses and estimation of some causal quantities on a firmer footing. It allows researchers to maintain agnostic positions and base their inferences more solidly on what they know to be truesuch as how units were sampled and how treatments were assignedand less on speculations about background data generating processes. At the same time, there are limits to model-free social science that affect the kinds of questions we can ask and the conditions we need to be in place to able to generate an answer. Building on pioneering work by scholars in computer science, statistics, and philosophy, we have outlined a principled approach to mobilizing prior knowledge to learn from new data in situations where randomization is unavailable and to answer questions for which randomization is unhelpful. In this approach, causal models are guides to research design, machines for inference, and objects of inquiry. As guides, the models yield expectations about the learning that can be derived from a given case or set of cases and from a given type of evidence, conditional on the question being asked. As inferential machines, models allow updating on that query once the data are in hand. Finally, when we confront a model with data, we learn about the parameters of the model itself, which can be used to answer a range of other causal questions and allowing cumulation of knowledge across studies. To complement the conceptual infrastructure we have provided software tools that let researchers build, update, and query binary causal models. 17.1 The benefits Strategies centered on building, updating, and querying causal models come with a set of striking advantages. Many questions. When we update a causal model, we do not estimate a single causal quantity of interest: we learn about the model. Most concretely, when we encounter new data, we update our beliefs about all parameters in the model at the same time. We can then use the updated parameters to answer very broad classes of causal questions, well beyond the population-level average effect. These include case-level questions (Does \\(X\\) explain \\(Y\\) in this case?), process questions (Through which channel does \\(X\\) affect \\(Y\\)?), and transportability questions (What are the implications of results derived in one context for processes and effects in other contexts?). Common answer strategy. Strikingly, these diverse types of questions are all asked and answered in this approach using the same procedure: forming, updating, and querying a causal model. Likewise, once we update a model given a set of data, we can then pose the full range of causal queries to the updated model. In this respect, the causal models approach differs markedly from common statistical frameworks in which distinct estimators are constructed to estimate particular estimands. Answers without identification. The approach can be used to generate answers even when queries are not identified. The ability to identify causal effects has been a central pursuit of much social science research in recent years. But identification is in some ways a curious goal. A causal quantity is identified, if, with infinite data, the correct value can be ascertained with certaintyinformally, the distribution that will emerge is consistent with only one parameter value. Oddly, however knowing that a model, or quantity, is identified in this way does not tell you that estimation with finite data is any good (Maclaren and Nicholson 2019). Nor is estimation of a non-identified model with finite data necessarily bad. While there is a tendency to discount models for which quantities of interest are not identified, in fact it is relatively easy to see that conisderable learning is possible even without identification, using the same procedure of updating and querying models. Updating non-identified models can lead to a tightening of posteriors, even if some quantities can never be distinguished from each other. Integration Embedding inference within an explicit causal model brings about an integration across forms of data and beliefs that may otherwise develop in isolation from one another. For one thing, the approach allows us to combine arbitrary mixes of forms of evidence, including data on causes and outcomes and evidence on causal processes (whether from the same or different sets of cases). Further, the causal-model approach ensures that our findings about cases (given evidence about those cases) are informed by what we know about the population to which those cases belong, and vice versa. And, as we discuss further below, approach generates integration between inputs and outputs into the inferential process: it ensures that the way in which we update from the data is logically consistent with our prior beliefs about the world. A framework for knowledge cumulation. Closely related to integration is cumulation: a causal-model framework provides a ready-made apparatus for combining information across studies. Thinking in meta-analytic terms, the framework provides a mechanism for combining the evidence from multiple, independent studies. Thinking sequentially, the model updated from one set of data can become the starting point for the next study of the same causal domain. Yet organizing inquiry around a causal model allows for cumulation in a deeper sense as well. Compared with most prevailing approaches to observational inferencewhere the background model is typically left implicit or conveyed informally or incompletelythe approach ensures transparency about the beliefs on which inferences rest. Explicitness about starting assumptions allows us to assess the degree of sensitivity of conclusions to our prior beliefs. Sensitivity analyses cannot, of course, tell us which beliefs are right. But they can tell us which assumptions are most in need of defending, pinpointing where more learning would be of greatest value. Those features of our model about which we are most uncertain and that matter most to our conclusions  be it the absence of an arrow, a restriction, a prior over nodal types, the absence of confounding  represent the questions most in need of answers down the road. A framework for learning about strategies. As we showed in chapters 13 and 14 access to a model provides an explicit formulation of how and what inferences will be drawn from future data patterns provides a formal framework for justifying design decisions. Of course this feature is not unique to model based inferenceone can certainly have a model that describes expectations over future data patterns and imagine what inferences you will make using design based inference or any otehr procedure. Conceptual clarifications. Finally, we have found, this framework has been useful for providing conceptual clarification for how to think about qualitative, quantitative, and mixed-method inference. Consider two. The first is with respect to the difference between within-case and between-case inference. In Humphreys and Jacobs (2015), for instance, we drew on a common operationalization of quantitative and qualitative data as akin to dataset and causal process observations, respectively, as defined by Collier, Brady, and Seawright (2010) ( see also Mahoney (2000)). In a typical mixed-method setup, we might think of combining a quantitative dataset as containing \\(X\\) and \\(Y\\) (and covariate) observations for many cases with qualitative observations on causal processes, such as a mediator \\(M\\), for a subset of these cases. But this apparent distinction has no meaning in the formal setup and analysis of models. There is no need to think of \\(X\\) and \\(Y\\) observations as being tied to a large-\\(N\\) analysis or to observations of mediating or other processes as being tied to small-\\(N\\) analysis. One could, for instance, have data on \\(M\\) for a large set of cases but data on \\(Y\\) or \\(X\\) for only a small number. Updating the model to learn about the causal query of interest will proceed in the same basic manner. The cross-case/within-case dichotomy plays no role in the way inferences are drawn: given any pattern of data we observe in the cases at hand, we are always assessing the likelihood of that data pattern under different values of the models parameters. In this framework, what we have conventionally thought of as qualitative and quantitative inference strategies are not just integrated; the distinction between them breaks down completely. A second is with regards to the relationship between beliefs about queries and beliefs about the informativeness of evidence. In many accouns of process tracing, researchers posit a set of prior beliefs about the values of estimands and otherindependentbeliefs about the informativeness of within-case information (see also Fairfield and Charman (2017), Bennett (2015)). Viewd theough a cusal models lens however both sets of beliefs  about the hypothesis being examined and about the probative value of the data  represent substantive probabilistic claims about the world, and in particular about causal relationships in the domain under investigation. They, thus, cannot not be treated as generally independent of one another: our beliefs about causal relations imply our beliefs about the probative value of the evidence. These implications flow naturally in a causal-model framework. When both sets of beliefs are themselves derived from an underlying model representing prior knowledge about the domain of interest, then the same conjectures that inform our beliefs about the hypotheses also inform our beliefs about the informativeness of additional data. Seen in this way the researcher is under pressure to provide reasons to support beliefs about probative value, but more constructively, they have availabel to them a strategy to do so. 17.2 The worries While we have found the syntax of Directed Acyclic Graphs to provide a flexible framework for setting up causal models, we have also become more keenly aware of some of the limitations of DAGs in representing causal processes. We discuss a few of these here. Well defined nodes? A DAG presupposes a set of well-defined nodes that come with location and time stamps. [Point to be elaborated.] This involves a discretization of the world that may not align with how qualitative researchers study the world. For instance, qualitative researchers do not just observe that (a) domino 1 fell and (b) domino 2 fell. They observe that domino 2 fell just as domino 1 hit it. Acyclic, really? DAGs are by definition acyclic. And it is not hard to argue that, since cause precedes effect, causal relations should be acyclic for any well-defined nodes. In practice, however, our variables often come with coarse periodizations: there was or was not mobilization in the 1990s; there was or was not democratization in the 1990s. We cannot extract the direction of arrows from the definition of nodes this coarse. Coherent underlying causal accounts. The approach we describe is one in which researchers are asked to provide a coherent modelalbeit with uncertaintyregarding the ways in which nodes are causally related to each other. For instance, a researcher interested in using information on \\(K\\) to ascertain whether \\(X\\) caused \\(Y\\) is expected to have a theory of whether \\(K\\) acts as a moderator or a mediator for \\(X\\), and whether it is realized before or after \\(Y\\). Yet it is possible that a researcher has well formed beliefs about the informativeness of \\(K\\) without an underlying model of how \\(K\\) is causally related to \\(X\\) or \\(Y\\). Granted, one might wonder where these beliefs come from or how they can be defended. We nonetheless note that one limitation of the approach we have described is that one cannot make use of an observation without a coherent account of that observations causal position relative to other variables and relationships of interest. Complexity. To maintain simplicity, we have largely focused in this book on models with binary nodes. At first blush, this class of causal models indeed appears very simple. Yet even with binary nodes, complexity rises rapidly as the number of nodes and connections among them increases. As a node goes from having 1 parent to 2 parents to 3 parents to 4 parents, for instance, the number of nodal types  at that node alone  goes from 4 to 16 to 256 to 65,536, with knock-on effects for the number of possible causal types (combinations of nodal types across the model). A move in the direction of continuous variables  say, from binary nodes to nodes with 3 ordinal values  would also involve a dramatic increase in the complexity to the type-space.1 There are practical and substantive implications of this. A practical implications is that one can hit computational constraints very quickly for even moderately sized models. Substantively, models can quickly involve more complexity than humans can comfortably understand. One solution is to move away from a fully non-parametric setting and impose structure on permissible function formsfor example by imposiing motonicity or no high level interactions. A second approach might be to give up on the commitment to a complete specification of causal relations and seek lower dimensional representations of models that are sufficient for questions we care about. For instance, for an \\(X \\rightarrow Y\\) model, if we are interested in understanding the probability that \\(X\\) caused \\(Y\\) in a \\(X=Y=1\\) case we need to learn about \\(\\theta^Y_{01}\\) and \\(\\theta^Y_{11}\\). But if we care only about the average effect of \\(X\\) then we need to learn only about \\(\\theta^Y_{10}-\\theta^Y_{01}\\). In the latter case rather we might work with just two parameters: define \\(\\tau := \\theta^Y_{10}-\\theta^Y_{01}\\) and \\(\\rho := \\theta^Y_{11}-\\theta^Y_{00}\\) then in a case with \\(X=1\\), the probability that \\(Y=1\\) is \\(\\frac{1+\\tau+\\rho}{2}\\). Observations of \\(Y\\) then let us update on \\(\\tau\\) and \\(\\rho\\) without having to specify all the nodal types. Unintended structure. The complexity of causal models means that it is easy to generate a fully specified causal model with features that you do not fully udnerstand. In the same way it is possible to make choices between models unaware of differences in assuptions that they have built in. Consider three examples: e.g. changige expectations of trematne effect beliefs about share a in a X-&gt;Y model fom reg data are different to learning from the saem data in a X-&gt;M-&gt;Y model wiht M unobserved. If you specify X-&gt;M-&gt;Y &lt;-W and W is a smoking gun then it must be smokoning gund for M and for Y Model-dependence of conclusions One striking finding of some of the analyses presented here is see how sensitive conclusions can be to what would seem to be quite modest changes to models. We see two ways of thinking about the implications of this fact for a causal-models framework. One lesson to draw would be that there are tight limits to building inference upon causal models. If results in this approach depend heavily on prior beliefs, which could be wrong, then we might doubt the utility of the framework. Perhaps all that we have done in this book is to make the case for pure design-based inference. An alternative lesson also offers itself, however. To the extent that our inferences depend on our background causal beliefs, a transparent and systematic engagement with models becomes all the more important. If inferences are not built explicitly on models, we have no way of knowing how fragile they are, how they would change under an alternative set of premises, or what kind of learning we need to undertake if we want to generate more secure conclusions. We do not see causal models as the only way forward or as a panacea, and we are conscious of the limitations and complexities of the approach we have outlined, as well as the need for extension and elaboration along numerous fronts. Yet we think there is value in further development of forms of empirical social science that can operate with analytic transparency outside the safe inferential confines of random assignment. 17.3 The future The two of us began this intellectual journey by developing an approach to Bayesian mixed-method analysis in which the researcher stipulates priors beliefs about estimands, the probative value of the evidence, and selection into assignment. A dissatisfcation we had with this approach was that it seemed to lack foundations: where do prior beliefs about estimands, probative value, and assignment come from? And how do we ensure internal consistency across these beliefs? This book answer represents our answer to that problem: a causal model allows the researcher to write down a set of elemental causal beliefs, from which all else  priors, probative value, selection effects  flows. Yet this answer raises its own question about foundations: where do our causal models come from? While we have provided some guidance on how to construct models and evaluate them, we have largely bracketed the question of how researchers might form, extract, or elicit the substantive causal beliefs that inform models. We see the development of transparent, systematic approaches to model construction as an important next step in the elaboration of the framework. One could imagine multiple approaches to model-generation, and we seek here to outline a set of desiderata toward which any model-generating technique might plausibly be oriented. 1. Theoretical grounding and coherence. One desirable feature of a causal model is that its implied claims make sense. Another way to put the point is that a good causal model will usually be interpretable by reference to a plausible theoretical logic. For instance, if our model allows for high inequality to cause mass mobilization, we might place a value on that feature of the model being underwritten by a set of defensible claims about the mechanism through which that effect might unfold. A further concern might be the coherence of the model. Suppose that we write down a \\(Inequality \\rightarrow Mobilization \\rightarrow Democratization \\leftarrow PriceInflation\\) model. Do the claims embedded in this model hold together, given the underlying theoretical logics? For instance, is it consistent to allow inequality to have an effect on mobilization but exclude inflation from operating through mobilization? If economic grievances can provoke mass mobilization, as in inequalitys effect, should we not also allow for rising food prices to have a similar effect? A theoretical logic will almost never be sufficient to justify a particular model, as there will generally be too many potential theoretical logics around a given domain to narrow down the possibilities sufficiently (especially taking the complexity desideratum, below, into account). Not will a theoretical logic be strictly necessary for a useful causal model. One could imagine allowing for an effect on \\(X\\) on \\(M\\) in a model based on empirical  perhaps experimental  evidence of such an effect, absent a theorization of the mechanism. 2. Consistency with all prior information. Another desirable property of a procedure for generating causal models would be a maximally complete, accurate incorporation of the information available prior to analysis that speaks to causal relationships within the domain of interest. In general, this desideratum is likely to act as a conservative constraint on the strength of beliefs embedded within a model. For instance, one set of prior information might point toward an \\(X \\rightarrow M \\rightarrow Y\\) chain of effects, yet this is a relatively restrictive model. Incorporating more prior information is unlikely to definitively discredit the possibility of this causal chain, but it might well yield evidence of pathways from \\(X\\) to \\(Y\\) that do not include \\(M\\). And if it does, then consistency with prior information would require us to add a direct link from \\(X\\) to \\(Y\\), generating a less restrictive model. IS THIS POINT FRAMED RIGHT? OR SHOULD IT INSTEAD BE ABOUT NOT MAKING STRONGER CLAIMS THAN THE PRIOR INFO JUSTIFIES (WHEREAS THE NEXT POINT IS ABOUT NOT MAKING WEAKER CLAIMS THAN YOU CAN)? 3. Leverage. As we have shown throughout this book, some models will provide more empirical leverage than others, in the sense that observations of their nodes will have greater probative value. Leverage typically derives from the strength of the prior beliefs embedded in a model. For instance, the causal model \\(X \\rightarrow M \\rightarrow Y\\) will tend to provide strong opportunities for updating than the model \\(X \\rightarrow M \\rightarrow Y\\) if we also have non-uniform beliefs over \\(X\\)s effects on \\(M\\) and \\(M\\)s effects on \\(Y\\). One way to put this is that we dont want to leave precision on the table. While we do not want our models to build in stronger beliefs than prior information can justify, we also would not want a model-generating procedure to yield models that are weaker than they could be. 4. Tractability. More complex models are harder to work with. As the number of a nodes parents increases, for instance, the number of nodal types increases steeply. It becomes accordingly harder for researchers to conceptualize and form meaningful priors over these nodal types. Moreover, the computational demands of operating even moderately complex models can be very high. 5. Transparency. Ideally, we would want any model-generating procedure to make use of prior information via an explicit, transparent set of procedures. If one researcher derives a model, a second researcher should be able to see clearly how the model was generated and, in turn, to assess how the model might have changed if additional or different information had been incorporated. 6. Reliability The procedure should ideally yield the same model, with the same restrictions and priors, when repeated and regardless of which researcher is implementing the procedure. COMBINE WITH TRANSPARENCY?? 7. Dynamic adaptability. Closely related to transparency is dynamic adaptibility. The base of prior information on any topic is constantly changing, and we would value a procedure that allows our models to adapt accordingly. It would be helpful if a procedure that generated a model at time \\(t\\) could be incrementally updated in light of new information for use at time \\(t+k\\). There will tend to be tradeoffs across these desiderata. For instance, tractability will sometimes be in tension with a full, accurate use of prior information. As we broaden the base of prior information, we are likely to add nodes as well as arrows (representing possible direct causal effects) between existing nodes. Likewise, taking more prior information into account may mean giving up leverage if, for instance, additional information makes us less certain about the prior weights over nodal types. Some desiderata will be complementary, however: models with more leverage will often include restrictions on nodal types, which will also reduce complexity. In any case, we expect that no single procedure will be able to maximize all desiderata at the same time. Consider a few operational possibilities: Crowdsourcing: One could imagine a platform that allowed researchers to gather and aggregate prior causal beliefs from a set of experts within a field of inquiry. Experts could be asked to weigh in on relationships among a fixed set of variables: which variables have direct effects on which? Experts could also be invited to add nodes, for instance, as mediators between the original set of nodes, as confounders, or as colliders. To generate restrictions and priors, experts could also be asked what kinds of effects (positive, negative, null) are relatively more and less likely. Instruments for eliciting such beliefs might vary widely, but one approach could be a conjoint design: for each node, respondents are presented, successively, with paired sets of assigned values for the nodes parents and then asked for which pair of parental values they expect the node itself to take on a higher value. Crowdsourcing would likely perform well in achieving comprehensiveness of the prior information base insofar as experts will be, at least implicitly, drawing on a wide range of observations, findings in the literature, and theoretical insights. The procedure is transparent insofar as the elicitation methods, expert sampling frame, and expert responses can be shared; on the other hand, we would have little insight into what information experts themselves have drawn on in arriving at their beliefs. The reliability of a crowdsourced procedure would depend in part on how large the crowd is: how many experts can be polled on a given causal domain. A key challenge would be implementing a crowdsourcing in a way that yielded a clear grounding in internally consistent theoretical logics. It is also our hunch that crowdsourced models will tend to be more complex, given that they will likely represent a broader range of causal possibilities and a more diffuse set of beliefs over causal effects. Crowdsourcing could also be implemented adaptively, with some additional effort. One could imagine a platform that would allow new experts to register their views at any time or for old experts to update their responses as their beliefs change. Formal models: As we show in the appendix to Chapter 4, we can readily translate the implications of a game-theoretic model into a causal model. Building a causal model atop a formal model ensures clear theoretical grounding, internal consistency, transparency, and reliability (insofar as a single formal model implies a single causal model). Formal models that yield clear predictions are also likely to generate relatively strong beliefs about causal effects and, thus, a good deal of leverage. Complexity could be more or less arbitrarily determined by the modeler. A key major weakness of a formal-model-based approach would be the flip side of leverage: rather than incorporating a wide array of beliefs, a formal model would instantiate the implications of a fixed set of assumptions set out by the modeler. Moreover, there is no obvious mechanism for adapting a formal model to new information. Data-driven approach: Perhaps the most transparent, reliable, adaptive, and conservative approach to building causal models is to rest them directly and maximally on prior data. We discuss in Chapter 15 how one can use experimental data to justify models. At its most conservative, the data-driven approach might involve only building into a model beliefs that can be grounded in an explicit meta-analysis of experimental findings  yet we might also incorporate observational findings. Of course, the most natural way to implement a data-driven approach would be to start with a causal model with minimal structure and then use all available prior data to update it. And, as we show in Chapter @ref{mm}, with the right initial model we can readily update on a mixture of experimental and observational data. It would be extremely straightforward, moreover, to update a data-driven model as new findings come in. The limitations of a data-driven approach are, effectively, the flip side of its virtues. Conservatively grounded in what the data can tell us, a data-driven procedure will tend to yield models that have less structure, with higher complexity and less leverage. Involving minimal assumptions, data-derived models will also be unconstrained by theoretical logic or consistency. Even a maximally data-driven approach cannot be assumption-free. One inescapable assumption is portability: we need to believe that the model that describes the context in which the prior data were generated also applies to the context in which new data are to be generated. Crodsourced models; discpline wide agreement on models building structures so research can contribute to models connecting more thoroughly to formal theorey logical coherence modularization If, for instance, we moved to nodes with 3 ordered categories, then each of \\(Y\\)s nodal types in an \\(X \\rightarrow Y\\) model would have to register 3 potential outcomes, corresponding to the 3 values that \\(X\\) takes on. And \\(Y\\) would have \\(3 \\times 3 \\times 3 = 27\\) nodal types (as \\(Y\\) can take on 3 possible values for each possible value of \\(X\\)). "]]
