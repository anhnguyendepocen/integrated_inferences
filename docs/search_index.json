[
["final-words.html", "Chapter 17 Final Words 17.1 Gains 17.2 Lessons learned along the way 17.3 Worries about what you have to put in 17.4 Limits on what you can get out 17.5 Looking ahead", " Chapter 17 Final Words The central idea of this book is that we can learn about the world by combining new evidence with causal models that represent prior knowledge about causal relations in the domain of interest. The growth of randomized experiments and other design-based approaches over the last two decades has made it possible to dispense with or diminish the role of background assumptions for some research questions and contexts. This is a remarkable achievement that has put the testing of some hypotheses and estimation of some causal quantities on a firmer footing. At the same time, there are limits to model-free social science. In particular, design-based inference relies on (as-good-as) random assignment by the researcher or by nature, placing bounds on the kinds of causes and contexts we can investigate. The approach is also generally limited to estimating a single causal quantity: the average causal effect. Building on pioneering work by scholars in computer science, statistics, and philosophy, we have outlined a principled approach to, and provided software tools for, mobilizing prior knowledge to learn from new data in situations where randomization is unavailable and to answer questions for which randomization is unhelpful. In this approach, causal models are guides to research design, machines for inference, and objects of inquiry. As guides, the models yield expectations about the learning that can be derived from a given case or set of cases and from a given type of evidence, conditional on the question being asked. As inferential machines, models allow updating on that query once the data are in hand. Finally, when we confront a model with data, we learn about the parameters of the model itself, which can be used to answer a range of other causal questions and allowing cumulation of knowledge across studies. 17.1 Gains The approach provides, we think, many stengths. Many questions. An advantage of the approach is the ability to answer very broad classes of causal questions, well beyond the population-level average effect, so central to much research in contemporary political science. These include case level questions (Does \\(X\\) explain \\(Y\\) in this case?), process questions (Through which channel does \\(X\\) affect \\(Y\\)?), and transportability questions (What are the implications of results derived in one context for processes and effects in other contexts?). Common answer strategy. Strikingly, these diverse types of questions are all asked and answered in this approach using a similar procedure: forming, updating, and querying a causal model. Likewise, once we update a model given a set of data, we can then pose the full range of causal queries to the updated model. In this respect, the causal models approach differs markedly from common statistical frameworks in which distinct estimators are constructed to estimate particular estimands. Answers without identification. The approach can be used to generate answers even when queries are not identified. The ability to “identify” causal effects has been a central pursuit of much social science research in recent years. But identification is in some ways a curious goal. A causal quantity is identified, if, with infinite data, the correct value can be ascertained with certainty—informally, the distribution that will emerge is consistent with only one parameter value. Oddly, however knowing that a model, or quantity, is identified in this way does not tell you that estimation with finite data is any good (Maclaren and Nicholson 2019). Nor is estimation of a non-identified model with finite data necessarily bad. While there is a tendency to discount models for which quantities of interest are not identified, in fact it is relatively easy to see that conisderable learning is possible even without identification, using the same procedure of updating and querying models. Updating non-identified models can lead to a tightening of posteriors, even if some quantities can never be distinguished from each other. Integration Embedding inference within an explicit causal model brings about an integration across forms of data and beliefs that may otherwise develop in isolation from one another. For one thing, the approach allows us to combine arbitrary mixes of forms of evidence, including data on causes and outcomes and evidence on causal processes (whether from the same or different sets of cases). Further, the causal-model approach ensures that our findings about cases (given evidence about those cases) are informed by what we know about the population to which those cases belong, and vice versa. And, as we discuss further below, approach generates integration between inputs and outputs into the inferential process: it ensures that the way in which we update from the data is logically consistent with our prior beliefs about the world. Clarification of which inputs need to be defended. The answers we get from the approach are necessarily model-dependent. But compared with most prevailing approaches to observational inference—where the background model is typically left implicit or conveyed informally or incompletely—the approach ensures transparency about the beliefs on which inferences rest. This allows us then to assess the degree of sensitivity of conclusions to our prior beliefs. As we have developed the approach, our thinking about qualitative, quantitative, and mixed-method inference has shifted. In using causal models and seeing their benefits, we have have also developed a keener sense of the risks they entail. We outline these lessons and these risks next. 17.2 Lessons learned along the way We note three ways in which our thinking about inference evolved in the course of this project. “Within” vs. “Between” Case Evidence. We embarked on this project motivated by an interest in how qualitative and quantitative data could be formally combined to draw case- and population-level causal inferences. In Humphreys and Jacobs (2015), we drew on a common operationalization of “quantitative” and “qualitative” data as akin to “dataset” and “causal process” observations, respectively, as defined by Collier, Brady, and Seawright (2010); this is a distinction that roughly maps onto somewhat older notions of “cross-case” and “within-case” forms of analysis (Mahoney (2000)). In a typical mixed-method setup, we might think of combining a “quantitative” dataset as containing \\(X\\) and \\(Y\\) (and covariate) observations for many cases with “qualitative” observations on causal processes, such as a mediator \\(M\\), for a subset of these cases. In fact, as we came to realize, the apparent distinction here between forms of data has no meaning in the formal setup and analysis of models. There is no need to think of \\(X\\) and \\(Y\\) observations as being tied to a large-\\(N\\) analysis or to observations of mediating or other processes as being tied to small-\\(N\\) analysis. One could, for instance, have data on \\(M\\) for a large set of cases but data on \\(Y\\) or \\(X\\) for only a small number. Updating the model to learn about the causal query of interest will proceed in the same basic manner. The cross-case/within-case dichotomy plays no role in the way inferences are drawn: given any pattern of data we observe in the cases at hand, we are always assessing the likelihood of that data pattern under different values of the model’s parameters. In this framework, what we have conventionally thought of as qualitative and quantitative inference strategies are not just integrated; the distinction between them breaks down completely. A single system. Our initial thinking about integrating inferences was not particularly well integrated. In Humphreys and Jacobs (2015), we posited a set of prior beliefs with which the researcher would begin, including beliefs about the values of estimands (\\(\\lambda\\) values) and beliefs about the informativeness of within-case (clue) information (\\(\\phi\\) values). These sets of beliefs were essentially independent of one another, as they are in many accounts of process tracing, including Bayesian approaches (Fairfield and Charman (2017), Bennett (2015)). In the standard Bayesian approach, one articulates a degree of confidence in some hypothesis about the world and one articulates a belief about the value of the evidence one goes looking for (e.g, that the search for the evidence constitutes a “hoop test” for the hypothesis). And these two sets of beliefs can be arbitrarily combined. What we came to realize, however, was that both sets of beliefs — about the hypothesis being examined and about the probative value of the data — represent substantive probabilistic claims about the world, and in particular about causal relationships in the domain under investigation. They, thus, cannot not be treated as generally independent of one another: our beliefs about causal relations imply our beliefs about the probative value of the evidence. These implications flow naturally in a causal-model framework. When both sets of beliefs are themselves derived from an underlying model representing prior knowledge about the domain of interest, then the same conjectures that inform our beliefs about the hypotheses also inform our beliefs about the informativeness of additional data. Pretending to have priors. As we explored the world of causal models, we started out thinking that, in providing priors over causal relations, one is directly stating beliefs about how the world works. For instance, one might believe that either \\(X\\) caused \\(Y\\) or that it did not; and one might believe either that \\(M=1\\) should be observe in the event that \\(X\\) caused \\(Y\\) or it should not be. These statements are, in fact, clearly model-dependent. Beyond the model required to describe events in such crisp terms, the statements involve counterfactuals on counterfactuals—models of causal processes. Once a model involves assertions of conditional independence, we are clearly in the business of dealing in simplifications. Our priors become less statements of how we believe the world works to becoming somewhat statements about what set of models are least bad within a class of tractable abstractions. 17.3 Worries about what you have to put in While we have found the syntax of Directed Acyclic Graphs to provide a flexible framework for setting up causal models, we have also become more keenly aware of some of the limitations of DAGs in representing causal processes. We discuss a few of these here. Well defined nodes? A DAG presupposes a set of well-defined nodes that come with location and time stamps. [Point to be elaborated.] This involves a discretization of the world that may not align with how qualitative researchers study the world. For instance, qualitative researchers do not just observe that (a) domino 1 fell and (b) domino 2 fell. They observe that domino 2 fell just as domino 1 hit it. Acyclic, really? DAGs are by definition acyclic. And it is not hard to argue that, since cause precedes effect, causal relations should be acyclic for any well-defined nodes. In practice, however, our variables often come with coarse periodizations: there was or was not mobilization in the 1990s; there was or was not democratization in the 1990s. We cannot extract the direction of arrows from the definition of nodes this coarse. Coherent underlying causal accounts. The approach we describe is one in which researchers are asked to provide a coherent model—albeit with uncertainty—regarding the ways in which nodes are causally related to each other. For instance, a researcher interested in using information on \\(K\\) to ascertain whether \\(X\\) caused \\(Y\\) is expected to have a theory of whether \\(K\\) acts as a moderator or a mediator for \\(X\\), and whether it is realized before or after \\(Y\\). Yet it is possible that a researcher has well formed beliefs about the informativeness of \\(K\\) without an underlying model of how \\(K\\) is causally related to \\(X\\) or \\(Y\\). Granted, one might wonder where these beliefs come from or how they can be defended. We nonetheless note that one limitation of the approach we have described is that one cannot make use of an observation without a coherent account of that observation’s causal position relative to other variables and relationships of interest. 17.4 Limits on what you can get out Complexity. To maintain simplicity, we have largely focused in this book on models with binary nodes. At first blush, this class of causal models indeed appears very simple. Yet even with binary nodes, complexity rises rapidly as the number of nodes and connections among them increases. As a node goes from having 1 parent to 2 parents to 3 parents, for instance, the number of nodal types — at that node alone — goes from 4 to 16 to 64, with knock-on effects for the number of possible causal types (combinations of nodal types across the model). A move in the direction of continuous variables — say, from binary nodes to nodes with 3 ordinal values — would also involve a dramatic increase in the complexity to the type-space. A potential solution is to move away from a fully non-parametric setting and impose structure on permissible function forms. [To expand on this point] Limits of qualitative data under ignorable assignments. A key payoff deploying causal models is the prospect of combining in-depth observations of a small number of cases with less-intensive investigation of a larger number of cases. Yet one of the lessons of the foregoing analysis is that the gains to such mixing may be limited. For instance, where the causal effect of \\(X\\) on \\(Y\\) can be identified (assignment of \\(X\\) is as-good-as random), one will learn little about this effect from process observations in a small number of cases. Put differently, case studies simply cannot add much to experimental estimates of the ATE, though there may be other queries of interest on which small-\\(N\\) process evidence can be informative. [To be expanded] Model-dependence of conclusions One striking finding of some of the analyses presented here is see how sensitive conclusions can be to what would seem to be quite modest changes to models. We see two ways of thinking about the implications of this fact for a causal-models framework. One lesson to draw would be that there are tight limits to building inference upon causal models. If results in this approach depend heavily on prior beliefs, which could be wrong, then we might doubt the utility of the framework. Perhaps all that we have done in this book is to make the case for pure design-based inference. An alternative lesson also offers itself, however. To the extent that our inferences depend on our background causal beliefs, a transparent and systematic engagement with models becomes all the more important. If inferences are not built explicitly on models, we have no way of knowing how fragile they are, how they would change under an alternative set of premises, or what kind of learning we need to undertake if we want to generate more secure conclusions. We do not see causal models as the only way forward or as a panacea, ad we are exquisitely aware of the limitations and complexities of the approach we have outlined, as well as the need for extension and elaboration along numerous fronts. Yet we think there would be value in further development of forms of empirical social science that can operate with analytic transparency outside the safe inferential confines of random assignment. 17.5 Looking ahead References "]
]
