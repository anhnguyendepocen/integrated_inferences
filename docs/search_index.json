[
["mm.html", "Chapter 10 Mixing models 10.1 A jigsaw puzzle: Learning from multiple models 10.2 Combining observational and experimental data 10.3 Transportation of findings across contexts", " Chapter 10 Mixing models We provide three examples of situations in which by combining models, researchers learn more than they could from any single model. 10.1 A jigsaw puzzle: Learning from multiple models Consider a situation in which we believe the same model holds in multiple sites but in which learning about the model requires combining data about different parts of the model from multiple studies. The graph is not too interesting in this example, what is more interesting is the data structure We imagine we have access to three types of data; Study 1 is a factorial study examining the joint effects of \\(X\\) and \\(Z\\) on \\(Y\\), \\(K\\) is not observed Study 2 is an RCT looking at the relation between \\(Z\\) and \\(K\\). \\(X\\) and \\(Y\\) are not observed. Study 3 is an RCT looking at the effects of \\(X\\) on \\(Y\\), ancillary data on context, \\(K\\) is collected, but \\(Z\\) is not observed For each study we can ask: what is the probability that \\(X\\) caused \\(Y\\) in \\(X=Y=1\\) cases conditional on \\(K\\). Table 10.1 gives the answers. In each case the conclusion does not depend on \\(K\\)—though part of the causal model, and available in data in 2 cases, the individual studies don’t have enough information about the full model to be able to make use of \\(K\\). In study 1 data on \\(K\\) is not available, in study 2 it is available but researchers do not know, quantitatively, how it relates to \\(Z\\). In the third study the \\(Z,K\\) relationship is well understood but the joint relation between \\(Z,X\\), and \\(Y\\) is not understood. Table 10.1: The clue \\(K\\) uninformative in all three studies Study Given mean sd 1 X == 1 &amp; Y == 1 &amp; K == 1 0.530 0.123 X == 1 &amp; Y == 1 &amp; K == 0 0.529 0.121 2 X == 1 &amp; Y == 1 &amp; K == 1 0.503 0.161 X == 1 &amp; Y == 1 &amp; K == 0 0.502 0.161 3 X == 1 &amp; Y == 1 &amp; K == 1 0.501 0.165 X == 1 &amp; Y == 1 &amp; K == 0 0.502 0.162 Table 10.2 shows the inferences when the data are combined with joint updating across all parameters. In this case fuller understanding of the model lets researchers use information on \\(K\\) to update on values for \\(Z\\) and in turn update on the likely effects of \\(X\\) on \\(Y\\). Rows 3-4 highlight that the updating works through inferences on \\(Z\\) and there if \\(Z\\) is known (whether it is equal to 0 or 1), as in Study 2, there are no additional gains from knowledge of \\(K\\). Table 10.2: Clue is informative after combining studies linking \\(K\\) to \\(Z\\) and \\(Z\\) to \\(Y\\) Given mean sd X == 1 &amp; Y == 1 &amp; K == 1 0.76 0.09 X == 1 &amp; Y == 1 &amp; K == 0 0.49 0.07 X == 1 &amp; Y == 1 &amp; K == 1 &amp; Z == 1 0.80 0.09 X == 1 &amp; Y == 1 &amp; K == 0 &amp; Z == 1 0.80 0.09 Thus the collection of studies collectively allow for inferences that are not possible from any one study. In Chapter 15 we will discuss justifications for model based inference, but we note already that in this example we have an instance in which a researcher (examining a case in study 3) might wish to draw inferences using \\(K\\), but she does not have anything in study 1 that justifies using \\(K\\) for inference. However with access to studies 2 and 3, and conditional on the overall model, she has a justification for process tracing strategy. The general principle is that weaker commitments to lower level theories —here the causal structure—can justify more fully inferences from more fully specifie higher level theories. 10.2 Combining observational and experimental data Experimental studies are sometimes referred to as gold standard. But an interesting weakness of experimental studies is that, by dealing so effectively with self selection into treatment, they limit our ability to learn about self selection. Often however we want to know what causal effects would be specifically for people that would take up a treatment in non experimental settings. This kind of problem is studied for example by Knox et al. (2019). A causal model can encompass both experimental and observational data and let you answer this kind of question. To illustrate, imagine that node \\(R\\) indicates whether a unit was assigned to be randomly assigned to treatment (\\(X=Z\\) if \\(R=1\\)) or took on its observational value (\\(X=O\\) if \\(R=0\\)). We assume the exclusion restriction that entering the experimental sample is not related to \\(Y\\) other than through assignment of \\(X\\). We plot the model in Figure 10.1. Figure 10.1: A model that nests an observational and an experimental study. The treatment \\(X\\) either takes on the observational value \\(O\\), or the assigned values \\(Z\\), depending on whether or not the case has been randomized, \\(R\\). In this model, \\(X\\) has only one causal type since its job is to operate as a kind of switch, inheriting the value of \\(Z\\) or \\(O\\) depending on \\(R\\). Parameters allow for complete confounding between \\(O\\) and \\(Y\\) but \\(Z\\) and \\(Y\\) are unconfounded. We imagine parameter values in which there is a true .2 effect of \\(X\\) on \\(Y\\). However the effect is positive (.6) for cases in which \\(X=1\\) under observational assignment but negative (-.2) for cases in which \\(X=0\\) under observational assignment. (See appendix for complete specification.) The implied estimands and priors are as in Table 10.3. Table 10.3: Estimands in different sites Query Given Using mean sd ATE - parameters 0.2 ATE - priors 0.0 0.26 ATE R==0 parameters 0.2 ATE R==0 priors 0.0 0.26 ATE R==1 parameters 0.2 ATE R==1 priors 0.0 0.26 The true effect is .2 but naive analysis on the observational data would yield a strongly upwardly biased estimate. Table 10.4 shows differences-in-means estimates using data on observational units only drawn from this model. Table 10.4: Inferences on the ATE from differences in means Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF X 0.845 0.026 32.937 0 0.794 0.896 199 The estimates from updating on the full model, shown in Table 10.5, are much better. Table 10.5: Estimates on the ATE for observational (\\(R=0\\)) and experimental (\\(R=1\\)) set. Query Given Using mean sd ATE - posteriors 0.203 0.031 ATE R==0 posteriors 0.203 0.031 ATE R==1 posteriors 0.203 0.031 Since the model used both the experimental and the observational data, it is interesting to ask whether the observational data improved the estimates of the treatment effect or does inference draw only from the experimental data? We answer the question in the appendix by updating using experimental data only. We find there that we do indeed get a tightening of posterior variance and a more accurate result when we use the observational data but that the gains are relatively small: the experimental data alone is quite powerful. The gains would be smaller still if we had more data, in which case inferences from the experimental data would be more accurate still. However we do learn something of particular interest from this model. A key feature here is that there is heterogeneity between those that are in treatment and those that are in control in the observational sample. We learn nothing about this heterogeneity from the experimental data alone but we learn a lot from the mixed model, picking up the strong self selection into treatment in the observational group: Table 10.6: Effects of \\(X\\) conditional on \\(X\\) for units that were randomly assigned or not. Effects of \\(X\\) do not depend on \\(X\\) in the experimental group, but they do in the observational group becuase of seld selection. Query Given Using mean sd ATE R==1 &amp; X==0 posteriors 0.203 0.031 ATE R==1 &amp; X==1 posteriors 0.203 0.031 ATE R==0 &amp; X==0 posteriors -0.183 0.027 ATE R==0 &amp; X==1 posteriors 0.593 0.048 In essence by mixing the experimental and observational data we can learn what the effects for those that self select into treatment and what they would be for those that self select into control. The results here relate to the LATE theorem (Angrist and Imbens 1995) in the following way. If we imagine using data only on (a) the experimental group in control and (b) the observational group, some of whom are in treatment, we can conceptualize our design as one in which the observational group are “encouraged” to take up treatment and we figure out the effect for the compliers in this group (those that self select into treatment). At the same time if we imagine using data only on (a) the experimental group in treatment and (b) the observational group, some of whom are in control, we can conceptualize our design as one in which the observational group are “encouraged” to take teh control condition and we figure out the effect for the compliers in this group (those that self select into control). 10.3 Transportation of findings across contexts Say we study the effect of \\(X\\) on \\(Y\\) in case 0 (a country, for instance) and want to make inferences to case 1 (another country). Our problem however is that effects are heterogeneous and features that differ across units may be related both to treatment assignment, outcomes, and selection into the sample. This is the problem studied by Pearl and Bareinboim (2014). In particular Pearl and Bareinboim (2014) show for which nodes data is needed in order to “licence” external claims, given a model. We illustrate with a simple model in which a confounder has a different distribution in a study site and a target site. Figure 10.2: Extrapolation when confounders have different distributions across cases. Table 10.7: Priors and true values (parameters) for three estimand: the frequency of \\(W\\), the effect of \\(X\\) on \\(Y\\), and the effect conditional on \\(W=1\\) Query Given Using mean sd Incidence Case==0 priors 0.334 0.237 Incidence Case==0 parameters 0.333 Incidence Case==1 priors 0.666 0.238 Incidence Case==1 parameters 0.667 ATE Case==0 priors 0.002 0.140 ATE Case==0 parameters 0.333 ATE Case==1 priors 0.003 0.142 ATE Case==1 parameters 0.573 CATE Case==0 priors 0.002 0.174 CATE Case==0 parameters 0.812 CATE Case==1 priors 0.002 0.174 CATE Case==1 parameters 0.812 Priors and estimands (parameters) are show in Table 10.7. We see that the incidence of \\(W\\) as well as the ATE of \\(X\\) on \\(Y\\) is larger in case 1 than in case 0 (in parameters, though not in priors). However the effect of \\(X\\) on \\(Y\\) conditional on \\(W\\) is the same in both places. We now update the model using data on \\(X\\) and \\(Y\\) only from one case (case 1) and data on W from both and check inferences on the other. Table 10.8: Extrapolation when two sites differ on \\(W\\) and \\(W\\) is observable in both sites Query Given Using mean sd Incidence Case==0 posteriors 0.336 0.007 Incidence Case==0 parameters 0.333 Incidence Case==1 posteriors 0.661 0.007 Incidence Case==1 parameters 0.667 ATE Case==0 posteriors 0.340 0.011 ATE Case==0 parameters 0.333 ATE Case==1 posteriors 0.570 0.009 ATE Case==1 parameters 0.573 CATE Case==0 posteriors 0.810 0.009 CATE Case==0 parameters 0.812 CATE Case==1 posteriors 0.810 0.009 CATE Case==1 parameters 0.812 We do well in recovering the (different) effects both in the location we study and the one in which we do not. In essence querying the model for the out of sample case requests a type of post stratification. We get the right answer, though as always this depends on the model being correct. Had we attempted to make the extrapolation without data on \\(W\\) in country 1 we would get it wrong. In that case however we would also report greater posterior variance. The posterior variance here captures the fact that we know things could be different in country 1, but we don’t know in what way they are different. Note that we get the CATE right since in the model this is assumed to be the same across cases. Table 10.9: Extrapolation when two sites differ on \\(W\\) and \\(W\\) is not observable in target country. Query Given Using mean sd Incidence Case==0 posteriors 0.329 0.007 Incidence Case==0 parameters 0.333 Incidence Case==1 posteriors 0.675 0.007 Incidence Case==1 parameters 0.667 ATE Case==0 posteriors 0.319 0.011 ATE Case==0 parameters 0.333 ATE Case==1 posteriors 0.572 0.009 ATE Case==1 parameters 0.573 CATE Case==0 posteriors 0.811 0.009 CATE Case==0 parameters 0.812 CATE Case==1 posteriors 0.811 0.009 CATE Case==1 parameters 0.812 References "]
]
