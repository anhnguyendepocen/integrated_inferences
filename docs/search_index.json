[["mixing.html", "Chapter 9 Integrated inferences 9.1 Theres only ever one case 9.2 General procedure 9.3 Illustrated inferences 9.4 Considerations 9.5 Principles of reasoning about learning 9.6 Conclusion", " Chapter 9 Integrated inferences We extend the analysis of Chapter 7 to cases with population data. In these cases we get to learn about the distribution of causal effects and are able to update the models we use for case level inference. The main goal of this chapter is to generalize the model developed in Chapter 7 to research situations in which we have data on multiple cases. We start however with a conceptual point: the structure introduced in Chapter 6 for single case analysis can be used as is for multi-case analysis. Thus the conceptual work for mixed methods inference from models has been done already. Our goal here is more technicalhow to exploit assumptions regarding independence across cases to generate simpler models causal processes that affect many units. As we do so we provide microfoundations for the models in Chapter 6 (as with those in Humphreys and Jacobs (2015)) with the probative value of clues deriverable from a causal structure and data. 9.1 Theres only ever one case Conceptualized correctly, there is no deep difference between the logic of inference used in single case and many case studies. The reason is not, as King, Keohane, and Verba (1994) suggest, that all causal inference is fundamentally correlational, even in seemingly single case studies. Nor is the point that single case studies can be disaggregated into many cases. The intuition, we think, really runs in the opposite direction: fundamentally, model-based inference always involves comparing a pattern of data with the logic of the model. Studies with multiple cases can be conceptualized as single-case studies: the drawing of inferences from a single collection of clues. In practice, when we move from a causal model with one observation to a causal model with multiple observations, we can use the structure we introduced in Chapter 6 but simply replace nodes that have a single value (i.e., scalars) with nodes containing multiple values (i.e., vectors). We then make inferences about the relations between vectors from seeing the values of those vectors, or other vectors that serve as clues. To illustrate, consider the following situation. There are two units studied, drawn from some population, a binary treatment \\(X\\) is assigned independently with probability .5 to each case; an outcome \\(Y\\) along with clue variable \\(K\\) is observable. We suppose \\(X\\) can affect \\(Y\\) and in addition there is a background, unobserved, variable \\(\\theta\\) (causal type) that takes on values in \\(\\{a,b,c,d\\}\\), that affects both \\(K\\) and \\(Y\\) (we interpret \\(\\{a,b,c,d\\}\\) as introduced in section 2.1). In particular we suppose that in any given case \\(K=1\\) whenever \\(X\\) causes \\(Y\\), and \\(K=1\\) with a 50% probability otherwise. Thus, \\(K\\) is informative about a units causal type. Note that we have described the problem at the unit level. However we can redescribe it at the population level thus: a treatment vector \\(X\\) can take on one of four values, \\((0,0), (0,1), (1,0), (1,1)\\) with equal probability (or more strictly: as determined by \\(\\theta\\)). \\(\\theta\\) is also a vector with two elements that can take on one of 16 values \\((a,a), (a,b),\\dots (d,d)\\) as determined by \\(\\lambda_\\theta\\) \\(K\\) has the same domain as \\(X\\) and \\(Y\\), and element \\(K[j]=1\\) if \\(\\theta[j]=b\\). \\(Y\\) is a vector that reflects the elements of \\(\\theta\\) and \\(X\\) in the obvious way (e.g \\(X=(0,0), \\theta=(a,b)\\) generates outcomes \\(Y=(1,0)\\). Say we are interested in the Sample Average Treatment Effect. We will consider three operations, one in which both units have \\(X\\) forced to 0 and two in which one unit has \\(X\\) set to 0 and the other has \\(X\\) set to 1. Thus we are interested in the average effect of changing one unit to treatment while the other is held in control. Note also that before our estimands were binaryof the form: is it a \\(b\\) type?and our answer was a probability; now our estimand is categorical and our answer is a distribution (what is the probability the SATE is 0, what is the probability the SATE is .5, etc) We now have a representation that maps directly onto the case level structures used in Chapters 6 and 7 and can use the tools introduced there to analyze this seemingly multi-case study. Inference Independence You can see that that representing node values in vector forms like this allows for more general vector-level mappings that could involve SUTVA violations: for instance perhaps \\(Y_i=1\\) if either \\(X_1\\) or \\(X_2 = 1\\). 9.2 General procedure In practice however thinking of nodes as capturing the outcomes on all units leads to enormous complexity. For example an exogeneous variable \\(X\\) which takes on values of 0 or 1 at random for 10 units has \\(2^{10}\\) types in this conceptualization, rather than just two when thought of at the case level. We reduce complexity however by thinking of models as operating on units and learning about models by observing multiple realizations of processes covered by the model, rather than just one. Thinking about it this way is not free however as it requires invoking independence assumptions  that outcomes in two units do not depend on each other. If we cannot stand by that assumption, then we have to build independence failures into our models. Taking this step the procedure we now use in the mixed methods works as follows: INTROUDCE CONCEPTS AND THEN ILLUSTRATE A DAG. As for process tracing, we begin with a graphical causal model specifying possible causal linkages between nodes. Our chain model for instance has DAG: \\(X \\rightarrow M \\rightarrow Y\\). Nodal types. Just as in process tracing, the DAG and variable ranges define the set of possible nodal types in the modelthe possible ways in which each variable is assigned (if exogenous) or determined by its parents (if endogenous). Causal types. And, again, a full set of nodal types gives rise to a full set of causal types, encompassing all possible combinations of nodal types across all nodes in the model. Priors. The first difference between single- and multiple-case inference lies in how we set priors on causal types. In process tracing, we set parameter values for each nodal type (or conditional nodal type, for unobserved confounding). Our parameterse.g., \\(\\lambda^X_0\\), \\(\\lambda^Y_{01}\\)represent our beliefs about the proportions of these types in the population. When we only observe a single data typedata on a single casewe do not have sufficient information to learn about the distribution of types in the population. And so we treat these population-level beliefs as fixed parameters, rather than priors that we update on. (What we update on, in process tracing, is our priors on whether a given case is of a particular type or set of types.) Likewise, uncertainty about those population-level parameters has no effect on our inferences for a single case. When we get to observe data on multiple cases, however, we have the opportunity to learn both about the cases at hand and about the population. Moreover, our level of uncertainty about population-level parameters will shape our inferences. We thus want our parameters (the \\(\\lambda\\)s) to be drawn from a prior distribution  a distribution that expresses our uncertainty and over which we can update once we see the data. While different distributions may be appropriate to the task in general, uncertainty over proportions (of cases, events, etc.) falling into a set of discrete categories is usefully described by a Dirichlet distribution, as discussed in Chapter 6. The parameters of a Dirichlet distribution (the \\(\\alpha\\)s) can be thought of as conveying both the relative expected proportions in each category and our degree of uncertainty. ADD MULTILEVEL GRAPH Box: Setting priors For a model with no unobserved confounding, setting priors requires specifying a prior distribution for each set of nodal types. Parameters are provided as vectors of positive numbers with one number for each nodal type. These numbers correspond to the \\(\\alpha\\) parameters of a Dirichlet distribution. The relative size of each number governs the the relative probability of each nodal type. The absolute sizes govern the certainty over the types. To wit. For a simple \\(X \\rightarrow Y\\) model, we have two parameter sets: one for \\(X\\)s types and one for \\(Y\\)s types. For \\(X\\)s types, we specify \\(\\alpha^X_0\\) and \\(\\alpha^X_1\\), corresponding to the nodal types \\(\\theta^X_0\\) and \\(\\theta^X_1\\), respectively. A distribution of the form (\\(\\alpha^X_0=100, \\alpha^X_1=100)\\) implies a lot of confidence that a given unit has \\(X=1\\) with probability .5. A distribution of the form (\\(\\alpha^X_0=.1, \\alpha^X_1=.1)\\) implies that either \\(X=1\\) with a high probability (for all units) or \\(X=0\\) with a low probability (for all units), but we are not sure which. For \\(Y\\)s types, we specify \\(\\alpha^Y_{00}\\), \\(\\alpha^Y_{10}\\), \\(\\alpha^Y_{01}\\), and \\(\\alpha^Y_{11}\\), corresponding to the nodal types \\(\\theta^Y_{00}\\), etc. So, for instance: \\(\\alpha^Y_{00}=1\\), \\(\\alpha^Y_{10}=1\\), \\(\\alpha^Y_{01}=1\\), and \\(\\alpha^Y_{11}=1\\) yields a uniform distribution in which all share allocations of types in the population are equally likely. \\(\\alpha^Y_{00}=3\\), \\(\\alpha^Y_{10}=3\\), \\(\\alpha^Y_{01}=3\\), and \\(\\alpha^Y_{11}=3\\) puts more weight on share allocations in which the shares are relatively equal. \\(\\alpha^Y_{00}=5\\), \\(\\alpha^Y_{10}=5\\), \\(\\alpha^Y_{01}=10\\), and \\(\\alpha^Y_{11}=5\\) puts greater weight positive causal effects than the other three types. Unobserved confounding. When there is unobserved confounding, we need parameter sets that allow for a joint distribution over nodal types. Thus, if we believe the likelihood of \\(X=1\\) is correlated with whether or not \\(X\\) has a positive effect on \\(Y\\), we will need two parameter sets (rather than one) for \\(X\\): one for \\(X\\)s value when \\(\\theta^Y = \\theta^Y_{01}\\) and one for \\(X\\)s value when \\(\\theta^Y \\neq \\theta^Y_{01}\\). For each of these parameter sets, we specify two \\(\\alpha\\) parameters representing our beliefs about \\(X\\)s assignment. We can draw \\(\\lambda\\) values for these conditional nodal types from the resulting Dirichlet distributions, as above, and can then calculate causal type probabilities in the usual way. Distributions over causal types. For a model with any number of nodes, we can then imagine a draw of one \\(\\lambda^j\\) from its prior distribution for each node, giving a full \\(\\lambda\\) vector. Any particular \\(\\lambda\\) vector, in turn, implies a probability distribution over causal types (\\(\\theta\\)). With the help of a parameter matrix (mapping from parameters to causal types), we can then, just as with process tracing, calculate the prior probability that a case is of any particular causal type, given the parameter (\\(\\lambda\\)) values we have drawn. Implicitly, then, our prior distribution over \\(\\lambda\\) gives rise in turn to a prior distribution over the causal type shares in the population. Event probabilities. We now need to build a likelihood function that can map from beliefs about the world to data: i.e., that can tell us how likely we are to see a given data patternacross multiple casesunder a given distribution of causal types in the population. The first step in building the likelihood function is to calculate event probabilities: the probability of observing a case of a particular data type given a particular population-level distribution of causal type shares (that is, given a \\(\\lambda\\) draw). We assume, for now, that we deploy the same data strategy for each case, collecting data on all nodes. We denote an event probability for a given data pattern for variables \\(X, Y, \\dots\\) as \\(w_{x, y, \\dots}\\). For instance, the probability of observing \\(X=0, Y=1\\) in a case (given \\(\\lambda\\)) is \\(w_{01}\\). An ambiguity matrix, just as for process tracing, tells us which causal types are consistent with a particular data type, as observed for a single case. To calculate the probability of the data given a distribution of causal types, we simply add together the probabilities of all of the causal types with which it is consistent. See, for instance, the parameter matrix and the ambiguity matrix in Tables 9.1 and 9.2. We have indicated a single draw of \\(\\lambda\\) values (population type shares) in the parameter matrix, and these have been used to calculate the priors on causal types provided in the ambiguity matrix. Lets now calculate the event probability for each data type. Starting with \\(X=0, Y=0\\), we can read off the ambiguity matrix that the consistent causal types are (\\(\\theta^X_0, \\theta^Y_{00}\\)) and (\\(\\theta^X_0, \\theta^Y_{01}\\)). The event probability, \\(w_{00}\\), is then given by adding together the probabilities of these two causal types, \\(0.1 + 0.2 = 0.3\\). All four event probabilities, for the four data types, are then calculated in the same way: \\(w_{00} = 0.1 + 0.2 = 0.3\\) \\(w_{10} = 0.1 + 0.1 = 0.2\\) \\(w_{01} = 0.1 + 0.2 = 0.2\\) \\(w_{11} = 0.2 + 0.1 = 0.3\\) As any case must be of one and only one data type, the full set of event probabilities for a single \\(\\lambda\\) draw must naturally sum to \\(1\\). Table 9.1: A parameter matrix for a simple \\(X ightarrow Y\\) model (with no unobserved confounding), indicating a single draw of \\(\\lambda\\) values from the prior distribution. X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 Shares.param_names Shares.param_value Shares.param_set Shares.node Shares.nodal_type Shares.gen Shares.priors X.0 1 0 1 0 1 0 1 0 X.0 0.4 X X 0 1 1 X.1 0 1 0 1 0 1 0 1 X.1 0.6 X X 1 1 1 Y.00 1 1 0 0 0 0 0 0 Y.00 0.3 Y Y 00 2 1 Y.10 0 0 1 1 0 0 0 0 Y.10 0.2 Y Y 10 2 1 Y.01 0 0 0 0 1 1 0 0 Y.01 0.2 Y Y 01 2 1 Y.11 0 0 0 0 0 0 1 1 Y.11 0.3 Y Y 11 2 1 Table 9.2: An ambiguity matrix for a simple \\(X ightarrow Y\\) model (with no unobserved confounding), showing the priors over causal types arising from a single draw of \\(\\lambda\\) from its prior distribution. X0Y0 X1Y0 X0Y1 X1Y1 prior X0Y00 1 0 0 0 0.12 X1Y00 0 1 0 0 0.18 X0Y10 0 0 1 0 0.08 X1Y10 0 1 0 0 0.12 X0Y01 1 0 0 0 0.08 X1Y01 0 0 0 1 0.12 X0Y11 0 0 1 0 0.12 X1Y11 0 0 0 1 0.18 For a case in which only partial data are observed, we follow the same basic logic as with partial process-tracing data. We retain all columns (data types) in the ambiguity matrix that are consistent with the partial data. So, for instance, if we observe only \\(Y=1\\), we would retain both the \\(X=0, Y=1\\) column and the \\(X=1, Y=1\\) column. We then calculate the event probability by summing causal-type probabilities for all causal types that could have produced these partial data  i.e., all those with a \\(1\\) in either column. Likelihood. Now that we know the probability of observing each data pattern in a single case given \\(\\lambda\\), we can use these event probabilities to aggregate up to the likelihood of observing a data pattern across multiple cases (given \\(\\lambda\\)). With discrete variables, we can think of a given multiple-case data pattern simply as a set of counts: for, say, \\(X, Y\\) data, we will observe a certain number of \\(X=0, Y=0\\) cases (\\(n_{00}\\)), a certain number of \\(X=1, Y=0\\) cases (\\(n_{10}\\)), a certain number of \\(X=0, Y=1\\) cases (\\(n_{01}\\)), and a certain number of \\(X=1, Y=1\\) cases (\\(n_{11}\\)). A data pattern, given a particular set of variables observed (a search strategy), thus has a multinomial distribution. The likelihood of a data pattern under a given search strategy, in turn, takes the form of a multinomial distribution conditional on the number of cases observed and the event probabilities for each data type, given a \\(\\lambda\\) draw. Let us assume now that we have a 3-node model, with \\(X, Y\\), and \\(M\\) all binary. Let \\(n_{XYK}\\) denote an 8-element vector recording the number of cases in a sample displaying each possible combination of \\(X,Y,K\\) data, thus: \\(n_{XYM}=(n_{000},n_{001},n_{100},\\dots ,n_{111})\\). The elements of \\(n_{XYK}\\) sum to \\(n\\), the total number of cases studied. Likewise, let the event probabilities for data types given \\(\\lambda\\) be registered in a vector, \\(w_{XYK}=(w_{000},w_{001},w_{100},\\dots ,w_{111})\\). The likelihood of a data pattern, \\(\\mathcal D\\) is then: \\[ \\Pr(\\mathcal{D}|\\lambda) = \\text{Multinom}\\left(n_{XYK}|n, w_{XYK}\\right) \\\\ \\] In other words, the likelihood of observing a particular data pattern given \\(\\lambda\\) is given by the corresponding value of the multinomial distribution given the event probabilities. What if we have a mixture of search strategies? Suppose, for instance, that we have collected \\(X,Y\\) data on a set of cases, and that we have additionally collected data on \\(M\\) for a random subset of these. We can think of this as conducting quantitative analysis on a large sample and conducting in-depth process tracing on a subsample. We then can summarize our data in two vectors, the 8-element \\(n_{XYM}\\) vector for the cases with process tracing, and a 4-element vector \\(n_{XY*} = (n_{00*},n_{10*},n_{01*},n_{11*}\\) for the partial data on those cases with no process tracing. Likewise, we now have two sets of event probabilities: one for the cases with complete data, \\(w_{XYM}\\), and a 4-element vector for those with partial data, \\(w_{XY*}\\). Let \\(n\\) denote the total number of cases examined, and \\(k\\) the number for which we have data on \\(K\\). Now, assuming that each observed case represents an independent, random draw from the population, we can form the likelihood function as a product of multinomial distributions: \\[ \\Pr(\\mathcal{D}|\\theta) = \\text{Multinom}\\left(n_{XY*}|n-k, w_{XY*}\\right) \\times \\text{Multinom}\\left(n_{XYK}|k, w_{XYK}\\right) \\\\ \\] BOX 9.2.0.1 Likelihood and sampling Say a data strategy seeks data on \\(X\\) and \\(Y\\) in 2 cases and seeks data on \\(M\\) if ever \\(X=Y=1\\). The probability of each data type is as given in table below: type: prob: \\(X1M0Y1\\) \\(\\lambda^X_1(\\lambda^M_{00}+\\lambda^M_{10})(\\lambda^Y_{11}+\\lambda^Y_{10})\\) \\(X1M1Y1\\) \\(\\lambda^X_1(\\lambda^M_{11}+\\lambda^M_{01})(\\lambda^Y_{11}+\\lambda^Y_{01})\\) \\(X0Y0\\) \\(\\lambda^X_0(\\lambda^M_{00}+\\lambda^M_{01})(\\lambda^Y_{00}+\\lambda^Y_{01}) + \\lambda^X_0(\\lambda^M_{10}+\\lambda^M_{11})(\\lambda^Y_{00}+\\lambda^Y_{10})\\) \\(X0Y1\\) \\(\\lambda^X_0(\\lambda^M_{00}+\\lambda^M_{01})(\\lambda^Y_{10}+\\lambda^Y_{11}) + \\lambda^X_0(\\lambda^M_{10}+\\lambda^M_{11})(\\lambda^Y_{01}+\\lambda^Y_{11})\\) \\(X1Y0\\) \\(\\lambda^X_1(\\lambda^M_{00}+\\lambda^M_{10})(\\lambda^Y_{00}+\\lambda^Y_{01}) + \\lambda^X_1(\\lambda^M_{01}+\\lambda^M_{11})(\\lambda^Y_{00}+\\lambda^Y_{10})\\) The two observations can be thought of as a multinomial draw from these five event types. Alternatively they can also be thought of as the product of a draw from a strategy in which a set of units is drawn with observations on \\(X,Y\\) only and another set is drawn with observations on \\(X, M, Y\\). In the single multinomial view we have the probability of seeing data with \\(X=Y=0\\) in one case and \\(X=1, M=0, Y=1\\) in another is: \\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\\) In the conditional strategy view we have \\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\\) In the two strategy view we have \\(P(X=0, Y=0)P(X=1, M=0, Y=1)\\) which is the same up to a constant. Say rather than conditioning \\(X=Y=1\\) to examine \\(M\\) one of the two cases were chosen at random to observe \\(M\\) and it just so happend to be be a case with \\(X=Y=1\\): type: prob: \\(X0Y0\\) \\(0.5\\lambda^X_0(\\lambda^M_{00}+\\lambda^M_{01})(\\lambda^Y_{00}+\\lambda^Y_{01}) + 0.5\\lambda^X_0(\\lambda^M_{10}+\\lambda^M_{11})(\\lambda^Y_{00}+\\lambda^Y_{10})\\) \\(X0Y1\\) \\(0.5\\lambda^X_0(\\lambda^M_{00}+\\lambda^M_{01})(\\lambda^Y_{10}+\\lambda^Y_{11}) + 0.5\\lambda^X_0(\\lambda^M_{10}+\\lambda^M_{11})(\\lambda^Y_{01}+\\lambda^Y_{11})\\) \\(X1Y0\\) \\(0.5\\lambda^X_1(\\lambda^M_{00}+\\lambda^M_{10})(\\lambda^Y_{00}+\\lambda^Y_{01}) + 0.5\\lambda^X_1(\\lambda^M_{01}+\\lambda^M_{11})(\\lambda^Y_{00}+\\lambda^Y_{10})\\) \\(X1Y1\\) \\(0.5\\lambda^X_1(\\lambda^M_{00}+\\lambda^M_{10})(\\lambda^Y_{10}+\\lambda^Y_{11}) + 0.5\\lambda^X_1(\\lambda^M_{11}+\\lambda^M_{01})(\\lambda^Y_{11}+\\lambda^Y_{01})\\) + \\(X0M0Y0\\) \\(0.5\\lambda^X_0(\\lambda^M_{00}+\\lambda^M_{01}))(\\lambda^Y_{00}+\\lambda^Y_{01})\\) \\(X0M1Y0\\) \\(0.5\\lambda^X_0(\\lambda^M_{11}+\\lambda^M_{10}))(\\lambda^Y_{00}+\\lambda^Y_{10})\\)  \\(X1M1Y1\\) \\(0.5\\lambda^X_1(\\lambda^M_{11}+\\lambda^M_{01})(\\lambda^Y_{11}+\\lambda^Y_{01})\\) In the single multinomial view we have the probability of seeing data with \\(X=Y=0\\) in one case and \\(X=1, M=0, Y=1\\) in another is now: \\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\\) In the conditional strategy view we have \\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\\) In the two strategy view we have \\(P(X=0, Y=0)P(X=1, M=0, Y=1)\\) which is the same up to a constant. 9.2.1 Estimation WRITE GENERAL APPROACH WEITE BAYES RULE AND REFER BACK TO CHAPTER 9.2.2 Query Describe and illustrate 9.3 Illustrated inferences 9.3.1 Chain model show table with columns: * 14 columns: 10 nodel types, high abcd 4 * no data, * 1 data point on X=1 Y=1 only * 1 data point on X=1 Y=1 M = 1 * 10 data point on X=1 Y=1 only * 10 data point on X=1 Y=1 M = 1 9.4 Considerations 9.4.1 The DAG can be enough when \\(N &gt; 1\\) In Chapter 7, we discussed the fact that a DAG by itself is insufficient to generate learning about causal effects from data on a single case; we also need prior beliefs about population-level shares of nodal types. When working with multiple cases, however, we can learn about causal effects when starting with nothing more than the DAG. In particular, it is sometimes possible to draw causal information from correlations across cases, given only the DAG. For instance, in an \\(X \\rightarrow M \\rightarrow Y\\) model, even if we start with flat priors over \\(M\\)s nodal types, observing a correlation (or no correlation) between \\(X\\) and \\(M\\) across multiple cases provides information about \\(X\\)s effect on \\(M\\). Simply, a stronger, positive (negative) \\(X, M\\) correlation implies a stronger positive (negative) effect of \\(X\\) on \\(M\\). In turn, a stronger \\(X,M\\) correlation implies a stronger effect of \\(X\\) on \\(Y\\) since, under this model, that effect has to run through an effect of \\(X\\) on \\(M\\). Whats more, data from multiple cases can provide probative value for within-case inference. Suppose, for the \\(X \\rightarrow M \\rightarrow Y\\) model, that we start with flat priors over all nodal types. As discussed in Chapter 7, observing \\(M\\) in a single case cannot be informative about \\(X\\)s effect on \\(Y\\) in that case. If we have no idea of the direction of the intermediate causal effects, then we have no idea which value of \\(M\\) is more consistent with an \\(X \\rightarrow M\\) effect or which an \\(M \\rightarrow Y\\) effect. But suppose that we first observe data on \\(X\\) and \\(M\\) for a group of cases and find a strong positive correlation between the two variables. We now update to a belief that any effect of \\(X\\) on \\(M\\) is more likely to be positive than negative. Now, lets say we look at one of our cases, in which \\(X=1\\) and \\(Y=1\\) and want to know if \\(X\\) caused \\(Y\\). Knowing now that any such effect would most likely have operated via a positive \\(X \\rightarrow M\\) effect means that observing \\(M\\) will be informative: \\(M=1\\) will be more consistent with an \\(X \\rightarrow Y\\) effect than will \\(M=0\\). The same logic, of course, also holds for observing cross-case correlations between \\(M\\) and \\(Y\\). Drawing probative value from cross-case data is, of course, dependent on the causal model. For instance, if there is confounding between \\(M\\) and \\(Y\\), we would not derive probative value on \\(M\\) from observing 9.4.2 Learning without identification Some causal queries are identified while others are not. When a query is identified, each true value for the query is associated with a unique data distribution given infinite data. As we gather more and more data, our posterior on the query should converge on the true value. When a query is not identified, multiple true values of the query will be associated with the same data distribution given infinite data. With a non-identified query, our posterior will never converge on a unique value regardless of how much data we collect; multiple answers will be equally consistent with the data. We can illustrate the difference by comparing an \\(ATE\\) query to a probability of causation query for a simple \\(X \\rightarrow Y\\) model. When asking about the \\(ATE\\), we are asking about the average effect of \\(X\\) on \\(Y\\), or the difference between \\(\\lambda^Y_{01}\\) (share of units with positive effects) and \\(\\lambda^Y_{10}\\) (share with negative effects). When asking about the probability of causation, we are asking, for a case with given values of \\(X\\) and \\(Y\\), about the probability that \\(X\\) caused \\(Y\\) in that case. This query is defined by a different set of parameters. For, say, an \\(X=1, Y=1\\) case and our \\(X \\rightarrow Y\\) model, the probability of causation is given by just \\(\\lambda^Y_{01}\\). Let us assume a true set of parameters, unknown to the researcher, such that \\(\\lambda^Y_{01} = 0.6\\), \\(\\lambda^Y_{10} = 0.1\\) while we set \\(\\lambda^Y_{00} = 0.2\\) and \\(\\lambda^Y_{11} = 0.1\\). Thus, the true average causal effect is \\(0.5\\). We now use the parameters and the model to simulate a large amount of data (\\(N=10,000\\)). We then return to the model, set flat priors over nodal types, and update the model using the simulated data. We graph the posterior on our two queries, the \\(ATE\\) and the probability of positive causation in an \\(X=1, Y=1\\) case, in Figure ??. Figure 9.1: ATE is identified, PC is not identified but has informative bounds The figure illustrates nicely the difference between an identified and non-identified query. While the \\(ATE\\) converges on the right answer, the probability of causation fails to converge even with a massive amount of data. We see instead a range of values for this query on which our updated model places roughly equal posterior probability. Importantly, however, we see that we do learn about the probability of causation. Despite the lack of convergence, our posterior rules out a wide range of values. While our prior on the query was 0.5, we have correctly updated toward a range of values that includes (and happens to be fairly well centered over) the true value (\\(\\approx 0.86\\)). A distinctive feature of updating a causal model is that it allows us to learn about non-identified quantitites in this manner. We will end up with ridges in our posterior distributions: ranges or combinations of parameter values that are equally likely given the data. But our posterior weight can nonetheless shift toward the right answer. At the same time, for non-identified queries, we have to be cautious about the impact of our priors. As \\(N\\) becomes large, the remaining curvature we see in our posteriors may simply be function of those priors. One way to inspect for this is to simulate a very large dataset and see whether the curvature remainsXXXXXXXXXX A second approach would be to do sensitivity analyses by updating the model on the same data with different sets of priors to see how this affects the shape of the posterior. model &lt;- make_model(&quot;X1 -&gt; M1 -&gt; Y &lt;- M2 &lt;- X2&quot;) # restrict such that *only* M1 OR M2 could cause Y -- can we create a DD test? / achieve identification 9.4.3 Beyond binary data While the setup used in this book involves only binary nodes, the approach described here readily generalizes to other levels of measurement. A shift to other levels of measurement can be straightforwardly accommodated through an expansion of the nodal-type space. Suppose that we want to operate with variables with 3 ordinal categories. In an \\(X \\rightarrow Y\\) model, \\(Y\\)s nodal types have to accommodate 3 possible values that \\(X\\) can take on, and 3 possible values that \\(Y\\) can take on for any value of \\(X\\). This yields 27 nodal types: 27 possible sets of \\(Y\\) values corresponding to the 3 values that \\(X\\) could take on. Notably, moving to 3-level ordinal variables already allows for considerably greater flexibility in response functions. For instance, relations could be non-linear, with \\(Y\\) increasing as \\(X\\) goes from 0 to 1, and then remaining flat as \\(X\\) goes from 1 to 2. Relations could also be non-monotonic, with \\(Y\\) increasing as \\(X\\) goes from 0 to 1, and then decreasing as \\(X\\) goes from 1 to 2. Of course, we extend this approach to make measurement arbitrarily fine-grained and allow for arbitrarily complex functional forms . More generally, allow \\(Y\\) to take on \\(m\\) possible values. With \\(k\\) explanatory variables, each taking on \\(r\\) possible values, we then have \\(m^{r^k}\\) nodal types for \\(Y\\). Thus, the cost of more granular measurement is complexity  an explosion of the parameter space  as the nodal type space expands rapidly with the granularity of measurement and the number of explanatory variables With 3 3-level ordinal variables pointing into the same outcome, we have \\(3^{27} = 7.6\\) trillion nodal types! We expect that, as measurement becomes more granular, researchers will want to manage the complexity by placing structure onto the possible patterns of causal effects. Structure, imposed through model restrictions, can quite rapidly tame the complexity. For some substantive problems, one form of structure we might be willing to impose is monotonicity. In our \\(X \\rightarrow Y\\) model with 3-level variables, excluding non-monotonic effects brings down the number of nodal types from 27 to 17. Alternatively, we may have a strong reason to rule out effects in one direction: disallowing negative effects, for instance, brings us down to 10 nodal types. If we are willing to assume linearity the number of nodal types plummets to 5. REMOVE REFERENCE TO OLS; SAY WE DEAL WITH THIS ELSEWHERE IN THE CONCLUSION. Of course, standard approaches to empirical modeling typically impose a great deal of structure  consider, for instance, the ubiquity of the linearity assumption in regression modeling  for precisely the same reason: to simplify the parameter space. As with other forms of empirical modeling, researchers working with causal models will need to decide how they want to trade off model fit and complexity of the parameter space in the choices they make about nodal measurement and model restrictions. 9.4.4 Measurement error One potential application of the approach we have described in this chapter to integrating differing forms of data is to addressing the problem of measurement error. The conceptual move to address measurement error in a causal model setup is quite simple: we incorporate the error-generating process into our model. Consider, for instance, a model in which we build in a process generating measurement error on the dependent variable. \\[X \\rightarrow Y \\rightarrow Y_\\text{measured} \\leftarrow \\text{source of measurement error}\\] Here \\(X\\) has an effect on the true value of our outcome of interest, \\(Y\\). The true value of \\(Y\\), in turn, has an effect on the value of \\(Y\\) that we measure, but so too does a potential problem with our coding process. Thus, the measured value of \\(Y\\) is a function of both the true value and error. To motivate the setup, imagine that we are interested in the effect of a rule restricting long-term care staff to working at a single site (\\(X\\)) on novel coronavirus outbreaks in long-term care facilities (\\(Y\\)), defined as infections among two or more staff or residents. We do not directly observe infections, however; rather, we observe positive results of PCR tests. We also know that testing is neither comprehensive nor uniform. For some units, regular random testing is carried out on staff and residents while in others only symptomatic individuals are tested. It is the latter arrangement that potentially introduces measurement error. If we approach the problem naively, ignoring measurement error and treating \\(Y_\\text{measured}\\) as though it were identical to \\(Y\\), we would face attenutation bias in our estimates of the effect of \\(X\\) on \\(Y\\) if some units are engaged in only symptomatic testing and this generates missed outbreaks. A slightly more sophisticated approach would be to acknowledge this attenuation bias, treating our estimate of the \\(ATE\\) as a lower bound. Yet we can go further if we work with the above causal model. Without any additional data, we can update on both \\(\\lambda_Y\\) and \\(\\lambda^{Y_\\text{measured}}\\). We could, for instance, impose restrictions that exclude negative effects of \\(Y\\) on \\(Y_\\text{measured}\\).1 Then, if we observe (say) a negative correlation between \\(X\\) and \\(Y_\\text{measured}\\), we can update on the substantive effect of interest  \\(\\lambda^Y\\)  in the direction of a larger share of negative effects: it is only via negative effects of \\(X\\) on \\(Y\\) that a negative correlation between \\(X\\) and \\(Y_\\text{measured}\\) could emerge. At the same time, we learn about the measure as we update on \\(\\lambda^{Y_\\text{measured}}\\): the negative observed correlation \\(X\\) and \\(Y_\\text{measured}\\) is an indicator of the degree to which \\(Y_\\text{measured}\\) is picking up true \\(Y\\). We can do considerably better, however, if we can collect more detailed information on at least some units. One data strategy would be to invest in observing, \\(Y\\), the true outbreak status of each unit for a subset of units on which we already have data on \\(X\\) and \\(Y_\\text{measured}\\)  say, by implementing our own random-testing protocol at a set of facilities. Observing both \\(X\\) and the true \\(Y\\) will allow us to update more directly on \\(\\lambda^Y\\), the true effect of \\(X\\) on \\(Y\\). Just as importantly, observing both \\(Y\\) and \\(Y_\\text{measured}\\) will allow us to update more directly on measurement quality, \\(\\lambda^{Y_\\text{measured}}\\). A second data strategy (which could be combined with the first) would be to collect data, for some subset of units, on the source of the measurement error. If we collected data on the use of random vs. symptomatic-only testing, we could then update on two further parameters: \\(\\lambda^\\text{source of measurement error}\\) and on the part of \\(\\lambda^{Y_\\text{measured}}\\) representing response of \\(Y_\\text{measured}\\). In other words, we would learn both about how prevalent the conditions generating measurement error are and about much they throw off our measure. 9.4.5 Spillovers A common threat to causal inference is the possibility of spillovers: a given units outcome being affected by the treatment status of another (e.g., possibly neighboring) unit. We can readily set up a causal model to allow for estimation of various quantities related to spillovers. Consider, for instance, the causal model represented in Figure ??. We consider here a cluster of 3 units across which spillovers might occur. We might imagine, for instance, a cluster of geographically proximate villages separated from other clusters such that spillovers might occur between villages within a cluster, but can be ruled out across clusters. Here \\(X_i\\) and \\(Y_i\\) represent village \\(i\\)s treatment status and outcome, respectively. The pattern of directed edges indicates that each villages outcome might be affected both by its own and by its neighbors treatment status. The dataset will now be structured such that the unit of analysis is the cluster. WAIT, I AM NOT SURE THIS IS RIGHT. CANT WE HAVE THE UNITS BE VILLAGES, WITH THE COLUMNS IN THE DATASET BEING X1, X2, X3, Y_i FOR ALL VILLAGES? Figure 9.2: A causal model allowing for spillovers across 3 units, in which each units treatment status can affect other units outcomes. model &lt;- make_model(&quot;X1 -&gt; Y1 &lt;- X2 -&gt; Y2 &lt;- X1&quot;) plot(model) data &lt;- fabricatr::fabricate(N = 100, X1 = rbinom(N,1,.5), X2 = rbinom(N,1,.5), Y1 = X1, Y2 = X1*X2) if(do_diagnosis) update_model(model, data, keep_transformed = TRUE) %&gt;% write_rds(&quot;saved/spillovers.rds&quot;) read_rds(&quot;saved/spillovers.rds&quot;) %&gt;% query_model( list( only_self_treated = &quot;(Y1[X1=1, X2=0] - Y1[X1=0, X2=0] + Y2[X1=0, X2=1] - Y2[X1=0, X2=0])/2&quot;, only_other_treated = &quot;(Y1[X1=0, X2=1] - Y1[X1=0, X2=0] + Y2[X1=1, X2=0] - Y2[X1=0, X2=0])/2&quot;, one_treated = &quot;((Y1[X1=1, X2=0] + Y1[X1=0, X2=1])/2 - Y1[X1=0, X2=0] + (Y2[X1=1, X2=0] + Y2[X1=0, X2=1])/2 - Y2[X1=0, X2=0])/2&quot;, both_treated = &quot;((Y1[X1=1, X2=1] - Y1[X1=0, X2=0]) + (Y2[X1=1, X2=1] - Y2[X1=0, X2=0]))/2&quot;), using = &quot;posteriors&quot;) ## Query Given Using Case.estimand mean sd ## 1 only_self_treated - posteriors FALSE 0.371077874 0.04784773 ## 2 only_other_treated - posteriors FALSE 0.000272663 0.04289087 ## 3 one_treated - posteriors FALSE 0.185675268 0.03875585 ## 4 both_treated - posteriors FALSE 0.746689003 0.05197868 Spillovers may also be addressed through an appropriate definition of causal types. For example a unit \\(i\\) that is affected either by receiving treatment or via the treatment of a neighbor, \\(j\\), might have potential outcomes \\(Y_i(X_i,X_j)=\\max(X_i,X_j)\\) while another type that is not influenced by neighbor treatment status has \\(Y_i(X_i,X_j)=\\max(X_i)\\). With such a set-up, relevant clue information might discriminate between units affected by spillovers and those unaffected. With current structure, you can estimate various spillover relevant quantities Can think about a dataset in which columns are individuals: a column for each individuals treatment status and a column for each individuals outcome status. A unit is a cluster of individuals in a closed system without spillovers beyond them,. Units are now groups. Can ask whats the difference in outcome for a unit if \\(N\\) of its neighbors are treated vs. no neighbors treated. Could model an assignment process for spillover experiments: 9.4.6 Clustering and other violations of independence The structure we introduced assumes that all units are independent but in many applications groups of units react in similar ways to group level features. For instance a national level event affects individual decision making in common ways. In such cases the higher level events may or may not be observed. Our standard model is not designed to capture failures of independence between units like this. However it is possible to capture some forms of clustering.2 As an illustration we might imagine our units are in pairs (couples, say) an \\(W\\) is an unobserved pair level node that shuts off causal effects for both units. We might then define the model as follows: model &lt;- make_model(&quot;X1 -&gt; Y1 &lt;- W -&gt; Y2 &lt;- X2&quot;) %&gt;% set_restrictions(&quot;(Y1[X1=1, W=0] != Y1[X1=0, W=0])&quot;) %&gt;% set_restrictions(&quot;(Y2[X2=1, W=0] != Y2[X2=0, W=0])&quot;) and define estimands as average effects for both units in a pair. In such cases we would find, for instance, that data on \\(n\\) units is more information when the \\(n\\) units are drawn from many pairs than when they are drawn from few. Table 9.3: Data from many pairs is more informative than the same data from fewer pairs. Data mean sd 2 obs from each of 2 clusters 0.018 0.094 1 obs from each of 4 clusters 0.020 0.095 9.4.7 Parameteric models 9.4.8 Prior data/beliefs channel the learning from new data When we learn from new data, we always update conditional on any prior information. Consider the following example. Suppose that we are working with our familiar \\(X \\rightarrow M \\rightarrow Y\\) model. We first observe a large amount of \\(X,Y\\) data in which the two variables are strongly and positively correlated, thus indicative of a positive \\(ATE\\) of \\(X\\) on \\(Y\\). Next, we turn to process tracing a small number of cases: suppose we collect data on \\(M\\) in one \\(X=1, Y=1\\) case and one \\(X=0, Y=0\\) case, and we observe \\(M=1\\) in both cases. Well, \\(M\\) is uncorrelated with \\(X\\) across these two cases, constituting evidence against an effect of \\(X\\) on \\(Y\\). Since these are both cases in which a positive effect could have been operating, this finding will reduce our posterior on the share of positive effects in the population and, in turn, on the \\(ATE\\). However, the strong prior information on the \\(ATE\\) that we began with still anchors our updating. Our downward updating on the \\(ATE\\) will be modest since our posterior is always a compromise between our (here, strong) priors and new information. More precisely, we will update less on the \\(ATE\\), about which we had strong prior information, than we will update about the share of positive effects, about which our prior data provided weaker information. In addition, there is a knock-on effect for our beliefs about the share of negative effects in the population. If we have a strong prior about the value of the \\(ATE\\), and our beliefs about the share of positive effects goes down substantially, then our beliefs about the share of negative effects must also fall. (Recall that the \\(ATE\\) is simply the share of positive effects minus the share of negative effects.) Intuitively, we can think of our beliefs about negative effects as updating to preserve our beliefs about the \\(ATE\\). And note that, if we had had no prior information about average effects, then learning about positive effects would have have had no implications for our beliefs about negative effects since there would be no overall constraint on the relationship between positive- and negative effect shares. A more general way to describe this dynamic is that learning about a kind of case that we directly observe can generate second-hand learning about a kind of case that we do not directly observe through the constraint on our beliefs imposed by the our priors. This is, really, just a special instance of our priors generating probative value: our prior on the \\(ATE\\) can make evidence about positive effects informative about negative effects. If we had flat priors on the \\(ATE\\), learning about positive effects would have no impact on our beliefs about negative effects. A parallel example arises when we want to learn about a model with multiple causal pathways. Consider the model \\(X \\rightarrow M \\rightarrow Y \\leftarrow N \\leftarrow X\\), where \\(X\\) can have an effect on \\(Y\\) through either \\(M\\) or \\(N\\). And let us set priors such that we believe the the two paths to be equally likely. Suppose that, as before, we have started with a substantial amount of \\(X,Y\\) data indicative of a large positive \\(ATE\\). Now, we look for data on \\(M\\) in a handful of cases and find an \\(M\\) pattern inconsistent with any kind of effect through \\(M\\). What happens to our beliefs about the \\(ATE\\)? In general, finding evidence against one way an effect can happen should reduce our confidence in the effect happening at all. However, if we have started out with a strong prior on the \\(ATE\\) but equal prior weight on the \\(M\\) and \\(N\\) pathways, then what we will see is countervailing updating across the two pathways: while our confidence in the operation of the \\(M\\) pathway will fall substantially, our posterior on effects operating via the \\(N\\) pathway will rise  because of the constraint on the total effect imposed by our strong priors on the \\(ATE\\). And our \\(ATE\\) beliefs will fall only modestly. Evidence against the \\(M\\)-pathway effect will function as evidence for the \\(N\\)-pathway effects and, to a limited degree, as evidence against a total effect. A further implication for process tracing is that there will generally be sharp limits to what we can learn about total effects if we study mediators along only some of the theorized pathways if we already have some prior information about total effects. The difficulty is that whatever we learn from the mediators we do observe will be offset by countervailing shifts in our beliefs about other pathways, generated by the constraint in our prior knowledge about the total effect. Suppose, for instance, that we start with some belief that economic development makes democracy more likely, and we believe that there may be two mechanisms: one operating through a rising middle class and one operating through a more robust and organized working class. Suppose then that we examine data on the organization of the working class and find that it does not vary with per capita GDP. We will then, of course, reduce our confidence in the working-class pathway. However, we must also increase our confidence in the operation of the middle-class pathway  because (a) we have prior reason to believe that the overall development \\(\\rightarrow\\) democracy effect exists and (b) we have not observed a mediator along the middle-class pathway. On balance, then, learning about just the one pathway will not have a large impact on beliefs about the overall effect of GDP on democratization. The larger lesson here is that, if our process tracing strategy involves the examination of mediators to learn about total \\(X \\rightarrow Y\\) effects, then how much we stand to learn depends on how comprehensively our examination of mediators covers thes plausible pathways connecting \\(X\\) to \\(Y\\). To be clear, we do not need to collect mediator clues on all possible pathways. If we have strong priors that one or more possible pathways are very unlikley, then we might safely be able to avoid collecting observations along those pathways without substantially reducing the prospects for learning. Also, the specific point that we are making here applies to using mediator data to answer queries about the effect of \\(X\\) on \\(Y\\). If instead we want to know which particular pathway is operating, then the lesson here is quite different, and more encouraging. For one thing, collecting evidence on just one pathway can be highly informative about the operation of that pathway. For another, if we do have strong priors on the \\(ATE\\), then learning about one pathway can also be informative about other pathways, just as we saw in our \\(M\\)- and \\(N\\)-pathway example. 9.5 Principles of reasoning about learning As we did in Chapter 7, we provide here some guidance in how to reason about the learning that arises from mixed data. We focus especially on ways in which learning from multiple cases differs from learning from a single case. 9.6 Conclusion ADD REFERENCE TO TABLE 1 OF FOR MIXED DATA Ability and Achievement Otis Duncan We might also set a flat prior on the prevalence of measurement error and exclude positive effects of measurement error on \\(Y_\\text{measured}\\). In this illustration the two units in each pair are treated as separate nodes rather than as repeated instances of realizations of the same node. Implicitly then the effect for one unit type (men, say) can be quite independent of the effect of another type (women, say). Indeed, here they are linked only through the unobserved variable \\(W\\). "]]
