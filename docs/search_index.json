[
["mixingapp.html", "Chapter 9 Mixed-Method Application: Inequality and Democracy Revisited 9.1 A trained model 9.2 Data 9.3 Inference 9.4 Prior / posterior comparison for multiple estimands 9.5 Discussion", " Chapter 9 Mixed-Method Application: Inequality and Democracy Revisited In chapter 7 we drew inferences from a ‘theory based’ democracy and inequality model on data. Here we train the model on data before making case level inferences, allowing for the possibility of confounding in the assignment of inequality. In this case we update our beliefs over the population parameters and not just over the case level parameters. Thus we simultaneously learn about our thoery and use our theory to learn about cases. The data informed inferences are, on the whole, weaker than the theory based inferences of Chapter 7. 9.1 A trained model We now apply these ideas on mixed method research to our model of democracy and inequality. The key difference to the exercise in in Chapter 7 is that whereas there we took the model as given, and sought to draw inferences to case given the model, the model now becomes an object that we both learn from and learn about. In essence we use the data on many cases to update our beliefs about the general model and then use this \"trained’ model to then make inferences about cases. Along with this change in goals come some changes in the structure of the model: Instead of specifying beliefs about causal types, \\(\\theta\\), we now need to specify a belief over the distribution of causal types, \\(\\lambda\\). Concretely whereas in the simple process tracing model we specified that inequality has a positive effect on mobilization for some share of units, we now specify a distribution over the share of units for which inequality could have a positive effect, ranging anywhere from 0 to 100% As we train the model we allow now for the possibility that there is unobserved confounding – in particular the possibility that inequality is less (or more!) likely in places in which inequality would induce mobilization. We do not impose confounding in one direction of another, but we do allow for the possibility of confounding. As a result we may have correlations in our posteriors over beliefs regarding confounding and beliefs about effects. Model definition in code We can now define the model compactly using gbiqq as follows. model &lt;- make_model(&quot;I -&gt; M -&gt; D &lt;- P; I -&gt; D&quot;, add_priors = FALSE) %&gt;% set_restrictions(c( &quot;(M[I=1] &lt; M[I=0])&quot;, &quot;(D[I=1] &gt; D[I=0]) | (D[M=1] &lt; D[M=0]) | (D[P=1] &lt; D[P=0])&quot;)) %&gt;% set_confound(list(I = &quot;(M[I=1] == 1) &amp; (M[I=0] == 1)&quot;)) %&gt;% set_priors() This model, with confounding, is represented graphically as in Figure ?? 9.2 Data We use the same data as before, based on the analysis in Haggard and Kaufman (2012), but now rather than implementing analysis case by case, the joint distribution of the data will become important for training the model. Here is a snapshot of the data: Case P I M D Afghanistan NA 1 NA 0 Albania 0 0 1 1 Algeria NA 0 NA 0 Angola NA 1 NA 0 Argentina 0 0 1 1 Bangladesh 0 0 0 1 Note that although data is gathered on \\(D\\) and \\(I\\) in all cases, data on mobilization, \\(M\\), and external pressure, \\(P\\), was only gathered for some (in fact, for those cases in which there was democratization). \\(M\\) in particular derives from qualitative research that assessed whether mobilization took place in those cases that democratized. The raw correlations berween variables is as shown in Table ??. Note that some of these correlations are missing because data was only gathered on some variables conditional on the values of others. For those quantities where do see correlations they are not especially strong. There is a weak relation between inequality and democratization – though this is consistent with inequality having different types of effect. the strongest correlation here is between \\(P\\) and \\(M\\), which are assumed to be uncorrelated in the model, though this correlation is also quite weak. ## Warning in cor(data[, -1], use = &quot;pairwise.complete.obs&quot;): the standard ## deviation is zero P I M D P 1.000 0.157 -0.177 NA I 0.157 1.000 0.114 -0.154 M -0.177 0.114 1.000 NA D NA -0.154 NA 1.000 9.3 Inference With data and model in hand we can update our model to get posteriors on the distribution of all admissible causal types. In practice this is done by constructing a stan model that maps from a set of parameters to a distribution on causal types which in turn provide a likelihood function for observable data. (Using the gbiqq package the posterior is calculated by gbiqq(model, data)) The parameters param_mat &lt;- get_parameter_matrix(model) dim(param_mat) ## [1] 29 240 9.3.1 Did inequality cause democracy? 9.3.2 Did inequality prevent democracy? We see that inequality appears more likely to prevent democratization than to cause it. We are most confident that inequality played a preventative role in those cases in which there was mobilization but still no democratization. We are most confident that inequality had a positive effect in those cases in which we observe mobilization—but even then the probability that inequality made the difference is small. 9.4 Prior / posterior comparison for multiple estimands Estimands can be calculated for both the prior and posterior distributions. Inequality causes democratization: Table 9.1: Prior Query Subset Using mean sd not named All priors 0.048 0.045 not named D==1 &amp; I==1 priors 0.128 0.121 not named D==1 &amp; I==1 &amp; M ==1 priors 0.156 0.137 not named D==1 &amp; I==1 &amp; M==0 priors 0.000 0.000 Table 9.1: Posterior Query Subset Using mean sd not named All posteriors 0.038 0.028 not named D==1 &amp; I==1 posteriors 0.123 0.089 not named D==1 &amp; I==1 &amp; M ==1 posteriors 0.167 0.117 not named D==1 &amp; I==1 &amp; M==0 posteriors 0.000 0.000 Inequality prevents democratization: Table 9.2: Prior Query Subset Using mean sd not named All priors 0.267 0.085 not named D==0 &amp; I==1 priors 0.468 0.157 not named D==0 &amp; I==1 &amp; M ==1 priors 0.490 0.180 not named D==0 &amp; I==1 &amp; M==0 priors 0.403 0.134 Table 9.2: Posterior Query Subset Using mean sd not named All posteriors 0.237 0.055 not named D==0 &amp; I==1 posteriors 0.353 0.088 not named D==0 &amp; I==1 &amp; M ==1 posteriors 0.410 0.144 not named D==0 &amp; I==1 &amp; M==0 posteriors 0.308 0.077 FLAG: Multiple estimands. 9.5 Discussion References "]
]
