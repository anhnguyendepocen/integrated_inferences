[
["questions.html", "Chapter 4 Causal Queries 4.1 Case-level causal effects 4.2 Case-level causal attribution 4.3 Case-level explanation 4.4 Average causal effects 4.5 Causal Paths", " Chapter 4 Causal Queries Although a lot of empirical work focuses on identifying average causal effects, there is a rich array of other well defined causal questions that can be asked about how variables relate to each other causally. We decribe major families of question and illustrate how these can all be described as questions about the values of nodes in a causal model. A general interest in causality masks tremendous heterogeneity in the kinds of causal questions that scholars tend to ask. Consider the relationship between inequality and democratization. We might seek, for instance, to know inequality’s average impact on democratization across some set of cases. Alternatively, we might be interested in a particular case—say, Mongolia in 1995—and want to know whether this is a context in which inequality has an effect—a question about causal effects at the case level. Relatedly—but distinctly—we might wonder whether the level of democracy in Mongolia in 1995 is causally attributable to the level of inequality in that case. And we may be interested in how causal effects unfold, inquiring about the pathway or mechanism through which inequality affects democratization—a question we can also ask at two levels. We can ask whether inequality affected democratization in Mongolia through mobilization of the masses; and we can ask how commonly inequality affects democratization through mobilization across a broad set of cases. Pushing further we might ask whether inequality would have produced democratization if mobilization was prevented from occurring. Rather separate methodological literatures have been devoted to the study of average causal effects, the analysis of case-level causal effects and explanations, and the identification of causal pathways. It is typically understood that their analysis requires quite distinct sets of tools. In this chapter, we take a key integrative step in showing that each of these queries can be readily captured in a causal model. More specifically, we demonstrate how causal queries can be represented as question about one or more nodes on a causal graph. When we assimilate our causal questions into a causal model, we are placing what we want to know in formal relation to both what we already know and what we can potentially observe. As we will see in later chapters, this move allows us then to deploy the model to generate strategies of inference: to determine which observations, if we made them, would be likely to yield the greatest leverage on our query, given our prior knowledge about the way the world works. And by the same logic, once we see the evidence, this integration allows us to “update” on our query—figure out in systematic fashion what we have learned—in a manner that takes background knowledge into account. In the remainder of this chapter, we walk through the conceptualization and causal-model interpretation of five key causal queries: Case-level causal effects Case-level causal attribution Case-level explanation Average causal effects Causal pathways These five are not exhaustive of the causal questions that can be captured in causal graphs, but they are among the more common foci of social scientific investigation. 4.1 Case-level causal effects The simplest causal question is whether some causal effect operates in an individual case. Does \\(X\\) have an effect on \\(Y\\) in this case? For instance, is Yemen in 1995 a case in which a change in economic inequality would produce a change in whether or not the country democratizes? We could put the question more specifically as a query about a causal effect in a particular direction, for instance: Does inequality have a positive effect on democratization in the case of Yemen in 1995? In counterfactual terms, a query about case-level causation is a question about what would happen if we could manipulate a variable in the case: if we could hypothetically manipulate \\(X\\)’s value in the case, would \\(Y\\)’s value also change? To ask whether a positive (or negative) effect operates for a case is to ask whether a particular counterfactual relation holds in that case. If we assume a binary setup for simplicity, to ask whether inequality has a positive effect on democratization is to ask: if we set \\(I\\) to \\(0\\) would \\(D\\) take on a value of \\(0\\), and if we set \\(I\\) to \\(1\\), would \\(D\\) take on a value of \\(1\\)? (Both of these conditions must hold for \\(I\\) to have a positive effect on \\(D\\).) We can easily represent this kind of query in the context of a causal model. We show the DAG for such a model in Figure . As introduced in Chapter 3, \\(\\theta^Y\\) here represents the causal type characterizing \\(Y\\)’s response to \\(X\\) and, if \\(X\\) and \\(Y\\) are binary, can take on one of four values: \\(\\theta^Y_{10}\\), \\(\\theta^Y_{01}\\), \\(\\theta^Y_{00}\\), and \\(\\theta^Y_{11}\\) (which map onto our original \\(a, b, c\\) and \\(d\\) types). Importantly, given that the value of nodes (or variables) is allowed to vary across cases, this setup allows for \\(\\theta_Y\\)—the causal effect of \\(X\\) on \\(Y\\)—to vary across cases. Thus, \\(X\\) may have a positive effect on \\(Y\\) in one case (with \\(\\theta^Y=\\theta^Y_{01}\\)), \\(X\\) may have a negative (\\(\\theta^Y=\\theta^Y_{10}\\)) or no effect (\\(\\theta^Y=\\theta^Y_{00}\\) or \\(\\theta^Y_{11}\\)) on \\(Y\\) in other cases. Figure 4.1: This DAG is a graphical representation of the simple causal setup in which the effect of \\(X\\) on \\(Y\\) in a given case depends on the case’s causal type, represented by \\(\\theta^Y\\). With a single binary causal variable of interest, we let \\(\\theta_Y\\) take on values \\(\\theta^Y_{ij}\\), with \\(i\\) representing the value \\(Y\\) takes on if \\(X=0\\) and \\(j\\) representing the value \\(Y\\) takes on if \\(X=1\\). With a binary framework outcome, \\(\\theta^Y\\) ranges over the four values: \\(\\theta^Y_{00}\\), \\(\\theta^Y_{10}\\), \\(\\theta^Y_{01}\\) and \\(\\theta^Y_{11}\\). In this model, then, the query, “What is \\(X\\)’s causal effect in this case?” simply becomes a question about the value of \\(\\theta_Y\\). Interpreted as “what is the expected effect of \\(X\\) on \\(Y\\)?” the question becomes one of estimating \\(\\Pr(\\theta^Y = \\theta^Y_{01}) - \\Pr(\\theta^Y = \\theta^Y_{10})\\). Similarly in a mediation model of the form \\(X\\rightarrow M \\rightarrow Y\\), like that discussed in Chapter 2, the question “What is the the expected effect of \\(X\\) on \\(Y\\)?” requires estimating \\[\\Pr((\\theta^M = \\theta^M_{01} \\&amp; \\theta^Y = \\theta^Y_{01}) | (\\theta^M = \\theta^M_{10} \\&amp; \\theta^Y = \\theta^Y_{10})) - \\Pr((\\theta^M = \\theta^M_{01} \\&amp; \\theta^Y = \\theta^Y_{10}) | (\\theta^M = \\theta^M_{10} \\&amp; \\theta^Y = \\theta^Y_{01}))\\] Of course, these \\(\\theta\\)s are not directly observable: causal types are intrinsically unobserved properties of cases. So, as we will see in later chapters, research design becomes a challenge of determining which observable nodes in the graph are potentially informative about the unobservable nodes that constitute our causal queries. 4.2 Case-level causal attribution A query about causal attribution is related to, but different from, a query about a case-level causal effect. When asking about \\(X\\)’s case-level effect, we are asking, “Would a change in \\(X\\) cause a change in \\(Y\\) in this case?” The question of causal attribution is slightly different: “Did \\(X\\) cause \\(Y\\) to take on the value it did in this case?” More precisely, we are asking, “Given the values that \\(X\\) and \\(Y\\) in fact took on in this case, would \\(Y\\)’s value have been different if \\(X\\)’s value had been different?” For instance, given that we know that inequality in Taiwan was relatively low and that Taiwan democratized in 1996, was low inequality a cause of Taiwan’s democratization in 1996? Put differently, given low economic inequality and democratization in Taiwan in 1996, would the outcome in this case have been different if inequality had been high? This goes beyond simply asking whether Taiwan is a case in which inequality has a causal effect on democratization. Whereas a case-level causal effect is defined in terms of a single \\(\\theta\\) node, we define a causal-attribution query in terms of a larger set of nodes. To attribute \\(Y\\)’s value in a case to \\(X\\), we need to know not only whether this is the kind of case in which \\(X\\) could have an effect on \\(Y\\) but also whether the context is such that \\(X\\)’s value in fact made a difference. Consider, for instance, the general setup in Figure 4.2. Here, \\(Y\\) is a function of two variables, \\(X\\) and \\(W\\). This means that \\(\\theta^Y\\) is somewhat more complicated than in a setup with one causal variable: \\(\\theta^Y\\) must here define \\(Y\\)’s response to different combinations of two other variables, \\(X\\) and \\(W\\), since both of these variables point directly into \\(Y\\). Thus, \\(\\theta^Y\\) must cover the full set of possible causal interactions between two binary causal variables. Figure 4.2: This DAG is a graphical representation of the simple causal setup in which \\(Y\\) depends on two variables \\(X1\\) and \\(X2\\). How \\(Y\\) responds to X1 and X2 depnds on \\(\\theta^Y\\), the DAG itself does not provide information on whether or how X1 and X2 interact with each other. We already saw the set of causal types for a set up like this in Chapter 2 (see Table ??). In the table, there are four column headings representing the four possible combinations of \\(X1\\) and \\(X2\\) values. Each row represents one possible pattern of \\(Y\\) values as \\(X1\\) and \\(X2\\) move through their four combinations. One way to conceptualize the size of the causal-type “space” is to note that \\(X1\\) can have any of our four causal effects (the four binary types) on \\(Y\\) when \\(X2=0\\); and \\(X1\\) can have any of four causal effects when \\(X2=1\\).1 This yields 16 possible response patterns to combinations of \\(X1\\) and \\(X2\\) values. A query about causal attribution—whether \\(X1 = 1\\) caused \\(Y=1\\)—for the model in Figure 4.2, would be defined in terms of both \\(X2\\) and \\(\\theta_Y\\). Parallel to our Taiwan example, suppose that we have a case in which \\(Y=1\\) and in which \\(X1\\) was also 1, and we want to know whether \\(X1\\) caused \\(Y\\) to take on the value it did. Answering this question requires knowing whether the case’s type is such that \\(X1\\) would have had a positive causal effect on \\(Y\\), given the value of \\(X2\\) (which we might think of as the context). Thus, given that we start with knowledge of \\(X1\\)’s and \\(Y\\)’s values, our query about causal attribution amounts to a query about two nodes on the graph: (a) the value of \\(X2\\) and (b) whether the value of \\(\\theta^Y\\) is such that \\(X1\\) has a positive causal effect given \\(X2\\)’s value. Suppose, for instance, that we were to observe \\(X2=1\\). We then need to ask whether the causal type, \\(\\theta_Y\\), is such that \\(X1\\) has a positive effect when \\(X2=1\\). Consider type 8, or \\(\\theta_{01}^{11}\\). This is a causal type in which \\(X1\\) has a positive effect when \\(X2=0\\) but no effect when \\(X2=1\\). Put differently, \\(X2=1\\) is a sufficient condition for \\(Y=1\\), meaning that \\(X1\\) makes no difference to the outcome when \\(X2=1\\). In all we have four qualifying types. In other words, we can attribute a \\(Y=1\\) outcome to \\(X1=1\\) when \\(X2=1\\) and the causal type is one of these four. By parallel reasoning, there are also four causal types for which we can attribute a \\(Y=1\\) outcome to \\(X1=1\\) when \\(X2=0\\). Thus, a question about causal attribution is a question about the joint value of a set of nodal types: about whether the combination of context and causal type is such that changing \\(X\\) would have changed the outcome. 4.3 Case-level explanation So far we have been dealing with causes in the standard counterfactual sense: antecedent conditions a change in which would have produced a different outcome. Sometimes, however, we are interested in identifying antecedent conditions that were not counterfactual difference-makers but that nonetheless generated or produced the outcome. Consider, for instance, a situation in which an outcome was overdetermined: multiple conditions were present, each of which on their own, could have generated the outcome. Then none of these conditions caused the outcome in the counterfactual sense; yet one or more of them may have been distinctively important in producing the outcome. The concept of an actual cause may be useful in putting a finer point on this kind of causal question. Let us first approach the concept at an intuitive level. An antecedent condition, \\(A\\), that played a role in generating an outcome might not be a counterfactual cause because, had it not occurred, some second chain of events set in motion by \\(B\\) would have unfolded, generating the outcome anyway. In the standard counterfactual scenario, \\(A\\) is not a counterfactual cause: take away \\(A\\) and the outcome still happens because of the chain of events emanating from \\(B\\). Yet let us imagine that the fact that \\(A\\) did occur prevented part of \\(B\\)’s chain of consequences from unfolding and itself producing the outcome. Then let us imagine a tweaked counterfactual comparison in which we fix the observed fact that \\(B\\)’s causal sequence did not fully unfold. We can then ask: conditional on \\(B\\)’s sequence not fully unfolding, would \\(A\\) have been a counterfactual cause of the outcome? If so, then we say that \\(A\\) is an “actual cause”\" of the outcome. We have, in a sense, identified \\(A\\) as distinctively important in the production of the outcome, even if it was not a case-level cause in the usual sense. More formally, and using the definition provided by (Halpern 2015), building on (Halpern and Pearl 2005) and others, we say that a condition (\\(X\\) taking on some value \\(x\\)) was an actual cause of an outcome (of \\(Y\\) taking on some value \\(y\\)), where \\(x\\) and \\(y\\) may be collections of events, if: \\(X=x\\) and \\(Y=y\\) both happened there is some set of variables, \\(\\mathcal W\\), such that if they were fixed at the levels that they actually took in the case, and if \\(X\\) were to be changed, then \\(Y\\) would change (where \\(\\mathcal W\\) can also be an empty set) no strict subset of \\(X\\) satisfies 1 and 2 (there is no redundant part of the condition, \\(X=x\\)) The definition thus describes a condition that would have been a counterfactual cause of the outcome if we were to imagine holding constant some set of events that in fact occurred (and that, in reality, might not have been constant if the actual cause had not in fact occurred). A motivating example used in much of the literature on actual causes (e.g. Hall 2004) imagines two characters, Sally and Billy, simultaneously throwing stones at a bottle. Both are great shots and hit whatever they aim at. Sally’s stone hits first, and so the bottle breaks. However, Billy’s stone would have hit had Sally’s not hit, and would have broken the bottle. Did Sally’s throw cause the bottle to break? Did Billy’s? By the usual definition of causal effects, neither Sally’s nor Billy’s action had a causal effect: without either throw, the bottle would still have broken. We commonly encounter similar situations in the social world. We observe, for instance, the onset of an economic crisis and the breakout of war—either of which would be sufficient to cause the government’s downfall—but with the economic crisis occurring first and toppling the government before the war could do so. Yet neither economic crisis nor war made a difference to the outcome. To return to the bottle example, while neither Sally’s nor Billy’s throw is a counterfactual cause, there is an important sense in which Sally’s action obviously broke the bottle, and Billy’s did not. This intuition is confirmed by applying the definition above. Consider first the question: Did Sally’s throw break the bottle? Conditions 1 and 3 are easily satisfied, since Sally throw and the bottle break (Condition 1), and “Sally threw” has no strict subsets (Condition 3). Condition 2 is met if Sally’s throw made a difference, counterfactually speaking; and in determining this, we are permitted to condition on (to fix in the counterfactual comparison) any event or set of events that actually happened (or on on none at all). To see why Condition 2 is satisfied, we have to think of there being three steps in the process: Sally and Billy throw, Sally’s or Billy’s rock hits the bottle, and the bottle breaks. In actuality, Billy’s stone did not hit the bottle. And conditioning on this actually occurring event (Billy’s stone not hitting), the bottle would not have broken had Sally not thrown. From the perspective of counterfactual causation, it may seem odd to condition on Billy’s stone not hitting the bottle when thinking about Sally not throwing the stone since Sally’s throwing the stone was the very thing that prevented Billy from hitting the bottle. Yet Halpern argues that this is an acceptable thought experiment for establishing the importance of Sally’s throw since conditioning is constrained to the actual facts of the case. Moreover, the same logic shows why Billy is not an actual cause. The reason is that Billy’s throw is only a cause in those conditions in which Sally did not hit the bottle. But because Sally actually hit the bottle, we are not permitted to condition on Sally not hitting the bottle in determining actual causation. We thus cannot—even through conditioning on actually occurring events—construct any counterfactual comparison in which Billy’s throw is a counterfactual cause of the bottle’s breaking. The striking result here is that there can be grounds to claim that a condition was the actual cause of an outcome even though, under the counterfactual definition, the effect of that condition on the outcome is 0. (At the same time, all counterfactual causes are automatically actual causes; they meet Condition 2 by conditioning on nothing at all, an empty set \\(\\mathcal W\\).) One immediate methodological implication follows: since actual causes need not be causes, there are risks in research designs that seek to understand causal effects by tracing back actual causes—i.e., the way things actually happened. If we traced back from the breaking of the bottle, we might be tempted to identify Sally’s throw as the cause of the outcome. We would be right only in an actual-causal sense, but wrong in the standard, counterfactual causal sense. Chains of events that appear to “generate” an outcome are not always causes.2 As with other causal queries, the question “Was \\(X=x\\) the actual cause of \\(Y=y\\)?” can be redefined as a question about which values for exogenous nodes produce conditions under which \\(X\\) could have made a difference. To see how, let us run through the Billy and Sally example again, but formally in terms of a model. Consider Figure , where we represent Sally’s throw (\\(S\\)), Billy’s throw (\\(B\\)), Sally’s rock hitting the bottle (\\(H^S\\)), Billy’s rock hitting the bottle (\\(H^B\\)), and the bottle cracking (\\(C\\)). Each endogenous variable has a \\(\\theta\\) term associated with it, capturing its response to its parents. We capture the possible “preemption” effect with the arrow pointing from \\(H^S\\) to \\(H^B\\), allowing that whether Sally’s rock hits to affect whether Billy’s rock hits. Let us again imagine that Sally threw (\\(S=1\\)), Billy threw (\\(B=1\\)), and the bottle cracked (\\(C=1\\)). Let us say that \\(\\theta^{H^B}\\) takes on a value such that (a) \\(H^B=0\\) whenever \\(H^S=1\\) (Sally’s hit preempts Billy’s) and (b) \\(B\\) has a positive effect on \\(H^B\\) when \\(H^S=0\\) (Billy’s throw hits if Sally’s doesn’t). Further, assume that \\(S\\) has a positive effect on \\(H^S\\). Let us finally posit that \\(\\theta^C\\) takes on a value such that \\(C=1\\) if \\(H^B\\) equals \\(1\\).3 This is a set of \\(\\theta\\) values under which the query, “Does \\(S\\) have a causal effect on \\(C\\)?” must be answered in the negative. Similarly, this is a context in which \\(C=1\\) cannot be causally attributed to \\(S=1\\). If Sally had not thrown, then Sally’s rock would not have hit the bottle, which means that Billy’s rock would have hit, and the bottle would still have cracked—still, \\(C=1\\). However, it is still possible that \\(S=1\\) was an actual cause of \\(C=1\\). To complete this query, we need to ask whether there is some node value that we can hold fixed at the value that it actually assumed in the case such that \\(S\\) would have a causal effect on the outcome. Fixing \\(B=1\\) (Billy throws) cannot help (since if Billy throws, Billy hits, and the bottle cracks anyway). However, under \\(S=1\\) and \\(B=1\\), given the \\(\\theta\\) values we have posited, \\(H^B=0\\): Billy’s rock does not hit. If we hold constant that \\(H^B=0\\), then there is an “opportunity” for \\(S\\) to matter in that \\(C\\) is no longer forced to 1 (by Billy’s rock hitting). But for \\(S\\) to matter under his scenario, something else has to be true: \\(\\theta^C\\)’s value must allow for \\(H^S\\) to have a positive effect on \\(C\\) when \\(H^B=0\\). Using our two-cause notation (with \\(H^S\\) on the horizontal axis, and \\(H^B\\) on the vertical), and given that we have already stipulated that \\(C=1\\) when \\(H^B=1\\), the one permissible value for \\(\\theta^C\\) is \\(\\theta^{11}_{01}\\). This is causal type in which neither \\(H^B\\) nor \\(H^S\\) can be causal if both Billy and Sally throw: whenever one variable is 1, the other has no effect. But it is also a type in which each has a causal effect if the other is held at 0. It is also the case, as we have said, that all counterfactual causes are actual causes. They are, quite simply, counterfactual causes when we hold nothing fixed (\\(\\mathcal W\\) is the empty set). Thus, in fact, any \\(\\theta^S\\), \\(\\theta^{H^S}\\) and \\(\\theta^C\\) values in which \\(S\\) has a positive effect when \\(B=1\\) will do. This includes, for instance, a \\(\\theta^C\\) value in which Billy’s hitting has no effect on the bottle (perhaps Billy doesn’t throw hard enough!): e.g., \\(\\theta^{01}_{01}\\). Here, Sally’s throw is both a counterfactual cause and an actual cause of the bottle’s cracking. The larger point is that actual cause queries can, like all other causal queries, be defined as questions about the values of nodes in a causal model. Figure 4.3: This DAG is a graphical representation of the simple causal setup in which the effect of \\(X\\) on \\(Y\\) in a given case depends on the case’s causal type, represented by \\(\\theta^Y\\). With a single binary causal variable of interest, we let \\(\\theta_Y\\) take on values \\(\\theta^Y_{ij}\\), with \\(i\\) representing the value \\(Y\\) takes on if \\(X=0\\) and \\(j\\) representing the value \\(Y\\) takes on if \\(X=1\\). With a binary framework outcome, \\(\\theta^Y\\) ranges over the four values: \\(\\theta^Y_{00}\\), \\(\\theta^Y_{10}\\), \\(\\theta^Y_{01}\\) and \\(\\theta^Y_{11}\\). Actual causes are conceptually useful whenever there are two sufficient causes for an outcome, but one preempts the operation of the other. For instance, we might posit that both the United States’ development of the atomic bomb was a sufficient condition for U.S. victory over Japan in World War II, and that U.S. conventional military superiority was also a sufficient condition and would have operated via a land invasion of Japan. Neither condition was a counterfactual cause of the outcome because both were present. However, holding constant the absence of a land invasion, the atomic bomb was a difference-maker, rendering it an actual cause. The concept of actual cause thus helps capture the sense in which the atomic bomb contributed to the outcome, even if it was not a counterfactual cause. Similarly, the question of how common it is for a condition to be an actual cause can be expressed as values of nodes, possibly including nodes that record parameter values for the relevant exogenous nodes. An extended notion (Halpern 2016, p 81) of actual causes restricts the imagined counterfactual deviations to states that are more likely to arise (more “normal”) than the factual state. We will call this notion a ‘’notable cause.’’ Similarly, one cause, \\(A\\), is “more notable” than another cause, \\(B\\), if a deviation in \\(A\\) from its realized state is (believed to be) more likely than a deviation in \\(B\\) from its realized state. For intuition, we might wonder why a Republican was elected to the presidency in a given election. In looking at some minimal winning coalition of states that voted Republican, we might distinguish between a set of states that always vote Republican and a set of states that usually go Democratic but voted Republican this time. If the coalition is minimal winning, then every state that voted Republican is a cause of the outcome in the standard (difference making) sense. However, only the states that usually vote Democratic are notable causes since it is only for them that the counterfactual scenario (voting Democratic) was more likely to arise than the factual scenario. In a sense, we take the “red” states’ votes for the Republican as given—placing it, as it were, in the causal background—and identify as “notable” those conditions that mattered and easily could have gone differently. By the same token, we can say that, among those states that voted Republican this time, those that more commonly vote Democratic are more notable causes than those that less commonly vote Democratic. Again, whether something is a notable cause, or the likelihood in some population that a condition is a notable cause, can be expressed as a claim about the value of a set of root nodes. Though not a focus of our applied examples we show formally how to estimate these estimands in the Appendix, section XXX. 4.4 Average causal effects A more general query asks about an average causal effect in some population. In counterfactual terms, a question about average causal effects is: if we manipulated the value of \\(X\\) for all cases in the population—first setting \\(X\\) to one value for all cases, then changing it to another value for all cases—by how much would the average value of \\(Y\\) in the population change? Like other causal queries, a query about an average causal effect can be conceptualized as learning about a node in a causal model. We can do this by conceiving of any given case as being a member of a population composed of different causal types. When we seek to estimate an average causal effect, we seek information about the shares of these causal types in the population. More formally and adapted from Humphreys and Jacobs (2015), we can use \\(\\lambda^Y_{ij}\\) to refer to the share of cases in a population that has causal type \\(\\theta^Y_{ij}\\). Thus, given our four causal types above, \\(\\lambda^Y_{10}\\) is the proportion of cases in the population with negative effects; \\(\\lambda_{01}\\) is the proportion of cases with positive effects; and so on. We can, of course, also think of these shares as probabilities; that is, we can think of any given case as being ``drawn’’ from a multinomial distribution with probabilities \\(\\lambda = (\\lambda^Y_{10}, \\lambda^Y_{01}, \\lambda^Y_{00}, \\lambda^Y_{11})\\). One nice feature of this setup, with both \\(X\\) and \\(Y\\) as binary, the average causal effect can be simply characterized as the share of positive-effect cases less the share of negative-effect cases: \\(\\lambda^Y_{01} - \\lambda^Y_{10}\\). Graphically, we can represent this setup by including \\(\\lambda^Y\\) in a more complex causal graph as in Figure . As in our setup for case-level causal effects, \\(X\\)’s effect on \\(Y\\) in a case depends on (and only on) the case’s causal type, \\(\\theta^Y\\). The key difference is that we now model the case’s type not as exogenously given, but as a function of two additional variables: the distribution of causal types in a population and a random process through which the case’s type is “drawn” from that distribution. We represent the type distribution as \\(\\lambda^Y\\) (a vector of values for the proportions \\(\\lambda^Y_{10}, \\lambda^Y_{01}, \\lambda^Y_{00}, \\lambda^Y_{11}\\)) and the random process drawing a \\(\\theta^Y\\) value from that distribution as \\(U_\\theta\\). FLAG: CLARIFY PHILOSOPHOICAL INTERPREATAION OF LAMBDA AS SHARES In this model, our causal query—about \\(X\\)’s average causal effect—is thus defined by the vector \\(\\lambda^Y\\), and specifically by the shares of negative- and positive-causal-effect cases, respectively, in the population. What is \\(X\\)’s average effect on \\(Y\\) amounts to asking: what are the values of \\(\\lambda^Y_{10}\\) and \\(\\lambda^Y_{01}\\)? As with \\(\\theta^Y\\), \\(\\lambda^Y\\) is not directly observable. And so the empirical challenge is to figure out what we can observe that would allow us to learn about \\(\\lambda^Y\\)’s component values?4 Figure 4.4: This DAG is a graphical representation of a causal setup in which cases are drawn from a population composed of different causal types. As before, \\(X\\)’s effect on \\(Y\\) is a function of a causal-type variable, \\(\\theta^Y\\). Yet here we explicitly model the process through which the case’s type is drawn from a distribution of types in a population. The variable \\(\\lambda\\) is a vector representing the multinomial distribution of causal types in the population while \\(U_\\theta\\) is a random variable representing the draw of each case from the distribution defined by \\(\\lambda\\). A case’s causal type, \\(\\theta^Y\\), is thus a joint function of \\(\\lambda^Y\\) and \\(U^{\\theta_Y}\\). We can, of course, likewise pose queries about other population-level causal quantities. For instance, we could ask for what proportion of cases in the population \\(X\\) has a positive effect: this would be equivalent to asking the value of \\(\\lambda^Y_{01}\\), one element of the \\(\\lambda^Y\\) vector. Or we could ask about the proportion of cases in which \\(X\\) has no effect, which would be asking about \\(\\lambda^Y_{00} + \\lambda^Y_{11}\\). 4.5 Causal Paths To develop richer causal understandings, researchers often seek to describe the causal path or paths through which effects propagate. Consider the DAG in Figure 4.5, in which \\(X\\) can affect \\(Y\\) through two possible pathways: directly and via \\(M\\). Assume again that all variables are binary, taking on values of \\(0\\) or \\(1\\). As we have seen in Chapter 3, mediation models require causal-type nodes that point into any mediators as well as into the outcome variable. So here we have drawn in a causal-type variable defining \\(M\\)’s response to \\(X\\), \\(\\theta^M\\), and a causal-type variable capturing \\(Y\\)’s response, \\(\\theta^Y\\). Importantly, \\(\\theta^Y\\) defines \\(Y\\)’s response to two parent variables: \\(M\\) and \\(X\\). Suppose that we observe \\(X=1\\) and \\(Y=1\\) in a case. Suppose, further, that we have reasonable confidence that \\(X\\) has had a positive effect on \\(Y\\) in this case. We may nonetheless be interested in knowing whether that causal effect ran through \\(M\\). We will refer to this as a query about a causal path. A causal path query, of course, goes beyond assessing whether some mediating event along the path occurred. We cannot, for instance, establish that the top path in Figure was operative simply by determining the value of \\(M\\) in this case—though that will likely be useful information. Rather, the question of whether the top (mediated) causal path is operative is a composite question of two parts: First, does \\(X\\) have an effect on \\(M\\) in this case? Second, does that effect—the difference in \\(M\\)’s value caused by a change in \\(X\\)—in turn cause a change in \\(Y\\)’s value? In other words, what we want to know is whether the effect of \\(X\\) on \\(Y\\) depends on—will not operate without—the effect of \\(X\\) on \\(M\\).5 Framing the query in this way makes clear that asking whether a causal effect operated via a given path is in fact asking about a specific set of causal effects lying along that path. Figure 4.5: Here \\(X\\) has effects on \\(Y\\) both indirectly through \\(M\\) and directly. As we can show, we can also define a causal-path query as a question about specific nodes on a causal graph. In particular, just as we have defined other questions about causal effects in terms of causal-type nodes, a causal path can also be defined in terms of the values of type nodes: specifically, in the present example, in terms of the nodes \\(\\theta^M\\) and \\(theta^Y\\). To see why, let us first note that there are two combinations of effects that would allow \\(X\\)’s positive effect on \\(Y\\) to operate via \\(M\\): (1) \\(X\\) has a positive effect on \\(M\\), which in turn has a positive effect on \\(Y\\); or (2) \\(X\\) has a negative effect on \\(M\\), which has a negative effect on \\(Y\\). Thus, in establishing whether \\(X\\) affects \\(Y\\) through \\(M\\), the first question is whether \\(X\\) affects \\(M\\) in this case. Whether or not it does is a question about the value of the causal-type node, \\(\\theta^M\\). Let us assume that \\(\\theta^M\\) can take on four possible values corresponding to the four possible responses to \\(X\\): \\(\\theta^M_{10}, \\theta^M_{01}, \\theta^M_{00}, \\theta^M_{11}\\).6 For sequence (1) to operate, \\(\\theta^M\\) must take on the value \\(\\theta^M_{01}\\), representing a positive effect of \\(X\\) on \\(M\\). For sequence (2) to operate, \\(\\theta^M\\) must take on the value \\(\\theta^M_{10}\\), representing a negative effect of \\(X\\) on \\(M\\). \\(\\theta^Y\\), as for our causal-attribution example, defines \\(Y\\)’s response to different combinations of two other variables—here, \\(X\\) and \\(M\\)—since both of these variables point directly into \\(Y\\). Another way to think about this setup is that \\(M\\) is not just a possible mediator of \\(X\\)’s indirect effect; \\(M\\) is also a potential moderator of \\(X\\)’s direct effect. Where \\(X\\) can have both an mediated effect through \\(M\\) and a direct effect, \\(X\\) and \\(M\\) also potentially interact in affecting \\(Y\\). This results in sixteeen possible values for \\(\\theta^Y\\)—again as shown above in Table ??. What values of \\(\\theta^Y\\) then are compatible with the operation of the \\(M\\) causal path? Let us first consider this question with respect to sequence (1), in which \\(X\\) has a positive effect on \\(M\\), and that positive effect is necessary for \\(X\\)’s positive effect on \\(Y\\) to occur. For this sequence to operate, \\(\\theta^M\\) must take on the value of \\(\\theta^M_{01}\\). When it comes to \\(\\theta^Y\\), then, what we need to look for types in which \\(X\\)’s effect on \\(Y\\) depends on \\(M\\)’s taking on the value it does as a result of \\(X\\)’s positive effect on \\(M\\). We are thus looking for causal types that represent two kinds of counterfactual causal relations operating on nodes. First, \\(X\\) must have a positive effect on \\(Y\\) when \\(M\\) changes as it should given \\(X\\)’s positive effect on \\(M\\). Second, that change in \\(M\\), generated by a change in \\(X\\), must be necessary for \\(X\\)’s positive effect on \\(Y\\) to operate. The thought experiment here thus imagines a situation in which \\(X\\) changes from \\(0\\) to \\(1\\),7 but \\(M\\) does not change to the value that it should as a result of this change in \\(X\\). We then inspect our types to see if \\(Y\\) would change from \\(0\\) to \\(1\\) in this situation. It is this counterfactual that isolates the causal significance of the path that runs through \\(M\\). It is only if \\(Y\\) would not change to \\(1\\) in this situation that we have identified a causal-type for which the \\(M\\)-mediated path matters. Assuming a positive effect of \\(X\\) on \\(M\\) (\\(\\theta^M=\\theta^M_{01}\\)), we thus need to apply three queries to \\(\\theta^Y\\):8 Is \\(X=1\\) a counterfactual cause of \\(Y=1\\)? Establishing this positive effect of \\(X\\) involves two queries: Where \\(X=0\\), does \\(Y=0\\)? As we are assuming \\(X\\) has a positive effect on \\(M\\), if \\(X=0\\) then \\(M=0\\) as well. We thus look down the \\(X=0, M=0\\) column and eliminate those types in which we do not observe \\(Y=0\\). This eliminates types \\(9\\) through \\(16\\). Where \\(X=1\\), does \\(Y=1\\)? Again, given \\(X\\)’s assumed positive effect on \\(M\\), \\(M=1\\) under this condition. Looking down the \\(X=1, M=1\\) column, we eliminate those types where we do not see \\(Y=1\\). We retain only types \\(2, 4, 6,\\) and \\(8\\). Is \\(X\\)’s effect on \\(M\\) necessary for \\(X\\)’s positive effect on \\(Y\\)? That is, do we see \\(Y=1\\) only if \\(M\\) takes on the value that \\(X=1\\) generates (\\(M=1\\))? To determine this, we inspect the counterfactual condition in which \\(X=1\\) yet \\(M=0\\), and we ask: does \\(Y=0\\)? Of the four remaining types, only \\(2\\) and \\(6\\) pass this test. Under these and only these two values of \\(\\theta^Y\\)—\\(\\theta_{00}^{01}\\) and \\(\\theta_{00}^{11}\\)—we will see a positive effect of \\(X\\) on \\(Y\\) for which the \\(M\\)-mediated path is causally necessary as long as \\(X\\) also has a positive effect on \\(M\\). These two \\(\\theta^Y\\) values are also different from one another in an interesting way. For type \\(\\theta_{00}^{11}\\), \\(X\\)’s effect on \\(Y\\) runs strictly through \\(M\\): if \\(M\\) were to change from \\(0\\) to \\(1\\) without \\(X\\) changing, \\(Y\\) would still change from \\(0\\) to \\(1\\). \\(X\\) is causally important for \\(Y\\) only insofar as it affects \\(M\\). In a case of type \\(\\theta_{00}^{11}\\), then, anything else that similarly affects \\(M\\) would generate the same effect on \\(Y\\) as \\(X\\) does. In type \\(\\theta_{00}^{01}\\), however, both \\(X\\)’s change to \\(1\\) and the resulting change in \\(M\\) are necessary to generate \\(Y\\)’s change to \\(1\\); \\(X\\)’s causal effect thus requires both the mediated and the unmediated pathway. Andhere \\(X\\) itself matters in the counterfactual sense; for a case of type \\(\\theta_{00}^{01}\\), some other cause of \\(M\\) would not generate the same effect on \\(Y\\). We can undertake the same exercise for sequence (2), in which \\(X\\) first has a negative effect on \\(M\\), or \\(\\theta^M=\\theta^M_{10}\\). Here we adjust the three queries for \\(\\theta^Y\\) to take account of this negative effect. Thus, we adjust query 1a so that we are looking for \\(Y=0\\) when \\(X=0\\) and \\(M=1\\). In query 1b, we look for \\(Y=1\\) when \\(X=1\\) and \\(M=0\\). And for query 2, we want types in which \\(Y\\) fails to shift to \\(1\\) when \\(X\\) shifts to \\(1\\) but \\(M\\) stays at \\(1\\). Types \\(\\theta_{01}^{00}\\) and \\(\\theta_{11}^{00}\\) pass these three tests. In sum, we can define a query about causal paths as a query about the value of \\(\\theta\\) terms on the causal graph. For the graph in Figure , asking whether \\(X\\)’s effect runs via the \\(M\\)-mediated path is asking whether one of four combinations of \\(\\theta^M\\) and \\(\\theta^Y\\) hold in case: \\(\\theta^M=\\theta^M_{01}\\) and (\\(\\theta^Y=\\theta_{00}^{01}\\) or \\(\\theta_{00}^{11}\\)) \\(\\theta^M=\\theta^M_{01}\\) and (\\(\\theta^Y=\\theta_{01}^{00}\\) or \\(\\theta_{11}^{00}\\)) It is worth noting how different this formulation of the task of identifying causal pathways is from widespread understandings of process tracing. Scholars commonly characterize process tracing as a method in which we determine whether a mechanism was operating by establishing whether the events lying along that path occurred. As a causal-model framework makes clear, finding out that \\(M=1\\) (or \\(M=0\\), for that matter) does not establish what was going on causally. Observing this intervening step does not by itself tell us what value \\(M\\) would have taken on if \\(X\\) had taken on a different value, or whether this would have changed \\(Y\\)’s value. We need instead to conceive of the problem of identifying pathways as one of figuring out the counterfactual response patterns of the variables along the causal chain. As we will demonstrate later in the book, explicitly characterizing those response patterns as nodes in a causal model helps us think systematically about empirical strategies for drawing the relevant inferences. References "]
]
