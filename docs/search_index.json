[["theory.html", "Chapter 6 Theories as causal models 6.1 Models as theories of 6.2 Uses 6.3 The rules 6.4 Structural consistency 6.5 From structure to beliefs about types 6.6 Probabilistic consistency 6.7 Illustration of unpacking nodal types 6.8 Conclusion 6.9 Chapter Appendices 6.10 Connections to other writing on theory 6.11 Illustration of a Mapping from a Game to a DAG", " Chapter 6 Theories as causal models We describe an approach in which theoretical claims are thought of as model justifications within a hierarchy of causal models. Lower-level models serve as a theory for a higher level model if the higher level model can be deduced from the lower level model. The empirical content of a lower level model is the possible reduction in variance of the higher level model that it can provide. In Chapter 3, we worked with a set of theories. But we havent yet been very explicit by what we mean by a theory or how theory maps onto a causal-model framework. In this book, we will think of theory as a type of explanation: a theory provides an account of how or under what conditions a set of causal relationships operate. We generally express both a theory and the claims being theorized as causal models. The theory is then is a model that implies another modelpossibly with the help of some data. To fix ideas: a simple claim might be that A caused B in case \\(j\\). This claim is itself a model, albeit a very simple one. The theory that supports this model might be of the form A always causes B, A always causes B whenever C (and C holds in case j), or A causes B and B causes C. All of which might be arguments provided to support the simple claim: if you believe the theory you believe the implication. The rest of this chapter builds out this idea and uses it provide a way of characterizing when a theory is useful or not. First, we elaborate upon our working definition of theory, showing how it operates within a conception of models in levels. This requires thinking through how a more detailed, lower-level causal structure can imply, and thus explain, a less-detailed higher-level structure. We also work through how the nodal and causal types in a more detailed model, and beliefs about those types, map onto types (and beliefs about types) in a simpler model. Further, we outline what kinds of elaborations of a simple model are possible (as we outlined in Chapter 2 what kinds of simplifications of models are permissible). We then turn to the relationship between theory and evidence in a causal-model framework, as compared to the way that relationship operates in a more conventional theory-testing approach. Put simply, when we work with causal models, we do not subject our theories to up-or-down empirical tests against data; rather, we allow the data to shift our beliefs across causal possibilities within a multi-dimensional theoretical space. In embedding theorization within the world of causal models, we ultimately have an empirical objective in mind. Theorizing a causal relationship of interest, in our framework, means elaborating our causal beliefs about the world in greater detail. As we show in later chapters, theorizing in the form of a causal model allows us to generate research designs: to identify sources of inferential leverage and to explicitly and systematically link observations of components of a causal system to the causal questions we seek to answer. We discuss toward the end of the chapter how this definition of theory relates to common understandings of theory in the social sciences. 6.1 Models as theories of Let us say that a causal model, \\(M^\\prime\\), is a theory of \\(M\\) if \\(M\\) is implied by \\(M^\\prime\\). Theory is, thus, all relative. \\(M^\\prime\\) might itself sit atopbe supported bya theory, \\(M^{\\prime\\prime}\\), that implies \\(M^\\prime\\). To help fix the idea of theory as supporting or underlying the model(s) it theorizes, we refer to the theory, \\(M^\\prime\\), as a lower-level model relative to \\(M\\) and refer to \\(M\\) as a higher-level model relative to its theorization, \\(M^\\prime\\).1 Both structural models and probabilistic modelspossibly in combination with dataimply other models. We discuss each in turn. 6.1.1 Implications of structural causal models Structural models can imply other simpler structural models. Take the very simple model, \\(M\\), represented in Figure 6.1(a). The model simply states that \\(X\\) has (or can have) a causal effect on \\(Y\\). What models might imply model \\(M\\)? The figure points to two. Both models \\(M^\\prime\\) and \\(M^{\\prime\\prime}\\) imply model \\(M\\). They can be thought of as theories, or lower-level model, of \\(M\\). Model \\(M^\\prime\\) differs by the addition of a node, \\(K\\), in the causal chain between \\(X\\) and \\(Y\\). We can say that \\(M^\\prime\\) is a theory of \\(M\\) for two reasons. First it provides a justificationif you believe \\(M^\\prime\\) you should believe \\(M\\): if \\(X\\) affects \\(Y\\) through \\(K\\), then \\(X\\) affects \\(Y\\). But as well as a justification it also provides an explanation of \\(M\\). If we ask, why does \\(X\\) affect \\(Y\\)? \\(M^\\prime\\) provides an answer: \\(X\\) affects \\(Y\\) because \\(X\\) affects \\(K\\), and \\(K\\) affects \\(Y\\). Model \\(M^{\\prime\\prime}\\) differs by the addition of a node, \\(C\\), that moderates the effect of \\(X\\) on \\(Y\\). \\(M^{\\prime\\prime}\\) justifies \\(M\\) in the sense that if you believe \\(M^{\\prime\\prime}\\) you should believe \\(M\\). It provides an explanation of a kind also: if you believe model \\(M^{\\prime\\prime}\\) you likely believe that the relation between \\(X\\) and \\(Y\\) is what it is because of \\(C\\). Had \\(C\\) been different the causal relation between \\(X\\) and \\(Y\\) might have been also. Figure 6.1: Here we represent the simple claim that one variable causes another, and two theories  lower-level models  that could explain this claim. Both model (b) and model (c) involve theorization via disaggregation of nodes. 6.1.2 Implications of probabilistic causal models A probabilistic model can also be implied by another probabilistic model coupled with data. Indeed that is the essence of model updating. For this reason we can fruitfully think of a an initial model as being a theory of an updated model, coupled with data. Thought of in this way we have clarity over what is meant when we turn to theory to support a claim, but also what is meant when we seek to justify a theory. We might imagine a scholar arguing: \\(M\\): \\(X\\) caused \\(Y\\) in country \\(j\\). When pushed for a justification for the claim they provide the lower level model\\(M:\\) the average effect of \\(X\\) on \\(Y\\) in countries with feature \\(C=1\\) is 0.95, making it likely that \\(X\\) caused \\(Y\\) in this case. In fact here \\(M\\) is implied by \\(M\\) coupled with data \\(C=1\\). If pushed further as to why that theory is itself credible they might point to a lower level model consisting of structural model \\(X\\rightarrow Y \\leftarrow C\\) plus flat priors coupled with data on \\(X,Y\\) and \\(C\\). At each stage as more justification is provided the researcher formally provides lower level models. 6.2 Uses 6.2.1 Explanation Theorization starts with the proliferation of substantive variablesadding beliefs about intervening steps in a causal process. But, critically, it also involves an accompanying disaggregation of unexplained variation. Addition and splitting thus go hand-in-hand: the insertion of a mediator between \\(X\\) and \\(Y\\) also involves the splitting of \\(Y\\)s type node (\\(\\theta_Y\\)). We have already discussed two possible forms of structural elaboration or theorization: (i) disaggregating existing nodes, i.e., by introducing beliefs about mediation or moderation, or (ii) adding nodes representing variation in a feature of context that is implicitly held constant in the higher-level model. There are, however, other possible ways of elaborating a model. For instance, we can add antecedent conditions: causes of nodes that were exogenous in the higher-level model. Likewise, we can add downstream effects: outcomes of nodes that were terminal in the higher-level model. Figure 6.2: A higher-level model and a lower-level model that is impermissible. The central principle governing allowable elaborations is that a lower-level model must not introduce dependencies between variables that were omitted in the higher-level model. We provide an example of a violation of this principle in Figure 6.2. We start with a higher-level model, in panel (a), in which inequality affects democratization through mobilization. We then elaborate the model in panel (b) by adding ethnic homogeneity as a moderator of mobilizations effect. However, because ethnic homogeneity is also modeled here as affecting inequality, we have now introduced a source of dependence between inequality and democratization that was omitted from the higher-level model. In panel (a), democratization and inequality were dependent only via mobilization; and so they are conditionally independent given mobilization. In panel (b), democratization and mobilization are additionally dependent via their common cause, ethnic homogeneity. By the rules governing causal graphs (see Chapter ), the higher-level model specifically prohibited this second source of dependencysince all dependencies between variables must be represented. Put differently, if two variables are independent or conditionally independent given a third variablein one model, then this same relation of independence (or conditional independence) must be captured in any theory of that model. A theory can add conditional independencies not present in the higher-level model. For instance, a mediation theory, \\(X \\rightarrow M \\rightarrow Y\\), implies a conditional independence that is not present in the higher-level, \\(X \\rightarrow Y\\) model that it supports: in the lower-level model only, \\(X\\) is conditionally independent of \\(Y\\) given \\(M\\). But we may not theorize aways (conditional) independencies insisted on by our higher-level claim. Return to models \\(M\\) and \\(M&#39;\\) in Figure 6.1(a). Importantly, in moving from the higher- to the lower-level model, we have effectively split the nodal-type term \\(\\theta^Y\\) into two parts: \\(\\theta^{Y_\\text{lower}}\\) and \\(\\theta^K\\). Intuitively, in the higher-level model, (a), \\(Y\\) is a function of \\(X\\) and \\(\\theta^Y\\), the latter representing all things other than \\(X\\) than can affect \\(Y\\). Or, in the language of our nodal-type setup, \\(\\theta^Y\\) represents all of the (unspecified) sources of variation in \\(X\\)s effect on \\(Y\\). When we insert \\(K\\) into the model, however, \\(X\\) now does not directly affect \\(Y\\) but only does so via \\(K\\). Further, we model \\(X\\) as acting on \\(K\\) in a manner conditioned by \\(\\theta^K\\), which represents all of the (unspecified) factors determining \\(X\\)s effect on \\(K\\). The key thing to notice here is that \\(\\theta^K\\) now represents a portion of the variance that \\(\\theta^Y\\) represented in the higher-level graph: some of the variation in \\(X\\)s effect on \\(Y\\) now arises from variation in \\(X\\)s effect on \\(K\\), which is captured by \\(\\theta^K\\). So, for instance, \\(X\\) might have no effect on \\(Y\\) because \\(\\theta^K\\) takes on the value \\(\\theta^K_{00}\\), so that \\(X\\) has no effect on \\(K\\). Put differently, any effect of \\(X\\) on \\(Y\\) must arise from an effect of \\(X\\) on \\(K\\); so \\(\\theta^K\\)s value must be either \\(\\theta^K_{01}\\) or \\(\\theta^K_{10}\\) for \\(X\\) to affect \\(Y\\).2 What \\(\\theta^K\\) represents, then, is that part of the original \\(\\theta^Y\\) that arose from some force other than \\(X\\) operating at the first step of the causal chain from \\(X\\) to \\(Y\\). So now, \\(\\theta^Y\\) in the lower-level graph is not quite the same entity as it was in the higher-level graph. In the original graph, \\(\\theta^Y\\) represented all sources of variation in \\(X\\)s effect on \\(Y\\). In the lower-level model, with \\(K\\) as mediator, \\(\\theta^Y\\) represents only the variation in \\(K\\)s effect on \\(Y\\). Put differently, \\(\\theta^Y\\) has been expunged of any factors shaping the first stage of the causal process, which now reside in \\(\\theta^K\\). We highlight this change in \\(\\theta^Y\\)s meaning by referring in the second model to \\(\\theta^{Y_\\text{lower}}\\). Consider next model \\(M^{\\prime\\prime}\\) panel (c) in Figure 6.1, which also supports (implies) the higher-level model in panel \\((a)\\). The logical relationship between models \\((a)\\) and \\((c)\\), however, is somewhat different. Here the lower-level model specifies one of the conditions that comprised \\(\\theta^Y\\) in the higher-level model. In specifying a moderator, \\(C\\), we have extracted \\(C\\) from \\(\\theta^Y\\), leaving \\(\\theta^{Y_\\text{lower}}\\) to represent all factors other than \\(C\\) that condition \\(Y\\)s response to its parents. More precisely, \\(\\theta^{Y_\\text{lower}}\\) now represents the set of nodal types defining how \\(Y\\) responds jointly to \\(X\\) and \\(C\\). Again, the relabeling as \\(\\theta^{Y_\\text{lower}}\\) reflects this change in the terms meaning. Whereas in Model \\(M^{\\prime}\\) we have extracted \\(\\theta^K\\) from \\(\\theta^Y\\), in Model \\(M^{\\prime\\prime}\\), it is \\(C\\) itself that we have extracted from \\(\\theta^Y\\), substantively specifying what had been just a random disturbance. &gt; 6.2.2 Integration of theory and empirics The understanding of theory as a causal model has important implications for how we think about the relationship between theory and evidence and about theoretical development. In a common hypothetico-deductive framework, we formulate a theory a priori, derive its empirical predictions, and then test the theory by examining whether those predictions are borne out by the data. If the evidence does not line up with the predictions, the theory is falsified. We might then respond by amending the theory, but the amended theory must then be tested against new data. As we will see in chapters to come, when we confront a causal model with data, we do not seek to confirm or falsify the model, but to update beliefs over its parameters. In particular, we can update beliefs about the (possibly joint) distribution of nodal types in the population of interest, potentially arriving a new theory. To illustrate the difference, consider Saunders (2011) argument about transformative foreign military intervention, discussed in Chapter 3. As we noted, Saunders argumentthe particular causal effects operating across the causal linkagesrepresents one of roughly 4 million possible combinations of nodal types that could operate within the causal structure that the argument (on our reading, at least) assumes. For instance, her argument implies that the nodal type \\(\\theta^B\\) takes on a value such that the conditions \\(F=1, P=1,\\) and \\(T=1\\) generate \\(B=1\\), and we get \\(B=0\\) otherwise; that \\(\\theta^I\\) takes on a value such that \\(B=1, F=1\\) and \\(B=0, F=0\\) produce \\(I=1\\), for either value of \\(A\\); and \\(A\\) has a positive effect on \\(I\\) whenever \\(B \\neq F\\); and so on, for all endogenous nodes. It would make little sense to read Saunders argument as implying that this combination of nodal types is the only one operating in the world. But we might think of the argument as implying that this combination appears with some frequencyit implies a belief that this combination of nodal types characertizes some substantial proportion of cases in the relevant population. If we were then to confront this model with data (observations of some set of nodes for some set of cases), we would be seeking not to falsify the theory but to learn about the distribution of nodal types, relative to some prior belief about this distribution. We could, for instance, start with only the causal structure and flat priors over all nodal types. Or we might start with Saunders theoretical argument itself as a basis for placing greater prior weight on the nodal types implied by that argument. Updating based on new data then has the potential to shift our beliefs within this models parameter space, toward beliefs in the prevalence of some types at each node and away from others. Our posterior estimates might suggest that the set of effects that Saunders theorizes are more or less prevalent than we had ex ante believed. And, equally importantly, we can expect the very same kind of learning about all other nodal types that possible under this causal structure. That is, we can learn about the prevalence of effects across this causal structure that are not anticipated by Saunders argument at allsuch as, say, the prevalence of negative effects of \\(A\\) on \\(I\\) or of positive effects of \\(B \\neq F\\) on \\(I\\)s. Of course, in updating over nodal types we are evaluating the relevance of Saunders argument; if the nodal types implied by her theory turn out to have greater weight in our posteriors, her argument has in a sense been more successful in explaining the world than if those nodal types end up with less weight. But what we come away with is more than the assessment of a theory, understood as a single set of propositions about the way the world works. We learn about the world of the model as a wholeabout all of the causal effects that it allows. On this view, we do not proceed via pure deduction, from a priori theory to empirical test. While our models might be informed by deductive reasoning (see Chapter appendix), we also develop theory through engagement with the data. 6.3 The rules 6.3.1 Mappings are not 1 to 1 The mappings between higher-level claims and theories may not be one-to-one. A single theory can support multiple higher-level models. Moreover, a single higher-level relation can be supported by multiple, possibly incompatible lower-level theories. To illustrate, consider two lower level theories of democratization: (\\(L_1\\)): \\(Inequality \\rightarrow Democratization \\leftarrow Mobilization\\) (\\(L_2\\)): \\(Inequality \\rightarrow Mobilization \\rightarrow Democratization\\) Note how these theories are incompatible with one another. While \\(Inequality\\) and \\(Democratization\\) are independent in \\(L_1\\), they are causally related in \\(L_2\\). Moreover, in \\(L_2\\), \\(Inequality\\) and \\(Democratization\\) are related only through \\(Mobilization\\), while in \\(L_1\\), \\(Democratization\\) is directly affected by \\(Inequality\\).3 Now, consider the following three higher-level claims: (\\(H_1\\)): \\(Inequality \\rightarrow Mobilization\\) (\\(H_2\\)): \\(Inequality \\rightarrow Democratization\\) (\\(H_3\\)): \\(Mobilization \\rightarrow Democratization\\) \\(H_1\\) can be supported only by one of these theories: only in \\(L_2\\), and not in \\(L_1\\), does \\(Inequality\\) cause \\(Mobilization\\).4 However, our other two hypotheses could each rest on both of the lower-level theories, even though those two theories are incompatible with one another. \\(H_1\\) could be derived from (explained by) either theory: though the two theories differ on whether mobilization is a mediator or a moderator, they agree that inequality can affect democratization. Similarly, both theories imply \\(H_2\\), in which \\(Mobilization\\) affects \\(Democratization\\), even though the two theories disagree on whether inequality is an antecedent to mobilization or a moderator of its effect. Thus, multiple theories can usually be proposed to explain any given causal effect, and those theories need not be consistent with each other. When seeking an explanation for, say, \\(H_1\\), the choice between \\(L_1\\) and \\(L_2\\) cannot be dictated by logical mappings between models; it must be drawn from a substantive belief about which set of causal dependencies operates in the world. On the other hand, \\(L_2\\) is logically ruled out as an explanation of \\(H_3\\). It is also true that any given theory logically implies multiple higher-level claims about causal relations. \\(L_2\\) implies both \\(H_2\\) and \\(H_3\\). Note, however, that the multiple higher-level claims that follow from a theory must be compatible with one another. 6.4 Structural consistency 6.5 From structure to beliefs about types So far we have been discussing the structural components of theories: we have seen how a given causal structure can be justified in terms of a more detailed causal structure. But theories also involve claims about what kinds of effects operate between variables. For instance, the belief that inequality generates democratization, of course, represents a different kind of theory from the belief that inequality prevents democratization, although the two might share a DAG structure. As discussed in Chapter 2, a probabilistic causal model comprises both a causal structure and beliefs about distributions over the exogenous nodes  i.e., in our setup, over a models nodal types. In an \\(I \\rightarrow D\\) model, for instance, probabilistic beliefs include beliefs about the probability that a given case has the type \\(\\theta^D_{01}\\) types and the probability that it has the type \\(\\theta^D_{10}\\). Thus, as we have with structure, we can think about how a set of beliefs about the distribution of nodal types at a higher level can be supported by beliefs about nodal-type distributions in a lower-level model. For instance, suppose we start with an \\(I \\rightarrow D\\) model and the belief that \\(Pr(\\theta^D=\\theta^D_{01}) = 0.5\\)  i.e., effects are positive \\(50\\%\\) of the time. On a structural level, as we have seen, this model could be supported by the model \\(I \\rightarrow M \\rightarrow D\\). But what beliefs about causal effects in this lower-level model might support the belief that effects of \\(I\\) on \\(D\\) are positive \\(50\\%\\) of the time? As with structural mappings, we can imagine a whole range of probabilistic beliefs at the lower level that would be consistent with a given higher-level belief. In a \\(I \\rightarrow M \\rightarrow D\\) model, we can arrive at a positive effect of \\(I\\) on \\(D\\) either through a combination of the nodal types \\(\\theta_{01}^M\\) and \\(\\theta_{01}^{D_{\\text lower}}\\) (linked positive effects) or of the nodal types \\(\\theta_{10}^M\\) and \\(\\theta_{10}^{D_{\\text lower}}\\) (linked negative effects). So, for instance, a lower-level model in which \\(Pr(\\theta^M=\\theta_{01}^M)=0.5\\), \\(Pr(\\theta^{D_{\\text lower}}=\\theta_{01}^{D_{\\text lower}})=0.5\\), \\(Pr(\\theta^M=\\theta_{10}^M)=0.5\\), and \\(Pr(\\theta^{D_{\\text lower}}=\\theta_{10}^{D_{\\text lower}})=0.5\\) would be consistent with the belief that \\(Pr(\\theta^D=\\theta^D_{01}) = 0.5\\). So too, however, would a lower-level model in which \\(Pr(\\theta^M=\\theta_{01}^M)=0.707\\), \\(Pr(\\theta^{D_{\\text lower}}=\\theta_{01}^{D_{\\text lower}})=0.707\\), \\(Pr(\\theta^M=\\theta_{10}^M)=0\\), and \\(Pr(\\theta^{D_{\\text lower}}=\\theta_{10}^{D_{\\text lower}})=0\\) equally implies \\(Pr(\\theta^D=\\theta^D_{01}) = 0.5\\) in the higher-level model. Meanwhile, there is a whole range of beliefs about effects in the lower-level model that do not justify the higher-level belief. For instance, any lower-level model in which \\((Pr(\\theta^D=\\theta^D_{00}) + Pr(\\theta^D=\\theta^D_{11})) &gt; 0.5\\) is inconsistent with the belief in a 0.5 probability of positive \\(I \\rightarrow D\\) effects and cannot serve as a theory of the higher-level model. We will generally want to think of lower-level models with quite different distributional beliefs as representing different theories, as they will typically capture quite different substantive beliefs about how the world works. We can think of the first lower-level model, above, as one in which inequality can cause democratization via two mechanisms, either by causing mass-mobilization which causes democratizaiton or by preventing mass-mobilization which prevents democratization  while the second model is a theory in which only the former mechanism operates. 6.6 Probabilistic consistency 6.6.1 Type disaggregation in a mediation model Whereas Model (a) has nodal types defined for \\(D\\),5 Model (b) has nodal types defined both for node \\(M\\) and for node \\(D\\). We thus allow \\(I\\) to have a positive, negative, or no effect on \\(M\\), with \\(\\theta^M\\) taking on four possible values, \\(\\theta_{10}^M,\\theta_{01}^M,\\theta_{00}^M\\),and \\(\\theta_{11}^M\\). Further, we allow for \\(M\\) to have a positive, negative, or no effect on \\(D\\), with \\(\\theta^D_{\\text{lower}}\\)s possible values again being one of \\(\\theta_{10}^{D_{\\text lower}}\\), \\(\\theta_{01}^{D_{\\text lower}}\\), \\(\\theta_{00}^{D_{\\text lower}}\\), \\(\\theta_{11}^{D_{\\text lower}}\\). We can now think about combinations of nodal types in the lower-level model as mapping onto nodal types in the higher-level model. Table 6.1 illustrates. Table 6.1: Mapping from lower-level nodal types on \\(M\\) and \\(D\\) to higher-level nodal types on \\(D\\). \\(\\theta_{10}^{D_{lower}}\\) \\(\\theta_{01}^{D_{lower}}\\) \\(\\theta_{00}^{D_{lower}}\\) \\(\\theta_{11}^{D_{lower}}\\) \\(\\theta_{10}^{M}\\) \\(\\theta_{01}^{D_{higher}}\\) \\(\\theta_{10}^{D_{higher}}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{11}^{D_{higher}}\\) \\(\\theta_{01}^{M}\\) \\(\\theta_{10}^{D_{higher}}\\) \\(\\theta_{01}^{D_{higher}}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{11}^{D_{higher}}\\) \\(\\theta_{00}^{M}\\) \\(\\theta_{11}^{D_{higher}}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{11}^{D_{higher}}\\) \\(\\theta_{11}^{M}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{11}^{D_{higher}}\\) \\(\\theta_{00}^{D_{higher}}\\) \\(\\theta_{11}^{D_{higher}}\\) For instance, in a case in which both \\(\\theta^M=\\theta^M_{01}\\) (there is a positive effect of \\(I\\) on \\(M\\)) and \\(\\theta^{D_{\\text{lower}}}=\\theta_{01}^{D_{lower}}\\) (there is a positive effect of \\(M\\) on \\(D\\)), we have a positive effect of \\(I\\) on \\(D\\)meaning that, in the higher-level model, \\(\\theta^{D_{higher}}=\\theta^{D_{higher}}_{01}\\). Two linked negative effects at the lower level likewise generate a positive effect of \\(I\\) on \\(D\\)and so map onto the same higher-level nodal type, \\(\\theta^{D_{higher}}=\\theta^{D_{higher}}_{01}\\). Further, it is easy to see that if there is no causal effect at either the \\(I \\rightarrow M\\) step or the \\(M \\rightarrow D\\) step, we will have one of the null effect types at the higher level. This is because, in Model (b), \\(I\\) cannot affect \\(D\\) unless there are causal effects at both constituent steps. In other words, in Model (b), \\(I\\) can affect \\(D\\) only through \\(M\\) in this model; there are no direct effects or other pathways permitted. To foreshadow the discussion in later chapters, these mappings of nodal types between levels are critical. They allow us to draw inferences about causal relations at a lower level and then use those inferences to answer questions posed at a higher level. For instance, if we can learn about the effect of inequality on mass mobilization (a question posed at the lower level), then we can apply that learning to answering a question about whether inequality affects democratization (a higher-level question). 6.6.2 Type disaggregation in a moderation model Alternatively, we might wonder why or under what conditions inequality causes democratization. Our simple claim, in panel (a), allows that \\(I\\) can cause \\(D\\), but provides no information about the conditions under which it does so. Those conditions are implicitly embedded within \\(\\theta^D\\), where they are left unspecified. We could, however, theorize some of what is left unsaid in in panel (a). We do this in panel (c), where we posit ethnic homogeneity (\\(E\\)) as a moderator of inequalitys effect on democratization. Panel (c) represents a theory of panel (a) in that it can help account for variation in causal effects that is unaccounted for in Model (a). Put differently, Model (c) gives substantive meaning to an aspect of the phenomenon that is merely residual variation in Model (a). Model (a) provides no account of why inequality has the effects it does, relying fully on \\(\\theta^D\\) as a placeholder for this uncertainty. In Model (c), \\(\\theta^D\\) plays a more modest role, with the substantive variable of ethnic homogeneity now doing some of the work of determining inequalitys possible effects. In this graph, we again have a \\(\\theta_D^{\\text{lower}}\\) term, but it is a different object from \\(\\theta_D^{\\text{lower}}\\) in the mediation graph. In this moderation model, \\(\\theta_D^{\\text{lower}}\\) is more complex as it determines the mapping from two binary variables into \\(D\\). \\(D\\)s nodal type in this setup now represents how a cases outcome will respond to four different possible combinations of \\(I\\) and \\(E\\) values. Rather than four nodal types for \\(D\\), we now have 16, as there are 16 possible ways in which one binary variable might respond to two binary parent variables (see Table ?? in Chapter 2). In Table 6.2 we give a mapping from a subset of these lower-level types to the higher-level types corresponding to Model (a). Table 6.2: Values for \\(D\\) given \\(E\\) and \\(I\\). With two binary causal variables, there are 16 nodal types: 16 ways in which \\(D\\) depends on \\(I\\) and \\(E\\). These lower level types map into higher level types for a model in which \\(D\\) depends on \\(I\\) only, as shown in the final column. Lower Type \\(I=0,E=0\\) \\(I=0,E=1\\) \\(I=1,E=0\\) \\(I=1, E=1\\) Higher Type \\(\\theta^{D}_{0000}\\) 0 0 0 0 \\(\\theta^{D}_{00}\\) \\(\\theta^{D}_{0001}\\) \\(\\theta^{D}_{0010}\\) 0 0 0 0 0 1 1 0 \\(\\theta^{D}_{01}\\) if \\(E=1\\), else \\(\\theta^D_{00}\\) \\(\\theta^D_{00}\\) if \\(E=1\\), else \\(\\theta^D_{01}\\) \\(\\theta^{D}_{0011}\\) 0 0 1 1 \\(\\theta^{D}_{01}\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\theta^{D}_{1110}\\) 1 1 1 0 \\(\\theta^D_{11}\\) if \\(E=0\\), else \\(\\theta^D_{10}\\) \\(\\theta^{D}_{1111}\\) 1 1 1 1 \\(\\theta^D_{11}\\) Importantly we see that the mapping between lower- and higher-level types can depend on the value of the moderator. More generally, since we can think of the value of exogeneous nodes, \\(E\\) and \\(I\\), as being nodal types for those nodes,6 we can think of the lower level nodal type as a concatenation of the higher-level nodal types for \\(E\\) and \\(D\\). Thus, we can think of the the higher-level type as depending uniquely on the fully specified lower level type. For instance, a case can have type \\(\\theta^D_{01}\\) in the higher-level model if it is of type \\(\\theta^D_{0010}\\) and c in the lower-level model. This is a case for which \\(I\\) has a positive effect on \\(D\\) when \\(E=0\\) and in which \\(E\\) is in fact 0. On the other hand, the same lower-level \\(D\\) type in combination with \\(\\theta^{E}_1\\) maps onto the type \\(\\theta_{10}\\) in the higher-level modela type in which \\(D\\) responds negatively to \\(I\\). In later chapters, we represent all lower- to higher-level mappings relevant to a question of interest with the use of type-reduction tables that allow one to readily see how inferences drawn at one level inform causal questions posed at another level. 6.7 Illustration of unpacking nodal types We now show more specifically how sets of nodal types in lower-level models map into nodal types in higher-level models. For concreteness, let us return to our democratization example and consider first the very basic claim that inequality can have an affect on democratization. We represent this simple claim in Figure 6.3, Panel (a). In this simple model, \\(I\\) may sometimes have an effect on \\(D\\) and sometimes not; and that effect may be positive or negative. \\(I\\)s effect will, of course, depend on the cases nodal type on \\(D\\). Figure 6.3: DAG representations of three theories. DAGs only capture claims that one variable causes another, conditional on other variables. Theories (b) and (c) each imply theory (a). Next, the figure shows two models that can each explain Model (a), though in different ways. Model (b) answers the explanatory question, How does inequality affect democratization? Model (c) answers the explanatory question, Why does inequalitys effect on democratization vary? or Under what conditions does \\(I\\) have a given effect on \\(D\\)? Both theories provide richer, more interpretable accounts of the phenomenon of interest than the simpler model that they are theorizing. These lower-level models also imply a set of nodal types that are richer than that implied by (a). Recall that in Chapter 2, we considered the idea that at any node, a nodal type may be conceptualized as a case-specific exogenous disturbance that governs the mapping from input variables to outcome variables. The type node \\(\\theta^D\\) can take on the values \\(\\theta^D_{10}, \\theta^D_{01}, \\theta^D_{00}, \\theta^D_{11}\\), and this node can take on different values in different cases. However, differences in \\(\\theta^D\\)s value are left entirely unaccounted for. We are saying nothing about why inequality causes democratization in some places, prevents democratization in other places, and has no effect in still other places. Let us consider how Models (b) and (c) provide answers to these questions and how these answers map onto these models nodal types. 6.7.1 Implied consistency of priors We caution that the mappings of distributional beliefs between levels is not always intuitive. Suppose, for instance, that we begin with no information about causal effects in a model and so want to set flat priors, meaning that we accord equal prior weight to all nodal types at each node. In Model (a), flat priors would mean putting an 0.25 weight on each of the following: positive effects, negative effects, zero effects with \\(D\\) always \\(0\\), and negative effects with \\(D\\) always \\(1\\). Now, suppose we engage in the same flat-prior-setting in the lower-level model, Model (b). That is, we put equal weight (i.e., 0.25 across the board) on all nodal types at node \\(M\\) and equal weight (0.25 across the board) on all nodel types at node \\(D\\). Surprisingly perhaps, setting flat priors at this lower level in fact implies a strong weighting against either positive or negative causal effects at the higher level. Now, we are saying that the probability of a positive effect at the higher level is \\((0.25 \\times 0.25) + (0.25 \\times 0.25) = 0.125\\); and likewise for negative effects. Put simply, the fact that the lower-level model involves more mediating steps between \\(I\\) and \\(D\\) means that more things have line up for an \\(I \\rightarrow D\\) effect to emerge  and so causal effects will be rarer under a flat distribution of nodal types in this model than they are in the simpler, higher-level model. Another way to think about this is that simply by spelling out the mediating steps in a causal chain, we can, perhaps indadvertently, generate beliefs that causal effects at the higher level are weaker than we might have thought. We can, of course, set priors at the lower level that would map onto flat priors at the higher level.7 Our advice to researchers is, simply, to check for consistency of priors across levels: to ask whether the priors that we set at a lower level imply beliefs at the higher level that we are willing to live with. 6.8 Conclusion 6.9 Chapter Appendices 6.9.1 Summary Boxes BOX 1 Two kinds of theories. Theories are lower-level causal models that explain or provide an account of a higher-level, simpler model. There are two forms of theorization: The disaggregation of nodes. A single node in a higher-level model can be split into multiple nodes. For instance, for a higher-level model in which \\(X \\rightarrow Y \\leftarrow \\theta^Y\\): Mediation: A mediator, \\(M\\), can be introduced between \\(X\\) and \\(Y\\), thus splitting \\(\\theta^Y\\) into \\(\\theta^M\\) and \\(\\theta^{Y_\\text{lower}}\\). The mediation theory thus explains the \\(X \\rightarrow Y\\) relationship. Moderation: A component of \\(\\theta^Y\\) can be extracted and specified as a substantive variable. This variable is now a substantively conceptualized moderator of the \\(X \\rightarrow Y\\) relationship. The moderation theory thus provides a fuller explanation of why \\(X\\) has different effects on \\(Y\\) in different contexts. Generalization. A feature of context omitted and implicitly held constant in a higher-level model can be explicitly included in the model. The higher-level model is now explained as a special case of a more general set of causal relations. 6.10 Connections to other writing on theory We close this chapter by considering how the understanding of theory that we work with in this book compares to other prominent understandings of theory. Theory as tautology. The claim that the number of Nash equilibria is generically odd in finite games is often understood to be a theoretical claim. Unless there are errors in the derivation of the result, the claim is true in the sense that the conclusions follow from the assumptions. There is no evidence that we could go looking for in the world to assess the claim. The same can be said of the theoretical claims of many formal models in social sciences; they are theoretical deductions of the if-then variety (Clarke and Primo 2012). Theory in this sense is true by tautology. By contrast, theory as we define it in this book refers to claims with empirical content: a theory refers to causal relations in the world that might or might not hold, and is susceptible to empirical testing. The deductive logical relations that hold in a causal model are those of conditional independence, as discussed in Chapter 2: for instance, if \\(X\\) causes \\(Y\\) only through \\(M\\) in a theory, then \\(X\\) and \\(Y\\) are conditionally independent given some value of \\(M\\). Theory as a collection of maps. According to Clarke and Primo (2012), building on a semantic view of theory (Giere (2010)), a theory is a collection of models, together with a set of hypotheses linking them to the real world. As in our usage, Clarke and Primo see theories and models as very similar objects: for them, a theory is a system of models; for us, a theory is a supporting model. In both frameworks, there is no real difference in kind between models and theories. Our approach also shares with Clarke and Primo the idea that models are not full and faithful reflections of reality; they are maps designed for a particular purpose. In the case of causal models, the purpose is to capture relationships of independence and possible causal dependence. As we have shown, that is a purpose that allows for the stripping away of detailthough it also forbids certain simplifications (such as any simplification that removes a dependency between variables). Clarke and Primo see models as useful to the extent that they are similar to features of the real world in ways related to the models purpose. Along these lines, a causal model will be useful to the extent that it posits relations of independence that are similar to those prevailing in the domain under investigation. Theory as a testable claim In the hypothetico-deductive framework, often traced back to Popper (2002) and highly influential in empirical political science, empirical social science is an activity of theory-testing. Having developed a theory, we then derive from it a set of empirical predictions and then test those predictions against evidence. In Clarke and Primo (2012), we also seek to confirm theories by developing and testing hypotheses about the similarity of a model or theory to particular features of the world. In both cases, a theory is positedpossibly on the basis of logic or background knowledgeand then assessed. The value (truth or usefulness) of the model itself is the object of inquiry. In a causal-model framework, theories are always tentative, and we can subject any model or theory to empirical evaluation, a task to which we turn in Chapter 16. However, in the books setup, theories are first and foremost expressions of what we already know and dont know about a given causal domain when inquiry begins. We encode this background knowledge in order to inform research-design choices and draw inferences from the data. Models and theories are thus, in this sense, the world within which inquiry unfolds. Indeed, as we explore in Chapter 4, the very questions we ask live withincan be represented as parts ofour theories. Theory as generalization In another of the many uses of theory, political scientists often think of theorization as generalization. For Van Evera (1997) and Przeworski and Teune (1970), for instance, theories are by their nature general statements that we can use to explain specific events. In this view, Diamond resources caused Sierra Leones civil war is a case-specific explanation; Natural resource endowments cause civil war is a theoretical formulation. In our treatment of theory as a lower-level causal model, however, there is no generic sense in which a theory is more or less general than the higher-level claim that it explains. In this books framework, we can theorize by generalizing: when we elaborate a model by building in variation in a factor that was held constant in the higher-level claim, we are making the model more general in scope. If our natural resources claim implicitly applies only to weak states, we can theorize this claim by allowing state strength to vary and articulating how the natural-resource effect hinges on that claim. However, when we theorize by disaggregating nodessay, by adding intervening causal stepswe have in fact made a more specific claim. Natural resources may cause civil war under a broad set of circumstances. Natural resources will cause civil war through looting by rebel groups under an almost certainly narrower set of circumstances. Here, the more elaborate argumentthe theorization of why \\(X\\) causes \\(Y\\)is actually a stronger claim, with narrower scope, than the simpler one that it supports. The value of parsimony Van Evera (1997) and Przeworski and Teune (1970) also express a common view in characterizing parsimony as a quality of good theory. While they recognize that parsimony must often be traded off against other goods, such as accuracy and generality, ceteris paribus a more parsimonious theoryone that uses fewer causal variables to explain variation in a given outcomeis commonly understood to be a better theory. We do not take issue with the idea that simpler models and explanations are, all else equal, better. But the succeeding chapters also demonstrate a distinctive and important way in which all else will often not be equal when we seek to use theory to guide research design and support causal inference. To foreshadow the argument to come, the elaboration of more detailed, lower-level models can direct us to new opportunities for learning. As we unpack a higher-level claim, we will often be identifying additional features of a phenomenon the observation of which can shed light on causal questions of interest. Moreover, our background beliefsthe prior knowledge on which causal inference must usually restare often more informative at lower levels than at higher levels: it will, for instance, often be easier for us express beliefs about causal effects for smaller steps along a causal chain than about an overarching \\(X \\rightarrow Y\\) effect. Making things more complicated, of course, still makes things more complicated. And we should avoid doing so when the payoff is small, as it will sometimes be. But in the pages to come, we will also see a distinct set of benefits that arise from drilling more deeply into our basis of prior knowledge when formulating inferential strategies. 6.11 Illustration of a Mapping from a Game to a DAG Our running example supports a set of higher level models, but it can also be implied by a lower level models. Here we illustrate with an example in which the lower level model is a game theoretic model, together with a solution.8 In Figure 6.4 we show a game in which nature first decides on the type of the media and the politician  is it a media that values reporting on corruption or not? Is the politician one who has a dominant strategy to engage in corruption or one who is sensitive to the risks of media exposure? In the example the payoffs to all players are fully specified, though for illustration we include parameter \\(b\\) in the voters payoffs which captures utility gains from sacking a politician that has had a negative story written about them whether or not they actually engaged in corruption. A somewhat less specific, though more easily defended, theory would not specify particular numbers as in the figure, but rather assume ranges on payoffs that have the same strategic implications. The theory is then the game plus a solution to the game. Here for a solution the theory specifies subgame perfect equilibrium. In the subgame perfect equilibrium of the game; marked out on the game tree (for the case \\(b=0\\)) the sensitive politicians do not engage in corruption when there is a free press  otherwise they do; a free press writes up any acts of corruption, voters throw out the politician if indeed she is corrupt and this corruption is reported by the press. As with any structural model, the theory says what will happen but also what would happen if things that should not happen indeed happened. Figure 6.4: A Game Tree. Solid lines represent choices on the (unique) equilibrium path of the subgames starting after natures move for the case in which \\(b=0\\). To draw this equilibrium as a DAG we include nodes for every action taken, nodes for features that determine the game being played, and the utilities at the end of the game. If equilibrium claims are justified by claims about the beliefs of actors then these could also appear as nodes. To be clear however these are not required to represent the game or the equilibrium, though they can capture assumed logics underlying the equilibrium choice. For instance a theorist might claim that humans are wired so that whenever they are playing a Stag Hunt game they play defect. The game and this solution can be represented on a DAG without reference to the beliefs of actors about the action of other players. However, if the justification for the equilibrium involves optimization given the beliefs of other players, a lower level DAG could represent this by having a node for the game description that points to beliefs about the actions of others, that then points to choices. In a game with dominant strategies, in contrast, there would be no arrows from these beliefs to actions. For our running example, nodes could usefully include the politicians expectations, since the governments actions depend on expectations of the actions of others. However, given the game there is no gain from including the medias expectations of the voters actions since in this case the medias actions do not depend on expectations of the voters actions then these expectations should be included. In Figure 6.5 we provide two examples of DAGs that illustrate lower level models that support our running example. The upper panel gives a DAG reflecting equilibrium play in the game described in Figure 6.4. Note that in this game there is an arrow between \\(C\\) and \\(Y\\) even though \\(Y\\) does not depend on \\(C\\) for some values of \\(b\\)this is because conditional independence requires that two variables are independent for all values of the conditioning set. For simplicity also we mark \\(S\\) and \\(X\\), along with \\(b\\) as features that affect which subgame is being playedtaking the subgames starting after Natures move. Note that the governments expectations of responses by others matters, but the expectations of other players do not matter given this game and solution. Note that the utilities appear twice in a sense. They appear in the subgame node, as they are part of the definition of the gamethough here they are the utilities that players expect at each terminal node; when they appear at the end of the DAG they are the utilities that actually arise (in theory at least). The lower level DAG is very low and much more general, representing the theory that in three player games of complete information, players engage in backwards induction and choose the actions that they expect to maximize utility given their beliefs about the actions of others. The DAG assumes that players know what game is being played (Game), though this could also be included for more fundamental justification of behavioral predictions. Each action is taken as a function of the beliefs about the game, the expectations about the actions of others, and knowledge of play to date. The functional equationsnot shownare given by optimization and belief formation assuming optimization by others. Figure 6.5: The upper panel shows a causal graph that describes relations between nodes suggested by analysis of the game in Figure and which can imply the causal graph of Figure . The game itself (or beliefs about the game) appear as a node, which are in turn determined by exogneous factors. The lower panel represents a still lower level and more general theory ``players use backwards induction in three step games of complete information. These lower level graphs can themselves provide clues for assessing relations in the higher level graphs. For instance, the lower level model might specify that the value of \\(b\\) in the game affects the actions of the government only through their beliefs about the behavior of voters, \\(E\\). These beliefs may themselves have a stochastic component, \\(U_E\\). Thus \\(b\\) high might be thought to reduce the effect of media on corruption. For instance if \\(b \\in \\mathbb{R}_+\\), we have \\(C= 1-FG(1-\\mathbb{1}(b&gt;1))\\). If \\(X\\) is unobserved and one is interested in whether \\(S=0\\) caused corruption, knowledge of \\(b\\) is informative. It is a root node in the causal estimand. If \\(b&gt;1\\) then \\(S=0\\) did not cause corruption. However if \\(b\\) matters only because of its effect on \\(E\\) then the query depends on \\(U_E\\). In this case, while knowing \\(b\\) is informative about whether \\(S=0\\) caused \\(C=1\\), knowing \\(E\\) from the lower level graph is more informative. Note that the model we have examined here involves no terms for \\(U_C\\), \\(U_R\\) and \\(U_Y\\)that is, shocks to outcomes given action. Yet clearly any of these could exist. One could imagine a version of this game with trembling hands, such that errors are always made with some small probability, giving rise to a much richer set of predictions. These can be represented in the game tree as moves by nature between actions chosen and outcomes realized. Importantly in a strategic environment such noise could give rise to different types of conditional independence. For instance say that a Free Press only published its report on corruption with probability \\(\\pi^R\\), then with \\(\\pi^R\\) high enough the sensitive government might decide it is worth engaging in corruption even if there is a free press; in this case the arrow from \\(X\\) to \\(C\\) would be removed. Interestingly in this case as the error rate rises, \\(R\\) becomes less likely, meaning that the effect of a \\(S\\) on \\(Y\\) becomes gradually weaker (since governments that are not sensitive become more likely to survive) and then drops to 0 as sensitive governments start acting just like nonsensitive governments. 6.11.1 Quantifying the gains from a theory We have alluded to the fact that we may want to theorize our models  develop more elaborate, lower-level models to support them  because we can get potentially reap greater inferential leverage from the more elaborate theory. But how much more? For instance, what are the gains from a theory that introduces a node \\(K\\) relative to one that does not include \\(K\\)? What is the value-added of the more elaborate theory? One approach to assessing the contribution of a theory is to calculate the mean reduction in Bayes risk. Suppose we start with a baseline model with variables in the set \\(\\mathcal W\\) and want to answer a query, \\(Q\\). We can then define the gains from theory as: \\[\\text{Gains from theory} = 1- \\frac{E_{K|\\mathcal W}(Var(Q|K,\\mathcal W))}{Var(Q|\\mathcal W)}\\] We can think of the Bayes risk as the inverse of an \\(R^2\\) measure in a regression framework (see also Gelman and Pardoe (2006)): it is the variance in our query given what we have observed. Here we are definining the gains from theory as the degree to which we have reduced that variance by observing \\(K\\) and \\(\\mathcal W\\), relative to just observing \\(\\mathcal W\\). Another approach is to ask: how much better are our guesses having observed \\(K\\) compared to what we would have guessed before, given what we know having observed \\(K\\)? Expected wisdom. \\[Wisdom = \\int(q_0 - q)^2 - (q_k - q)^2 p(q | k)dq\\] This captures how much better off we are with the guess we have made given current data (\\(q_k\\)) compared to the guess we would have made without it (\\(q_0\\)), knowing what we know having observe \\(K\\) (\\(p(q|k)\\). A modest advantage of this conceptualization is that we can still record gains in learning even if the learning operates such that the posterior variance is larger than the prior variance. Even so, the implications for strategy are the same since wisdom is maximized by a strategy that reduces expected squared error. Other possible measures of gains from theory might include the simple correlation between \\(K\\) and \\(Q\\), or entropy-based measures (see Zhang and Srihari (2003) for many more possibilities). For this problem the correlation is given by (see appendix): \\[\\rho_{KQ} = \\frac{(\\phi_b+\\phi_d)(1-2p)(p(1-p))^{.5}}{ (p\\phi_b+(1-p)\\phi_d)(1-(p\\phi_b+(1-p)\\phi_d)))^{.5}}\\] One might also use a measure of mutual information from information theory: \\[I(Q,K) = \\sum_q \\sum_k P(q,k)\\log\\left(\\frac{P(q,k)}{P(q)P(k)}\\right)\\] To express this mutual information as a share of variation explained, we could divide \\(I(Q,K)\\) by the entropy of \\(Q\\), \\(H(Q)\\) where \\(H(Q) = -\\sum_qP(q)\\log(P(q))\\). The resulting ratio can be interpreted as 1 minus the ratio of the entropy of \\(Q\\) conditional (on \\(K\\)) to the unconditional entropy of \\(Q\\). For this example, Figure shows gains as a function of \\(\\phi_b\\) given a fixed value of \\(\\phi_d\\). The figure also shows other possible measures of probative value, with, in this case, the reduction in entropy tracking the reduced posterior variance closely. Figure 6.6: The solid line shows gains in precision (reduced posterior variance) for different values of \\(\\phi_b\\) given \\(\\phi_d=0.25\\) and \\(p=.5\\) for the example given in the text. Additional measures of probative value are also provided including \\(|\\phi_b - \\phi_d|\\), the correlation of \\(K\\) and \\(Q\\), and the reduction in entropy in \\(Q\\) due to mutual information in \\(Q\\) and \\(K\\). References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
