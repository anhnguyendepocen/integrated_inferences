[["final-words.html", "Chapter 17 Final Words 17.1 Gains 17.2 Lessons learned along the way 17.3 Worries about what you have to put in 17.4 Limits on what you can get out 17.5 Looking ahead", " Chapter 17 Final Words The central idea of this book is that we can learn about the world by combining new evidence with causal models that represent prior knowledge about causal relations in the domain of interest. The growth of randomized experiments and other design-based approaches over the last two decades has made it possible to dispense with or diminish the role of background assumptions for some research questions and contexts. This is a remarkable achievement that has put the testing of some hypotheses and estimation of some causal quantities on a firmer footing. At the same time, there are limits to model-free social science. In particular, design-based inference relies on (as-good-as) random assignment by the researcher or by nature, placing bounds on the kinds of causes and contexts we can investigate. The approach is also generally limited to estimating a single causal quantity: the average causal effect. Building on pioneering work by scholars in computer science, statistics, and philosophy, we have outlined a principled approach to, and provided software tools for, mobilizing prior knowledge to learn from new data in situations where randomization is unavailable or to answer questions for which randomization is unhelpful. In this approach, causal models are guides to research design, machines for inference, and objects of inquiry. As guides, the models yield expectations about the learning that can be derived from a given case or set of cases and from a given type of evidence, conditional on the question being asked. As inferential machines, models allow updating on that query once the data are in hand. Finally, when we confront a model with data, we learn about the parameters of the model itself, which can be used to answer a range of other causal questions and allowing cumulation of knowledge across studies. 17.1 Gains The approach provides, we think, many stengths. Many questions. An advantage of the approach is the ability to answer very broad classes of causal questions, well beyond the population-level average effect, so central to much research in contemporary political science. These include case level questions (Does \\(X\\) explain \\(Y\\) in this case?), process questions (Through which channel does \\(X\\) affect \\(Y\\)?), transportability questions (What are the implications of results derived in one context for processes and effects in other contexts?). Common answer strategy. Strikingly, these many questions are all asked and answered using a similar procedure: forming, updating, and querying a causal model. The approach differs markedly from approaches in which distinct estimators are constructed to estimate particular estimands. Answers without identification. Surprisingly, perhaps, the procedure we describe can be used to generate answers even when imperfect answers are not identified. The ability to identify causal effects has been a central pursuit of much social science research in recent years. But the identification is a curious goal in some ways. A causal quantity is identified, if, with infinite data, the correct value can be ascertained with certaintyinformally, the distribution that will emerge is consistent with only one parameter value. Oddly, however knowing that a model, or quantity, is identified in this way does not tell you that estimation with finite data is any good (Maclaren and Nicholson 2019). Nor is estimation of a non identified model with finite data necessarily bad. While there is a tendency to discount models for which quantities of interest are not identified, in fact it is relatively easy to see that conisderable learning is possible even without identification, using the same procedure of updating and querying models. Updating non-identified models can lead to a tighterning of posteriors, even if some quantities can never be distinguished from each other. Clarification of what inputs need to be defended. The answers we get from the approach are necessarily model-dependent. But compared with most prevailing approaches to observational inferencewhere the background model is typically left implicit or conveyed informally or incompletelythe approach ensures both consistency between inferences and prior beliefs, given the data, and transparency about the beliefs on which inferences rest. These features allow us then to assess the degree of sensitivity of conclusions to our prior beliefs. As we have developed the approach, our thinking about qualitative, quantitative, and mixed-method inference has shifted. In using causal models and seeing their benefits, we have have also developed a keener sense of the risks they entail. We outline these lessons and these risks next. 17.2 Lessons learned along the way We note three ways in which our thinking about inference evolved in the course of this project. Within vs. Between Case Evidence. We embarked on this project motivated by an interest in how qualitative and quantitative data could be formally combined to draw case- and population-level causal inferences. In Humphreys and Jacobs (2015), we drew on a common operationalization of quantitative and qualitative data as akin to dataset and causal process observations, respectively, as defined by Collier, Brady, and Seawright (2010); this is a distinction that roughly maps onto somewhat older notions of cross-case and within-case forms of analysis Mahoney (2000). In a typical setup, we would think of data on \\(X\\) and \\(Y\\) data on many cases and \\(M\\) data on process for some. In fact however this distinction has no meaning in the formal set up and analysis of models. One could just as easily be interested in the effect of \\(X\\) on \\(Y\\) and have plentiful data on \\(M\\) but limited data on \\(Y\\) or \\(X\\). In this framework the qualitative and quantitative inference strategies are not just integrated, the distinction between them breaks down completely. A single system. We started off thinking of beliefs about the values of estimands and beliefs about the informativeness of within case information as being essentially independent. This was a feature of the models we explored in Humphreys and Jacobs (2015) and implicit in many accounts of process tracing: you articulate a belief about some hypothesis and you articulate a belief about how informative evidence will be about your hypothesis. When both of these beliefs are themselves derived from an integrated model however then the same conjectures that inform your beliefs about the hypotheses also inform your beliefs about the informativeness of additional data, you just cannot think of them as independent from each other. Pretending to have priors. We started off thinking that in providing priors over causal relations you were directly stating beliefs about how the world works. In the simple case one might think that either \\(X\\) caused \\(Y\\) or it did not and either \\(M\\) should be seen in the event that \\(X\\) caused \\(Y\\) or it shouldnt be. But these statements are in fact clearly model dependent. Beyond the model required to describe events in such crisp terms, the statements involve counterfactuals on counterfactualsmodels of causal processes. Once a model involves assertions of conditional independence we are clearly in the business of dealing in simplifications and our priors become less statements of how we believe the world works to become somewhat statements about what set of models are least bad within a class of abstractions. 17.3 Worries about what you have to put in While we have found the syntax of Directed Acyclic Graphs provides a flexible framework for setting up causal models we also became more keenly aware of some of the limitations of DAGs in representing causal processes. Well defined nodes? DAGS presuppose a set of well defined nodes the come with location and time stamps. This involves a discretization of the world that may not align with how qualitative researchers study the world. For instance qualitative researchers do not just observe that (a) domino 1 fell and (b) domino 2 fell. They observe that domino 2 fell just as domino 1 hit it. Acyclic really? DAGs are by definition acyclic and it is not hard to argue that, since cause precedes effect, causal relations should be acyclic for any well defined nodes. In practice however our variables come with coarse periodizations: there was mobilization in the 1990s, there was democratization in the 1990s. We cannot extract the direction of arrows from the definition of nodes this coarse. Coherent accounts. The approach we describe is on in which researchers are asked to provide a coherent modelalbeit with uncertaintyregarding the ways that nodes are causally related to each other. For instance a researcher interested in using information on \\(K\\) to ascertain whether \\(X\\) cause \\(Y\\) or not is expected to have a theory of whether \\(K\\) acts as a moderator or a ediator for \\(X\\) or whether it is ralized before or after \\(Y\\). Yet it is possible that a researcher has well formed beliefs about the informativeness of \\(K\\) without a model for how \\(K\\) is causally related to \\(X\\) or \\(Y\\). Granted one might wonder where these beliefs come from or how they can be defended, but it seem a weakness not to be able to make use of them without requiring a coherent account of their causal position. 17.4 Limits on what you can get out Complexity. To maintain simplicity we have largely focused on models with binary nodes. At first blush this class of causal models appears very simple. In fact however we quickly learn that even with a small set of nodes produces a dizzying variety of causal types. Limits of qualitative data under ignorable assignments. You generally cannot conclude all that much about population quantities from only a small number of cases when causal effects are identified. Model-dependence of conclusions We have been interested to see how sensitive conclusions can be to relatively modest changes to models. We see two ways of thinking about the implications of this fact for a causal-models framework. One is to focus on the limits to building inference upon causal models. If results depend on prior beliefs, which could be wrong, how valuable are the results? At the same time, the close relationship between assumptions and inferences makes a transparent and systematic engagement with models all the more important: if inferences are not built explicitly on models, we have no way of knowing how fragile they are or how they would change under an alternative set of premises. 17.5 Looking ahead References "]]
