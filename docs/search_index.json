[
["examplesappendix.html", "Chapter 17 Analysis of canonical models with gbiqq 17.1 \\(X\\) causes \\(Y\\), no confounding 17.2 \\(X\\) causes \\(Y\\), with unmodelled confounding 17.3 \\(X\\) causes \\(Y\\), with confounding modelled 17.4 Simple mediation model 17.5 Simple moderator model 17.6 Billy and Suzy’s moderator and mediation model 17.7 An IV model 17.8 A model that allows application of the frontdoor criterion 17.9 A model with a violation of sequential ignorability 17.10 Learning from a collider 17.11 A model mixing observational and experimental data 17.12 Transportation of findings across contexts", " Chapter 17 Analysis of canonical models with gbiqq We walk through a set of canonical models and show how to define and analyze them using gbiqq. 17.1 \\(X\\) causes \\(Y\\), no confounding In the simplest \\(X\\) causes \\(Y\\) model the ATE is identified but the “probability of causation” (PC) is not: we can however generally place bounds on PC. The model can be written: model &lt;- make_model(&quot;X -&gt; Y&quot;) plot_dag(model) This sparse definition assumes that there is no confounding and no constraints on the ways \\(X\\) relates to \\(Y\\). You can see the parameter matrix, which confirms this, showing the mapping from parameters to causal types: Table 17.1: Parameter matrix for X causes Y model without confounding X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 X0 1 0 1 0 1 0 1 0 X1 0 1 0 1 0 1 0 1 Y00 1 1 0 0 0 0 0 0 Y10 0 0 1 1 0 0 0 0 Y01 0 0 0 0 1 1 0 0 Y11 0 0 0 0 0 0 1 1 We can simulate data using the bare bones model and assuming a “true model” in which there is a true positive effect of 0.5. data &lt;- simulate_data(model, n = 1000, parameters = c(.5, .5, .2, .1, .6, .1)) The kinds of inferences on the probability that \\(X\\) has a positive effect on \\(Y\\) given different data is calculated as follows: updated &lt;- gbiqq(model, data) We can then ask questions about particular estimands like this: ATE &lt;- &quot;Y[X=1] - Y[X=0]&quot; PC &lt;- &quot;Y[X=1] &gt; Y[X=0]&quot; results &lt;- gbiqq::query_model( updated, queries = list(ATE = ATE, ATE = ATE, PC = PC, PC = PC), using = list(&quot;priors&quot;, &quot;posteriors&quot;)) Query Subset Using mean sd ATE All priors -0.01 0.32 ATE All posteriors 0.53 0.03 PC All priors 0.25 0.19 PC All posteriors 0.63 0.06 We see from the posterior variance on PC that PC is not identified (or more precisely they key feature is that this distribution does not tighten even with very large N). For more intuition we graph the posteriors: We find that they do not converge but they do place positive mass in the right range. Within this range, the shape of the posterior depends on the priors only. 17.2 \\(X\\) causes \\(Y\\), with unmodelled confounding An \\(X\\) causes \\(Y\\) model with confounding can be written: model &lt;- make_model(&quot;X -&gt; Y&quot;) %&gt;% set_confound(list(X = &quot;(Y[X=1]&gt;Y[X=0])&quot;, X = &quot;(Y[X=1]&lt;Y[X=0])&quot;, X = &quot;(Y[X=1] ==1)&quot;)) plot_dag(model) The parameter matrix here has more parameters than nodal types, reflecting the conditional assignment probabilities of \\(X\\) – \\(X\\) can have different assignment probabilities for different nodal types for \\(Y\\). Table 17.2: Parameter matrix for X causes Y model with arbitrary confounding X0.Y00 X1.Y00 X0.Y10 X1.Y10 X0.Y01 X1.Y01 X0.Y11 X1.Y11 X0 0 0 0 0 0 0 1 0 X1 0 0 0 0 0 0 0 1 X0 0 0 1 0 0 0 0 0 X1 0 0 0 1 0 0 0 0 X0 0 0 0 0 1 0 0 0 X1 0 0 0 0 0 1 0 0 X0 1 0 0 0 0 0 0 0 X1 0 1 0 0 0 0 0 0 Y00 1 1 0 0 0 0 0 0 Y10 0 0 1 1 0 0 0 0 Y01 0 0 0 0 1 1 0 0 Y11 0 0 0 0 0 0 1 1 With the possibility of any type of confounding, the best we can do is place “Mansky bounds” on the average causal effect. To see this, let’s plot a histogram of our posterior on average causal effects, given lots of data: data &lt;- simulate_data( model, n = 1000, parameters = c(.5, .5, .5, .5, .5, .5, .5, .5, .1, .1, .7, .1)) updated &lt;- gbiqq(model, data, refresh = 0) ## Prior distribution added to model The key thing here is that the posterior on the ATE has shifted, as it should, but it is not tight, even with large data. In fact the distribution of the posterior covers one unit of the range between -1 and 1. 17.3 \\(X\\) causes \\(Y\\), with confounding modelled Say now we have a theory that the relationship between \\(X\\) and \\(Y\\) is confounded by unobserved variable \\(C\\). Although \\(C\\) is unobserved we can still include it in the model and observe the confounding it generates by estimating the model on data generated by the model but assuming that we cannot observe \\(C\\). model &lt;- make_model(&quot;C -&gt; X -&gt; Y &lt;- C&quot;) %&gt;% set_restrictions(c( &quot;(Y[X=1] &lt; Y[X=0]) | (Y[C=1] &lt; Y[C=0])&quot;, &quot;(X[C=1] &lt; X[C=0])&quot;)) %&gt;% set_parameters(type = &quot;prior_mean&quot;) The ATE estimand in this case is given by: Query Subset Using mean ATE All parameters 0.333 In the first column below we run a regression using data generated from this model but with \\(C\\) unobserved. The second column shows what we would estimate if were able to observe \\(C\\). Dependent variable: Y (1) (2) X 0.443*** 0.332*** (0.009) (0.009) C 0.331*** (0.009) Constant 0.277*** 0.168*** (0.006) (0.007) Observations 10,000 10,000 R2 0.197 0.293 Adjusted R2 0.196 0.293 Residual Std. Error 0.448 (df = 9998) 0.420 (df = 9997) F Statistic 2,445.636*** (df = 1; 9998) 2,076.113*** (df = 2; 9997) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Our posteriors over the effect of \\(X\\) on \\(Y\\) and the effect of the unobserved confounder (\\(C\\)) on \\(Y\\) have a joint distributed with negative covariance. To illustrate we will use the same data but assume priors from model where we do not restrict the relationship between \\(C\\) and \\(Y\\) and show the joint distribution of our posteriors. model &lt;- make_model(&quot;C -&gt; X -&gt; Y &lt;- C&quot;) %&gt;% set_restrictions(&quot;(X[C=1] &lt; X[C=0])&quot;) 17.4 Simple mediation model We define a simple mediation model and illustrate learning about whether \\(X=1\\) caused \\(Y=1\\) from observations of \\(M\\). model &lt;- make_model(&quot;X -&gt; M -&gt; Y&quot;) %&gt;% set_confound(confound = list(X = &quot;M[X=1]==1&quot;)) %&gt;% set_parameters(c(.5, .5, .2, .8, .2, 0, .8, 0, .2, 0, .8, 0)) plot_dag(model) Data and estimation: data &lt;- simulate_data(model, n = 1000, using = &quot;parameters&quot;) updated &lt;- gbiqq(model, data) result &lt;- gbiqq::query_model( updated, queries = list(COE = &quot;c(Y[X=1] &gt; Y[X=0])&quot;), subsets = c(&quot;X==1 &amp; Y==1&quot;, &quot;X==1 &amp; Y==1 &amp; M==0&quot;, &quot;X==1 &amp; Y==1 &amp; M==1&quot;), using = &quot;posteriors&quot;) Query Subset Using mean sd COE X==1 &amp; Y==1 posteriors 0.913 0.192 COE X==1 &amp; Y==1 &amp; M==0 posteriors 0.039 0.106 COE X==1 &amp; Y==1 &amp; M==1 posteriors 0.914 0.192 Note that observation of \\(M=0\\) results in a 0 probability for the posterior that \\(X\\) caused \\(Y\\), while observation of \\(M=1\\) has only a modest positive effect. The mediator thus provides a hoop test for the proposition that \\(X\\) caused \\(Y\\). 17.5 Simple moderator model We define a simple model with a moderator and illustrate how updating about COE is possible using the value of a mediator as a clue. model &lt;- make_model(&quot;X -&gt; Y; Z -&gt; Y&quot;) plot_dag(model) data &lt;- simulate_data( model, n = 1000, parameters = c(.5, .5, .5, .5, .02, .02, .02, .02, .02, .02, .02, .02, .02, .70, .02, .02, .02, .02, .02, .02)) posterior &lt;- gbiqq(model, data) result &lt;- gbiqq::query_model( updated, queries = list(COE = &quot;Y[X=1] &gt; Y[X=0]&quot;), subsets = list(&quot;X==1 &amp; Y==1&quot;, &quot;X==1 &amp; Y==1 &amp; Z==0&quot;, &quot;X==1 &amp; Y==1 &amp; Z==1&quot;), using = &quot;posteriors&quot;) Query Subset Using mean sd COE X==1 &amp; Y==1 posteriors 0.795 0.044 COE X==1 &amp; Y==1 &amp; Z==0 posteriors 0.404 0.143 COE X==1 &amp; Y==1 &amp; Z==1 posteriors 0.883 0.037 As an exercise, define a model where, learning about a model with moderators allows you to tighten bounds on COE even without observing the value of the mediator. 17.6 Billy and Suzy’s moderator and mediation model We can describe a simple version of the Billy and Suzy stone throwing game as a model with moderation and mediation in three nodes. model &lt;- make_model(&quot;Suzy -&gt; Billy -&gt; Smash &lt;- Suzy&quot;) %&gt;% set_restrictions(c( # If Suzy throws the bottle breaks &quot;(Smash[Suzy=1]==0)&quot;, # The bottle won&#39;t break by itself &quot;(Smash[Billy=0, Suzy = 0]==1)&quot;, # Suzy&#39;s throw doesn&#39;t *encourage* Billy to throw &quot;Billy[Suzy=1]&gt;Billy[Suzy=0]&quot;)) plot_dag(model) Here “Suzy” means Suzy throws, “Billy”: means Billy throws—which he might not do if Suzy throws—and “Smash” means the bottle gets smashed. The version here is a somewhat less deterministic version of the classic account. Suzy is still an ace shot but now she may or may not throw and Billy may or may not respond positively to Suzy and if he does respond he may or may not be successful. With all these possibilities we have twelve unit causal types instead of 1. We have two estimands of interest: counterfactual causation and actual causation. Conditional on Suzy throwing and the bottle breaking, would the bottle not have broken had Suzy not thrown her stone. That’s counterfactual causation. The actual causation asks the same question but conditioning on the fact that Billy did or did not thrown his stone—which we know could itself be due to Suzy throwing her stone. If so then we might think of an “active path” from Suzy’s throw to the smashing, even though had she not thrown the bottle would have smashed anyhow. Our results: actual_cause &lt;- query_model(model, using = &quot;priors&quot;, queries = c( Counterfactual = &quot;Smash[Suzy = 1] &gt; Smash[Suzy = 0]&quot;, Actual = &quot;Smash[Suzy = 1, Billy = Billy[Suzy = 1] ] &gt; Smash[Suzy = 0, Billy = Billy[Suzy = 1]]&quot;), subsets = c(&quot;Suzy==1 &amp; Smash==1&quot;, &quot;Suzy==1 &amp; Smash==1 &amp; Billy==0&quot;, &quot;Suzy==1 &amp; Smash==1 &amp; Billy==1&quot;), expand_grid = TRUE ) Query Subset Using mean sd Counterfactual Suzy==1 &amp; Smash==1 priors 0.668 0.236 Counterfactual Suzy==1 &amp; Smash==1 &amp; Billy==0 priors 0.751 0.221 Counterfactual Suzy==1 &amp; Smash==1 &amp; Billy==1 priors 0.502 0.289 Actual Suzy==1 &amp; Smash==1 priors 0.834 0.167 Actual Suzy==1 &amp; Smash==1 &amp; Billy==0 priors 1.000 0.000 Actual Suzy==1 &amp; Smash==1 &amp; Billy==1 priors 0.502 0.289 Our inferences, without even observing Billys throw distinguish between Suzy being a counterfactual cause and an actual cause. We think it likely that Suzy’s throw was an actual cause of the outcome though we are less sure that it was a counterfactual causes. Observing Billy’s throw strengthens our inferences. If Billy didn’t throw then we are sure Suzy’s throw was the actual cause, though we are still in doubt about whether her throw was a counterfactual cause. Note that if we observed Suzy not throwing then we would learn more about whether she would be a counterfactual cause since we would have learned more about whether Billy reacts to her and also about whether Billy is a good shot. Query Subset Using mean sd Counterfactual Suzy==0 &amp; Billy==0 priors 1.000 0.000 Counterfactual Suzy==0 &amp; Billy==1 priors 0.493 0.289 Counterfactual Suzy==0 &amp; Billy==1 &amp; Smash==1 priors 0.000 0.000 Actual Suzy==0 &amp; Billy==0 priors 1.000 0.000 Actual Suzy==0 &amp; Billy==1 priors 0.745 0.224 Actual Suzy==0 &amp; Billy==1 &amp; Smash==1 priors 0.500 0.291 17.7 An IV model We define a simple mediation model and illustrate learning about whether \\(X=1\\) caused \\(Y=1\\) from observations of \\(M\\). model &lt;- make_model(&quot;X -&gt; M -&gt; Y&quot;) %&gt;% set_confound(confound = list(M = &quot;Y[M=1]==1&quot;)) plot_dag(model) result &lt;- gbiqq::query_model( updated, queries = list(ATE = &quot;c(Y[M=1] - Y[M=0])&quot;), subsets = list(TRUE, &quot;M[X=1] &gt; M[X=0]&quot;, &quot;M==0&quot;, &quot;M==1&quot;), using = &quot;posteriors&quot;) Query Subset Using mean sd ATE All posteriors 0.590 0.063 ATE M[X=1] &gt; M[X=0] posteriors 0.592 0.071 ATE M==0 posteriors 0.571 0.120 ATE M==1 posteriors 0.607 0.036 We calculate the average causal effect for all and for the compliers and conditional on values of \\(M\\). 17.8 A model that allows application of the frontdoor criterion 17.9 A model with a violation of sequential ignorability 17.10 Learning from a collider Pearl describes a model similar to the following as a case for which controlling for covariate \\(W\\) induces bias in the estimation of the effect of \\(X\\) on \\(Y\\), which could otherwise be esimated without bias. model &lt;- make_model(&quot;X -&gt; Y &lt;- S; S -&gt; W&quot;) %&gt;% set_confound(list(X = &quot;W[S=1]&gt;W[S=0]&quot;)) %&gt;% set_parameters(parameters = c(.1, .9, .5, .5, .9, .1, .1,.1,.7,.1, .2, 0,0,0, 0,0,0,0, .6,0,0,0, 0,0,0,.2)) plot_dag(model) data &lt;- simulate_data(model, n = 20000) data$S &lt;- NA The true effect of \\(X\\) on \\(Y\\) is .3 but the PC is quite different for units with \\(W=0\\) and \\(W=1\\): Query Subset Using mean Y(1)-Y(0) All parameters 0.300 Y(1)-Y(0) X==1 &amp; Y==1 parameters 0.600 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==0 parameters 0.083 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==1 parameters 0.744 These are the quantities we seek to recover. The ATE can be gotten fairly precisely in a simple regression. But controlling for \\(W\\) introduces bias both for the unconditional and the conditional effects of \\(X\\): Dependent variable: Y (1) (2) (3) X 0.311*** 0.309*** 0.022** (0.007) (0.006) (0.009) W 0.371*** -0.008 (0.006) (0.010) X:W 0.574*** (0.012) Constant 0.196*** 0.011* 0.200*** (0.006) (0.006) (0.007) Observations 20,000 20,000 20,000 R2 0.090 0.234 0.311 Adjusted R2 0.090 0.234 0.311 Residual Std. Error 0.467 (df = 19998) 0.429 (df = 19997) 0.407 (df = 19996) F Statistic 1,987.200*** (df = 1; 19998) 3,050.590*** (df = 2; 19997) 3,005.497*** (df = 3; 19996) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 How does the Bayesian model do, with and without data on \\(W\\)? Inferences that do not use \\(W\\) get ATE right on average, but PC is not identified and statements about PC conditional on \\(W\\) are not possible: Without \\(W\\): Table 17.3: Collider excluded from model Query Subset Using mean sd Y(1)-Y(0) All posteriors 0.301 0.007 Y(1)-Y(0) X==1 &amp; Y==1 posteriors 0.798 0.056 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==0 posteriors 0.792 0.066 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==1 posteriors 0.793 0.065 We see including the collider does not induce error in estimation of the ATE, even though it does in a regression framework. It provides an ability to make different PC case level claims given W, but these are nevertheless far off in this example because we still do not have identification. With \\(W\\): Table 17.4: Collider included in model Query Subset Using mean sd Y(1)-Y(0) All posteriors 0.302 0.006 Y(1)-Y(0) X==1 &amp; Y==1 posteriors 0.792 0.039 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==0 posteriors 0.626 0.121 Y(1)-Y(0) X==1 &amp; Y==1 &amp; W==1 posteriors 0.839 0.039 17.11 A model mixing observational and experimental data We imagine that node \\(R\\) indicates whether a unit was assigned to be randomly assigned to treatment assignment (\\(X=Z\\) if \\(R=1\\)) or took on its observational value (\\(X=O\\) if \\(R=0\\)). We assume the exclusion restriction that entering the experimental sample is not related to \\(Y\\) other than through assignment of \\(X\\). model &lt;- make_model(&quot;R -&gt; X; O -&gt;X; Z -&gt; X; X -&gt; Y&quot;, add_priors = FALSE) %&gt;% set_restrictions(&quot;(X[R=1, Z=0]!=0) | (X[R=1, Z=1]!=1) | (X[R=0, O=0]!=0) | (X[R=0, O=1]!=1)&quot;) %&gt;% set_priors() %&gt;% set_confound(list(O = &quot;(Y[X=1] &gt; Y[X=0])&quot;, O = &quot;(Y[X=1] &lt; Y[X=0])&quot;, O = &quot;(Y[X=1] == 1)&quot;)) plot_dag(model) The parameter matrix has just one type for \\(X\\) since \\(X\\) really operates here as a kind of switch, inheriting the value of \\(Z\\) or \\(O\\) depending on \\(R\\). Parameters allow for complete confounding between \\(O\\) and \\(Y\\) by \\(Z\\) and \\(Y\\) are unconfounded. model &lt;- set_parameters(model, c(.2, .8, .8, .2, .2, .8, .8, .2, .5, .5, .5, .5, 1, .2, .2, .4, .2)) The estimands: Query Subset Using mean ATE All parameters 0.2 ATE R==0 parameters 0.2 ATE R==1 parameters 0.2 The priors: Query Subset Using mean sd ATE All priors -0.002 0.319 ATE R==0 priors -0.002 0.319 ATE R==1 priors -0.002 0.319 Data: data &lt;- simulate_data(model, n = 600) # Uncomment if data on $O$ is not available for cases assigned to $R=1$. # data$O[data$R == 1] &lt;- NA The true effect is .2 but naive analysis on the observational data would yield a srtongly upwardly biased estimate. The gbiqq estimates are: posterior &lt;- gbiqq(model, data) Query Subset Using mean sd ATE All posteriors 0.19 0.048 ATE R==0 posteriors 0.19 0.048 ATE R==1 posteriors 0.19 0.048 Did observational data improve the estimates from the experimental data? posterior &lt;- gbiqq(model, data[data$R==1,]) Query Subset Using mean sd ATE All posteriors 0.227 0.053 ATE R==0 posteriors 0.227 0.053 ATE R==1 posteriors 0.227 0.053 A key quantity of interest from this model is the average effect of treatment conditional on being in treatment in the observational group. We have: Query Subset Using mean sd ATE R==1 &amp; X==0 posteriors 0.190 0.048 ATE R==1 &amp; X==1 posteriors 0.190 0.048 ATE R==0 &amp; X==0 posteriors -0.122 0.072 ATE R==0 &amp; X==1 posteriors 0.414 0.060 17.12 Transportation of findings across contexts We study the effect of \\(X\\) on \\(Y\\) in country 1 and want to make inferences to country 2, Our problem however is that countries differ in terms of some feature, \\(W\\), that is distributed differently in the two countries and that affects \\(Y\\) via some mechanism \\(K\\). [[We assume that we have an experiment in country 1 but only observational variation in country 2.]] For instance, \\(X\\) is cash and \\(Y\\) is welfare. \\(W\\) is background levels of conflict which affects welfare via security \\(K\\), possibly differently in both countries. Although they differ, we have the following encompassing theory for both countries. model &lt;- make_model(&quot;W -&gt; K -&gt; Y &lt;- X&quot;) "],
["references.html", "References", " References "]
]
