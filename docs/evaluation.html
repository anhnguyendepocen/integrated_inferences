<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 16 Evaluating models | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 16 Evaluating models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Evaluating models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="justifying-models.html"/>
<link rel="next" href="final-words.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.2</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>10</b> Mixing models</a><ul>
<li class="chapter" data-level="10.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>10.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="10.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>10.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="10.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>10.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="10.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>10.4</b> Multilevel models, meta-analysis</a></li>
<li class="chapter" data-level="10.5" data-path="mm.html"><a href="mm.html#real-multilevel"><i class="fa fa-check"></i><b>10.5</b> Real multilevel</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="11" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>11</b> Elements of Design</a><ul>
<li class="chapter" data-level="11.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>11.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="11.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>11.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>11.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="11.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>11.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="11.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-variance-almost-always-goes-down"><i class="fa fa-check"></i><b>11.2.2</b> Expected variance (almost) always goes down</a></li>
<li class="chapter" data-level="11.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>11.2.3</b> Illustration</a></li>
<li class="chapter" data-level="11.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-loss-functions"><i class="fa fa-check"></i><b>11.2.4</b> Other loss functions</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>11.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>13</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="13.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a></li>
<li class="chapter" data-level="13.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>13.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="13.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>13.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="13.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>13.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>13.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="13.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>13.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="13.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>13.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="13.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>13.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="13.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>13.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="13.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>13.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>14.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>14.2</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>14.3</b> Explorations</a><ul>
<li class="chapter" data-level="14.3.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>14.3.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.4</b> Principles</a><ul>
<li class="chapter" data-level="14.4.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>14.4.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="14.4.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>14.4.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="14.4.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>14.4.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.1</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.2" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.2</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a><ul>
<li class="chapter" data-level="15.4.1" data-path="justifying-models.html"><a href="justifying-models.html#a-model-of-models"><i class="fa fa-check"></i><b>15.4.1</b> A model of models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>17.1</b> General lessons</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>17.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>17.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="17.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>17.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="evaluation" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Evaluating models</h1>
<hr />
<p>Model based inference takes the model seriously. But deep down we know that all of these models are wrong, in myriad ways. We examine strategies for figuring out whether a model is likely doing more harm than good.</p>
<hr />
<p>Throughout this book we have maintained the conceit that you believe your model. But it is also obvious that even the most non-parametric-seeming models depend on substantive assumptions and that these are almost certainly wrong. The question then is not how much you believe your model (or whether you really believe what you say you believe) but whether your model is useful is some sense. How can we evaluate the usefulness of our models?</p>
<div id="five-strategies" class="section level2">
<h2><span class="header-section-number">16.1</span> Five Strategies</h2>
<p>Sometimes a model is just a poor representation of the underlying causal processes.</p>
<p>Imagine a situation in which researchers believe that the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> runs entirely through <span class="math inline">\(M\)</span>, positing a model of the form <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>. Imagine, however, that the true causal process is one in which <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> <em>directly</em>; <span class="math inline">\(X\)</span> has no effect on <span class="math inline">\(M\)</span>, so that there is no indirect effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>; and <span class="math inline">\(M\)</span> never has a negative effect on <span class="math inline">\(Y\)</span>.</p>
<p>The problem with the posited model, then, is that it represents overly strong beliefs about independence relations: it does not allow for a direct effect that is in fact operating.</p>
<!-- AJ: "Restrictedness" seems a bit off here insofar as the "unrestricted" model is also restricted in essentially assuming no operative $X -> M$ arrow, as well as no negative direct effects.  -->
<p>We are perfectly able to update using this too-strong <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model and the data — but the updated model can produce wildly inaccurate causal inferences. We show this using set of 200 observations simulated from a “true” model with direct effects only and an average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> of <span class="math inline">\(1/3\)</span>.<a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a> In the left panel of Figure <a href="#fig:modelsch15"><strong>??</strong></a>, we show the estimated average treatment effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> when using these data to update the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model.</p>
<p>In the righthand panel of the figure, we show the inferences using the same data but a model that makes weaker assumptions by allowing for direct effects: a <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow X\)</span> model. With both models, we start with flat priors over nodal types.<a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a></p>
<p>We represent the true average effect with the vertical line in each graph.</p>
<p>As we can see, the weaker (i.e., more permissive) model performs OK: the true effect falls well within the posterior predictive distribution on the ATE. However, the stronger model, which excludes direct effects, generates a posterior predictive distribution that essentially excludes the right answer. So, if we go into the analysis with the stronger model, we have a problem.</p>
<p>But will we notice?</p>
<p>In the remainder of this section, we explore a range of diagnostics that researchers can undertake to evaluate the usefulness of their models or to compare models with one another: checking assumptions of conditional independence built into a model; attending to computational clues; checking the model’s fit; using “leave-one-out” cross-validation; and assessing model sensitivity.</p>
<div class="figure"><span id="fig:15badmodels"></span>
<img src="ii_files/figure-html/15badmodels-1.png" alt="A restricted model yields a credibility interval that does not contain the actual average effect." width="672" />
<p class="caption">
Figure 16.1: A restricted model yields a credibility interval that does not contain the actual average effect.
</p>
</div>
<!-- * $X$ correlates with $Y$ -->
<!-- * $X$ does not correlate with $M$  -->
<!-- * $M$ does not correlate with $Y$.  -->
<!-- These data are inconsistent with the model: under this model, if $X$ doesn't cause $M$ and $M$ doesn't cause $Y$, then there is no other way for $X$ to cause $Y$.  -->
<div id="check-conditional-independence" class="section level3">
<h3><span class="header-section-number">16.1.1</span> Check conditional independence</h3>
<p>First, even before engaging in updating, we can look to see whether the data pattern is consistent with our causal model. In particular, we can check whether there are inconsistencies with the Markov condition that we introduced in Chapter 2: that every node is <em>conditionally independent</em> of its non-descendants, given its parents. In this case, if the stronger model is right, then given <span class="math inline">\(M\)</span>, <span class="math inline">\(Y\)</span> should be independent of <span class="math inline">\(X\)</span>.</p>
<p>Is it?</p>
<p>One way to check is to assess the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> given <span class="math inline">\(M\)</span> in the data. Specifically, we regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> for each value of <span class="math inline">\(M\)</span>, once for <span class="math inline">\(M=1\)</span> and again for <span class="math inline">\(M=0\)</span>; a correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at either value of <span class="math inline">\(M\)</span> would be problematic for the conditional independence assumption embedded in the stronger model.</p>
<p>Note that this form of diagnostic test is a classical one in the frequentist sense: we start by hypothesizing that our model is correct and then ask whether the data were unlikely given the model.</p>
<table>
<caption><span id="tab:unnamed-chunk-24">Table 16.1: </span>Regression coefficient on <span class="math inline">\(X\)</span> given <span class="math inline">\(M=0\)</span> and <span class="math inline">\(M=1\)</span></caption>
<thead>
<tr class="header">
<th align="right">M</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.369</td>
<td align="right">0.099</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0.573</td>
<td align="right">0.080</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We report the regression coefficients on <span class="math inline">\(X\)</span> in the table below. It is immediately apparent that we have a problem. At both values of <span class="math inline">\(M\)</span>, there is a strong correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, evidence of a violation of the Markov condition implied by the stronger model.<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a></p>
<p>Identifying the full set of conditional independence assumptions in a causal model can be difficult. There are however well developed algorithms for identifying what sets, if any, you need to conditional on to ensure conditional Independence between two nodes given a DAG. <code>R</code> users can quickly access such results using the <code>impliedConditionalIndependencies</code> function in dagitty package.</p>
<!-- AJ: I do not follow the sentence starting with "Intuitively" in the above. -->
<!-- ROUGH TEXT: -->
<!-- approach 2 -- say actual confound is q~=0; but model  assumes q = 0. Draw data from priors, draw data; given data type (001, 100 etc) plot (a) the posterior distribution under no confounding nad (b) the distribution of estimands that gave rise to the data.   -->
<!-- (Verma and Pearl, 1990) identify conditions under which we can check some independence assumptions. -->
<!--  Pearl (1995) gives conditions for assessing for discrete data whether $Z$ has a  direct effect on $Y$. (Involves inequalities) -->
<!-- Evans (Graphical methods for inequality constraints in marginalized DAGs) generalizes the instrumental inequality. -->
</div>
<div id="computational-clues" class="section level3">
<h3><span class="header-section-number">16.1.2</span> Computational clues</h3>
<p>Second, we may be lucky and run into computation issues. In this example there is a good chance that when you fit the stronger model, <code>stan</code> will throw an error:</p>
<blockquote>
<p><code>Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</code></p>
</blockquote>
<!-- AJ: Needs elaboration: why is this error a function of problems with the model? -->
<!-- MH: I agree; do feel free to look into it; I will try -->
<!-- AJ: I have done some digging and not found anything helpful on this -->
<!-- MH: Well that's just great -->
<!-- AJ: Looked a little more - still nothing! Whence did you get a sense there might be something to this? -->
</div>
<div id="bayesian-p-value-are-the-data-unexpected-given-your-model" class="section level3">
<h3><span class="header-section-number">16.1.3</span> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</h3>
<p>A third approach asks whether features of the data you observe are in some sense unusual given your model, or more unusual given your model than another model. For instance, if one model assumed no adverse effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> and no confounding, then a strong negative correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> would be unusual, even for the model updated with this data; and this negative correlation would <em>more</em> unusual for this model than for a model that allowed for adverse effects.</p>
<p>In fact, this approach is quite classical: we are looking to see whether we should “reject” our model in light of inconistent data.</p>
<!-- AJ: But it can also be done in a comparative sense as we do below, right? Which is then not about "rejection", right? I've actually adjusted the text two paragraphs up to make the idea of comparison more prominent. This works?-->
<p>An approach for doing this using simulated data from the posterior predictive distribution is described in <span class="citation">Gabry et al. (<a href="#ref-gabry2019visualization" role="doc-biblioref">2019</a>)</span>.<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a></p>
<p>We consider two test statistics, comparing our stronger to our weaker model. First, we look just at the distribution of the outcome <span class="math inline">\(Y\)</span> to see how the actual distribution in the data compares to the predicteddistribution from the updated model. Second, we look at the actual correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and see how this compares to the predicted distribution. In both cases we calculate a two sided <span class="math inline">\(p\)</span>-value by assessing and doubling the share of the mass of the predictive posterior distribution that lies on the more extreme side of the observed data. If the observed data were at the mean of the predicive distribution, then we would have a <span class="math inline">\(p\)</span>-value of 1. If it were at the 95th percentile we would have a <span class="math inline">\(p\)</span>-value of 0.10. (We note that in this straightforward calculation we assess the probability of the data given the same model that generated the data; approaches could also be used that seek out of sample estimates of teh probability of observing the observed data.)</p>
<!-- AJ: Last sentence confuses me. Aren't we using data only from unrestricted_model? -->
<p>For the first test, we see that the predicted distribution of the outcome <span class="math inline">\(Y\)</span> is similar for both updated models; and the actual mean outcome is within the distribution of predicted mean outcomes. The <span class="math inline">\(p\)</span>-values for the stronger (0.11) and weaker models (0.14) suggest that the observed mean <span class="math inline">\(Y\)</span> values are about equally likely for both models.</p>
<p>When it comes to the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, however, the two models perform very differently. The posterior predictive distribution from the stronger model is centered around a <span class="math inline">\(0\)</span> correlation and does not even extend out as far as the observed correlation. The resulting <span class="math inline">\(p\)</span>-value is 0, meaning that from the perspective of the stronger model the <span class="math inline">\(X,Y\)</span> correlation in the data is entirely unexpected. A frequentist looking at the observed correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> should feel comfortable rejecting the stronger model. The updated weaker model, in contrast, predicts a strong correlation, and the observed correlation is comfortably within the posterior predictive distribution, with a <span class="math inline">\(p\)</span>-value of 0.08.</p>
<!-- AJ: Need to code in the p-values -->
<p>At first blush, the abysmal performance of the stronger model may seem paradoxical. Even after this model has <em>seen</em> the <span class="math inline">\(X,Y\)</span> correlations in the data, the model still finds those correlations highly surprising. What keeps the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model from learning, however, is the strength of the assumptions it contains. The problem is that <span class="math inline">\(M\)</span> is uncorrelated with <span class="math inline">\(X\)</span> in the true data-generating process, so the stronger model learns that there is no indirect effect. But, at the same time, this model does not <em>allow</em> for a direct effect. Despite what would seem to be overwhelming evidence of a systematic <span class="math inline">\(X,Y\)</span> correlation, a causal relationship connecting <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> remains extremely unlikely given the <span class="math inline">\(X,M\)</span> data pattern and the impossibility of direct effects. The stronger model just can’t handle the truth. The weaker model, on the other hand, readily learns about the direct <span class="math inline">\(X \rightarrow Y\)</span> effect.</p>
<p><img src="ii_files/figure-html/ch15simulations-1.png" width="672" /></p>
<!-- ## Model likelihoods -->
<!-- Bayesian information criterion (BIC)^[$BIC = \ln(n)k - 2\ln(\hat{L})$ where $\hat{L}$ is the maximized likelhood, $k$ is the number of parameters, and $n$ the number of data points.] -->
<!-- BIC involves a penalty for more parameters -->
<!-- ```{r, echo = FALSE} -->
<!-- if(do_diagnosis) { -->
<!-- observed_data <- collapse_data(data, restricted_model) -->
<!-- likely <- function(model, s, posterior = TRUE) { -->
<!--   if(posterior)  pars <- model$posterior_distribution[1:s,] -->
<!--   if(!posterior) pars <- get_prior_distribution(model, s)[1:s,] -->
<!--   L <- apply(pars, 1,  function(par) make_data_probabilities(model, pars = par, observed_data, normalize = FALSE)) -->
<!--   mean(L) -->
<!--   } -->
<!-- s <- 500 -->
<!-- L_prior         <- likely(restricted_model, s, posterior = FALSE) -->
<!-- L_restricted    <- likely(restricted_model, s) -->
<!-- L_unrestricted  <- likely(unrestricted_model, s) -->
<!-- df <- data.frame(L = (c(L_unrestricted/L_prior, L_restricted/L_prior, L_unrestricted/L_restricted))) -->
<!-- rownames(df) <- c("Unrestricted / Prior", "Restricted / Prior", "Unrestricted / Restricted") -->
<!-- write_rds(df, "saved/ch15_likelihoodsdf.rds")  -->
<!-- } -->
<!-- df <- read_rds("saved/ch15_likelihoodsdf.rds")  -->
<!-- kable(df, col.names = "Bayes factors", digits = 2, caption = "Posterior odds: the relative likelihood of one model over another") -->
<!-- ``` -->
<!-- Compare likelihoods of the data under different models -->
<!-- Check look package for rstan -->
</div>
<div id="leave-one-out-loo-cross-validation" class="section level3">
<h3><span class="header-section-number">16.1.4</span> Leave-one-out (LOO) cross-validation</h3>
<p>A further class of model-validation methods involves cross-validation. Rather than asking how well the updated model predicts the data used to update it, cross-validation uses the data at hand to estimate how well the model is likely to predict new data that have not yet been seen. One way to do this is to split the available data, using one subsample to update and then assessing predictions using the other subsample. We focus here, however, on approaches that use <em>all</em> of the available data to estimate out-of-sample predictive performance.</p>
<p>One such approach is the “leave-one-out” (LOO) algorithm. In a LOO approach, we update the model using all data points except for one and then ask how well the model performs in predicting the left-out observation. We repeat this for every data point in the dataset to assess how well we can predict the entire dataset.</p>
<p>Often, the LOO approach is used to predict a particular outcome variable. In a  framework, however, we are interested in predictions over the joint realization of all nodes, not just a single “outcome.” Thus, we calculate the posterior probability of each data point, using the model updated with all of the other observations.</p>
<!-- AJ: Is the "predict all nodes" using a sledghammer here?Should we be setting this up in a more query-dependent way, I wonder? Could the same model be good for some kind of queries but not for others? Not quite sure how to think about that -- about *what* we'd be predicting conditional on what the query is, and maybe this isn't a coherent notion. -->
<!-- AJ: Change figure labels to stronger/weaker models. Also, need to make x-axes "data count" (without referring to a model) -->
<p><img src="ii_files/figure-html/unnamed-chunk-25-1.png" width="672" /><img src="ii_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<p>The LOO estimate of out-of-sample predictive fit, for a dataset with <span class="math inline">\(n\)</span> observations, is then:</p>
<p><span class="math display">\[\prod_1^np(y_i|y_{-i}, \text{model})\]</span>
where <span class="math inline">\(y_{-i}\)</span> is the data pattern with observation <span class="math inline">\(y_i\)</span> left out, and <span class="math inline">\(y_i\)</span> represents the values of all nodes of interest for observation <span class="math inline">\(i\)</span>.</p>
<!-- AJ: Any reason not to use a log in the above equation? Would this make some of the outputs easier to read? -->
<!-- MH it would get a more humnan scale but think raw numbers are more intuitive? -->
<p>We implement LOO cross-validation of the stronger and weaker models using 200 observations generated from the same data-generating model employed above. We find that the LOO likelihood of the data under the stronger model is 1.64e-182 while
the likelihood is 4.33e-175 under the weaker model. Thus, the weaker model represents an estimated improvement in out-of-sample prediction on the order of 2.64e+07.</p>
<p>We can visualize the pattern in Figure XXXX, where we plot the likelihood of each possible data type under the stronger model against the likelihood of that data type under the weaker model. Looking at the scales of the two axes—which is much more compressed on the horizontal than on the vertical—one can see that the stronger model is not able to differentiate as much across the data types as the weaker.</p>
<!-- AJ: What are these likelihoods exactly? They are informed by updating, I assume? But updating using what data exactly -- what's left out? Generally unsure if my text above is right.-->
<p>Notably, the stronger model is not able to “learn” from the data about the (<em>in fact</em>, operative) relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. We can see that, for any given <span class="math inline">\(X, M\)</span> combination, the two possible values of <span class="math inline">\(Y\)</span> are predicted with essentially the same likelihood. The stronger model also seems to have “learned” from chance correlations in the data that different values <span class="math inline">\(X,M\)</span> combinations are differentially likely—even though they are uncorrelated under the true model. The weaker model, on the other hand, basically divides the data types into two groups: those with a positive <span class="math inline">\(X,Y\)</span> correlation and those with a negative <span class="math inline">\(X,Y\)</span> correlation and has correctly (given the true model) learned that the former is more likely than the latter.</p>
<p>In Figure XXXX, we then see how the likelihoods of each data type line up with the actual count of each data type. As we can see, the weaker model updates to likelihoods that fit the actual data pattern well while the stronger model does not.</p>
<p>We can also turn the tables and imagine that the <em>stronger</em> model represents the true data-generating process. We implement LOO cross-validation of the two models using 200 data points generated from the stronger model. In Figure XXXX, we see a comparison of the likelihoods of the data types under the two updated models and note that they are extremely similar. This represents an important asymmetry: the model that makes weaker assumptions performs far better in handling data generated by a “stronger” true model than does the stronger model in learning about a process that violates one of its assumptions. Since the weaker model allows for both direct and indirect effects, the weaker <em>can</em> learn about the parameters of the true process in the first situation; but the strong model cannot do so in the second situation because it has by assumption ruled out a key feature of that process (the direct effect).</p>
<p><img src="ii_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>BETTER: PLOT CASES ON BOTTOM AND TWO LIKELIHOODS AS POINTS; HAVE TYPES AS LABELS X AI IF POSSIBLE</p>
<p>While it is difficult to see this in Figure XXXX, the stronger model still performs better here than the weaker model. The likelihood of the data under the stronger model is now 3.57e-119, compared to
the likelihood of 1.04e-124 under the weaker model. Thus, the weaker model represents an estimated loss to out-of-sample prediction on the order of 2.91e-06. This is not surprising insofar as the stronger model <em>precisely</em> models the data-generating process while the extra parameters in the weaker model allow for “learning” from chance features of the data.</p>
<p>These examples display features of estimation of out-of-sample prediction accuracy familiar from a regression context. In a regression framework, adding parameters to a model may improve fit to sample—generating gains to out-of-sample prediction accuracy when the new parameters pick up systematic features of the data-generating process—but run a risk of over-fitting to chance pattenrs in the data. Similarly, in a structural-causal-model framework, for a model with weaker assumptions and more parameters. We saw that the weaker model performed much better when the true process involved direct effects since the extra parameters, allowing for direct effects, captured something “real” going on. But the same model performed slightly worse than the stronger model when there were no direct effects to pick up, such that the extra parameter could only model noise.</p>
<!-- AJ: Last graph here doesn't seem right, with the data-type labels all stacked vertically. And no graph for unrestricted model. -->
<!-- Note on parsimony. It is interesting to note that more complex models have to pay their way: if they do not predict better than simpler models, then simpler models  are favored. For the intuition imagine in fact $X$ and $Y$ are unrelated. Say we had two data points, one with... -->
</div>
<div id="sensitivity" class="section level3">
<h3><span class="header-section-number">16.1.5</span> Sensitivity</h3>
<p>The last approach we consider brackets the question of which model is better and asks, instead: how much do your conclusions depend on the model? You can worry less about your assumptions if the conclusions are not strongly dependent on them.</p>
<p>To illustrate using a process tracing example, consider a situation in which we are unsure about posited parameter values: that is, about the probability of particular effects at particular nodes. It is likely to be the case in many research situations that we are considerably uncertain about how to quantify intuitive or theoretically informed beliefs about the relative likelihood of different effects.</p>
<p>Suppose, for instance, that we begin with an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. And suppose, further, that we believe that it is unlikely that <span class="math inline">\(M\)</span> has an adverse effect on <span class="math inline">\(Y\)</span>. But we are not sure <em>how</em> unlikely that adverse effect is. (We assume all other modal types are equally likely.) Finally, say that we want to use the observation of <span class="math inline">\(M\)</span> to draw an inference about whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> in an <span class="math inline">\(X=Y=1\)</span> case.</p>
<p>How much does our inference on <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>—when we see <span class="math inline">\(M=0\)</span> or <span class="math inline">\(M=1\)</span>—depend on this second stage assumption about the probability of a negative <span class="math inline">\(M \rightarrow Y\)</span> effect?</p>
<p>We answer the question by looking at posterior beliefs for a range of possible values for the relevant parameter, <span class="math inline">\(\lambda^Y_{10}\)</span>. In Table REF, we examine a range of values for <span class="math inline">\(\lambda^Y_{10}\)</span>, from 0 to 0.25 (full parity with other types). For each parameter value, we first show the resulting prior belief about the probability that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. We can see that, before we observe <span class="math inline">\(M\)</span>, we think that a positive <span class="math inline">\(X \rightarrow Y\)</span> effect is more likely as a negative <span class="math inline">\(M \rightarrow Y\)</span> effect is more likely. This stands to reason since a negative second-stage effect is one possible process in which a positive <span class="math inline">\(X \rightarrow Y\)</span> effect might occur. And higher values for <span class="math inline">\(\lambda^Y_{10}\)</span> come disproportionately at the expense of types under which <span class="math inline">\(X\)</span> cannot affect <span class="math inline">\(Y\)</span>.<a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a></p>
<p>In the next two columns, we show the posterior belief we arrive at when we observe <span class="math inline">\(M=0\)</span> and then <span class="math inline">\(M=1\)</span>, for each <span class="math inline">\(\lambda^Y_{10}\)</span> assumption. Looking at the last column first, we see that our inference from <span class="math inline">\(M=1\)</span> does <em>not</em> depend at all on our beliefs about adverse <span class="math inline">\(M \rightarrow Y\)</span> effects. The reason is that, if we see <span class="math inline">\(M=1\)</span>, we already know that <span class="math inline">\(M\)</span> did not have a negative effect on <span class="math inline">\(Y\)</span>, given that we also know <span class="math inline">\(Y=1\)</span>. Our beliefs are purely a function of the probability that there are positive effects at both stages as compared to the probability of other causal types that could yield <span class="math inline">\(X=M=Y=1\)</span>, a comparison unaffected by the probability of a negative <span class="math inline">\(M \rightarrow Y\)</span> effect.</p>
<p>Our inferences when <span class="math inline">\(M=0\)</span>, on the other hand, do depend on <span class="math inline">\(\lambda^Y_{10}\)</span>: when we see <span class="math inline">\(M=0\)</span>, our belief about a positive <span class="math inline">\(X \rightarrow Y\)</span> effect depends on the likelihood of <em>negative</em> effects at both stages. We see, then, that the likelier we think negative effects are at the second stage, the higher our posterior confidence in a positive <span class="math inline">\(X \rightarrow Y\)</span> effect when we see <span class="math inline">\(M=0\)</span>.</p>
<table>
<caption><span id="tab:unnamed-chunk-27">Table 16.2: </span>Inferences on the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> upon seeing <span class="math inline">\(M=0\)</span> or <span class="math inline">\(M=1\)</span> for a range of possible values of <span class="math inline">\(\lambda^Y_{10}\)</span></caption>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\lambda^Y_{10}\)</span></th>
<th align="right">Prior</th>
<th align="right"><span class="math inline">\(M=0\)</span></th>
<th align="right"><span class="math inline">\(M=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">0.167</td>
<td align="right">0.000</td>
<td align="right">0.25</td>
</tr>
<tr class="even">
<td align="right">0.05</td>
<td align="right">0.183</td>
<td align="right">0.068</td>
<td align="right">0.25</td>
</tr>
<tr class="odd">
<td align="right">0.10</td>
<td align="right">0.200</td>
<td align="right">0.125</td>
<td align="right">0.25</td>
</tr>
<tr class="even">
<td align="right">0.15</td>
<td align="right">0.217</td>
<td align="right">0.173</td>
<td align="right">0.25</td>
</tr>
<tr class="odd">
<td align="right">0.20</td>
<td align="right">0.233</td>
<td align="right">0.214</td>
<td align="right">0.25</td>
</tr>
<tr class="even">
<td align="right">0.25</td>
<td align="right">0.250</td>
<td align="right">0.250</td>
<td align="right">0.25</td>
</tr>
</tbody>
</table>
<p>Even though our inferences given <span class="math inline">\(M=1\)</span> do not depend on <span class="math inline">\(\lambda^Y_{10}\)</span>, the amount that we <em>update</em> if we see <span class="math inline">\(M=1\)</span> <em>does</em> depend on <span class="math inline">\(\lambda^Y_{10}\)</span>. This is because <span class="math inline">\(\lambda^Y_{10}\)</span> affects our belief, prior to seeing <span class="math inline">\(M\)</span>, that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Working with a low <span class="math inline">\(\lambda^Y_{10}\)</span> value, we start out less confident that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>, and thus our beliefs make a bigger jump if we do see <span class="math inline">\(M=1\)</span> than if we had worked with a <span class="math inline">\(\lambda^Y_{10}\)</span> higher value.</p>
<p>However, to the extent that we want to know how our assumptions affect our <em>conclusions</em>, the interesting feature of this illustration is that sensitivity depends on what we find. The answer to our query is sensitive to the <span class="math inline">\(\lambda^Y_{10}\)</span> assumption if we find <span class="math inline">\(M=0\)</span>, but not if we find <span class="math inline">\(M=1\)</span>. It is also worth noting that, even if we observe <span class="math inline">\(M=0\)</span>, the sensitivity is limited across the range of parameter values tested. In particular, for all <span class="math inline">\(\lambda^Y_{10}\)</span> values below parity (0.25), seeing <span class="math inline">\(M=0\)</span> moves our beliefs <em>in the same direction.</em></p>
<p>We can use the same basic approach to examine how our conclusions change if we relax assumptions about nodal-type restrictions, about confounds, or about causal structure.</p>
<p>We also note that in cases in which you cannot quantify uncertainty about parameters you might still be able to engage in a form of “qualitative inference.” There is a literature on probabilistic causal models that assesses the scope for inferences when researchers provide ranges of plausible values for parameters (perhaps intervals, perhaps only signs, positive negative, zero), rather than specifying a probability distribution. For a comprehensive treatment of qualitative algebras, see <span class="citation">Parsons (<a href="#ref-parsons2001qualitative" role="doc-biblioref">2001</a>)</span>. Under this kind of approach, a researcher might willing to say that they think some probability <span class="math inline">\(p\)</span> is not plausibly greater than .5, but unwilling to make a statement about their beliefs about where in the <span class="math inline">\(0\)</span> to <span class="math inline">\(0.5\)</span> range it lies. Such incomplete statements can be enough to rule our classes of conclusion.</p>
</div>
</div>
<div id="evaluating-the-democracy-inequality-model" class="section level2">
<h2><span class="header-section-number">16.2</span> Evaluating the Democracy-Inequality model</h2>
<p>** GENERATE A TABLE SHOWING HOW PIMD DOES ON 5 CRITERIA **</p>
<div id="check-assumptions-of-conditional-independence" class="section level3">
<h3><span class="header-section-number">16.2.1</span> Check assumptions of conditional independence</h3>
<p>Our model presupposes that <span class="math inline">\(P\)</span> and <span class="math inline">\(I\)</span> are independent and that <span class="math inline">\(P\)</span> and <span class="math inline">\(M\)</span> are independent. Note that the model is consistent with the possibility that, conditional on <span class="math inline">\(D\)</span>, there is a correlation betwen <span class="math inline">\(M\)</span> and <span class="math inline">\(P\)</span> or between <span class="math inline">\(I\)</span> and <span class="math inline">\(P\)</span>, as <span class="math inline">\(D\)</span> acts as a collider for these pairs of nodes.</p>
<p>We check these assumptions through a set of simple regression models, displayed in <a href="evaluation.html#tab:ch15cipimd">16.3</a>. In the first two rows, we examine the simple correlation between <span class="math inline">\(P\)</span> and <span class="math inline">\(I\)</span> and between <span class="math inline">\(P\)</span> and <span class="math inline">\(M\)</span>, respectively. We can see from the estimates in these two rows that the data pattern is consistent with our assumptions of unconditional independence for these two pairs of variables.</p>
<p>In</p>
<!-- MH: Realize we actually have a big iussue here: we only have M,P data in cases with D = 1 so we are in fact condtiioining on D and so we do *not* expect independence  -->
<table>
<caption><span id="tab:ch15cipimd">Table 16.3: </span>Regression coefficients to assess conditional independence</caption>
<thead>
<tr class="header">
<th align="left">Correlation</th>
<th align="left">Given</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">P,I</td>
<td align="left">-</td>
<td align="right">0.151</td>
<td align="right">0.155</td>
<td align="right">0.337</td>
</tr>
<tr class="even">
<td align="left">P,M</td>
<td align="left">-</td>
<td align="right">-0.175</td>
<td align="right">0.164</td>
<td align="right">0.292</td>
</tr>
<tr class="odd">
<td align="left">P,I</td>
<td align="left">M = 0</td>
<td align="right">-0.071</td>
<td align="right">0.277</td>
<td align="right">0.800</td>
</tr>
<tr class="even">
<td align="left">P,I</td>
<td align="left">M = 1</td>
<td align="right">0.329</td>
<td align="right">0.170</td>
<td align="right">0.066</td>
</tr>
<tr class="odd">
<td align="left">P,M</td>
<td align="left">I = 0</td>
<td align="right">-0.400</td>
<td align="right">0.214</td>
<td align="right">0.080</td>
</tr>
<tr class="even">
<td align="left">P,M</td>
<td align="left">I = 1</td>
<td align="right">0.000</td>
<td align="right">0.244</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<!-- Should add columns saying for which two nodes the correlation is being assessed. -->
<p>We can dig a little deeper, however. The model <em>also</em> implies that <span class="math inline">\(P\)</span> should be independent of <span class="math inline">\(I\)</span> given <span class="math inline">\(M\)</span>, and of <span class="math inline">\(M\)</span> given <span class="math inline">\(I\)</span> — since <span class="math inline">\(D\)</span> blocks all paths between <span class="math inline">\(P\)</span> and either <span class="math inline">\(I\)</span> or <span class="math inline">\(M\)</span>. We test these assumptions in the next 4 rows. In rows 3 and 4 of the table, we examine the conditional independence of <span class="math inline">\(P\)</span> and <span class="math inline">\(I\)</span> given <span class="math inline">\(M=0\)</span> and given <span class="math inline">\(M=1\)</span>. Here the evidence is more troubling for our model, as we see a relative strong relation between <span class="math inline">\(P\)</span> and <span class="math inline">\(I\)</span> when <span class="math inline">\(M=1\)</span>. Substantively, this implies that in cases where there is mobilization, pressure is more common where inequality is high than where inequality is low. While we cannot identify the correct model from this data pattern, one possible explanation could be that pressure has a direct effect on mobilization, making mobilization a collider for inequality and pressure.</p>
<p>Looking at rows 5 and 6, we see that there is a correlation between <span class="math inline">\(P\)</span> and <span class="math inline">\(M\)</span> when inequality is low. Substantively, in states with low inequality, mobilization is more common in cases without international pressure (<span class="math inline">\(P=0\)</span>) (arising in 0 of 13 cases) than in cases that experience pressure arising in just 1 of 5 cases. Again, our model may be missing a direct link from pressure to mobilization, which would generate the possibility that inequality and pressure interactively affect mobilization.</p>
<!-- Unclear what the case numbers above are referring to. For instance, I see 13 cases with I=0, P=0. But what's the 0?-->
<!-- I am thinking we should now bring in models that relax the assumptions that appear not to hold in the CI analysis. For instance, introduce an arrow from $P$ to $M$. -->
</div>
<div id="bayesian-p-value" class="section level3">
<h3><span class="header-section-number">16.2.2</span> Bayesian <span class="math inline">\(p\)</span>-value</h3>
<p>We turn next to</p>
<p><img src="ii_files/figure-html/ch15pvalue_pimd-1.png" width="672" /></p>
<!-- p_two_sided <- function(Y, y, digits = 2){ -->
<!--   if(y <  mean(Y)) return(round(2* mean(y > Y), digits)) -->
<!--   if(y >= mean(Y)) return(round(2* mean(y <= Y), digits)) -->
<!-- } -->
<!-- hist(replicates_restricted$Y,  -->
<!--      main = paste("Y mean | stronger: p = ", p_temp), -->
<!--                   xlim = xlimY, xlab = "predictions")  -->
<!--      abline(v = mean(data$Y), col = "red") -->
<!-- p_temp <- p_two_sided(replicates_restricted$C, cor(data$Y, data$X)) -->
<!-- hist(replicates_restricted$C,  -->
<!--      main = paste("X, Y covariance | stronger: p =", p_temp),  -->
<!--      xlim = xlimC, xlab = "predictions"); abline(v = cor(data$Y, data$X), col = "red") -->
<!-- p_temp <- p_two_sided(replicates_unrestricted$Y, mean(data$Y)) -->
<!-- hist(replicates_unrestricted$Y,  -->
<!--      main = paste("Y mean | weaker: p = ", p_temp), -->
<!--      xlim = xlimY, xlab = "predictions"); abline(v = mean(data$Y), col = "red") -->
<!-- p_temp <- p_two_sided(replicates_unrestricted$C, cor(data$Y, data$X)) -->
<!-- hist(replicates_unrestricted$C,  -->
<!--      main = paste("X, Y covariance | weaker: p = ", p_temp),  -->
<!--      xlim = xlimC, xlab = "predictions"); abline(v = cor(data$Y, data$X), col = "red") -->
<!-- <!-- AJ: Should we also calculate a p-value? -->
<!-- AJ: And what about comparing multiple models? -->
</div>
<div id="loo-validation" class="section level3">
<h3><span class="header-section-number">16.2.3</span> LOO validation</h3>
<p>Turning to “leave one out” model assessment, we now consider comparing the base model to models that make weaker assumptions. In one alternative model, we drop the assumption of monotonicity of <span class="math inline">\(M\)</span> in <span class="math inline">\(I\)</span> and instead put a low prior probability on negative <span class="math inline">\(I \rightarrow M\)</span> effects. We also test a maximally flexible model (given the DAG) in which we make no montonocity assumptions for any of the causal effects.</p>
<p><img src="ii_files/figure-html/loo_pimdplots-1.png" width="672" /><img src="ii_files/figure-html/loo_pimdplots-2.png" width="672" /><img src="ii_files/figure-html/loo_pimdplots-3.png" width="672" />
<!-- AJ: Getting error for LOO plots -- can't find plot_loo function. --></p>
<p>In Figures @ref(loo_pimdplots), we show the relationship, for each model, of the likelihood of each data type against the number of cases of that data type in the data. A data type is here defined as a possible combination of realized values on all nodes (<span class="math inline">\(I, P, M\)</span> and <span class="math inline">\(D\)</span>). In each plot, the diagonal line represents equality between the proportion of expected cases under the model and the proportion of actual cases. Just eyeballing the relationships, it appears as though the two stronger models might be performing better than the fully unrestricted model.</p>
<p>More formally, we calculate the LOO likelihood for each model as 1.02e-73 for the model with monotonicity assumptions throughout, 1.98e-74 for the model that relaxes the monotonicity assumption for <span class="math inline">\(I \rightarrow M\)</span>, and 7.06e-74 for the model with no monotonicity assumptions at all. In other words, we see that the most restrictive model performs best, by about an order of magnitude, followed by the least restrictive model, and then the moderately restrictive one.</p>
</div>
<div id="sensitivity-to-priors" class="section level3">
<h3><span class="header-section-number">16.2.4</span> Sensitivity to priors</h3>
<p>In our model we assumed that <span class="math inline">\(M\)</span> is monotonic in <span class="math inline">\(I\)</span>. How much do conclusions depend on this? We answer the question by comparing our conclusion to what we would conclude withiout this assumption. Our answers depend on the quantity examined.</p>
<p>We first show results for population inference from a mixed methods analysis. As seen in Table XX our inferences regarging the overall effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span> are not very sensitive to this assumption. Our conditional inferences are, however. In particular, in cases with <span class="math inline">\(I=0, D=1\)</span> we are more likely to think that democratization was due to <em>low</em> inequality given the unrestricted model. When we see that in fact there was no mobilization, our attribution increases in the restricted model but decreases in the unrestricted model. In the fully unrestricted model our inferences are not affected at all by observation of <span class="math inline">\(M=0\)</span>.</p>
<!-- FLAG: AJ: Check intuition here! -->
<p>In the non-monotonic model we entertain the possibility that low inequality mattered not just directly but also, perhaps, by inducing protests. However, when you observe no protests, you rule out this possible pathway. In the monotonic model you do not think that democratization could have been produced by low inequality via demonstrations—but nevertheless entertain the possibility of mobilization that is <em>not</em> due to inequality, which could nevertheless be the cause of democratization. In this case, observing no mobilization removes a rival, cause of democratization, not a second channel.</p>
<p>In all, we judge the conditional inferences as very sensitive to the monotonicity assumptions we put in place.</p>
<table>
<caption><span id="tab:15pimdgraphs">Table 16.4: </span>Posteriors on the effect of I on D depending on whether the to M relation is assumed to be monotonic (M1) or not (M2)</caption>
<thead>
<tr class="header">
<th align="left">Given</th>
<th align="right">Mean (M1)</th>
<th align="right">sd (M1)</th>
<th align="right">Mean (M2)</th>
<th align="right">sd (M2)</th>
<th align="right">Mean (M3)</th>
<th align="right">sd (M3)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">-</td>
<td align="right">-0.23</td>
<td align="right">0.06</td>
<td align="right">-0.25</td>
<td align="right">0.06</td>
<td align="right">-0.01</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td align="left">I==0 &amp; D==1</td>
<td align="right">-0.44</td>
<td align="right">0.07</td>
<td align="right">-0.50</td>
<td align="right">0.08</td>
<td align="right">-0.51</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td align="left">I==0 &amp; M==0 &amp; D==1</td>
<td align="right">-0.48</td>
<td align="right">0.10</td>
<td align="right">-0.41</td>
<td align="right">0.11</td>
<td align="right">-0.51</td>
<td align="right">0.03</td>
</tr>
</tbody>
</table>
<p>We now consider case-level analysis. For this setup, we consider negative effects of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span> <em>unlikely</em>, rather than impossible, and we consider null and positive effects somewhat likely. We refer to these priors as “quantitative priors” in the sense that they place a numerical value on beliefs rather than a logical restriction. Here, we set our prior on <span class="math inline">\(\theta^M\)</span> as: <span class="math inline">\(p(\theta^M=\theta^M_{10})=0.1\)</span>, <span class="math inline">\(p(\theta^M=\theta^M_{00})=0.3\)</span>, <span class="math inline">\(p(\theta^M=\theta^M_{11})=0.3\)</span>, and <span class="math inline">\(p(\theta^M=\theta^M_{01})=0.3\)</span> in comparison to the 0, 1/3,1/3,1/3 distribution. We show the results for the inferences given different findings in Tables <a href="evaluation.html#tab:HK8cases1quant">16.5</a> and <a href="evaluation.html#tab:HK8cases2quant">16.6</a>.</p>
<table>
<caption><span id="tab:HK8cases1quant">Table 16.5: </span> Four cases with low inequality and democratization. Question of interest: Was low inequality a cause of democracy? Table shows posterior beliefs for different data for 4 cases given information on <span class="math inline">\(M\)</span> or <span class="math inline">\(P\)</span>. Data from Haggard and Kaufman (2012).</caption>
<thead>
<tr class="header">
<th align="left">Given</th>
<th align="right">Restricted</th>
<th align="right">Unrestricted</th>
<th align="left">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">I == 0 &amp; D == 1</td>
<td align="right">0.438</td>
<td align="right">0.484</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">I == 0 &amp; D == 1 &amp; M == 0 &amp; P == 0</td>
<td align="right">0.667</td>
<td align="right">0.667</td>
<td align="left">Mexico (2000)</td>
</tr>
<tr class="odd">
<td align="left">I == 0 &amp; D == 1 &amp; M == 0 &amp; P == 1</td>
<td align="right">0.393</td>
<td align="right">0.393</td>
<td align="left">Taiwan (1996)</td>
</tr>
<tr class="even">
<td align="left">I == 0 &amp; D == 1 &amp; M == 1 &amp; P == 0</td>
<td align="right">0.571</td>
<td align="right">0.661</td>
<td align="left">Albania (1991)</td>
</tr>
<tr class="odd">
<td align="left">I == 0 &amp; D == 1 &amp; M == 1 &amp; P == 1</td>
<td align="right">0.263</td>
<td align="right">0.368</td>
<td align="left">Nicaragua (1984)</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:HK8cases2quant">Table 16.6: </span> Four cases with high inequality and democratization. Question of interest: Was high inequality a cause of democratization? Table shows posterior beliefs for different data for 4 cases given information on <span class="math inline">\(M\)</span> or <span class="math inline">\(P\)</span>. Data from Haggard and Kaufman (2012).</caption>
<thead>
<tr class="header">
<th align="left">Given</th>
<th align="right">Restricted</th>
<th align="right">Unrestricted</th>
<th align="left">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">I == 1 &amp; D == 1</td>
<td align="right">0.128</td>
<td align="right">0.122</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">I == 1 &amp; D == 1 &amp; M == 0 &amp; P == 0</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="left">Mongolia (1990)</td>
</tr>
<tr class="odd">
<td align="left">I == 1 &amp; D == 1 &amp; M == 0 &amp; P == 1</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="left">Paraguay (1989)</td>
</tr>
<tr class="even">
<td align="left">I == 1 &amp; D == 1 &amp; M == 1 &amp; P == 0</td>
<td align="right">0.250</td>
<td align="right">0.250</td>
<td align="left">Sierra Leone (1996)</td>
</tr>
<tr class="odd">
<td align="left">I == 1 &amp; D == 1 &amp; M == 1 &amp; P == 1</td>
<td align="right">0.107</td>
<td align="right">0.107</td>
<td align="left">Malawi (1994)</td>
</tr>
</tbody>
</table>
<p>The results differ in various modest ways. In the case in which <span class="math inline">\(I=D=1\)</span> conditional inferences are unaffected by the assumption on the effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span>. The reason is that since we still maintain a monotonicity assumption for the direct effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span> the only question is whether there was an indirect effect. Since we maintain the assumption of a monotonic effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(D\)</span> we know that there was no (indirect) effect if <span class="math inline">\(M\)</span> were 0. If however <span class="math inline">\(M\)</span> were 1 then <span class="math inline">\(I\)</span> did not have anegative effect on <span class="math inline">\(M\)</span> and teh only question is whether <span class="math inline">\(M=1\)</span> because of <span class="math inline">\(I\)</span> or independent of it — which depends only on the relative size ot <span class="math inline">\(\theta^M_{11}\)</span> and <span class="math inline">\(\theta^M_{01}\)</span>.</p>
<p>There are bigger differences when we are looking for negative effects of inequality, but even in this case the ordering of inferences does not change. As before in cases where <span class="math inline">\(M=0\)</span>, the monotinicity of of M in D is not relevant since htere is no question of a negative effect anyhow. However if <span class="math inline">\(M=1\)</span> then it is possible that <span class="math inline">\(I=0\)</span> caused <span class="math inline">\(D=1\)</span> via mobilization in the model that allows non monotonicity and so we put more weight on the possibility that <span class="math inline">\(I=0\)</span> was the cause.</p>
<p>We see these differences most clearly in the cases of Albania (as compared to Mexico) and Nicaragua (as compared to Taiwan). Under priors fully constrained to monotonic causal effects, we saw that the mediator clue, <span class="math inline">\(M\)</span>, made only a small difference to our inferences. However, if we allow for a negative effect of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span>, even while believing it to be unlikely, observing mobilization in Albania and Nicaragua makes us substantially more confident that inequality mattered, and differentiates our conclusions about these cases more sharply from our conclusions about Mexico and Taiwan, respectively.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-gabry2019visualization">
<p>Gabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. 2019. “Visualization in Bayesian Workflow.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> 182 (2): 389–402.</p>
</div>
<div id="ref-parsons2001qualitative">
<p>Parsons, Simon. 2001. <em>Qualitative Methods for Reasoning Under Uncertainty</em>. Vol. 13. Mit Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="82">
<li id="fn82"><p>Specifically, the data-generating model is <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow X\)</span>, with no effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> and thus no indirect effect, and no negative effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, and an otherwise flat parameter space.<a href="evaluation.html#fnref82" class="footnote-back">↩︎</a></p></li>
<li id="fn83"><p>Note that the “true” model here involves restrictions on nodal types (no <span class="math inline">\(X \rightarrow M\)</span> effects and no negative <span class="math inline">\(X \rightarrow Y\)</span> effects) while the analysis models are both unrestricted.<a href="evaluation.html#fnref83" class="footnote-back">↩︎</a></p></li>
<li id="fn84"><p>In applying the Markov condition, we also need to take into account any unobserved confounding. For instance, suppose that there was an unobserved confounder of the relationship between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> in the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. Then we would <em>not</em> expect <span class="math inline">\(Y\)</span> to be independent of <span class="math inline">\(X\)</span> conditional on <span class="math inline">\(M\)</span>. Intuitively, the data pattern we described could be consistent with such a model in which on average <span class="math inline">\(X\)</span> does not cause <span class="math inline">\(M\)</span> but still <em>in those cases in which <span class="math inline">\(X=M\)</span></em> we have <span class="math inline">\(Y=X\)</span>. Another way to think about this is that <span class="math inline">\(M\)</span> now acts as a collider between <span class="math inline">\(X\)</span> and another unobserved cause of <span class="math inline">\(Y\)</span>; so conditioning on <span class="math inline">\(M\)</span> introduces a correlation between <span class="math inline">\(X\)</span> and this unobserved cause, and thus between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<a href="evaluation.html#fnref84" class="footnote-back">↩︎</a></p></li>
<li id="fn85"><p>Tools in the <code>bayesplot</code> package can be used to show how typical the data we observe is for different models<a href="evaluation.html#fnref85" class="footnote-back">↩︎</a></p></li>
<li id="fn86"><p>Increasing weight on <span class="math inline">\(\lambda^Y_{10}\)</span> is drawn equally from <span class="math inline">\(\lambda^Y_{00}\)</span>, <span class="math inline">\(\lambda^Y_{11}\)</span>, and <span class="math inline">\(\lambda^Y_{10}\)</span>, with the first two of these three representing null effects.<a href="evaluation.html#fnref86" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="justifying-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="final-words.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
