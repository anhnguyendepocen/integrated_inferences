<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Integrated inferences | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Integrated inferences | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Integrated inferences | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ptapp.html"/>
<link rel="next" href="mixingapp.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#counterfactualmodel"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.3</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.3.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.3.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.3.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a><ul>
<li class="chapter" data-level="3.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="3.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="3.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>4</b> Theories as causal models</a><ul>
<li class="chapter" data-level="4.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>4.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="4.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>4.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="4.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>4.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="4.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>4.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>4.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="4.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>4.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="4.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>4.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>4.4</b> Conclusion</a><ul>
<li class="chapter" data-level="4.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>4.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>4.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="4.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>4.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="4.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>4.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>5</b> Causal Queries</a><ul>
<li class="chapter" data-level="5.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>5.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="5.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>5.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="5.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>5.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="5.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>5.4</b> Average causal effects</a></li>
<li class="chapter" data-level="5.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>5.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>6</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="6.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>6.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>6.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="6.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>6.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="6.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>6.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="6.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>6.1.4</b> Moments</a></li>
<li class="chapter" data-level="6.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>6.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>6.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="6.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>6.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="6.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>6.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>6.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="6.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>6.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="6.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>6.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="6.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>6.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="7" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>7</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="7.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>7.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>7.1.1</b> The intuition</a></li>
<li class="chapter" data-level="7.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>7.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="7.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>7.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pt.html"><a href="pt.html#mapping-from-models-to-classic-qualitative-tests"><i class="fa fa-check"></i><b>7.2</b> Mapping from models to classic qualitative tests</a></li>
<li class="chapter" data-level="7.3" data-path="pt.html"><a href="pt.html#principles-of-learning"><i class="fa fa-check"></i><b>7.3</b> Principles of learning</a><ul>
<li class="chapter" data-level="7.3.1" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>7.3.1</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="7.3.2" data-path="pt.html"><a href="pt.html#learning-requires-uncertainty"><i class="fa fa-check"></i><b>7.3.2</b> Learning requires uncertainty</a></li>
<li class="chapter" data-level="7.3.3" data-path="pt.html"><a href="pt.html#multiple-ways-for-queries-to-be-satisfied"><i class="fa fa-check"></i><b>7.3.3</b> Multiple ways for queries to be satisfied</a></li>
<li class="chapter" data-level="7.3.4" data-path="pt.html"><a href="pt.html#beware-of-highly-unlikely-queries"><i class="fa fa-check"></i><b>7.3.4</b> Beware of highly unlikely queries</a></li>
<li class="chapter" data-level="7.3.5" data-path="pt.html"><a href="pt.html#population-level-uncertainty-does-not-alter-case-level-causal-inference"><i class="fa fa-check"></i><b>7.3.5</b> Population-level uncertainty does not alter case-level causal inference</a></li>
<li class="chapter" data-level="7.3.6" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>7.3.6</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="7.3.7" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>7.3.7</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>8</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="8.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>8.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="8.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>8.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>8.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>8.3</b> Results</a></li>
<li class="chapter" data-level="8.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>8.4</b> Pathways</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>8.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="8.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>8.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>8.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="8.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>8.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>9</b> Integrated inferences</a><ul>
<li class="chapter" data-level="9.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>9.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="9.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>9.2</b> General procedure</a><ul>
<li class="chapter" data-level="9.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>9.2.1</b> Estimation</a></li>
<li class="chapter" data-level="9.2.2" data-path="mixing.html"><a href="mixing.html#query"><i class="fa fa-check"></i><b>9.2.2</b> Query</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>9.3</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixing.html"><a href="mixing.html#chain-model"><i class="fa fa-check"></i><b>9.3.1</b> Chain model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>9.4</b> Considerations</a><ul>
<li class="chapter" data-level="9.4.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>9.4.1</b> The identification problem</a></li>
<li class="chapter" data-level="9.4.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>9.4.2</b> Continuous data</a></li>
<li class="chapter" data-level="9.4.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>9.4.3</b> Measurement error</a></li>
<li class="chapter" data-level="9.4.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>9.4.4</b> Spillovers</a></li>
<li class="chapter" data-level="9.4.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>9.4.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="9.4.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>9.4.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="mixing.html"><a href="mixing.html#rules-of-thumb-for-reasoning-about-learning"><i class="fa fa-check"></i><b>9.5</b> Rules of thumb for reasoning about learning</a></li>
<li class="chapter" data-level="9.6" data-path="mixing.html"><a href="mixing.html#the-dag-can-be-enough-when-n-1"><i class="fa fa-check"></i><b>9.6</b> The DAG can be enough when <span class="math inline">\(N &gt; 1\)</span></a></li>
<li class="chapter" data-level="9.7" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>9.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>10</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="10.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>10.1</b> A trained model</a></li>
<li class="chapter" data-level="10.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>10.3</b> Inference</a><ul>
<li class="chapter" data-level="10.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>10.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="10.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>10.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="mixingapp.html"><a href="mixingapp.html#exercises"><i class="fa fa-check"></i><b>10.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>11</b> Mixing models</a><ul>
<li class="chapter" data-level="11.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>11.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="11.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>11.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="11.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>11.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="11.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>11.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="12" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>12</b> Elements of Design</a><ul>
<li class="chapter" data-level="12.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>12.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="12.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>12.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>12.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="12.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>12.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="12.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration"><i class="fa fa-check"></i><b>12.2.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>12.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>13</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>13.1</b> Core logic</a></li>
<li class="chapter" data-level="13.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>13.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="13.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>13.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="13.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>13.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="13.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>13.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>13.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="13.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>13.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Mixed methods data strategies</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-strategies"><i class="fa fa-check"></i><b>14.1</b> Case selection strategies</a><ul>
<li class="chapter" data-level="14.1.1" data-path="caseselection.html"><a href="caseselection.html#no-general-rules"><i class="fa fa-check"></i><b>14.1.1</b> No general rules</a></li>
<li class="chapter" data-level="14.1.2" data-path="caseselection.html"><a href="caseselection.html#specific-case-walk-through"><i class="fa fa-check"></i><b>14.1.2</b> Specific case walk through</a></li>
<li class="chapter" data-level="14.1.3" data-path="caseselection.html"><a href="caseselection.html#case-selection-from-causal-models-a-simulation-based-approach"><i class="fa fa-check"></i><b>14.1.3</b> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#wide-or-deep"><i class="fa fa-check"></i><b>14.2</b> Wide or Deep</a><ul>
<li class="chapter" data-level="14.2.1" data-path="caseselection.html"><a href="caseselection.html#walk-through-of-a-simple-comparison"><i class="fa fa-check"></i><b>14.2.1</b> Walk-through of a simple comparison</a></li>
<li class="chapter" data-level="14.2.2" data-path="caseselection.html"><a href="caseselection.html#results-from-simulations"><i class="fa fa-check"></i><b>14.2.2</b> Results from simulations</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.3</b> Principles</a></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying.html"><a href="justifying.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying.html"><a href="justifying.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying.html"><a href="justifying.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying.html"><a href="justifying.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying.html"><a href="justifying.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying.html"><a href="justifying.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying.html"><a href="justifying.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
<li class="chapter" data-level="15.5" data-path="justifying.html"><a href="justifying.html#exercise"><i class="fa fa-check"></i><b>15.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#the-benefits"><i class="fa fa-check"></i><b>17.1</b> The benefits</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#the-worries"><i class="fa fa-check"></i><b>17.2</b> The worries</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#the-future"><i class="fa fa-check"></i><b>17.3</b> The future</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixing" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Integrated inferences</h1>
<!-- Lots of this likely to change with integration with DAGs. -->
<div class="headerbox">
<div class="center">

</div>
<p>We extend the analysis of Chapter <a href="pt.html#pt">7</a> to cases with population data. In these cases we get to learn about the distribution of causal effects and are able to update the models we use for case level inference.</p>
</div>
<p><br></p>
<p>The main goal of this chapter is to generalize the model developed in Chapter <a href="pt.html#pt">7</a> to research situations in which we have data on multiple cases.</p>
<p>We start however with a conceptual point: the structure introduced in Chapter 6 for single case analysis can be used <em>as is</em> for multi-case analysis. Thus the conceptual work for mixed methods inference from models has been done already. Our goal here is more technical—how to exploit assumptions regarding independence across cases to generate simpler models causal processes that affect many units. As we do so we provide microfoundations for the models in Chapter 6 (as with those in <span class="citation">Humphreys and Jacobs (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>) with the probative value of clues deriverable from a causal structure and data.</p>
<div id="theres-only-ever-one-case" class="section level2">
<h2><span class="header-section-number">9.1</span> There’s only ever one case</h2>
<p>Conceptualized correctly, there is no deep difference between the logic of inference used in single case and many case studies. The reason is not, as <span class="citation">King, Keohane, and Verba (<a href="#ref-king1994designing" role="doc-biblioref">1994</a>)</span> suggest, that all causal inference is fundamentally correlational, even in seemingly single case studies. Nor is the point that single “case studies” can be disaggregated into many cases. The intuition, we think, really runs in the opposite direction: fundamentally, model-based inference always involves comparing <em>a</em> pattern of data with the logic of the model. Studies with multiple cases can be conceptualized as single-case studies: the drawing of inferences from a single <em>collection</em> of clues.</p>
<p>In practice, when we move from a causal model with one observation to a causal model with multiple observations, we can use the structure we introduced in Chapter 6 but simply replace nodes that have a single value (i.e., scalars) with nodes containing multiple values (i.e., vectors). We then make inferences about the relations between vectors from seeing the values of those vectors, or other vectors that serve as clues.</p>
<p>To illustrate, consider the following situation. There are two units studied, drawn from some population, a binary treatment <span class="math inline">\(X\)</span> is assigned independently with probability .5 to each case; an outcome <span class="math inline">\(Y\)</span> along with clue variable <span class="math inline">\(K\)</span> is observable. We suppose <span class="math inline">\(X\)</span> can affect <span class="math inline">\(Y\)</span> and in addition there is a background, unobserved, variable <span class="math inline">\(\theta\)</span> (causal type) that takes on values in <span class="math inline">\(\{a,b,c,d\}\)</span>, that affects both <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span> (we interpret <span class="math inline">\(\{a,b,c,d\}\)</span> as introduced in section <a href="models.html#counterfactualmodel">2.1</a>). In particular we suppose that in any given case <span class="math inline">\(K=1\)</span> whenever <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K=1\)</span> with a 50% probability otherwise. Thus, <span class="math inline">\(K\)</span> is informative about a unit’s causal type.</p>
<p>Note that we have described the problem at the unit level. However we can redescribe it at the population level thus:</p>
<ul>
<li>a treatment vector <span class="math inline">\(X\)</span> can take on one of four values, <span class="math inline">\((0,0), (0,1), (1,0), (1,1)\)</span> with equal probability (or more strictly: as determined by <span class="math inline">\(\theta\)</span>).</li>
<li><span class="math inline">\(\theta\)</span> is also a vector with two elements that can take on one of 16 values <span class="math inline">\((a,a), (a,b),\dots (d,d)\)</span> as determined by <span class="math inline">\(\lambda_\theta\)</span></li>
<li><span class="math inline">\(K\)</span> has the same domain as <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and element <span class="math inline">\(K[j]=1\)</span> if <span class="math inline">\(\theta[j]=b\)</span>.</li>
<li><span class="math inline">\(Y\)</span> is a vector that reflects the elements of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(X\)</span> in the obvious way (e.g <span class="math inline">\(X=(0,0), \theta=(a,b)\)</span> generates outcomes <span class="math inline">\(Y=(1,0)\)</span>.</li>
</ul>
<p>Say we are interested in the Sample Average Treatment Effect. We will consider three operations, one in which both units have <span class="math inline">\(X\)</span> forced to 0 and two in which one unit has <span class="math inline">\(X\)</span> set to 0 and the other has <span class="math inline">\(X\)</span> set to 1. Thus we are interested in the average effect of changing one unit to treatment while the other is held in control. Note also that before our estimands were binary—of the form: is it a <span class="math inline">\(b\)</span> type?–and our answer was a probability; now our estimand is categorical and our answer is a distribution (what is the probability the SATE is 0, what is the probability the SATE is .5, etc…)</p>
<p>We now have a representation that maps directly onto the case level structures used in Chapters 6 and 7 and can use the tools introduced there to analyze this seemingly multi-case study.</p>
<p>Inference…</p>
<p>Independence…
You can see that that representing node values in vector forms like this allows for more general vector-level mappings that could involve SUTVA violations: for instance perhaps <span class="math inline">\(Y_i=1\)</span> if <em>either</em> <span class="math inline">\(X_1\)</span> or <span class="math inline">\(X_2 = 1\)</span>.
<!-- In the below we examine a situation in which we consider the value of observing $K$ on one case --- in this set up this is equivalent to observing part of the vector $K$ and making inferences on the full vector $\theta$. --></p>
</div>
<div id="general-procedure" class="section level2">
<h2><span class="header-section-number">9.2</span> General procedure</h2>
<p>In practice however thinking of nodes as capturing the outcomes on all units leads to enormous complexity. For example an exogeneous variable <span class="math inline">\(X\)</span> which takes on values of 0 or 1 at random for 10 units has <span class="math inline">\(2^{10}\)</span> types in this conceptualization, rather than just two when thought of at the case level.</p>
<p>We reduce complexity however by thinking of models as operating on units and learning about models by observing <em>multiple</em> realizations of processes covered by the model, rather than just one. Thinking about it this way is not free however as it requires invoking independence assumptions — that outcomes in two units do not depend on each other. If we cannot stand by that assumption, then we have to build independence failures into our models.</p>
<p>Taking this step the procedure we now use in the mixed methods works as follows:</p>
<p><strong>INTROUDCE CONCEPTS AND THEN ILLUSTRATE</strong></p>
<p><strong>A DAG</strong>. As for process tracing, we begin with a graphical causal model specifying possible causal linkages between nodes. Our “chain” model for instance has DAG: <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>.</p>
<p><strong>Nodal types</strong>. Just as in process tracing, the DAG and variable ranges define the set of possible nodal types in the model—the possible ways in which each variable is assigned (if exogenous) or determined by its parents (if endogenous).</p>
<p><strong>Causal types</strong>. And, again, a full set of nodal types gives rise to a full set of causal types, encompassing all possible combinations of nodal types across all nodes in the model.</p>
<p><strong>Priors</strong>. The first difference between single- and multiple-case inference lies in how we set priors on causal types. In process tracing, we set parameter values for each nodal type (or conditional nodal type, for unobserved confounding). Our parameters—e.g., <span class="math inline">\(\lambda^X_0\)</span>, <span class="math inline">\(\lambda^Y_{01}\)</span>—represent our beliefs about the proportions of these types in the population. When we only observe a single data type—data on a single case—we do not have sufficient information to learn about the distribution of types in the population. And so we treat these population-level beliefs as fixed parameters, rather than priors that we update on. (What we update on, in process tracing, is our priors on whether a <em>given case</em> is of a particular type or set of types.) Likewise, uncertainty about those population-level parameters has no effect on our inferences for a single case. When we get to observe data on multiple cases, however, we have the opportunity to learn <em>both</em> about the cases at hand <em>and</em> about the population. Moreover, our level of uncertainty about population-level parameters will shape our inferences. We thus want our parameters (the <span class="math inline">\(\lambda\)</span>’s) to be drawn from a prior <em>distribution</em> — a distribution that expresses our uncertainty and over which we can update once we see the data.</p>
<p>While different distributions may be appropriate to the task in general, uncertainty over proportions (of cases, events, etc.) falling into a set of discrete categories is usefully described by a Dirichlet distribution, as discussed in Chapter <a href="bayeschapter.html#bayeschapter">6</a>. The parameters of a Dirichlet distribution (the <span class="math inline">\(\alpha\)</span>’s) can be thought of as conveying both the relative expected proportions in each category and our degree of uncertainty.</p>
<p><strong>ADD MULTILEVEL GRAPH</strong></p>
<div class="headerbox">
<div class="center">

</div>
<p><strong>Box: Setting priors</strong></p>
<p>For a model with no unobserved confounding, setting priors requires specifying a prior distribution for each set of nodal types. Parameters are provided as vectors of positive numbers with one number for each nodal type. These numbers correspond to the <span class="math inline">\(\alpha\)</span> parameters of a Dirichlet distribution. The relative size of each number governs the the relative probability of each nodal type. The absolute sizes govern the certainty over the types.</p>
<p>To wit. For a simple <span class="math inline">\(X \rightarrow Y\)</span> model, we have two parameter sets: one for <span class="math inline">\(X\)</span>’s types and one for <span class="math inline">\(Y\)</span>’s types.</p>
<p>For <span class="math inline">\(X\)</span>’s types, we specify <span class="math inline">\(\alpha^X_0\)</span> and <span class="math inline">\(\alpha^X_1\)</span>, corresponding to the nodal types <span class="math inline">\(\theta^X_0\)</span> and <span class="math inline">\(\theta^X_1\)</span>, respectively. A distribution of the form (<span class="math inline">\(\alpha^X_0=100, \alpha^X_1=100)\)</span> implies a lot of confidence that a given unit has <span class="math inline">\(X=1\)</span> with probability .5. A distribution of the form (<span class="math inline">\(\alpha^X_0=.1, \alpha^X_1=.1)\)</span> implies that either <span class="math inline">\(X=1\)</span> with a high probability (for all units) or <span class="math inline">\(X=0\)</span> with a low probability (for all units), but we are not sure which.</p>
<p>For <span class="math inline">\(Y\)</span>’s types, we specify <span class="math inline">\(\alpha^Y_{00}\)</span>, <span class="math inline">\(\alpha^Y_{10}\)</span>, <span class="math inline">\(\alpha^Y_{01}\)</span>, and <span class="math inline">\(\alpha^Y_{11}\)</span>, corresponding to the nodal types <span class="math inline">\(\theta^Y_{00}\)</span>, etc. So, for instance:</p>
<ul>
<li><span class="math inline">\(\alpha^Y_{00}=1\)</span>, <span class="math inline">\(\alpha^Y_{10}=1\)</span>, <span class="math inline">\(\alpha^Y_{01}=1\)</span>, and <span class="math inline">\(\alpha^Y_{11}=1\)</span> yields a uniform distribution in which all share allocations of types in the population are equally likely.</li>
<li><span class="math inline">\(\alpha^Y_{00}=3\)</span>, <span class="math inline">\(\alpha^Y_{10}=3\)</span>, <span class="math inline">\(\alpha^Y_{01}=3\)</span>, and <span class="math inline">\(\alpha^Y_{11}=3\)</span> puts more weight on share allocations in which the shares are relatively equal.</li>
<li><span class="math inline">\(\alpha^Y_{00}=5\)</span>, <span class="math inline">\(\alpha^Y_{10}=5\)</span>, <span class="math inline">\(\alpha^Y_{01}=10\)</span>, and <span class="math inline">\(\alpha^Y_{11}=5\)</span> puts greater weight positive causal effects than the other three types.</li>
</ul>
</div>
<p><strong>Unobserved confounding.</strong> When there is unobserved confounding, we need parameter sets that allow for a joint distribution over nodal types. Thus, if we believe the likelihood of <span class="math inline">\(X=1\)</span> is correlated with whether or not <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>, we will need two parameter sets (rather than one) for <span class="math inline">\(X\)</span>: one for <span class="math inline">\(X\)</span>’s value when <span class="math inline">\(\theta^Y = \theta^Y_{01}\)</span> and one for <span class="math inline">\(X\)</span>’s value when <span class="math inline">\(\theta^Y \neq \theta^Y_{01}\)</span>. For each of these parameter sets, we specify two <span class="math inline">\(\alpha\)</span> parameters representing our beliefs about <span class="math inline">\(X\)</span>’s assignment. We can draw <span class="math inline">\(\lambda\)</span> values for these conditional nodal types from the resulting Dirichlet distributions, as above, and can then calculate causal type probabilities in the usual way.</p>
<p><strong>Distributions over causal types.</strong> For a model with any number of nodes, we can then imagine a draw of one <span class="math inline">\(\lambda^j\)</span> from its prior distribution for each node, giving a full <span class="math inline">\(\lambda\)</span> vector. Any particular <span class="math inline">\(\lambda\)</span> vector, in turn, implies a probability distribution over <em>causal</em> types (<span class="math inline">\(\theta\)</span>). With the help of a parameter matrix (mapping from parameters to causal types), we can then, just as with process tracing, calculate the prior probability that a case is of any particular causal type, given the parameter (<span class="math inline">\(\lambda\)</span>) values we have drawn. Implicitly, then, our prior distribution over <span class="math inline">\(\lambda\)</span> gives rise in turn to a prior distribution over the causal type shares in the population.</p>
<p><strong>Event probabilities</strong>. We now need to build a likelihood function that can map from beliefs about the world to data: i.e., that can tell us how likely we are to see a given data pattern—across multiple cases—under a given distribution of causal types in the population. The first step in building the likelihood function is to calculate event probabilities: the probability of observing a case of a particular data type given a particular population-level distribution of causal type shares (that is, given a <span class="math inline">\(\lambda\)</span> draw). We assume, for now, that we deploy the same data strategy for each case, collecting data on all nodes.</p>
<p>We denote an event probability for a given data pattern for variables <span class="math inline">\(X, Y, \dots\)</span> as <span class="math inline">\(w_{x, y, \dots}\)</span>. For instance, the probability of observing <span class="math inline">\(X=0, Y=1\)</span> in a case (given <span class="math inline">\(\lambda\)</span>) is <span class="math inline">\(w_{01}\)</span>. An ambiguity matrix, just as for process tracing, tells us which causal types are consistent with a particular data type, as observed for a single case. To calculate the probability of the data given a distribution of causal types, we simply add together the probabilities of all of the causal types with which it is consistent.</p>
<p>See, for instance, the parameter matrix and the ambiguity matrix in Tables <a href="mixing.html#tab:parammmatrixmix">9.1</a> and <a href="mixing.html#tab:ambigmatrixmix">9.2</a>. We have indicated a single draw of <span class="math inline">\(\lambda\)</span> values (population type shares) in the parameter matrix, and these have been used to calculate the priors on causal types provided in the ambiguity matrix. Let’s now calculate the event probability for each data type. Starting with <span class="math inline">\(X=0, Y=0\)</span>, we can read off the ambiguity matrix that the consistent causal types are (<span class="math inline">\(\theta^X_0, \theta^Y_{00}\)</span>) and (<span class="math inline">\(\theta^X_0, \theta^Y_{01}\)</span>). The event probability, <span class="math inline">\(w_{00}\)</span>, is then given by adding together the probabilities of these two causal types, <span class="math inline">\(0.1 + 0.2 = 0.3\)</span>. All four event probabilities, for the four data types, are then calculated in the same way:</p>
<ul>
<li><span class="math inline">\(w_{00} = 0.1 + 0.2 = 0.3\)</span></li>
<li><span class="math inline">\(w_{10} = 0.1 + 0.1 = 0.2\)</span></li>
<li><span class="math inline">\(w_{01} = 0.1 + 0.2 = 0.2\)</span></li>
<li><span class="math inline">\(w_{11} = 0.2 + 0.1 = 0.3\)</span></li>
</ul>
<p>As any case must be of one and only one data type, the full set of event probabilities for a single <span class="math inline">\(\lambda\)</span> draw must naturally sum to <span class="math inline">\(1\)</span>.</p>
<table style="width:100%;">
<caption><span id="tab:parammmatrixmix">Table 9.1: </span>A parameter matrix for a simple <span class="math inline">\(X ightarrow Y\)</span> model (with no unobserved confounding), indicating a single draw of <span class="math inline">\(\lambda\)</span> values from the prior distribution.</caption>
<colgroup>
<col width="2%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="4%" />
<col width="11%" />
<col width="11%" />
<col width="9%" />
<col width="7%" />
<col width="10%" />
<col width="6%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">X0.Y00</th>
<th align="right">X1.Y00</th>
<th align="right">X0.Y10</th>
<th align="right">X1.Y10</th>
<th align="right">X0.Y01</th>
<th align="right">X1.Y01</th>
<th align="right">X0.Y11</th>
<th align="right">X1.Y11</th>
<th align="left">Shares.param_names</th>
<th align="right">Shares.param_value</th>
<th align="left">Shares.param_set</th>
<th align="left">Shares.node</th>
<th align="left">Shares.nodal_type</th>
<th align="right">Shares.gen</th>
<th align="right">Shares.priors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X.0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">X.0</td>
<td align="right">0.4</td>
<td align="left">X</td>
<td align="left">X</td>
<td align="left">0</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">X.1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">X.1</td>
<td align="right">0.6</td>
<td align="left">X</td>
<td align="left">X</td>
<td align="left">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Y.00</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">Y.00</td>
<td align="right">0.3</td>
<td align="left">Y</td>
<td align="left">Y</td>
<td align="left">00</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Y.10</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">Y.10</td>
<td align="right">0.2</td>
<td align="left">Y</td>
<td align="left">Y</td>
<td align="left">10</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Y.01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">Y.01</td>
<td align="right">0.2</td>
<td align="left">Y</td>
<td align="left">Y</td>
<td align="left">01</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Y.11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Y.11</td>
<td align="right">0.3</td>
<td align="left">Y</td>
<td align="left">Y</td>
<td align="left">11</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:ambigmatrixmix">Table 9.2: </span>An ambiguity matrix for a simple <span class="math inline">\(X ightarrow Y\)</span> model (with no unobserved confounding), showing the priors over causal types arising from a single draw of <span class="math inline">\(\lambda\)</span> from its prior distribution.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">X0Y0</th>
<th align="right">X1Y0</th>
<th align="right">X0Y1</th>
<th align="right">X1Y1</th>
<th align="right">prior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X0Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td align="left">X1Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.18</td>
</tr>
<tr class="odd">
<td align="left">X0Y10</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td align="left">X1Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td align="left">X0Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td align="left">X1Y01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td align="left">X0Y11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td align="left">X1Y11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.18</td>
</tr>
</tbody>
</table>
<p>For a case in which only partial data are observed, we follow the same basic logic as with partial process-tracing data. We retain all columns (data types) in the ambiguity matrix that are consistent with the partial data. So, for instance, if we observe only <span class="math inline">\(Y=1\)</span>, we would retain both the <span class="math inline">\(X=0, Y=1\)</span> column and the <span class="math inline">\(X=1, Y=1\)</span> column. We then calculate the event probability by summing causal-type probabilities for all causal types that could have produced these partial data — i.e., all those with a <span class="math inline">\(1\)</span> in <em>either</em> column.</p>
<p><strong>Likelihood</strong>. Now that we know the probability of observing each data pattern in a <em>single</em> case given <span class="math inline">\(\lambda\)</span>, we can use these event probabilities to aggregate up to the likelihood of observing a data pattern across multiple cases (given <span class="math inline">\(\lambda\)</span>). With discrete variables, we can think of a given multiple-case data pattern simply as a set of counts: for, say, <span class="math inline">\(X, Y\)</span> data, we will observe a certain number of <span class="math inline">\(X=0, Y=0\)</span> cases (<span class="math inline">\(n_{00}\)</span>), a certain number of <span class="math inline">\(X=1, Y=0\)</span> cases (<span class="math inline">\(n_{10}\)</span>), a certain number of <span class="math inline">\(X=0, Y=1\)</span> cases (<span class="math inline">\(n_{01}\)</span>), and a certain number of <span class="math inline">\(X=1, Y=1\)</span> cases (<span class="math inline">\(n_{11}\)</span>). A data pattern, given a particular set of variables observed (a search strategy), thus has a multinomial distribution. The likelihood of a data pattern under a given search strategy, in turn, takes the form of a multinomial distribution conditional on the number of cases observed and the event probabilities for each data type, given a <span class="math inline">\(\lambda\)</span> draw.</p>
<p>Let us assume now that we have a 3-node model, with <span class="math inline">\(X, Y\)</span>, and <span class="math inline">\(M\)</span> all binary. Let <span class="math inline">\(n_{XYK}\)</span> denote an 8-element vector recording the number of cases in a sample displaying each possible combination of <span class="math inline">\(X,Y,K\)</span> data, thus: <span class="math inline">\(n_{XYM}=(n_{000},n_{001},n_{100},\dots ,n_{111})\)</span>. The elements of <span class="math inline">\(n_{XYK}\)</span> sum to <span class="math inline">\(n\)</span>, the total number of cases studied. Likewise, let the event probabilities for data types given <span class="math inline">\(\lambda\)</span> be registered in a vector, <span class="math inline">\(w_{XYK}=(w_{000},w_{001},w_{100},\dots ,w_{111})\)</span>. The likelihood of a data pattern, <span class="math inline">\(\mathcal D\)</span> is then:</p>
<p><span class="math display">\[
\Pr(\mathcal{D}|\lambda) = 
  \text{Multinom}\left(n_{XYK}|n, w_{XYK}\right)  \\
\]</span>
In other words, the likelihood of observing a particular data pattern given <span class="math inline">\(\lambda\)</span> is given by the corresponding value of the multinomial distribution given the event probabilities.</p>
<p>What if we have a mixture of search strategies? Suppose, for instance, that we have collected <span class="math inline">\(X,Y\)</span> data on a set of cases, and that we have additionally collected data on <span class="math inline">\(M\)</span> for a random subset of these. We can think of this as conducting quantitative analysis on a large sample and conducting in-depth process tracing on a subsample. We then can summarize our data in two vectors, the 8-element <span class="math inline">\(n_{XYM}\)</span> vector for the cases with process tracing, and a 4-element vector <span class="math inline">\(n_{XY*} = (n_{00*},n_{10*},n_{01*},n_{11*}\)</span> for the partial data on those cases with no process tracing. Likewise, we now have two sets of event probabilities: one for the cases with complete data, <span class="math inline">\(w_{XYM}\)</span>, and a 4-element vector for those with partial data, <span class="math inline">\(w_{XY*}\)</span>. Let <span class="math inline">\(n\)</span> denote the total number of cases examined, and <span class="math inline">\(k\)</span> the number for which we have data on <span class="math inline">\(K\)</span>.</p>
<p>Now, assuming that each observed case represents an independent, random draw from the population, we can form the likelihood function as a product of multinomial distributions:</p>
<p><span class="math display">\[
\Pr(\mathcal{D}|\theta) = 
  \text{Multinom}\left(n_{XY*}|n-k, w_{XY*}\right) \times \text{Multinom}\left(n_{XYK}|k, w_{XYK}\right)  \\
\]</span></p>
<!-- |     **Causal types** $\rightarrow$     | $\theta^X_0,\theta^Y_{00}$ | $\theta^X_1,\theta^Y_{00}$ | $\theta^X_0,\theta^Y_{10}$ | $\theta^X_1,\theta^Y_{10}$ | $\theta^X_0,\theta^Y_{01}$ | $\theta^X_1,\theta^Y_{01}$ | $\theta^X_0,\theta^Y_{11}$ | $\theta^X_1,\theta^Y_{11}$ | Parameter values (a draw from the prior) | -->
<!-- |:--------------------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:-----------------------------------------:| -->
<!-- | **Population parameters** $\downarrow$ |                            |                            |                            |                            |                            |                            |                            |                            |                                           | -->
<!-- |              $\lambda^X_0$             |              0             |              1             |              0             |              1             |              0             |              1             |              0             |              1             |                    0.4                    | -->
<!-- |              $\lambda^X_1$             |              1             |              0             |              1             |              0             |              1             |              0             |              1             |              0             |                    0.6                    | -->
<!-- |            $\lambda^Y_{00}$            |              1             |              1             |              0             |              0             |              0             |              0             |              0             |              0             |                    0.3                    | -->
<!-- |            $\lambda^Y_{10}$            |              0             |              0             |              1             |              1             |              0             |              0             |              0             |              0             |                    0.2                    | -->
<!-- |            $\lambda^Y_{01}$            |              0             |              0             |              0             |              0             |              1             |              1             |              0             |              0             |                    0.2                    | -->
<!-- |            $\lambda^Y_{11}$            |              0             |              0             |              0             |              0             |              0             |              0             |              1             |              1             |                    0.3                    | -->
<!-- Table: (\#tab:parammmatrixmix). A parameter matrix for a simple $X \rightarrow Y$ model (with no unobserved confounding), indicating a single draw of $\lambda$ values from the prior distribution. -->
<p>BOX</p>
<div id="likelihood-and-sampling" class="section level4">
<h4><span class="header-section-number">9.2.0.1</span> Likelihood and sampling</h4>
<p>Say a data strategy seeks data on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in 2 cases and seeks data on <span class="math inline">\(M\)</span> if ever <span class="math inline">\(X=Y=1\)</span>.</p>
<p>The probability of each data type is as given in table below:</p>
<table>
<colgroup>
<col width="25%" />
<col width="74%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X1M0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{11}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{00}+\lambda^Y_{01}) + \lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{10}+\lambda^Y_{11}) + \lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{01}+\lambda^Y_{11})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{00}+\lambda^Y_{01}) + \lambda^X_1(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
</tbody>
</table>
<p>The two observations can be thought of as a multinomial draw from these five event types.</p>
<p>Alternatively they can also be thought of as the product of a draw from a strategy in which a set of units is drawn with observations on <span class="math inline">\(X,Y\)</span> only and another set is drawn with observations on <span class="math inline">\(X, M, Y\)</span>.</p>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
<p>Say rather than conditioning <span class="math inline">\(X=Y=1\)</span> to examine <span class="math inline">\(M\)</span> one of the two cases were chosen at random to observe <span class="math inline">\(M\)</span> and it just so happend to be be a case with <span class="math inline">\(X=Y=1\)</span>:</p>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{00}+\lambda^Y_{01}) + 0.5\lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{10}+\lambda^Y_{11}) + 0.5\lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{01}+\lambda^Y_{11})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{00}+\lambda^Y_{01}) + 0.5\lambda^X_1(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{10}+\lambda^Y_{11}) + 0.5\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span> +</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X0M0Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01}))(\lambda^Y_{00}+\lambda^Y_{01})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0M1Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{11}+\lambda^M_{10}))(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="odd">
<td>…</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span></td>
</tr>
</tbody>
</table>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is now:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
</div>
<div id="estimation" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Estimation</h3>
<p>WRITE GENERAL APPROACH</p>
<p>WEITE BAYES RULE AND REFER BACK TO CHAPTER</p>
</div>
<div id="query" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Query</h3>
<p>Describe and illustrate</p>
<!-- ## Illustration  -->
<!-- Consider a generalization of the models introduced in Chapter 6 in which a treatment $X$ is a cause of both $K$ and $Y$, and outcome $Y$ is a product of both $X$ and $K$. Though $K$ is both a mediator and a moderator for the effect of $X$. There are now 16 nodal types for $Y$, 4 for $K$ and 2 for $X$, yielding 32 causal types. -->
<!-- To allow for the possibility of non-random selection of $X$ we will assume that the assignment probability for $X$ depends on $U^Y$. This is a feature shared also in the baseline model when we specify $\pi$ as a function of types $a$,$b$,$c$,$d$. -->
<!-- Our piors requires specifying: -->
<!-- 1. A distribution over the 15-dimensional simplex representing possible values of $\lambda^Y$--which in turn determine types $u^Y$. -->
<!-- 2. A distribution over the 3-dimensional vector representing possible values of $\lambda^K$,  which in turn determine types $u^K$. -->
<!-- The model is restricted in various ways. We assume now confounding in the assignemnt of $X$. Less obviously we implicitly assume that $K$ is independent of $\theta^Y$ conditional on $X$. -->
<!-- With these elements in hand, however, all we need now is to provide a mapping from these fundamental parameters to the parameters used in the baseline model to form the likelihood.  -->
<!-- The key transformation is the identification of causal types resulting from the 64 combinations of $\lambda^Y$ and $\lambda^K$. These are shown below. -->
<!-- TABLE TO SHOW CAUSAL TYPES -->
<!-- Consider the following matrices of values for $u_Y$ and $u_K$, where $\lambda_{pq}^{rs}$ is the probability that $u^Y = t_{pq}^{rs}$, meaning that $Y$ would take the value $p$ when $X=0, K=0$,  $q$ when $X=0, K=1$,  $r$ when $X=1, K=0$,  and $s$ when $X=1, K=1$. Similarly $\lambda_{w}^{z}$ is the probability that $u^K$ takes value  $t_{w}^{z}$  meaning that $K$ takes the value $w$ when $X=0$ and $z$ when $X=1$. -->
<!-- TABLE TO SHOW CONDITIONAL PROBABILITIES OF K GIVEN X=1 AND TYPE -->
<!-- These types are the *transformed parameters*; the probability of a type is just the sum of the probabilities of the fundamental types that compose it, formed by taking the product of the $\lambda^Y$ and $\lambda^K$ values marked in the rows and columns of  table \ref{tab:types}.  -->
<!-- Similarly $\phi_{tx}$ can be constructed as the probability of observing $K$ conditional on this type (again, sums of products of probabilities associated with cells in table  \ref{tab:types}). For instance, using the row and column indices in exponents (GIVE FULL LABELS) from table \ref{tab:types}: -->
<!-- $$\phi_{b1}=\frac{\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}{ -->
<!-- \lambda_K^1(\lambda_Y^3+\lambda_Y^4+\lambda_Y^7+\lambda_Y^8)+\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^3(\lambda_Y^3+\lambda_Y^4+\lambda_Y^11+\lambda_Y^{12})+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}$$ -->
<!-- With these transformed parameters in hand, the likelihood is exactly the same as that specified in the baseline model. -->
</div>
</div>
<div id="illustrated-inferences" class="section level2">
<h2><span class="header-section-number">9.3</span> Illustrated inferences</h2>
<div id="chain-model" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Chain model</h3>
<p>show table with columns:<br />
* 14 columns: 10 nodel types, high abcd 4
* no data,
* 1 data point on X=1 Y=1 only
* 1 data point on X=1 Y=1 M = 1
* 10 data point on X=1 Y=1 only
* 10 data point on X=1 Y=1 M = 1</p>
</div>
</div>
<div id="considerations" class="section level2">
<h2><span class="header-section-number">9.4</span> Considerations</h2>
<div id="the-identification-problem" class="section level3">
<h3><span class="header-section-number">9.4.1</span> The identification problem</h3>
<ul>
<li>Do you require identification to make progress</li>
<li>What do you learn if things are not identified</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="mixing.html#cb1-1"></a>model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X1 -&gt; M1 -&gt; Y &lt;- M2 &lt;- X2&quot;</span>)</span>
<span id="cb1-2"><a href="mixing.html#cb1-2"></a></span>
<span id="cb1-3"><a href="mixing.html#cb1-3"></a><span class="co"># restrict such that *only* M1 OR M2 could cause Y -- can we create a DD test? / achieve identification</span></span></code></pre></div>
</div>
<div id="continuous-data" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Continuous data</h3>
<p>We can similarly shift from binary to continuous variable values through an expansion of the causal types. Suppose that <span class="math inline">\(Y\)</span> can take on <span class="math inline">\(m\)</span> possible values. With <span class="math inline">\(k\)</span> explanatory variables, each taking on <span class="math inline">\(r\)</span> possible values, we then have <span class="math inline">\(m^{r^k}\)</span> causal types and, correspondingly, very many more elements in <span class="math inline">\(\phi\)</span>. Naturally, in such situations, researchers might want to reduce complexity by placing structure onto the possible patterns of causal effects and clue probabilities, such as assuming a monotonic function linking effect sizes and clue probabilities.</p>
</div>
<div id="measurement-error" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Measurement error</h3>
<p>Model:</p>
<p><span class="math display">\[X \rightarrow Y  \rightarrow Y_{\text{measured}} \leftarrow \text{bad coding}\]</span></p>
<ul>
<li>What if we are naive</li>
<li>What if we are aware of risks but don;t know how bad bad coding is</li>
<li>What if we observed bad coding in a subsample</li>
</ul>
<p>We have assumed no measurement error; in applications there could be considerable interest in measurement error. On one hand clue information may contain information about possible mismeasurement on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; on the other hand there might interest in whether measured clues adequately capture those features of a causal process that is thought to be measureable.</p>
<p>The probability of different types of measurement error can be included among the set of parameters of interest, with likelihood functions adjusted accordingly. Suppose, for instance, that with probability <span class="math inline">\(\epsilon\)</span> a <span class="math inline">\(Y=0\)</span> case is recorded as a <span class="math inline">\(Y=1\)</span> case (and vice versa). Then the event probability of observing an <span class="math inline">\(X=1\)</span>,<span class="math inline">\(Y=1\)</span> case, for example, is <span class="math inline">\(\epsilon \lambda_a \pi_a + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_c \pi_c + (1-\epsilon) \lambda_d \pi_d\)</span>. %If instead there were measurement error on <span class="math inline">\(X\)</span> but not on <span class="math inline">\(Y\)</span>, then the event probability would be: <span class="math inline">\(\epsilon \lambda_a (1-\pi_a) + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_d (1-\pi_d) + (1-\epsilon) \lambda_d \pi_d\)</span>.
Similar expressions can be derived for measurement error on <span class="math inline">\(X\)</span> or <span class="math inline">\(K\)</span>. Specifying the problem in this way allows us both to take account of measurement error and learn about it.</p>
</div>
<div id="spillovers" class="section level3">
<h3><span class="header-section-number">9.4.4</span> Spillovers</h3>
<p>Spillovers may also be addressed through an appropriate definition of causal types. For example a unit <span class="math inline">\(i\)</span> that is affected either by receiving treatment or via the treatment of a neighbor, <span class="math inline">\(j\)</span>, might have potential outcomes <span class="math inline">\(Y_i(X_i,X_j)=\max(X_i,X_j)\)</span> while another type that is not influenced by neighbor treatment status has <span class="math inline">\(Y_i(X_i,X_j)=\max(X_i)\)</span>. With such a set-up, relevant clue information might discriminate between units affected by spillovers and those unaffected.</p>
</div>
<div id="clustering-and-other-violations-of-independence" class="section level3">
<h3><span class="header-section-number">9.4.5</span> Clustering and other violations of independence</h3>
</div>
<div id="parameteric-models" class="section level3">
<h3><span class="header-section-number">9.4.6</span> Parameteric models</h3>
</div>
</div>
<div id="rules-of-thumb-for-reasoning-about-learning" class="section level2">
<h2><span class="header-section-number">9.5</span> Rules of thumb for reasoning about learning</h2>
<p>As we did in Chapter @(pt), we provide here some guidance in how to reason about the learning that arises from mixed data. We focus especially on ways in which learning from multiple cases differs from learning from a single case.</p>
<!-- AJ: We'd discussed this going here, but I think it would be better placed in a substantive chapter. This is where people will be more likely to look for it.  -->
<!-- 1. Learning requires uncertainty. And expected learning goes up as you become more uncertain about what you’ll find.  If your causal model puts a very high probability on X having a positive effect on M, and you already know X’s value, you should expect to learn very little from observing M since you’re very likely to see exactly the M value you expect given X. (Currently in Chap. 12)((And we want to make research design choices based on expected learning, not based on the mere possibility of learning: yes, our beliefs will shift if we look for M and find the unexpected value. But because that data-realization is highly unlikely, we expect the learning from observing M to be minimal.  -->
<!-- 2. Pure within-case (or n=1) learning requires informative priors about the nodes to be observed. For instance, in a chain model, where we want to go and observe M, it’s not enough to have an informative prior about the X->Y relationship. We need an informative prior about the X->M or M->Y link in order to learn from M. For instance, are positive X->M effects more common than negative ones? -->
</div>
<div id="the-dag-can-be-enough-when-n-1" class="section level2">
<h2><span class="header-section-number">9.6</span> The DAG can be enough when <span class="math inline">\(N &gt; 1\)</span></h2>
<p>In Chapter @(pt), we discussed the fact that a DAG by itself is insufficient to generate learning about causal effects from data on a single case; we also need prior beliefs about population-level shares of nodal types. When working with multiple cases, however, we <em>can</em> learn about causal effects when starting with nothing more than the DAG. In particular, it is sometimes possible to draw causal information from correlations across cases, given only the DAG.</p>
<p>For instance, in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, even if we have flat priors over <span class="math inline">\(M\)</span>’s nodal types, observing a correlation (or no correlation) between <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> across multiple cases provides information about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(M\)</span>. Simply, a stronger, positive (negative) <span class="math inline">\(X, M\)</span> correlation implies a stronger positive (negative) effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span>. In turn, a stronger <span class="math inline">\(X,M\)</span> correlation implies a stronger effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> since, under this model, that effect has to run through an effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span>.</p>
<p>What’s more, data from multiple cases can <em>provide</em> probative value for within-case inference. Suppose, for the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, that we start with flat priors over all nodal types. As discussed in Chapter @(pt), observing <span class="math inline">\(M\)</span> in a single case cannot be informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> in that case. If we have no idea of the direction of the intermediate causal effects, then we have no idea which value of <span class="math inline">\(M\)</span> is more consistent with an <span class="math inline">\(X \rightarrow M\)</span> effect or which an <span class="math inline">\(M \rightarrow Y\)</span> effect. But suppose that we first observe data on <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> for a group of cases and find a strong positive correlation between the two variables. We now update to a belief that any effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> is more likely to be positive than negative. Now, let’s say we look at one of our cases, in which <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span> and want to know if <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span>. Knowing now that any such effect would most likely have operated via a positive <span class="math inline">\(X \rightarrow M\)</span> effect means that observing <span class="math inline">\(M\)</span> will be informative: <span class="math inline">\(M=1\)</span> will be more consistent with an <span class="math inline">\(X \rightarrow Y\)</span> effect than will <span class="math inline">\(M=0\)</span>. The same logic, of course, also holds for observing cross-case correlations between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span>.</p>
<!-- 4. If there are different ways a query can be satisfied, evidence against one of those ways is evidence against the query as a whole. Say we have a two-path model — with one direct and one indirect path — and we want to know if X affects Y. We observe a mediator, M, along the indirect path in a set of cases. If the M data pattern is inconsistent with an indirect effect, then this is also evidence against an overall effect. In general, finding evidence against one way the effect can happen reduces our confidence in the effect happening at all.  -->
<p><strong>Prior data/beliefs “channel” the learning from new data.</strong> When we learn from new data, we always update <em>conditional</em> on any prior information. Consider the following example. Suppose that we are working with our familiar <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. We first observe a large amount of <span class="math inline">\(X,Y\)</span> data in which the two variables are strongly and positively correlated, thus indicative of a positive <span class="math inline">\(ATE\)</span> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Next, we turn to process tracing a small number of cases: suppose we collect data on <span class="math inline">\(M\)</span> in one <span class="math inline">\(X=1, Y=1\)</span> case and one <span class="math inline">\(X=0, Y=0\)</span> case, and we observe <span class="math inline">\(M=1\)</span> in both cases. Well, <span class="math inline">\(M\)</span> is uncorrelated with <span class="math inline">\(X\)</span> across these two cases, constituting evidence against an effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Since these are both cases in which a positive effect <em>could</em> have been operating, this finding will reduce our posterior on the share of positive effects in the population and, in turn, on the <span class="math inline">\(ATE\)</span>.</p>
<p>However, the strong prior information on the <span class="math inline">\(ATE\)</span> that we began with still anchors our updating. Our downward updating on the <span class="math inline">\(ATE\)</span> will be modest since our posterior is always a compromise between our (here, strong) priors and new information. More precisely, we will update less on the <span class="math inline">\(ATE\)</span>, about which we had strong prior information, than we will update about the share of positive effects, about which our prior data provided weaker information.</p>
<p>In addition, there is a knock-on effect for our beliefs about the share of negative effects in the population. If we have a strong prior about the value of the <span class="math inline">\(ATE\)</span>, and our beliefs about the share of positive effects goes down substantially, then our beliefs about the share of negative effects must <em>also</em> fall. (Recall that the <span class="math inline">\(ATE\)</span> is simply the share of positive effects minus the share of negative effects.) Intuitively, we can think of our beliefs about negative effects as updating to “preserve” our beliefs about the <span class="math inline">\(ATE\)</span>. And note that, if we had had <em>no</em> prior information about average effects, then learning about positive effects would have have had no implications for our beliefs about negative effects since there would be no overall constraint on the relationship between positive- and negative effect shares.</p>
<p>A more general way to describe this dynamic is that learning about a kind of case that we directly observe can generate “second-hand” learning about a kind of case that we do not directly observe <em>through</em> the constraint on our beliefs imposed by the our priors. This is, really, just a special instance of our priors generating probative value: our prior on the <span class="math inline">\(ATE\)</span> can make evidence about positive effects informative about negative effects. If we had flat priors on the <span class="math inline">\(ATE\)</span>, learning about positive effects would have no impact on our beliefs about negative effects.</p>
<p>A parallel example arises when we want to learn about a model with multiple causal pathways. Consider the model <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow N \leftarrow X\)</span>, where <span class="math inline">\(X\)</span> can have an effect on <span class="math inline">\(Y\)</span> through either <span class="math inline">\(M\)</span> or <span class="math inline">\(N\)</span>. And let us set priors such that we believe the the two paths to be equally likely. Suppose that, as before, we have started with a substantial amount of <span class="math inline">\(X,Y\)</span> data indicative of a large positive <span class="math inline">\(ATE\)</span>. Now, we look for data on <span class="math inline">\(M\)</span> in a handful of cases and find an <span class="math inline">\(M\)</span> pattern inconsistent with any kind of effect through <span class="math inline">\(M\)</span>. What happens to our beliefs about the <span class="math inline">\(ATE\)</span>? In general, finding evidence against one way an effect can happen should reduce our confidence in the effect happening at all. However, if we have started out with a strong prior on the <span class="math inline">\(ATE\)</span> but equal prior weight on the <span class="math inline">\(M\)</span> and <span class="math inline">\(N\)</span> pathways, then what we will see is countervailing updating across the two pathways: while our confidence in the operation of the <span class="math inline">\(M\)</span> pathway will fall substantially, our posterior on effects operating via the <span class="math inline">\(N\)</span> pathway will <em>rise</em> — because of the constraint on the total effect imposed by our strong priors on the <span class="math inline">\(ATE\)</span>. And our <span class="math inline">\(ATE\)</span> beliefs will fall only modestly. Evidence against the <span class="math inline">\(M\)</span>-pathway effect will function as evidence for the <span class="math inline">\(N\)</span>-pathway effects and, to a limited degree, as evidence against a total effect.</p>
<p>A further implication for process tracing is that there will generally be sharp limits to what we can learn about total effects if we study mediators along only <em>some</em> of the theorized pathways if we already have some prior information about total effects. The difficulty is that whatever we learn from the mediators we <em>do</em> observe will be offset by countervailing shifts in our beliefs about other pathways, generated by the constraint in our prior knowledge about the total effect. Suppose, for instance, that we start with some belief that economic development makes democracy more likely, and we believe that there may be two mechanisms: one operating through a rising middle class and one operating through a more robust and organized working class. Suppose then that we examine data on the organization of the working class and find that it does not vary with per capita GDP. We will then, of course, reduce our confidence in the working-class pathway. However, we must also <em>increase</em> our confidence in the operation of the middle-class pathway — because (a) we have prior reason to believe that the overall development <span class="math inline">\(\rightarrow\)</span> democracy effect exists and (b) we have not observed a mediator along the middle-class pathway. On balance, then, learning about just the one pathway will not have a large impact on beliefs about the overall effect of GDP on democratization. The larger lesson here is that, if our process tracing strategy involves the examination of mediators to learn about total <span class="math inline">\(X \rightarrow Y\)</span> effects, then how much we stand to learn depends on how comprehensively our examination of mediators covers thes plausible pathways connecting <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>.</p>
<p>To be clear, we do not need to collect mediator clues on all <em>possible</em> pathways. If we have strong priors that one or more possible pathways are very unlikley, then we might safely be able to avoid collecting observations along those pathways without substantially reducing the prospects for learning.</p>
<p>Also, the specific point that we are making here applies to using mediator data to answer queries about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. If instead we want to know which <em>particular pathway</em> is operating, then the lesson here is quite different, and more encouraging. For one thing, collecting evidence on just one pathway can be highly informative about the operation of that pathway. For another, if we do have strong priors on the <span class="math inline">\(ATE\)</span>, then learning about one pathway can <em>also</em> be informative about other pathways, just as we saw in our <span class="math inline">\(M\)</span>- and <span class="math inline">\(N\)</span>-pathway example.</p>
<!-- Moreover, the degree to which prior data constrains learning depends, of course, on how much prior data we have. In the $X \rightarrow M \rightarrow Y$ model, if we have observed only a small amount of prior $X,Y$ data, then observing $M$ in a handful of cases will lead us to update more strongly on the $ATE$ in the above examples, then observing the M data in the on-the-regression-line cases will have a weaker impact on our beliefs about negative effects, and a bigger impact on our beliefs about ATE. Ditto for the 2-path model example. However, where prior data/beliefs on the ATE are strong, we’ll learn less about the ATE, and more about negative effects (or the direct path).  -->
<!-- 7. If there are different ways in which a query can be satisfied, evidence against the likelier way is stronger evidence against the query than is evidence against an unlikelier way. In the 2-path model, if we started out thinking that the indirect effect was more likely than the direct effect, then evidence against the direct effect will have a bigger impact on our beliefs about the overall model.  -->
<!-- 8. It is difficult to get empirical leverage on very unlikely queries. And queries may be unlikelier than they appear. Suppose we start with the 2-path model, and want to know if X has a positive effect on Y that rests on a chain of positive effects via M. And suppose, importantly, that we begin with flat priors over all nodal types. Our intuitions likely tell us that this is exactly the kind of question for which an observation of M is the perfect empirical strategy. And that intuition is, in a sense, correct: we can indeed learn about the query by observing M. Seeing M=1 in an X=Y=1 case, for instance. would be evidence consistent with the query while M=0 would be inconsistent. Fine. ((But we will only learn a little from this observation. The reason is that the query itself has a very low prior probability. It may actually not be obvious at first glance just how unlikely our query is to be true. (After all, the model has two causal paths, and we’re asking if positive effects run through one of them, right? Not quite.) Seeing this requires us to think about the joint probabilities implied by the query. First, the query requires X to have a positive effect on M, which we think there’s only a 25% chance of. In addition, the query puts a very narrow constraint on Y’s possible nodal types:  Y has to have a nodal type in which M has a positive effect on Y when X does not change, and in which X does not have a positive effect on Y unless M changes from 0 to 1. This pair of conditions is met by only 2 of Y’s 16 nodal types, implying a 12.5% chance. The prior on the query is thus 0.25 x 0.125 = 0.03125. Thus, while observing M=0 takes the probability of the query down to 0%, we started out very close to 0%! And observing M=1 results in only a small uptick, to about 6% because there remain many type combinations consistent with M=1 but that do not fit through the needle-eye of this query. -->
</div>
<div id="conclusion-1" class="section level2">
<h2><span class="header-section-number">9.7</span> Conclusion</h2>
<p>ADD REFERENCE TO TABLE 1 OF FOR MIXED DATA “Ability and Achievement” Otis Duncan</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-humphreys2015mixing">
<p>Humphreys, Macartan, and Alan M Jacobs. 2015. “Mixing Methods: A Bayesian Approach.” <em>American Political Science Review</em> 109 (04): 653–73.</p>
</div>
<div id="ref-king1994designing">
<p>King, G., R. O. Keohane, and S. Verba. 1994. <em>Designing Social Inquiry: Scientific Inference in Qualitative Research</em>. Princeton University Press. <a href="http://books.google.de/books?id=A7VFF-JR3b8C">http://books.google.de/books?id=A7VFF-JR3b8C</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ptapp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixingapp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
