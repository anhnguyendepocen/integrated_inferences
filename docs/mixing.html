<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Integrated inferences | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Integrated inferences | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Integrated inferences | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="application-process-tracing-with-a-causal-model.html">
<link rel="next" href="mixingapp.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Integrands</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-centrality-of-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Centrality of Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.1</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.2</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.2</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#features-of-causal-models"><i class="fa fa-check"></i><b>2.2.1</b> Features of causal models</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.3</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#causal-models-from-the-literature"><i class="fa fa-check"></i><b>2.3</b> Causal models from the literature</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#pierson-on-dismantling-the-welfare-state"><i class="fa fa-check"></i><b>2.3.1</b> Pierson on dismantling the welfare state</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4</b> Steps for constructing causal models</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#abstract-procedure"><i class="fa fa-check"></i><b>2.4.1</b> Abstract procedure</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#inequalitytheory"><i class="fa fa-check"></i><b>3.1</b> Two theories of inequality’s effects on democratization</a><ul>
<li class="chapter" data-level="3.1.1" data-path="theory.html"><a href="theory.html#theory-as-causal-functions"><i class="fa fa-check"></i><b>3.1.1</b> Theory as causal functions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.2</b> Theory as a “lower-level” model</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#disggregating-nodes"><i class="fa fa-check"></i><b>3.2.1</b> Disggregating nodes</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#generalizing-a-model"><i class="fa fa-check"></i><b>3.2.2</b> Generalizing a model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#mappings-are-not-one-to-one"><i class="fa fa-check"></i><b>3.3.1</b> Mappings are not one-to-one</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#permissible-moves-across-levels"><i class="fa fa-check"></i><b>3.3.2</b> Permissible moves across levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#beneath-the-graph-causal-types-in-lower-level-models"><i class="fa fa-check"></i><b>3.4</b> Beneath the Graph: Causal Types in Lower-Level Models</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#medtheory"><i class="fa fa-check"></i><b>3.4.1</b> Mediation as Theory</a></li>
<li class="chapter" data-level="3.4.2" data-path="theory.html"><a href="theory.html#modtheory"><i class="fa fa-check"></i><b>3.4.2</b> Moderation as Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
<li class="chapter" data-level="3.6" data-path="theory.html"><a href="theory.html#appendix-illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.6</b> Appendix: Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#causal-queries"><i class="fa fa-check"></i><b>4.1</b> Causal queries</a><ul>
<li class="chapter" data-level="4.1.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.1.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.1.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.1.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.1.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.1.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.1.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.1.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.1.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#illustration-with-the-running-example"><i class="fa fa-check"></i><b>4.2</b> Illustration with the Running Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> Bayes’ Rule for Continuous Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-correlational-inference"><i class="fa fa-check"></i><b>5.2.2</b> Bayesian correlational inference</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.3</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneoues-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneoues, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="clues.html"><a href="clues.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="clues.html"><a href="clues.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="clues.html"><a href="clues.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="clues.html"><a href="clues.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="clues.html"><a href="clues.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="clues.html"><a href="clues.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clues.html"><a href="clues.html#conditional-independence-alone-does-not-provide-probative-value"><i class="fa fa-check"></i><b>6.2.1</b> Conditional independence alone does not provide probative value</a></li>
<li class="chapter" data-level="6.2.2" data-path="clues.html"><a href="clues.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.2</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.3" data-path="clues.html"><a href="clues.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.3</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.4" data-path="clues.html"><a href="clues.html#probative-value"><i class="fa fa-check"></i><b>6.2.4</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a><ul>
<li class="chapter" data-level="7.3.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.3.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.3.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.3.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.4</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.5" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.5</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#the-parameter-matrix"><i class="fa fa-check"></i><b>8.2.1</b> The parameter matrix</a></li>
<li class="chapter" data-level="8.2.2" data-path="mixing.html"><a href="mixing.html#the-ambiguity-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The ambiguity matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="mixing.html"><a href="mixing.html#likelihood"><i class="fa fa-check"></i><b>8.2.3</b> Likelihood</a></li>
<li class="chapter" data-level="8.2.4" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.4</b> Estimation</a></li>
<li class="chapter" data-level="8.2.5" data-path="mixing.html"><a href="mixing.html#mixed-data"><i class="fa fa-check"></i><b>8.2.5</b> Mixed data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.5</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="10" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>10</b> Elements of Design</a><ul>
<li class="chapter" data-level="10.1" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-process-tracing-design"><i class="fa fa-check"></i><b>10.1</b> Declaring a process tracing design</a><ul>
<li class="chapter" data-level="10.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#steps"><i class="fa fa-check"></i><b>10.1.1</b> Steps</a></li>
<li class="chapter" data-level="10.1.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-in-code"><i class="fa fa-check"></i><b>10.1.2</b> Illustration in code</a></li>
<li class="chapter" data-level="10.1.3" data-path="elements-of-design.html"><a href="elements-of-design.html#diagnosands-evaluating-a-model"><i class="fa fa-check"></i><b>10.1.3</b> Diagnosands: Evaluating a model</a></li>
<li class="chapter" data-level="10.1.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-measures-of-a-gain-from-a-theory"><i class="fa fa-check"></i><b>10.1.4</b> Other measures of a gain from a theory</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-mixed-methods-design"><i class="fa fa-check"></i><b>10.2</b> Declaring a mixed methods design</a><ul>
<li class="chapter" data-level="10.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model"><i class="fa fa-check"></i><b>10.2.1</b> Model</a></li>
<li class="chapter" data-level="10.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#data-strategies"><i class="fa fa-check"></i><b>10.2.2</b> Data strategies</a></li>
<li class="chapter" data-level="10.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#estimands"><i class="fa fa-check"></i><b>10.2.3</b> Estimands</a></li>
<li class="chapter" data-level="10.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#answer-strategies"><i class="fa fa-check"></i><b>10.2.4</b> Answer Strategies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html"><i class="fa fa-check"></i><b>11</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="11.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#a-strategic-approach"><i class="fa fa-check"></i><b>11.1</b> A strategic approach</a></li>
<li class="chapter" data-level="11.2" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-running-example"><i class="fa fa-check"></i><b>11.2</b> Clue selection for the running example</a><ul>
<li class="chapter" data-level="11.2.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#dynamic-strategies"><i class="fa fa-check"></i><b>11.2.1</b> Dynamic Strategies</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-democracy-model"><i class="fa fa-check"></i><b>11.3</b> Clue selection for the Democracy model</a></li>
<li class="chapter" data-level="11.4" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#conclusion-2"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>12</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="12.1" data-path="wide.html"><a href="wide.html#intuitions-does-a-sufficiently-large-n-always-trump-k"><i class="fa fa-check"></i><b>12.1</b> Intuitions: Does a sufficiently large <span class="math inline">\(N\)</span> always trump <span class="math inline">\(K\)</span>?</a></li>
<li class="chapter" data-level="12.2" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>12.2</b> Evaluating strategies</a></li>
<li class="chapter" data-level="12.3" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>12.3</b> Varieties of mixing</a></li>
<li class="chapter" data-level="12.4" data-path="wide.html"><a href="wide.html#AppSimNotes"><i class="fa fa-check"></i><b>12.4</b> Notes on Simulations</a><ul>
<li class="chapter" data-level="12.4.1" data-path="wide.html"><a href="wide.html#AppE1"><i class="fa fa-check"></i><b>12.4.1</b> Probative values</a></li>
<li class="chapter" data-level="12.4.2" data-path="wide.html"><a href="wide.html#AppE2"><i class="fa fa-check"></i><b>12.4.2</b> Effect heterogeneity</a></li>
<li class="chapter" data-level="12.4.3" data-path="wide.html"><a href="wide.html#AppE3"><i class="fa fa-check"></i><b>12.4.3</b> Uncertainty about assignment processes</a></li>
<li class="chapter" data-level="12.4.4" data-path="wide.html"><a href="wide.html#AppE4"><i class="fa fa-check"></i><b>12.4.4</b> Uncertainty regarding the probative value of clues</a></li>
<li class="chapter" data-level="12.4.5" data-path="wide.html"><a href="wide.html#details-on-simulation-experiments"><i class="fa fa-check"></i><b>12.4.5</b> Details on simulation experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>13.1</b> Explorations</a><ul>
<li class="chapter" data-level="13.1.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>13.1.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#in-code"><i class="fa fa-check"></i><b>13.2</b> In code</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#compare-multiple-data-strategies"><i class="fa fa-check"></i><b>13.3</b> Compare multiple data strategies</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#experiments"><i class="fa fa-check"></i><b>13.4</b> Experiments</a></li>
<li class="chapter" data-level="13.5" data-path="caseselection.html"><a href="caseselection.html#chapter-appendix-accounting-for-case-selection"><i class="fa fa-check"></i><b>13.5</b> Chapter Appendix: Accounting for case selection</a><ul>
<li class="chapter" data-level="13.5.1" data-path="caseselection.html"><a href="caseselection.html#independent-case-selection-strategy"><i class="fa fa-check"></i><b>13.5.1</b> Independent case selection strategy</a></li>
<li class="chapter" data-level="13.5.2" data-path="caseselection.html"><a href="caseselection.html#conditional-random-case-selection"><i class="fa fa-check"></i><b>13.5.2</b> Conditional random case selection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="14" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html"><i class="fa fa-check"></i><b>14</b> Where does probative value come from?</a><ul>
<li class="chapter" data-level="14.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#causal-discovery"><i class="fa fa-check"></i><b>14.1</b> Causal discovery</a></li>
<li class="chapter" data-level="14.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#the-possibility-of-identification-of-probative-value-from-experimental-data"><i class="fa fa-check"></i><b>14.2</b> The possibility of identification of probative value from experimental data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#moderator"><i class="fa fa-check"></i><b>14.2.1</b> Moderator</a></li>
<li class="chapter" data-level="14.2.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#mediator"><i class="fa fa-check"></i><b>14.2.2</b> Mediator</a></li>
<li class="chapter" data-level="14.2.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#generally-not-so-easy"><i class="fa fa-check"></i><b>14.2.3</b> Generally not so easy</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#bounds-on-causes-of-effects"><i class="fa fa-check"></i><b>14.3</b> Bounds on causes of effects</a></li>
<li class="chapter" data-level="14.4" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#qualitative-beliefs-and-sensitivity-analyses"><i class="fa fa-check"></i><b>14.4</b> Qualitative beliefs and Sensitivity Analyses</a></li>
<li class="chapter" data-level="14.5" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#conditional-claims"><i class="fa fa-check"></i><b>14.5</b> Conditional claims</a></li>
<li class="chapter" data-level="14.6" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-about-parameters-within-a-model"><i class="fa fa-check"></i><b>14.6</b> Learning about parameters within a model</a></li>
<li class="chapter" data-level="14.7" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-from-observational-and-experimental-mixtures"><i class="fa fa-check"></i><b>14.7</b> Learning from observational and experimental mixtures</a></li>
<li class="chapter" data-level="14.8" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-across-populations"><i class="fa fa-check"></i><b>14.8</b> Learning across populations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>15</b> Robustness and Model-Evaluation</a><ul>
<li class="chapter" data-level="15.1" data-path="evaluation.html"><a href="evaluation.html#tools-for-evaluating-models"><i class="fa fa-check"></i><b>15.1</b> Tools for evaluating models</a></li>
<li class="chapter" data-level="15.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>15.2</b> Evaluating the Democracy-Inequality model</a></li>
<li class="chapter" data-level="15.3" data-path="evaluation.html"><a href="evaluation.html#prior-check"><i class="fa fa-check"></i><b>15.3</b> Prior check</a></li>
<li class="chapter" data-level="15.4" data-path="evaluation.html"><a href="evaluation.html#monotonic-restrictions"><i class="fa fa-check"></i><b>15.4</b> Monotonic restrictions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>16</b> Final Words</a><ul>
<li class="chapter" data-level="16.1" data-path="final-words.html"><a href="final-words.html#some-conclusions"><i class="fa fa-check"></i><b>16.1</b> Some conclusions</a></li>
<li class="chapter" data-level="16.2" data-path="final-words.html"><a href="final-words.html#words-of-warning"><i class="fa fa-check"></i><b>16.2</b> Words of warning</a></li>
<li class="chapter" data-level="16.3" data-path="final-words.html"><a href="final-words.html#general-and-specific-knowledge"><i class="fa fa-check"></i><b>16.3</b> General and specific knowledge</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="17" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>17</b> Analysis of canonical models with <code>gbiqq</code></a><ul>
<li class="chapter" data-level="17.1" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-no-confounding"><i class="fa fa-check"></i><b>17.1</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, no confounding</a></li>
<li class="chapter" data-level="17.2" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-unmodelled-confounding"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with unmodelled confounding</a></li>
<li class="chapter" data-level="17.3" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-confounding-modelled"><i class="fa fa-check"></i><b>17.3</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with confounding modelled</a></li>
<li class="chapter" data-level="17.4" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-mediation-model"><i class="fa fa-check"></i><b>17.4</b> Simple mediation model</a></li>
<li class="chapter" data-level="17.5" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-moderator-model"><i class="fa fa-check"></i><b>17.5</b> Simple moderator model</a></li>
<li class="chapter" data-level="17.6" data-path="examplesappendix.html"><a href="examplesappendix.html#an-iv-model"><i class="fa fa-check"></i><b>17.6</b> An IV model</a></li>
<li class="chapter" data-level="17.7" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-that-allows-application-of-the-frontdoor-criterion"><i class="fa fa-check"></i><b>17.7</b> A model that allows application of the frontdoor criterion</a></li>
<li class="chapter" data-level="17.8" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-with-a-violation-of-sequential-ignorability"><i class="fa fa-check"></i><b>17.8</b> A model with a violation of sequential ignorability</a></li>
<li class="chapter" data-level="17.9" data-path="examplesappendix.html"><a href="examplesappendix.html#learning-from-a-collider"><i class="fa fa-check"></i><b>17.9</b> Learning from a collider</a></li>
<li class="chapter" data-level="17.10" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-mixing-observational-and-experimental-data"><i class="fa fa-check"></i><b>17.10</b> A model mixing observational and experimental data</a></li>
<li class="chapter" data-level="17.11" data-path="examplesappendix.html"><a href="examplesappendix.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>17.11</b> Transportation of findings across contexts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixing" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Integrated inferences</h1>
<hr />
<p>We argue that mixed methods can be thought of as the analysis of single cases with vector valued variables. Reconceptualizing as large n is useful prmarily for computation reasons and often comes with hidden independence assumptions. We illustrate the single case approach and provide a set of models for the many case approach.</p>
<hr />
<!-- Lots of this likely to change with integration with DAGs. -->
<p>The main goal of this chapter is to generalize the model developed in Chapter 6 to problems with data on many cases. In doing so we generalize the model in <span class="citation">Humphreys and Jacobs (<a href="#ref-humphreys2015mixing">2015</a>)</span> to one that in which rather than the probative value of clues being <em>assumed</em>, they are derived from a causal structure.</p>
<p>We start however with a conceptual point: the exact structure introduced in Chapter 6 for single case analysis can be used <em>as is</em> for multi-case analysis. To see this you should think of the the nodes as vector-valued, and the estimands as just a particular summary of the vector-valued case level causal effects. Thought of this way the conceptual work for mixed methods inference from models has been done already and our goal here is more technical—how to exploit assumptions on independence across cases to generate simpler theories of repeated phenomena.</p>
<div id="theres-only-ever-one-case" class="section level2">
<h2><span class="header-section-number">8.1</span> There’s only ever one case</h2>
<p>Conceptualized correctly, there is no difference at all between the data types or the inference used in within-case and cross-case inference. The reason is not, as <span class="citation">King, Keohane, and Verba (<a href="#ref-king1994designing">1994</a>)</span> suggest, that all causal inference is fundamentally correlational, even in seemingly single case studies. Nor is the point that, looked at carefully, single “case studies” can be disaggregated into many cases. The intuition runs in the opposite direction: fundamentally, model-based inference always involves comparing <em>a</em> pattern of data with the logic of the model. Looked at carefully, studies with multiple cases can be conceptualized of as single-case studies: the drawing of inferences from a single collection of clues.</p>
<p>The key insight is that, when we move from a causal model with one observation to a causal model with multiple observations, all that we are doing is replacing nodes with a single value (i.e., scalars) with nodes containing multiple values (i.e., vectors).</p>
<p>To illustrate the idea that multi-case studies are really single-case studies with vector valued variables, consider the following situation. There are two units studied, drawn from some population, a binary treatment <span class="math inline">\(X\)</span> is assigned independently with probability .5 to each case; an outcome <span class="math inline">\(Y\)</span> along with clue variable <span class="math inline">\(K\)</span> is observable. We suppose <span class="math inline">\(X\)</span> can affect <span class="math inline">\(Y\)</span> and in addition there is a background, unobserved, variable <span class="math inline">\(\theta\)</span> (causal type) that takes on values in <span class="math inline">\(\{a,b,c,d\}\)</span>, that affects both <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span>. We will assume that <span class="math inline">\(\theta\)</span> is not independently assigned and that the two units are more likely to have the same values of <span class="math inline">\(\theta\)</span> than different values. For simplicity, we will suppose that for any given case <span class="math inline">\(K=1\)</span> whenever <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K=1\)</span> with a 50% probability otherwise. Thus, <span class="math inline">\(K\)</span> is informative about a unit’s causal type.</p>
<p>Note that we have described the problem at the unit level. We can redescribe it at the population level however as a situation in which a treatment vector <span class="math inline">\(X\)</span> can take on one of four values, <span class="math inline">\((0,0), (0,1), (1,0), (1,1)\)</span> with equal probability (or more strictly: as determined by <span class="math inline">\(\theta\)</span>). <span class="math inline">\(\theta\)</span> is also a vector with two elements that can take on one of 16 values <span class="math inline">\((a,a), (a,b),\dots (d,d)\)</span> as determined by <span class="math inline">\(U_\theta\)</span>. In this case we will assume that the 16 possibilities are not equally likely, which captures the failure of independence in the unit level assignments. <span class="math inline">\(Y\)</span> is a vector that reflects the elements of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(X\)</span> in the obvious way (e.g <span class="math inline">\(X=(0,0), \theta=(a,b)\)</span> generates outcomes <span class="math inline">\(Y=(1,0)\)</span>; though it is immediately obvious that representing nodes in vector forms allows for more general vector-level mappings to allow for SUTVA violations. <span class="math inline">\(K\)</span> has the same domain as <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and element <span class="math inline">\(K[j]=1\)</span> if <span class="math inline">\(\theta[j]=b\)</span>.</p>
<p>Note that to describe the estimand, the Sample Average Treatment Effect, we also need to consider operations and queries defined at the vector level. In practice we consider three operations, one in which both units have <span class="math inline">\(X\)</span> forced to 0 and two in which one nit has <span class="math inline">\(X\)</span> set to 0 and the other has <span class="math inline">\(X\)</span> set to 1. Thus we are interested in the average effect of changing one unit to treatment while the other is held in control. Note also that before our estimands were binary—of the form: is it a <span class="math inline">\(b\)</span> type?–and our answer was a probability; now our estimand is categorical and our answer is a distribution (what is the probability the SATE is 0, what is the probability the SATE is .5, etc…)</p>
<p>Represented in this way we can use the tools of Chapters 6 and 7 to fully examine this seemingly multi-case study. In the below we examine a situation in which we consider the value of observing <span class="math inline">\(K\)</span> on one case — in this set up this is equivalent to observing part of the vector <span class="math inline">\(K\)</span> and making inferences on the full vector <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="general-procedure" class="section level2">
<h2><span class="header-section-number">8.2</span> General procedure</h2>
<p>In practice however thinking of nodes as capturing the outcomes on all units leads to enormous complexity. For example an exogeneous variable <span class="math inline">\(X\)</span> which takes on values of 0 or 1 at random for 10 units has <span class="math inline">\(2^10\)</span> types in this conceptualization, rather than just two when thought of at the case level.</p>
<p>We reduce complexity however by thinking of models as operating on units and learning about models by observing <em>multiple</em> realizations of processes covered by the model, rather than just one. Thinking about it this way is not free however as it requires invoking some kind of independence assumptions — that outcomes in two units do not depend on each other. If we cannot stand by that assumption then we have to build independence failures into our models</p>
<p>With multiple cases we…</p>
<div id="the-parameter-matrix" class="section level3">
<h3><span class="header-section-number">8.2.1</span> The parameter matrix</h3>
</div>
<div id="the-ambiguity-matrix" class="section level3">
<h3><span class="header-section-number">8.2.2</span> The ambiguity matrix</h3>
</div>
<div id="likelihood" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Likelihood</h3>
</div>
<div id="estimation" class="section level3">
<h3><span class="header-section-number">8.2.4</span> Estimation</h3>
</div>
<div id="mixed-data" class="section level3">
<h3><span class="header-section-number">8.2.5</span> Mixed data</h3>
<p>Say a data strategy seeks data on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in 2 cases and seeks data on <span class="math inline">\(K\)</span> if ever <span class="math inline">\(X=Y=1\)</span>.</p>
<p>The probability of each data type is as given in table below:</p>
<table>
<colgroup>
<col width="25%" />
<col width="74%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^Y_{00}+\lambda^Y_{01}))\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^Y_{11}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^Y_{00}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{11}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01}))\)</span></td>
</tr>
</tbody>
</table>
<p>The two observations can be thought of as a multinomal draw from these five event types.</p>
<p>Alternatively they can also be thought of as the product of a draw from a strategy in which a set of units is drawn with observations on <span class="math inline">\(X,Y\)</span> only and another set is drawn with observations on <span class="math inline">\(X, M,Y\)</span>.</p>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
<p>Say rather than conditioning <span class="math inline">\(X=Y=1\)</span> to examine <span class="math inline">\(M\)</span> one of the two cases were chosen at random to observe <span class="math inline">\(M\)</span> and it just so happend to be be a case with <span class="math inline">\(X=Y=1\)</span>:</p>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(.5\lambda^X_0(\lambda^Y_{00}+\lambda^Y_{01}))\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(.5\lambda^X_0(\lambda^Y_{11}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(.5\lambda^X_1(\lambda^Y_{00}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1Y1\)</span></td>
<td><span class="math inline">\(.5\lambda^X_1(\lambda^Y_{11}+\lambda^Y_{01}))\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X0M0Y0\)</span></td>
<td><span class="math inline">\(.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01}))(\lambda^Y_{00}+\lambda^Y_{01}))\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0M1Y0\)</span></td>
<td><span class="math inline">\(.5\lambda^X_0(\lambda^M_{11}+\lambda^M_{10}))(\lambda^Y_{00}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="odd">
<td>…</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{11}+\lambda^Y_{10}))\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01}))\)</span></td>
</tr>
</tbody>
</table>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is now:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
</div>
</div>
<div id="illustration" class="section level2">
<h2><span class="header-section-number">8.3</span> Illustration</h2>
<p>Consider a generalization of the models introduced in Chapter 6 in which a treatment <span class="math inline">\(X\)</span> is a cause of both <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span>, and outcome <span class="math inline">\(Y\)</span> is a product of both <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span>. Though <span class="math inline">\(K\)</span> is both a mediator and a moderator for the effect of <span class="math inline">\(X\)</span>. There are now 16 nodal types for <span class="math inline">\(Y\)</span>, 4 for <span class="math inline">\(K\)</span> and 2 for <span class="math inline">\(X\)</span>, yielding 32 causal types.</p>
<p>To allow for the possibility of non-random selection of <span class="math inline">\(X\)</span> we will assume that the assignment probability for <span class="math inline">\(X\)</span> depends on <span class="math inline">\(U^Y\)</span>. This is a feature shared also in the baseline model when we specify <span class="math inline">\(\pi\)</span> as a function of types <span class="math inline">\(a\)</span>,<span class="math inline">\(b\)</span>,<span class="math inline">\(c\)</span>,<span class="math inline">\(d\)</span>.</p>
<p>Our piors requires specifying:</p>
<ol style="list-style-type: decimal">
<li>A distribution over the 15-dimensional simplex representing possible values of <span class="math inline">\(\lambda^Y\)</span>–which in turn determine types <span class="math inline">\(u^Y\)</span>.</li>
<li>A distribution over the 3-dimensional vector representing possible values of <span class="math inline">\(\lambda^K\)</span>, which in turn determine types <span class="math inline">\(u^K\)</span>.</li>
</ol>
<p>The model is restricted in various ways. We assume now confounding in the assignemnt of <span class="math inline">\(X\)</span>. Less obviously we implicitly assume that <span class="math inline">\(K\)</span> is independent of <span class="math inline">\(\theta^Y\)</span> conditional on <span class="math inline">\(X\)</span>.</p>
<p>With these elements in hand, however, all we need now is to provide a mapping from these fundamental parameters to the parameters used in the baseline model to form the likelihood.</p>
<p>The key transformation is the identification of causal types resulting from the 64 combinations of <span class="math inline">\(\lambda^Y\)</span> and <span class="math inline">\(\lambda^K\)</span>. These are shown below.</p>
<p>TABLE TO SHOW CAUSAL TYPES</p>
<p>Consider the following matrices of values for <span class="math inline">\(u_Y\)</span> and <span class="math inline">\(u_K\)</span>, where <span class="math inline">\(\lambda_{pq}^{rs}\)</span> is the probability that <span class="math inline">\(u^Y = t_{pq}^{rs}\)</span>, meaning that <span class="math inline">\(Y\)</span> would take the value <span class="math inline">\(p\)</span> when <span class="math inline">\(X=0, K=0\)</span>, <span class="math inline">\(q\)</span> when <span class="math inline">\(X=0, K=1\)</span>, <span class="math inline">\(r\)</span> when <span class="math inline">\(X=1, K=0\)</span>, and <span class="math inline">\(s\)</span> when <span class="math inline">\(X=1, K=1\)</span>. Similarly <span class="math inline">\(\lambda_{w}^{z}\)</span> is the probability that <span class="math inline">\(u^K\)</span> takes value <span class="math inline">\(t_{w}^{z}\)</span> meaning that <span class="math inline">\(K\)</span> takes the value <span class="math inline">\(w\)</span> when <span class="math inline">\(X=0\)</span> and <span class="math inline">\(z\)</span> when <span class="math inline">\(X=1\)</span>.</p>
<p>TABLE TO SHOW CONDITIONAL PROBABILITIES OF K GIVEN X=1 AND TYPE</p>
<p>These types are the <em>transformed parameters</em>; the probability of a type is just the sum of the probabilities of the fundamental types that compose it, formed by taking the product of the <span class="math inline">\(\lambda^Y\)</span> and <span class="math inline">\(\lambda^K\)</span> values marked in the rows and columns of table .</p>
<p>Similarly <span class="math inline">\(\phi_{tx}\)</span> can be constructed as the probability of observing <span class="math inline">\(K\)</span> conditional on this type (again, sums of products of probabilities associated with cells in table ). For instance, using the row and column indices in exponents (GIVE FULL LABELS) from table :</p>
<p><span class="math display">\[\phi_{b1}=\frac{\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}{
\lambda_K^1(\lambda_Y^3+\lambda_Y^4+\lambda_Y^7+\lambda_Y^8)+\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^3(\lambda_Y^3+\lambda_Y^4+\lambda_Y^11+\lambda_Y^{12})+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}\]</span></p>
<p>With these transformed parameters in hand, the likelihood is exactly the same as that specified in the baseline model.</p>
</div>
<div id="illustrated-inferences" class="section level2">
<h2><span class="header-section-number">8.4</span> Illustrated inferences</h2>
<div id="xy-model" class="section level3">
<h3><span class="header-section-number">8.4.1</span> XY model</h3>
<p>Consider the simple model in which <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> without confounding.</p>
<p>Assuming flat priors on types, what inferences do we draw from different sorts of (small) datasets. Do we learn more about effects from two cases that are the same, two cases that differ on X and Y only or two cases that differ on both.</p>
<p>The results are given in table <a href="mixing.html#tab:XYresultstable">8.1</a>.</p>
<table>
<caption><span id="tab:XYresultstable">Table 8.1: </span>Inferences for different data observations in a simple X-&gt;Y model</caption>
<thead>
<tr class="header">
<th align="left">data</th>
<th align="right">a</th>
<th align="right">b</th>
<th align="right">c</th>
<th align="right">d</th>
<th align="right">ate</th>
<th align="right">bd</th>
<th align="right">bc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">00</td>
<td align="right">0.20</td>
<td align="right">0.30</td>
<td align="right">0.31</td>
<td align="right">0.20</td>
<td align="right">0.09</td>
<td align="right">1.51</td>
<td align="right">0.96</td>
</tr>
<tr class="even">
<td align="left">01</td>
<td align="right">0.30</td>
<td align="right">0.20</td>
<td align="right">0.19</td>
<td align="right">0.31</td>
<td align="right">-0.10</td>
<td align="right">0.65</td>
<td align="right">1.04</td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="right">0.20</td>
<td align="right">0.30</td>
<td align="right">0.20</td>
<td align="right">0.31</td>
<td align="right">0.09</td>
<td align="right">0.97</td>
<td align="right">1.52</td>
</tr>
<tr class="even">
<td align="left">01, 01</td>
<td align="right">0.34</td>
<td align="right">0.16</td>
<td align="right">0.17</td>
<td align="right">0.34</td>
<td align="right">-0.17</td>
<td align="right">0.49</td>
<td align="right">0.98</td>
</tr>
<tr class="odd">
<td align="left">11, 11</td>
<td align="right">0.17</td>
<td align="right">0.34</td>
<td align="right">0.17</td>
<td align="right">0.33</td>
<td align="right">0.17</td>
<td align="right">1.03</td>
<td align="right">2.02</td>
</tr>
<tr class="even">
<td align="left">01, 11</td>
<td align="right">0.23</td>
<td align="right">0.23</td>
<td align="right">0.16</td>
<td align="right">0.37</td>
<td align="right">0.00</td>
<td align="right">0.62</td>
<td align="right">1.41</td>
</tr>
<tr class="odd">
<td align="left">10, 11</td>
<td align="right">0.25</td>
<td align="right">0.25</td>
<td align="right">0.25</td>
<td align="right">0.25</td>
<td align="right">0.00</td>
<td align="right">0.98</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">00, 11</td>
<td align="right">0.17</td>
<td align="right">0.37</td>
<td align="right">0.23</td>
<td align="right">0.23</td>
<td align="right">0.20</td>
<td align="right">1.58</td>
<td align="right">1.64</td>
</tr>
<tr class="odd">
<td align="left">11, 11, 11</td>
<td align="right">0.14</td>
<td align="right">0.36</td>
<td align="right">0.14</td>
<td align="right">0.36</td>
<td align="right">0.22</td>
<td align="right">1.01</td>
<td align="right">2.65</td>
</tr>
</tbody>
</table>
<p>We note a number of features:</p>
<ul>
<li><span class="math inline">\(X=1, Y=1\)</span> data does not discriminate between <span class="math inline">\(\theta^Y_{01}\)</span> and <span class="math inline">\(\theta^Y_{11}\)</span> and so while more of this data puts greater weight on both <span class="math inline">\(\lambda^Y_{01}\)</span> and <span class="math inline">\(\lambda^Y_{11}\)</span>, it does nothing to discriminate between them.</li>
<li>Similarly <span class="math inline">\(X=0, Y=0\)</span> data does not discriminate between <span class="math inline">\(\theta^Y_{01}\)</span> and <span class="math inline">\(\theta^Y_{00}\)</span> though it puts greater weight (uniformly) on <span class="math inline">\(\lambda^Y_{01}\)</span> and <span class="math inline">\(\lambda^Y_{00}\)</span>,</li>
<li>For this reason, greatest weight is placed on <span class="math inline">\(\theta^Y_{01}\)</span> when data on both <span class="math inline">\(X=Y=0\)</span> and <span class="math inline">\(X=Y=1\)</span> cases are found.</li>
<li>The fractions suggest a common formula:</li>
</ul>
<p><span class="math display">\[\lambda^Y|n_{xy} \sim Dirichlet\left(1+\frac{n_{01} + n_{10}}2, 1+\frac{n_{00} + n_{11}}2, 1+\frac{n_{00} + n_{10}}2, 1+\frac{n_{01} + n_{11}}2\right)\]</span></p>
<p>Posterior mean on ATE is then <span class="math inline">\(\frac{n_{00} + n_{11} - n_{01} - n_{10}}n\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="left">data</th>
<th align="right">a</th>
<th align="right">b</th>
<th align="right">c</th>
<th align="right">d</th>
<th align="right">ate</th>
<th align="right">bd</th>
<th align="right">bc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">111</td>
<td align="right">0.12</td>
<td align="right">0.13</td>
<td align="right">0.32</td>
<td align="right">0.43</td>
<td align="right">0.01</td>
<td align="right">0.31</td>
<td align="right">0.41</td>
</tr>
<tr class="even">
<td align="left">111, 111</td>
<td align="right">0.11</td>
<td align="right">0.14</td>
<td align="right">0.28</td>
<td align="right">0.48</td>
<td align="right">0.03</td>
<td align="right">0.29</td>
<td align="right">0.50</td>
</tr>
<tr class="odd">
<td align="left">000, 111</td>
<td align="right">0.12</td>
<td align="right">0.16</td>
<td align="right">0.36</td>
<td align="right">0.36</td>
<td align="right">0.04</td>
<td align="right">0.45</td>
<td align="right">0.44</td>
</tr>
<tr class="even">
<td align="left">111, 111, 111</td>
<td align="right">0.10</td>
<td align="right">0.15</td>
<td align="right">0.25</td>
<td align="right">0.50</td>
<td align="right">0.05</td>
<td align="right">0.29</td>
<td align="right">0.60</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="considerations" class="section level2">
<h2><span class="header-section-number">8.5</span> Considerations</h2>
<div id="the-identification-problem" class="section level3">
<h3><span class="header-section-number">8.5.1</span> The identification problem</h3>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X1 -&gt; M1 -&gt; Y &lt;- M2 &lt;- X2&quot;</span>)

<span class="co"># restrict such that *only* M1 OR M2 could cause Y -- can we create a DD test? / achieve identification</span></code></pre>
</div>
<div id="continuous-data" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Continuous data</h3>
<p>We can similarly shift from binary to continuous variable values through an expansion of the causal types. Suppose that <span class="math inline">\(Y\)</span> can take on <span class="math inline">\(m\)</span> possible values. With <span class="math inline">\(k\)</span> explanatory variables, each taking on <span class="math inline">\(r\)</span> possible values, we then have <span class="math inline">\(m^{r^k}\)</span> causal types and, correspondingly, very many more elements in <span class="math inline">\(\phi\)</span>. Naturally, in such situations, researchers might want to reduce complexity by placing structure onto the possible patterns of causal effects and clue probabilities, such as assuming a monotonic function linking effect sizes and clue probabilities.</p>
</div>
<div id="measurement-error" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Measurement error</h3>
<p>We have assumed no measurement error; in applications there could be considerable interest in measurement error. On one hand clue information may contain information about possible mismeasurement on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; on the other hand there might interest in whether measured clues adequately capture those features of a causal process that is thought to be measureable.</p>
<p>The probability of different types of measurement error can be included among the set of parameters of interest, with likelihood functions adjusted accordingly. Suppose, for instance, that with probability <span class="math inline">\(\epsilon\)</span> a <span class="math inline">\(Y=0\)</span> case is recorded as a <span class="math inline">\(Y=1\)</span> case (and vice versa). Then the event probability of observing an <span class="math inline">\(X=1\)</span>,<span class="math inline">\(Y=1\)</span> case, for example, is <span class="math inline">\(\epsilon \lambda_a \pi_a + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_c \pi_c + (1-\epsilon) \lambda_d \pi_d\)</span>. %If instead there were measurement error on <span class="math inline">\(X\)</span> but not on <span class="math inline">\(Y\)</span>, then the event probability would be: <span class="math inline">\(\epsilon \lambda_a (1-\pi_a) + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_d (1-\pi_d) + (1-\epsilon) \lambda_d \pi_d\)</span>.
Similar expressions can be derived for measurement error on <span class="math inline">\(X\)</span> or <span class="math inline">\(K\)</span>. Specifying the problem in this way allows us both to take account of measurement error and learn about it.</p>
</div>
<div id="spillovers" class="section level3">
<h3><span class="header-section-number">8.5.4</span> Spillovers</h3>
<p>Spillovers may also be addressed through an appropriate definition of causal types. For example a unit <span class="math inline">\(i\)</span> that is affected either by receiving treatment or via the treatment of a neighbor, <span class="math inline">\(j\)</span>, might have potential outcomes <span class="math inline">\(Y_i(X_i,X_j)=\max(X_i,X_j)\)</span> while another type that is not influenced by neighbor treatment status has <span class="math inline">\(Y_i(X_i,X_j)=\max(X_i)\)</span>. With such a set-up, relevant clue information might discriminate between units affected by spillovers and those unaffected.</p>
</div>
<div id="parameteric-models" class="section level3">
<h3><span class="header-section-number">8.5.5</span> Parameteric models</h3>
</div>
</div>
<div id="conclusion-1" class="section level2">
<h2><span class="header-section-number">8.6</span> Conclusion</h2>
<p>ADD REFERENCE TO TABLE 1 OF FOR MIXED DATA “Ability and Achievement” Otis Duncan</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-humphreys2015mixing">
<p>Humphreys, Macartan, and Alan M Jacobs. 2015. “Mixing Methods: A Bayesian Approach.” <em>American Political Science Review</em> 109 (04): 653–73.</p>
</div>
<div id="ref-king1994designing">
<p>King, G., R.O. Keohane, and S. Verba. 1994. <em>Designing Social Inquiry: Scientific Inference in Qualitative Research</em>. Princeton University Press. <a href="http://books.google.de/books?id=A7VFF-JR3b8C">http://books.google.de/books?id=A7VFF-JR3b8C</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="application-process-tracing-with-a-causal-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixingapp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
