<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Integrated inferences | Illustrating causal models</title>
  <meta name="description" content="Bayesian causal models for integrated inferences." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Integrated inferences | Illustrating causal models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://macartan.github.io/integrated_inferences/" />
  <meta property="og:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />
  <meta property="og:description" content="Bayesian causal models for integrated inferences." />
  <meta name="github-repo" content="macartan/integrated_inferences" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Integrated inferences | Illustrating causal models" />
  
  <meta name="twitter:description" content="Bayesian causal models for integrated inferences." />
  <meta name="twitter:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ptapp.html"/>
<link rel="next" href="mixingapp.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Integrated Inferences</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#counterfactualmodel"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#potential-outcomes"><i class="fa fa-check"></i><b>2.1.1</b> Potential outcomes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#generalization"><i class="fa fa-check"></i><b>2.1.2</b> Generalization</a></li>
<li class="chapter" data-level="2.1.3" data-path="models.html"><a href="models.html#summaries-of-potential-outcomes"><i class="fa fa-check"></i><b>2.1.3</b> Summaries of potential outcomes</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#graphing-models-and-using-graphs"><i class="fa fa-check"></i><b>2.3</b> Graphing models and using graphs</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#graphing"><i class="fa fa-check"></i><b>2.3.1</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.3.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#simplifying-models"><i class="fa fa-check"></i><b>2.3.3</b> Simplifying models</a></li>
<li class="chapter" data-level="2.3.4" data-path="models.html"><a href="models.html#retaining-probabilistic-relations"><i class="fa fa-check"></i><b>2.3.4</b> Retaining probabilistic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#conc2"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.5</b> Chapter Appendix</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.5.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.5.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.5.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.5.3" data-path="models.html"><a href="models.html#rules-for-moving-between-levels"><i class="fa fa-check"></i><b>2.5.3</b> Rules for moving between levels</a></li>
<li class="chapter" data-level="2.5.4" data-path="models.html"><a href="models.html#reading-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.5.4</b> Reading conditional independence from a graph</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform"><i class="fa fa-check"></i><b>3.1</b> Welfare state reform</a></li>
<li class="chapter" data-level="3.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions"><i class="fa fa-check"></i><b>3.2</b> Military Interventions</a></li>
<li class="chapter" data-level="3.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization"><i class="fa fa-check"></i><b>3.3</b> Development and Democratization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Queries</a>
<ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#actual-causes"><i class="fa fa-check"></i><b>4.3</b> Actual causes</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
<li class="chapter" data-level="4.6" data-path="questions.html"><a href="questions.html#general-procedure"><i class="fa fa-check"></i><b>4.6</b> General procedure</a></li>
<li class="chapter" data-level="4.7" data-path="questions.html"><a href="questions.html#appendix"><i class="fa fa-check"></i><b>4.7</b> Appendix</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#features-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Features of Bayesian updating</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>6</b> Theories as causal models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="theory.html"><a href="theory.html#models-as-theories-of"><i class="fa fa-check"></i><b>6.1</b> Models as <em>theories of</em></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="theory.html"><a href="theory.html#implications-of-structural-causal-models"><i class="fa fa-check"></i><b>6.1.1</b> Implications of structural causal models</a></li>
<li class="chapter" data-level="6.1.2" data-path="theory.html"><a href="theory.html#probabilistic-causal-models"><i class="fa fa-check"></i><b>6.1.2</b> Probabilistic causal models</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="theory.html"><a href="theory.html#theorygains"><i class="fa fa-check"></i><b>6.2</b> Gains from theory</a></li>
<li class="chapter" data-level="6.3" data-path="theory.html"><a href="theory.html#formal-theories-and-causal-models"><i class="fa fa-check"></i><b>6.3</b> Formal theories and causal models</a></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="7" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>7</b> Process Tracing with Causal Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>7.1</b> Process tracing and causal models</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>7.1.1</b> The intuition</a></li>
<li class="chapter" data-level="7.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>7.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="7.1.3" data-path="pt.html"><a href="pt.html#priors"><i class="fa fa-check"></i><b>7.1.3</b> Priors</a></li>
<li class="chapter" data-level="7.1.4" data-path="pt.html"><a href="pt.html#updating-on-types-given-the-data."><i class="fa fa-check"></i><b>7.1.4</b> Updating on types given the data.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pt.html"><a href="pt.html#mapping-from-models-to-classic-qualitative-tests"><i class="fa fa-check"></i><b>7.2</b> Mapping from models to classic qualitative tests</a></li>
<li class="chapter" data-level="7.3" data-path="pt.html"><a href="pt.html#assessing-the-possibility-of-probative-value-from-a-graph"><i class="fa fa-check"></i><b>7.3</b> Assessing the possibility of probative value from a graph</a></li>
<li class="chapter" data-level="7.4" data-path="pt.html"><a href="pt.html#principles-of-learning"><i class="fa fa-check"></i><b>7.4</b> Principles of learning</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-us-probative-value-for-a-single-case"><i class="fa fa-check"></i><b>7.4.1</b> A DAG alone does not get us probative value for a single case</a></li>
<li class="chapter" data-level="7.4.2" data-path="pt.html"><a href="pt.html#learning-requires-uncertainty"><i class="fa fa-check"></i><b>7.4.2</b> Learning requires uncertainty</a></li>
<li class="chapter" data-level="7.4.3" data-path="pt.html"><a href="pt.html#the-more-specific-the-query-the-more-difficult-it-is-to-gain-leverage"><i class="fa fa-check"></i><b>7.4.3</b> The more specific the query the more difficult it is to gain leverage</a></li>
<li class="chapter" data-level="7.4.4" data-path="pt.html"><a href="pt.html#population-level-uncertainty-does-not-alter-case-level-causal-inference"><i class="fa fa-check"></i><b>7.4.4</b> Population-level uncertainty does not alter case-level causal inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>8</b> Process Tracing Application: Inequality and Democracy</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>8.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="8.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>8.2</b> A Structural Causal Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>8.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>8.3</b> Results</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>8.3.1</b> Inferences for cases with observed democratization</a></li>
<li class="chapter" data-level="8.3.2" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>8.3.2</b> Cases with incomplete data</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ptapp.html"><a href="ptapp.html#theory-dependence"><i class="fa fa-check"></i><b>8.4</b> Theory dependence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>9</b> Integrated inferences</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mixing.html"><a href="mixing.html#sample-inference"><i class="fa fa-check"></i><b>9.1</b> Sample inference</a></li>
<li class="chapter" data-level="9.2" data-path="mixing.html"><a href="mixing.html#from-sample-queries-to-general-processes"><i class="fa fa-check"></i><b>9.2</b> From sample queries to general processes</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="mixing.html"><a href="mixing.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="mixing.html"><a href="mixing.html#inference"><i class="fa fa-check"></i><b>9.2.2</b> Inference</a></li>
<li class="chapter" data-level="9.2.3" data-path="mixing.html"><a href="mixing.html#wrinkles"><i class="fa fa-check"></i><b>9.2.3</b> Wrinkles</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mixing.html"><a href="mixing.html#mixed-methods"><i class="fa fa-check"></i><b>9.3</b> Mixed methods</a></li>
<li class="chapter" data-level="9.4" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>9.4</b> Considerations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="mixing.html"><a href="mixing.html#probative-value-can-be-derived-from-a-causal-structure-plus-data"><i class="fa fa-check"></i><b>9.4.1</b> Probative value can be derived from a causal structure plus data</a></li>
<li class="chapter" data-level="9.4.2" data-path="mixing.html"><a href="mixing.html#learning-without-identification"><i class="fa fa-check"></i><b>9.4.2</b> Learning without identification</a></li>
<li class="chapter" data-level="9.4.3" data-path="mixing.html"><a href="mixing.html#beyond-binary-data"><i class="fa fa-check"></i><b>9.4.3</b> Beyond binary data</a></li>
<li class="chapter" data-level="9.4.4" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>9.4.4</b> Measurement error</a></li>
<li class="chapter" data-level="9.4.5" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>9.4.5</b> Spillovers</a></li>
<li class="chapter" data-level="9.4.6" data-path="mixing.html"><a href="mixing.html#clustering"><i class="fa fa-check"></i><b>9.4.6</b> Clustering</a></li>
<li class="chapter" data-level="9.4.7" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>9.4.7</b> Parameteric models</a></li>
<li class="chapter" data-level="9.4.8" data-path="mixing.html"><a href="mixing.html#prior-databeliefs-channel-the-learning-from-new-data"><i class="fa fa-check"></i><b>9.4.8</b> Prior data/beliefs “channel” the learning from new data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>10</b> Integrated Inferences Application: Inequality and Democracy Revisited</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>10.1</b> A trained model</a></li>
<li class="chapter" data-level="10.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="mixingapp.html"><a href="mixingapp.html#inference-1"><i class="fa fa-check"></i><b>10.3</b> Inference</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democratization"><i class="fa fa-check"></i><b>10.3.1</b> Did inequality <em>cause</em> democratization?</a></li>
<li class="chapter" data-level="10.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>10.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="mixingapp.html"><a href="mixingapp.html#from-cases-to-population"><i class="fa fa-check"></i><b>10.4</b> From cases to population</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="mixingapp.html"><a href="mixingapp.html#contribution-to-case-level-inference"><i class="fa fa-check"></i><b>10.4.1</b> Contribution to case-level inference</a></li>
<li class="chapter" data-level="10.4.2" data-path="mixingapp.html"><a href="mixingapp.html#how-much-do-we-get-from-the-model-vs.-the-data"><i class="fa fa-check"></i><b>10.4.2</b> How much do we get from the model vs. the data?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>11</b> Mixing models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>11.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="11.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>11.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="11.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>11.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="11.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>11.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#a-model-informed-approach-to-clue-selection"><i class="fa fa-check"></i><b>12.1</b> A model-informed approach to clue-selection</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.1.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.1.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.1.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.1.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.1.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.2</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#conclusion"><i class="fa fa-check"></i><b>12.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Mixed methods data strategies</a>
<ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-strategies"><i class="fa fa-check"></i><b>13.1</b> Case selection strategies</a></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#no-general-rules"><i class="fa fa-check"></i><b>13.2</b> No general rules</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#specific-case-walk-through"><i class="fa fa-check"></i><b>13.3</b> Specific case walk through</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#case-selection-from-causal-models-a-simulation-based-approach"><i class="fa fa-check"></i><b>13.4</b> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wideordeep.html"><a href="wideordeep.html"><i class="fa fa-check"></i><b>14</b> Going wide, going deep</a>
<ul>
<li class="chapter" data-level="14.1" data-path="wideordeep.html"><a href="wideordeep.html#walk-through-of-a-simple-comparison"><i class="fa fa-check"></i><b>14.1</b> Walk-through of a simple comparison</a></li>
<li class="chapter" data-level="14.2" data-path="wideordeep.html"><a href="wideordeep.html#a-simulation-based-approach-to-choosing-mixes"><i class="fa fa-check"></i><b>14.2</b> A simulation-based approach to choosing mixes</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="wideordeep.html"><a href="wideordeep.html#approach"><i class="fa fa-check"></i><b>14.2.1</b> Approach</a></li>
<li class="chapter" data-level="14.2.2" data-path="wideordeep.html"><a href="wideordeep.html#simulation-results"><i class="fa fa-check"></i><b>14.2.2</b> Simulation results</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="wideordeep.html"><a href="wideordeep.html#factoring-in-the-cost-of-data"><i class="fa fa-check"></i><b>14.3</b> Factoring in the cost of data</a></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying.html"><a href="justifying.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="justifying.html"><a href="justifying.html#justifying-probative-value-for-process-tracing"><i class="fa fa-check"></i><b>15.1</b> Justifying probative value for process-tracing</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="justifying.html"><a href="justifying.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.1.2" data-path="justifying.html"><a href="justifying.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.1.2</b> Justifying the classic process-tracing tests</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="justifying.html"><a href="justifying.html#empirical-discovery-of-causal-structure"><i class="fa fa-check"></i><b>15.2</b> Empirical discovery of causal structure</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#four-strategies"><i class="fa fa-check"></i><b>16.1</b> Four Strategies</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.2</b> Bayesian <span class="math inline">\(p-\)</span>value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.3</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.4</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="conclusionchapter.html"><a href="conclusionchapter.html"><i class="fa fa-check"></i><b>17</b> Final Words</a>
<ul>
<li class="chapter" data-level="17.1" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-benefits"><i class="fa fa-check"></i><b>17.1</b> The benefits</a></li>
<li class="chapter" data-level="17.2" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-worries"><i class="fa fa-check"></i><b>17.2</b> The worries</a></li>
<li class="chapter" data-level="17.3" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-future"><i class="fa fa-check"></i><b>17.3</b> The future</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/CausalQueries/" target="blank">Uses CausalQueries</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Illustrating causal models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixing" class="section level1" number="9">
<h1><span class="header-section-number">Chapter 9</span> Integrated inferences</h1>
<div class="headerbox">
<div class="center">

</div>
<p>We extend the analysis of Chapter <a href="pt.html#pt">7</a> to settings in which we can simultaneously learn from cross case data on treatment and outcomes and causal process data for a subset of cases. In doing so we update our theory from cases and <em>use</em> our updated theory to draw case-level inferences. While our process tracing was entirely theory-informed, mixed-data inference is also <em>data</em>-informed.</p>
</div>
<p><br></p>
<!-- to do: likelihood principle -->
<!-- cluster illustration -->
<!-- bring impications of  partial data out of wrinkles / section: in the conclusion-->
<!-- conclusions: mixing and missing data-->
<p><br></p>
<p>In this chapter we generalize the model developed in Chapter <a href="pt.html#pt">7</a> to research situations in which we have data on multiple cases.</p>
<p>We start with a conceptual point: the structure introduced in Chapter 6 for single-case analysis can be used <em>as is</em> for multi-case analysis. Thus, the conceptual work for mixed methods inference from models has been done already. Our goal for the rest of the chapter is thus more technical than conceptual—to show how to shift focus beyond sample level queries and to exploit assumptions regarding independence across cases to generate simpler models of causal processes that affect many units. As we do so, we provide microfoundations for the models in Chapter <a href="ptapp.html#ptapp">8</a> (as with those in <span class="citation"><a href="#ref-humphreys2015mixing" role="doc-biblioref">Humphreys and Jacobs</a> (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>) with the probative value of clues derivable from a causal structure and data rather than provided directly by researchers.</p>
<div id="sample-inference" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Sample inference</h2>
<p>Conceptualized correctly, there is no deep difference between the logic of inference used in single-case and in multi-case studies. This is not because any single “case” can be disaggregated into many “cases,” thereby allowing for large <span class="math inline">\(n\)</span> analysis on small problems <span class="citation">(<a href="#ref-king1994designing" role="doc-biblioref">King, Keohane, and Verba 1994</a>)</span>. Rather, the opposite: fundamentally, model-based inference always involves comparing <em>a</em> pattern of data with the logic of the model. Studies with multiple cases can, in fact, be conceptualized as single-case studies: we always draw our inferences from a single <em>collection</em> of clues, whether those clues have come from one or from many units.</p>
<p>In practice, when we move from a causal model with one observation to a causal model with multiple observations, we can use the structure we introduced in Chapter <a href="pt.html#pt">7</a> but simply replace nodes that have a single value (i.e., scalars) with nodes containing multiple values (i.e., vectors) drawn from multiple cases. We then make inferences about causal relations between nodes from seeing the values of those nodes’ (or other nodes’) vectors.</p>
<p>To illustrate, consider the following situation. Suppose that our model includes a binary treatment <span class="math inline">\(X\)</span> that is assigned to 1 with probability 0.5; an outcome, <span class="math inline">\(Y\)</span>; and a third “clue” variable, <span class="math inline">\(K\)</span>, all observable. We posit an unobserved variable <span class="math inline">\(\theta^Y\)</span>, representing <span class="math inline">\(Y\)</span>’s nodal type, with <span class="math inline">\(\theta^Y\)</span> taking on values in <span class="math inline">\(\{a,b,c,d\}\)</span> with equal probability. (We interpret the types in <span class="math inline">\(\{a,b,c,d\}\)</span> as defined in Section <a href="models.html#counterfactualmodel">2.1</a>.) In addition to pointing into <span class="math inline">\(Y\)</span>, moreover, <span class="math inline">\(\theta^Y\)</span> affects <span class="math inline">\(K\)</span>. In particular, <span class="math inline">\(K=1\)</span> whenever <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(Y\)</span>, while <span class="math inline">\(K=1\)</span> with a 50% probability otherwise. In other words, our clue <span class="math inline">\(K\)</span> is informative about <span class="math inline">\(\theta^Y\)</span>, a unit’s nodal type for <span class="math inline">\(Y\)</span>. As familiar from Chapters <a href="pt.html#pt">7</a> and <a href="ptapp.html#ptapp">8</a>, when we observe <span class="math inline">\(K\)</span> in a case we can update on causal effects within the case since that <span class="math inline">\(K\)</span> value will have different likelihoods under different values of <span class="math inline">\(\theta^Y\)</span>.</p>
<p>So far, we have described the problem at the unit level. Let’s now consider a two-case setup. We do this by exchanging scalar nodes for vectors:</p>
<ul>
<li>We have a treatment node, <span class="math inline">\(X\)</span>, that can take on one of four values, <span class="math inline">\((0,0), (0,1), (1,0), (1,1)\)</span> with equal probability.</li>
<li><span class="math inline">\(\theta^Y\)</span> is now a vector with two elements that can take on one of 16 values <span class="math inline">\((a,a), (a,b),\dots (d,d)\)</span> as determined by <span class="math inline">\(\lambda_\theta\)</span>. We might imagine a uniform distribution over these 16 elements.</li>
<li><span class="math inline">\(Y\)</span> is a vector that is generated by <span class="math inline">\(\theta^Y\)</span> and <span class="math inline">\(\X\)</span> in the obvious way (e.g., <span class="math inline">\(X=(0,0), \theta^Y=(a,b)\)</span> generates outcomes <span class="math inline">\(Y=(1,0)\)</span>)</li>
<li>The vector <span class="math inline">\(K\)</span> has the same domain as <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and element <span class="math inline">\(K[j]=1\)</span> if <span class="math inline">\(\theta^Y[j]=b\)</span>.</li>
</ul>
<p>Now, consider a causal estimand. In a single-case setup, we might ask whether <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(Y\)</span> in the case. For a multi-case setup, we might ask what the Sample Average Treatment Effect, <span class="math inline">\(\tau\)</span>, is. Note a subtle difference in the nature of the answers we seek in these two situations. In the first (single-case) instance, our estimand is binary—of the form: “is the case a <span class="math inline">\(b\)</span> type?”—and our answer is a probability. In the multi-case estimation of the sample average treatment effect (“SATE”), our estimand is categorical and our answer is a probability distribution: we are asking “what is the probability that <span class="math inline">\(\tau\)</span> is 0?,” “what is the probability that <span class="math inline">\(\tau\)</span> is .5?” and so on.</p>
<!-- We will consider three counterfactual possibilities. In one, both units have $X$ forced to 0. In the other two, one unit has $X$ set to 0 and the other has $X$ set to 1. Thus, we are interested in the average effect of changing one unit to treatment while the other is held in control. -->
<p>While the estimand shifts, we can use the tools introduced for single-case process tracing in Chapters <a href="pt.html#pt">7</a> and <a href="ptapp.html#ptapp">8</a> to analyze this (superficially) multi-case study. To begin, our prior on the probability that <span class="math inline">\(\tau=1\)</span> is the prior that <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> in both cases, that is, that <span class="math inline">\(\theta^Y = (b,b)\)</span>: just 1 in 16.</p>
<p>Now, suppose that we observe that, for both units, <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span>. This data pattern is consistent only with four possible <span class="math inline">\(\theta\)</span> vectors: <span class="math inline">\((b,b), (d,d), (b, d), (d,b)\)</span>. Moreoever each of these four is equally likely to produce the data patter we see). So our belief that <span class="math inline">\(\tau=1\)</span> now shifts from 1 in 16 to to 1 in 4. Next, suppose that we further observe the data pattern <span class="math inline">\(\mathbf K = (1,1)\)</span>. The probability of this pattern for <span class="math inline">\(\Theta\)</span> vector <span class="math inline">\((b,b)\)</span> (<span class="math inline">\(\tau = 1\)</span>) is 1. And for the type vectors <span class="math inline">\((d,d), (b, d), (d,b)\)</span>, the probability of this <span class="math inline">\(\mathbf K\)</span> pattern is <span class="math inline">\(.25, .5,\)</span> and <span class="math inline">\(.5\)</span>, respectively. Applying Bayes’ rule, our updated belief that <span class="math inline">\(\tau = 1\)</span> is then <span class="math inline">\(1/(1 + .25 + .5 + .5) = 4/9\)</span>.</p>
<p>We can similarly figure out the posterior probability on any possible value of <span class="math inline">\(\tau\)</span> and so build up a full posterior distribution. And we can do so given any <span class="math inline">\(\mathbf K\)</span> pattern (i.e., <span class="math inline">\(\mathbf K\)</span> realization) across the cases. Thus, if we observe the data pattern <span class="math inline">\(\mathbf K = (0,1)\)</span>, the probability of this pattern for type vector <span class="math inline">\((b,b)\)</span> (<span class="math inline">\(\tau = 1\)</span>) is 0. For the type vectors <span class="math inline">\((d,d), (b, d), (d,b)\)</span> it is <span class="math inline">\(.25, 0, .5\)</span>, respectively. The table below represents the posterior distribution over a set of discrete treatment effect values given different <span class="math inline">\(K\)</span> patterns observed.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span> pattern</th>
<th><span class="math inline">\(Y\)</span> pattern</th>
<th><span class="math inline">\(K\)</span> pattern</th>
<th><span class="math inline">\(\tau = -1\)</span></th>
<th><span class="math inline">\(\tau = -.5\)</span></th>
<th><span class="math inline">\(\tau = 0\)</span></th>
<th><span class="math inline">\(\tau = .5\)</span></th>
<th><span class="math inline">\(\tau = 1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1,1)</td>
<td>(1,1)</td>
<td>(1,1)</td>
<td>0</td>
<td>0</td>
<td>1/9</td>
<td>4/9</td>
<td>4/9</td>
</tr>
<tr class="even">
<td>(1,1)</td>
<td>(1,1)</td>
<td>(1,0)</td>
<td>0</td>
<td>0</td>
<td>1/3</td>
<td>2/3</td>
<td>0</td>
</tr>
<tr class="odd">
<td>(1,1)</td>
<td>(1,1)</td>
<td>(0,0)</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>The conceptual point is that the general logic of inference with multiple units is the same as that with one unit. In both situations, we work out the likelihood of any given data <em>pattern</em> for each possible set of values of model parameters and update our beliefs about those parameters. And, from our posterior distribution over model parameters (e.g., <span class="math inline">\(\Theta^Y\)</span>), we then derive a posterior distribution over the possible answers to our query (e.g., values of <span class="math inline">\(\tau\)</span>).<a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a></p>
<!-- Two points are worth highlighting however. The first is that rather than updating over the query directly (for instance $\tau = .5$) directly, we update over the underlying parameter vector and map from underlying parameters to the query of interest. The second is that representing node values in vector forms like this allows for  vector-level mappings that imply more complex dependencies between units. For instance we might imagine instead that we observe $K=1$ if and only if $\theta = (b,b)$, in which case observation of $K$ lets us distinguish between $\tau = 1$ and $\tau = .5$ but not between $\tau = .5$ and $\tau = 0$. -->
</div>
<div id="from-sample-queries-to-general-processes" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> From sample queries to general processes</h2>
<p>Although the core conceptual logic is the same for multi-case and single-case inference, going forward, we operationalize these problems somewhat differently.</p>
<p>For the remainder of this chapter, and for the rest of the book, when we focus on muti-case studies, we will set our sights primarily on models that describe general processes. Rather than seeking to understand the average effect in a set of cases, we seek to understand the causal relations that gave rise to the set of cases. From these we sometimes draw inferences to cases but in general our models will involve queries pitched in general terms.</p>
<p>There are two reasons for this. The first is that we are interestied in learning across cases: To figure out how what we see in one case provides insight for what is happening in another. We do this by using data on some cases to update our beliefs about a general model that we think is of relevance for other cases. Thus we seek to learn about a general model. The second reason is more practical. The first is that if we can think of units as draws from a large population, and then invoke independence assumptions across types, then we can greatly reduce complexity by analyzing problems at the unit level rather than at the population level. In the 2-case example above, the vector <span class="math inline">\(\theta^Y\)</span> could take on any of 16 values (<span class="math inline">\((a,a), (a,b),\dots (d,d)\)</span>). At the case level, however, the node <span class="math inline">\(\theta^Y\)</span> can take on only 4 values (<span class="math inline">\(\{a,b,c,d\}\)</span>), yet we can learn about each case’s <span class="math inline">\(\theta^Y\)</span> value from data drawn from all the cases. Thinking about it this way simplifies the problem by greatly reducing the parameter space, but it is not free. It requires invoking the assumption that (potential) outcomes across units do not depend on each other. If we cannot stand by that assumption, then we will need to build independence failures into our models.</p>
<p>Taking this step, the procedure we now use in the mixed methods works as follows.</p>
<div id="set-up" class="section level3" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Set up</h3>
<ol style="list-style-type: decimal">
<li><p><strong>A DAG</strong>. As for process tracing, we begin with a graphical causal model specifying possible causal linkages between nodes. Our “chain” model for instance has DAG: <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>.</p></li>
<li><p><strong>Nodal types</strong>. Just as in process tracing, the DAG and variable ranges define the set of possible nodal types in the model—the possible ways in which each variable is assigned (if exogenous) or determined by its parents (if endogenous). For the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model there are 2 types for <span class="math inline">\(\theta^X\)</span>, 4 for <span class="math inline">\(\theta^M\)</span>, and 4 for <span class="math inline">\(\theta^Y\)</span>.</p></li>
<li><p><strong>Causal types</strong>. A full set of nodal types gives rise to a full set of causal types, encompassing all possible combinations of nodal types across all nodes in the model. We let <span class="math inline">\(\theta\)</span> denote an arbitrary causal type. For a <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, one possible causal type would be <span class="math inline">\(\theta = (\theta^X_1, \theta^M_{01}, \theta^M_{01})\)</span>.</p></li>
<li><p><strong>Parameters.</strong> As before, we use <span class="math inline">\(\lambda^V\)</span> to denote the probabilities of <span class="math inline">\(\theta^V\)</span> for a given node, <span class="math inline">\(V\)</span>. Recall that in process tracing, we sought to learn about <span class="math inline">\(\theta\)</span> and our priors were given by <span class="math inline">\(\lambda\)</span>. When we shift to multi-case inference, <span class="math inline">\(\lambda\)</span> becomes the parameter that we want to learn about: we seek to learn about the probability of different types arising in a population (or the <em>shares</em> of types in a large population).</p></li>
<li><p><strong>Priors</strong>. In the process tracing setup, we treat <span class="math inline">\(\lambda\)</span> as given: we do not seek to learn about <span class="math inline">\(\lambda\)</span>, and uncertainty over <span class="math inline">\(\lambda\)</span> plays no role. When we get to observe data on multiple cases, however, we have the opportunity to learn <em>both</em> about the cases at hand <em>and</em> about the population. Moreover, our level of uncertainty about population-level parameters will shape our inferences. We thus want our parameters (the <span class="math inline">\(\lambda\)</span>’s) to be drawn from a prior <em>distribution</em> — a distribution that expresses our uncertainty and over which we can update once we see the data. While different distributions may be appropriate to the task in general, uncertainty over proportions (of cases, events, etc.) falling into a set of discrete categories is usefully described by a Dirichlet distribution, as discussed in Chapter <a href="bayeschapter.html#bayeschapter">5</a>. Recall that the parameters of a Dirichlet distribution (the <span class="math inline">\(\alpha\)</span>’s) can be thought of as conveying both the relative expected proportions in each category and our degree of uncertainty.</p></li>
</ol>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="ii_files/figure-html/unnamed-chunk-10-1.png" alt="Types, parameters, and priors" width="95%" />
<p class="caption">
Figure 9.1: Types, parameters, and priors
</p>
</div>
<div class="headerbox">
<div class="center">

</div>
<p><strong>Box: Setting priors</strong></p>
<p>For a model with no unobserved confounding, setting priors requires specifying a prior distribution for each node. Specifically, we are expressing, for each node, a prior belief about the share of the population that is of each nodal type. We use a Dirichlet distribution, which allows us to indicate both our “best guess” about nodal type shares and our degree of uncertainty about those shares. The parameters of a Dirichlet distribution (the <span class="math inline">\(\alpha\)</span>’s) are provided as vectors of positive numbers with one number for each nodal type. The relative size of each number indicates our prior belief about the relative share of each nodal type. The absolute sizes indiciates our degree of prior certainty in those beliefs.
For a simple <span class="math inline">\(X \rightarrow Y\)</span> model, we have two <span class="math inline">\(\alpha\)</span> parameter sets: one for <span class="math inline">\(X\)</span>’s types and one for <span class="math inline">\(Y\)</span>’s types.</p>
<p>For <span class="math inline">\(X\)</span>’s types, we specify <span class="math inline">\(\alpha^X_0\)</span> and <span class="math inline">\(\alpha^X_1\)</span>, corresponding to the nodal types <span class="math inline">\(\theta^X_0\)</span> and <span class="math inline">\(\theta^X_1\)</span>, respectively. A distribution of the form (<span class="math inline">\(\alpha^X_0=100, \alpha^X_1=100)\)</span>, for instance, implies a great deal of confidence that the population is composed about equally of <span class="math inline">\(\theta^X_0\)</span> and <span class="math inline">\(\theta^X_1\)</span> cases (or, equivalently, that <span class="math inline">\(\lambda^X_1\)</span> is around 0.5). In contrast, a distribution of the form (<span class="math inline">\(\alpha^X_0=.1, \alpha^X_1=.1)\)</span> implies a very high level of uncertainty: we believe that either most cases are <span class="math inline">\(\theta^X_0\)</span>’s or that most cases are <span class="math inline">\(\theta^X_1\)</span>’s, but we are not sure which.</p>
<!-- AJ: NEED SOME MORE REASONING ABOUT THIS 0.1, 0.1 SCENARIO. WHAT DO ALPHA VALUES < 1 MEAN?  -->
<p>For <span class="math inline">\(Y\)</span>’s types, we specify <span class="math inline">\(\alpha^Y_{00}\)</span>, <span class="math inline">\(\alpha^Y_{10}\)</span>, <span class="math inline">\(\alpha^Y_{01}\)</span>, and <span class="math inline">\(\alpha^Y_{11}\)</span>, corresponding to the nodal types <span class="math inline">\(\theta^Y_{00}\)</span>, <span class="math inline">\(\theta^Y_{01}\)</span>, and so on. So, for instance:</p>
<ul>
<li><span class="math inline">\(\alpha^Y_{00}=1\)</span>, <span class="math inline">\(\alpha^Y_{10}=1\)</span>, <span class="math inline">\(\alpha^Y_{01}=1\)</span>, and <span class="math inline">\(\alpha^Y_{11}=1\)</span> yields a uniform prior distribution in which all share allocations of types in the population are equally likely.</li>
<li><span class="math inline">\(\alpha^Y_{00}=3\)</span>, <span class="math inline">\(\alpha^Y_{10}=3\)</span>, <span class="math inline">\(\alpha^Y_{01}=3\)</span>, and <span class="math inline">\(\alpha^Y_{11}=3\)</span> puts somewhat more weight on share allocations in which the shares are relatively equal.</li>
<li><span class="math inline">\(\alpha^Y_{00}=5\)</span>, <span class="math inline">\(\alpha^Y_{10}=5\)</span>, <span class="math inline">\(\alpha^Y_{01}=10\)</span>, and <span class="math inline">\(\alpha^Y_{11}=5\)</span> puts greater weight positive causal effects (<span class="math inline">\(\theta^Y_{01}\)</span>) than on the other three types.</li>
</ul>
<p>In a model without unobserved confounding, we set our beliefs about nodal type shares for each node independently. Thus, we can express more confidence in our beliefs about one node than about another by setting their <span class="math inline">\(\alpha\)</span> values at different absolute levels. However, we would need to introduce unobserved confounding into a model in order to express beliefs about <em>pairings</em> of nodal types <em>across</em> nodes — for instance, the belief that <span class="math inline">\(\theta^Y_{01}\)</span> is more likely when <span class="math inline">\(\theta^X_1 = 1\)</span>.</p>
</div>
</div>
<div id="inference" class="section level3" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Inference</h3>
<p>Inference then works by figuring out the probability of the data given different possible parameter vectors, <span class="math inline">\(\lambdas\)</span>, and then applying Bayes’ rule. In practice we proceed as follows.</p>
<p><strong>Distributions over causal types.</strong> We first need characterize our beliefs about causal types given any possible parameter vector <span class="math inline">\(\lambda\)</span>. Imagine a draw of one possible value of <span class="math inline">\(\lambda\)</span> from the prior. This <span class="math inline">\(\lambda\)</span> vector implies a set of nodal type shares for all nodes. That set of nodal type shares implies, in turn, a distribution over <em>causal</em> types (<span class="math inline">\(\theta\)</span>). For instance, the probability of causal type <span class="math inline">\(\theta = (\theta^X_1, \theta^Y_{01}, \theta^M_{01})\)</span> is simply <span class="math inline">\(p(\theta|\lambda)=\lambda^X_1\lambda^M_{01}\lambda^Y_{01}\)</span>. More generally:</p>
<p><span class="math display">\[p(\theta|\lambda) = \prod_{k,v:\theta^v_k\in\theta}\lambda^v_k\]</span></p>
<p><strong>Event probabilities</strong>. Each causal type in turn implies a single data realization, or data type. For instance <span class="math inline">\(\theta = (\theta^X_1, \theta^M_{01}, \theta^Y_{01})\)</span> implies data <span class="math inline">\(X=1, M=1, Y=1\)</span>. Let <span class="math inline">\(D(\theta)\)</span> denote the data type implied by causal type <span class="math inline">\(\theta\)</span>. A single data type, however, may be implied by multiple causal types. We use <span class="math inline">\(\Theta(d)\)</span> to denote the set of causal types that imply a given data type:</p>
<p><span class="math display">\[\Theta(d) : \{\theta| D(\theta) = d \}\]</span></p>
<p>The probability of a given data type <span class="math inline">\(d\)</span>, is then:</p>
<p><span class="math display">\[w_d = \sum_{\theta \in \Theta(d)}p(\theta|\lambda)\]</span></p>
<p>And we use <span class="math inline">\(\mathbf w\)</span> to denote the vector of event probabilities over all data types.</p>
<p>To illustrate, a data type <span class="math inline">\(d = (X=1, M =1, Y=1)\)</span> is consistent with four different causal types in the <span class="math inline">\(X\rightarrow M\rightarrow Y\)</span> model: <span class="math inline">\(\Theta(d) = \{(\theta^X_0, \theta^M_{01}, \theta^Y_{01}), (\theta^X_0, \theta^M_{11}, \theta^Y_{01}), (\theta^X_0, \theta^M_{01}, \theta^Y_{11}), (\theta^X_0, \theta^M_{11}, \theta^Y_{11})\}\)</span>. The probability of the data type is then calculated by summing up the probabilities of each causal type that implies the event: <span class="math inline">\(w_{111}:=\lambda^X_1(\lambda^M_{01} + \lambda^M_{11}))(\lambda^Y_{01} + \lambda^Y_{11})\)</span>.</p>
<p>In practice, calculating the full <span class="math inline">\(\mathbf w\)</span> vector is made easier by the construction of a “parameter matrix” and an “ambiguity matrix,” just as for process tracing, that tells us which causal types are consistent with a particular data type.</p>
<p>We use Tables <a href="mixing.html#tab:ambigmatrixmix">9.1</a> and <a href="mixing.html#tab:parammmatrixmix">9.2</a> to illustrate how to calculate the event probability for each data type for a given parameter vector <span class="math inline">\(\lambda\)</span>. Starting with data type <span class="math inline">\(X=0, Y=0\)</span> (first column of the ambiguity matrix), we see that the consistent causal types are (<span class="math inline">\(\theta^X_0, \theta^Y_{00}\)</span>) and (<span class="math inline">\(\theta^X_0, \theta^Y_{01}\)</span>), in rows 1 and 4. We then turn to columns 1 and 4 of the parameter matrix to read off the probability of each of these causal types—in each case given by the probability of the nodal types that it is formed out of. This gives <span class="math inline">\(.4 \times .3\)</span> and <span class="math inline">\(.4\times .2\)</span> giving a total probability of <span class="math inline">\(0.2\)</span> for the <span class="math inline">\(X=0, Y=0\)</span> event. All four event probabilities, for the four data types, are then calculated in the same way.</p>
<p>In practice we do this all using matrx operations.</p>
<table>
<caption><span id="tab:ambigmatrixmix">Table 9.1: </span>An ambiguity matrix for a simple <span class="math inline">\(X \rightarrow Y\)</span> model (with no unobserved confounding). Rows are causal types, columns are data types.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">X0Y0</th>
<th align="right">X1Y0</th>
<th align="right">X0Y1</th>
<th align="right">X1Y1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X0Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">X1Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">X0Y10</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">X1Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">X0Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">X1Y01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">X0Y11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">X1Y11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:parammmatrixmix">Table 9.2: </span>A parameter matrix for a simple <span class="math inline">\(X \rightarrow Y\)</span> model (with no unobserved confounding), indicating a single draw of <span class="math inline">\(\lambda\)</span> values from the prior distribution.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">X0.Y00</th>
<th align="right">X1.Y00</th>
<th align="right">X0.Y10</th>
<th align="right">X1.Y10</th>
<th align="right">X0.Y01</th>
<th align="right">X1.Y01</th>
<th align="right">X0.Y11</th>
<th align="right">X1.Y11</th>
<th align="right"><span class="math inline">\(\lambda\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X.0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.4</td>
</tr>
<tr class="even">
<td align="left">X.1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.6</td>
</tr>
<tr class="odd">
<td align="left">Y.00</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.3</td>
</tr>
<tr class="even">
<td align="left">Y.10</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.2</td>
</tr>
<tr class="odd">
<td align="left">Y.01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.2</td>
</tr>
<tr class="even">
<td align="left">Y.11</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0.3</td>
</tr>
</tbody>
</table>
<p><strong>Likelihood</strong>. Now that we know the probability of observing each data pattern in a <em>single</em> case given <span class="math inline">\(\lambda\)</span>, we can use these event probabilities to aggregate up to the likelihood of observing a data pattern across multiple cases (given <span class="math inline">\(\lambda\)</span>). For this aggregation, we make use of an independence assumption: that each unit is independently drawn from a common distribution. Doing so lets us move from a categorical distribution that gives the probability that a single case has a particular data type to a <em>multinomial</em> distribution that gives the probability of seeing an arbitrary data pattern across any number of cases.</p>
<p>Specifically, with discrete variables, we can think of a given multiple-case data pattern simply as a set of counts across categories. For, say, <span class="math inline">\(X, Y\)</span> data, we will observe a certain number of <span class="math inline">\(X=0, Y=0\)</span> cases (which we notate as <span class="math inline">\(n_{00}\)</span>), a certain number of <span class="math inline">\(X=1, Y=0\)</span> cases (<span class="math inline">\(n_{10}\)</span>), a certain number of <span class="math inline">\(X=0, Y=1\)</span> cases (<span class="math inline">\(n_{01}\)</span>), and a certain number of <span class="math inline">\(X=1, Y=1\)</span> cases (<span class="math inline">\(n_{11}\)</span>). A data pattern, given a particular set of variables observed (a search strategy), thus has a multinomial distribution. The likelihood of a data pattern under a given search strategy, in turn, takes the form of a multinomial distribution conditional on the number of cases observed, <span class="math inline">\(n\)</span>, and the probability of each data type, given a <span class="math inline">\(\lambda\)</span> draw. More formally, we write:</p>
<p><span class="math display">\[d \sim \text{Multinomial}(n, w(\lambda))\]</span></p>
<p>Let us assume now that we have a 3-node model, with <span class="math inline">\(X, Y\)</span>, and <span class="math inline">\(M\)</span> all binary. Let <span class="math inline">\(\mathbf n_{XYM}\)</span> denote an 8-element vector recording the number of cases in a sample displaying each possible combination of <span class="math inline">\(X,Y,M\)</span> data, thus: <span class="math inline">\(\mathbf D= \mathbf n_{XYM}:=(n_{000},n_{001},n_{100},\dots ,n_{111})\)</span>. The elements of <span class="math inline">\(\mathbf n_{XYM}\)</span> sum to <span class="math inline">\(n\)</span>, the total number of cases studied. Likewise, let the event probabilities for data types given <span class="math inline">\(\lambda\)</span> be registered in a vector, <span class="math inline">\(\mathbf w_{XYM}=(w_{000},w_{001},w_{100},\dots ,w_{111})\)</span>. The likelihood of a data pattern, <span class="math inline">\(\mathbf D\)</span> is then:</p>
<!-- AJ: is my added use of mathbf above to indicate vectors right? If so, it occurs to me that we should be mathbf'ing lambda just about everywhere. And should it be mathbf D in the equation below?-->
<p><span class="math display">\[
p(d|\lambda) = 
  \text{Multinom}\left(n_{XYM}|\sum n_{XYM}, w_{XYM}(\lambda)\right)  \\
\]</span>
In other words, the likelihood of observing a particular data pattern given <span class="math inline">\(\lambda\)</span> is given by the corresponding value of the multinomial distribution given the data probabilities.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Estimation</strong>. We now have all the components for updating on <span class="math inline">\(\lambda\)</span>. Applying Bayes rule (see Chapter @(bayeschapter)), we have:</li>
</ol>
<p><span class="math display">\[p(\lambda | d) = \frac{p(d | \lambda)p(\lambda)}{\int_{\lambda&#39;}{p(d | \lambda&#39;)p(\lambda&#39;)}}\]</span>
In the <code>CausalQueries</code> package this updating is implemented in <code>stan</code>, and the result of the updating is a dataframe that contains a collection of draws from the posterior distribution for <span class="math inline">\(\lambda\)</span>. Table <a href="mixing.html#tab:posteriortable">9.3</a> illustrates what such a dataframe might look like for an <span class="math inline">\(X\rightarrow M \rightarrow Y\)</span> model. Each row represents a single draw from <span class="math inline">\(p(\lambda|d)\)</span>. The 10 columns represent shares for each of the 10 nodal types in the model, under each <span class="math inline">\(lambda\)</span> draw.</p>
<table>
<caption><span id="tab:posteriortable">Table 9.3: </span>An illustration of a posterior distribution for a <span class="math inline">\(X \leftarrow M \leftarrow Y\)</span> model. Each row is a draw from <span class="math inline">\(p(\lambda|d))\)</span></caption>
<thead>
<tr class="header">
<th align="right">X.0</th>
<th align="right">X.1</th>
<th align="right">M.00</th>
<th align="right">M.10</th>
<th align="right">M.01</th>
<th align="right">M.11</th>
<th align="right">Y.00</th>
<th align="right">Y.10</th>
<th align="right">Y.01</th>
<th align="right">Y.11</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.47</td>
<td align="right">0.53</td>
<td align="right">0.21</td>
<td align="right">0.07</td>
<td align="right">0.17</td>
<td align="right">0.55</td>
<td align="right">0.20</td>
<td align="right">0.23</td>
<td align="right">0.15</td>
<td align="right">0.41</td>
</tr>
<tr class="even">
<td align="right">0.68</td>
<td align="right">0.32</td>
<td align="right">0.02</td>
<td align="right">0.41</td>
<td align="right">0.38</td>
<td align="right">0.19</td>
<td align="right">0.12</td>
<td align="right">0.20</td>
<td align="right">0.07</td>
<td align="right">0.61</td>
</tr>
<tr class="odd">
<td align="right">0.33</td>
<td align="right">0.67</td>
<td align="right">0.16</td>
<td align="right">0.45</td>
<td align="right">0.27</td>
<td align="right">0.12</td>
<td align="right">0.08</td>
<td align="right">0.02</td>
<td align="right">0.81</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td align="right">0.68</td>
<td align="right">0.32</td>
<td align="right">0.15</td>
<td align="right">0.10</td>
<td align="right">0.70</td>
<td align="right">0.05</td>
<td align="right">0.03</td>
<td align="right">0.07</td>
<td align="right">0.00</td>
<td align="right">0.90</td>
</tr>
<tr class="odd">
<td align="right">0.17</td>
<td align="right">0.83</td>
<td align="right">0.02</td>
<td align="right">0.11</td>
<td align="right">0.64</td>
<td align="right">0.22</td>
<td align="right">0.44</td>
<td align="right">0.06</td>
<td align="right">0.30</td>
<td align="right">0.20</td>
</tr>
<tr class="even">
<td align="right">0.83</td>
<td align="right">0.17</td>
<td align="right">0.16</td>
<td align="right">0.08</td>
<td align="right">0.02</td>
<td align="right">0.73</td>
<td align="right">0.49</td>
<td align="right">0.28</td>
<td align="right">0.12</td>
<td align="right">0.11</td>
</tr>
</tbody>
</table>
<ol start="5" style="list-style-type: decimal">
<li><strong>Querying</strong>.</li>
</ol>
<p>Once we have generated a posterior distribution for <span class="math inline">\(\lambda\)</span>, we can then query that distribution. The simplest queries relate to values of <span class="math inline">\(\lambda\)</span>. For instance, if we are interested in the probability that <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span>, given an updated <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, we want to know about the distribution of <span class="math inline">\(\lambda^M_{01}\)</span>. This distribution can be read directly from column 9 (<span class="math inline">\(Y01\)</span>) of Table @(tab:posteriortable). More complex queries can all be described as summaries of combinations of these columns. For instance, the query, “What is the average effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span>” is a question about the distribution of <span class="math inline">\(\lambda^M_{01} - \lambda^M_{10}\)</span>, which is given by the difference between columns 9 and 8 of the table. Still more complex queries may require keeping some nodes constant while varying others, yet all of these can be calculated as summaries of the combinations of columns of the posterior distribution, following the rules described in Chapter <a href="questions.html#questions">4</a>.</p>
<p>Table <a href="mixing.html#tab:chainillustration">9.4</a> shows examples of a full mapping from data to posteriors. We begin with a simple chain model of the form <span class="math inline">\(X\rightarrow M \rightarrow Y\)</span> with flat priors over nodal types and report inferences on a set of queries (columns) for difference data types (rows).</p>
<table>
<caption><span id="tab:chainillustration">Table 9.4: </span>Inferences on a chain model given different amounts of data (all on the diagonal, with X=0, Y=0 or X=1, Y=1). Columns 1-4 are shared of reduced form relations between X and Y, columns 5 - 8 show <span class="math inline">\(\tau_{ij}\)</span>—average effects of <span class="math inline">\(i\)</span> on <span class="math inline">\(j\)</span>; the last column shows the probability of causation.</caption>
<thead>
<tr class="header">
<th align="left">Data</th>
<th align="right">a</th>
<th align="right">b</th>
<th align="right">c</th>
<th align="right">d</th>
<th align="right"><span class="math inline">\(\tau_{XM}\)</span></th>
<th align="right"><span class="math inline">\(\tau_{MY}\)</span></th>
<th align="right"><span class="math inline">\(\tau_{XY}\)</span></th>
<th align="right">PC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">No data</td>
<td align="right">0.13</td>
<td align="right">0.13</td>
<td align="right">0.37</td>
<td align="right">0.38</td>
<td align="right">0.00</td>
<td align="right">-0.01</td>
<td align="right">0.00</td>
<td align="right">0.27</td>
</tr>
<tr class="even">
<td align="left">2 cases X, Y data only</td>
<td align="right">0.12</td>
<td align="right">0.14</td>
<td align="right">0.37</td>
<td align="right">0.37</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.02</td>
<td align="right">0.29</td>
</tr>
<tr class="odd">
<td align="left">2 cases, X, M, Y data</td>
<td align="right">0.12</td>
<td align="right">0.16</td>
<td align="right">0.36</td>
<td align="right">0.36</td>
<td align="right">0.20</td>
<td align="right">0.20</td>
<td align="right">0.04</td>
<td align="right">0.32</td>
</tr>
<tr class="even">
<td align="left">10 cases: X, Y data only</td>
<td align="right">0.11</td>
<td align="right">0.27</td>
<td align="right">0.31</td>
<td align="right">0.31</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.17</td>
<td align="right">0.45</td>
</tr>
<tr class="odd">
<td align="left">10 cases: X, M, Y data</td>
<td align="right">0.09</td>
<td align="right">0.44</td>
<td align="right">0.23</td>
<td align="right">0.23</td>
<td align="right">0.59</td>
<td align="right">0.59</td>
<td align="right">0.35</td>
<td align="right">0.66</td>
</tr>
</tbody>
</table>
<!-- |     **Causal types** $\rightarrow$     | $\theta^X_0,\theta^Y_{00}$ | $\theta^X_1,\theta^Y_{00}$ | $\theta^X_0,\theta^Y_{10}$ | $\theta^X_1,\theta^Y_{10}$ | $\theta^X_0,\theta^Y_{01}$ | $\theta^X_1,\theta^Y_{01}$ | $\theta^X_0,\theta^Y_{11}$ | $\theta^X_1,\theta^Y_{11}$ | Parameter values (a draw from the prior) | -->
<!-- |:--------------------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:-----------------------------------------:| -->
<!-- | **Population parameters** $\downarrow$ |                            |                            |                            |                            |                            |                            |                            |                            |                                           | -->
<!-- |              $\lambda^X_0$             |              0             |              1             |              0             |              1             |              0             |              1             |              0             |              1             |                    0.4                    | -->
<!-- |              $\lambda^X_1$             |              1             |              0             |              1             |              0             |              1             |              0             |              1             |              0             |                    0.6                    | -->
<!-- |            $\lambda^Y_{00}$            |              1             |              1             |              0             |              0             |              0             |              0             |              0             |              0             |                    0.3                    | -->
<!-- |            $\lambda^Y_{10}$            |              0             |              0             |              1             |              1             |              0             |              0             |              0             |              0             |                    0.2                    | -->
<!-- |            $\lambda^Y_{01}$            |              0             |              0             |              0             |              0             |              1             |              1             |              0             |              0             |                    0.2                    | -->
<!-- |            $\lambda^Y_{11}$            |              0             |              0             |              0             |              0             |              0             |              0             |              1             |              1             |                    0.3                    | -->
<!-- Table: (\#tab:parammmatrixmix). A parameter matrix for a simple $X \rightarrow Y$ model (with no unobserved confounding), indicating a single draw of $\lambda$ values from the prior distribution. -->
</div>
<div id="wrinkles" class="section level3" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Wrinkles</h3>
<div id="unobserved-confounding." class="section level4" number="9.2.3.1">
<h4><span class="header-section-number">9.2.3.1</span> Unobserved confounding.</h4>
<p>When there is unobserved confounding, we need parameter sets that allow for a joint distribution over nodal types. Unobserved confounding, put simply, means that there is confounding across nodes that is not captured by nodes and edges represented on the DAG. More formally, in the absence of unobserved confounding, we can treat the distribution of nodal types for a given node as independent of the distribution of nodal types for every other node. Unobserved confounding means that we believe that nodal types may be correlated across nodes. Thus, for instance, we might believe that those units assigned to <span class="math inline">\(M=1\)</span> have different potential outcomes for <span class="math inline">\(Y\)</span> than those assigned to <span class="math inline">\(M=0\)</span> – i.e., that the probability of <span class="math inline">\(M=1\)</span> is correlated with whether or not <span class="math inline">\(M\)</span> has an effect on <span class="math inline">\(Y\)</span>. To allow for such a correlation, we have to allow <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span> to have a joint distribution. There are different ways to do this in practice, but a simple approach is to split the parameter set corresponding to the <span class="math inline">\(Y\)</span> node into two: we specify one distribution for <span class="math inline">\(\theta^Y\)</span> when <span class="math inline">\(M=0\)</span> and a separate distribution for <span class="math inline">\(\theta^Y\)</span> when <span class="math inline">\(M=1\)</span>. For each of these parameter sets, we specify two <span class="math inline">\(\alpha\)</span> parameters representing our priors. We can draw <span class="math inline">\(\lambda\)</span> values for these conditional nodal types from the resulting Dirichlet distributions, as above, and can then calculate causal type probabilities in the usual way. Note that if we do this in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, we have one 2-dimensional Dirichlet distribution corresponding to <span class="math inline">\(X\)</span>, one 4-dimensional Dirichlet distribution corresponding to <span class="math inline">\(M\)</span>, and two 4 dimensional distributions corresponding to <span class="math inline">\(Y\)</span>. In all, with 1+3+3+3 degrees of freedom: exactly the number needed to represent a joint distribution over all <span class="math inline">\(\theta^X, \theta^M, \theta^Y\)</span> combinations.</p>
<!-- AJ: Why do we specify only "two" alpha parameters for each parameter set above? Not 4? -->
<!-- AJ: Check my math on degrees of freedom -->
<p>In the figure below we represent this confounding by indicating parameters values <span class="math inline">\(\lambda_{MY}\)</span> that determine the joint distribution over <span class="math inline">\(\theta_M\)</span> and <span class="math inline">\(\theta_Y\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="ii_files/figure-html/unnamed-chunk-11-1.png" alt="Types, parameters, and priors, with confounding" width="95%" />
<p class="caption">
Figure 9.2: Types, parameters, and priors, with confounding
</p>
</div>
<!-- AJ: dag_3d file seems to have disappeared. -->
</div>
<div id="sampling-and-the-likelihood-principle" class="section level4" number="9.2.3.2">
<h4><span class="header-section-number">9.2.3.2</span> Sampling and the likelihood principle</h4>
<!-- AJ: I haven't done much in this subsection, but I find this subsection quite hard to draw out the main point of. Does it need to be this complex? Could we not focus on just one of the approaches and then briefly signal that we can also construct it in different way, without walking through the other way? Running through both just seems like we're heading off on a bit of a tangent from the perspective of this chapter's objectives. 

I also don't know what it means for something to be "the same up to a constant." -->
<p>In constructing a likelihood function, we need to take the sampling strategy into account. Consider, for instance, the following <em>conditional</em> data strategy: we collect data on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in 2 cases, and we then measure <span class="math inline">\(M\)</span> in any case in which we observe <span class="math inline">\(X=1, Y=1\)</span>.</p>
<p>The probability of each data type is as given in table below:</p>
<table>
<colgroup>
<col width="25%" />
<col width="74%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X1M0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{11}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{00}+\lambda^Y_{01}) + \lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{10}+\lambda^Y_{11}) + \lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{01}+\lambda^Y_{11})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{00}+\lambda^Y_{01}) + \lambda^X_1(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
</tbody>
</table>
<p>The two observations can be thought of as a multinomial draw from these five event types.</p>
<p>Alternatively they can also be thought of as the product of a draw from a strategy in which a set of units is drawn with observations on <span class="math inline">\(X,Y\)</span> only and another set is drawn with observations on <span class="math inline">\(X, M, Y\)</span>.</p>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
<p>Say rather than conditioning <span class="math inline">\(X=Y=1\)</span> to examine <span class="math inline">\(M\)</span> one of the two cases were chosen at random to observe <span class="math inline">\(M\)</span> and it just so happened to be be a case with <span class="math inline">\(X=Y=1\)</span>:</p>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th>type:</th>
<th>prob:</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X0Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{00}+\lambda^Y_{01}) + 0.5\lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01})(\lambda^Y_{10}+\lambda^Y_{11}) + 0.5\lambda^X_0(\lambda^M_{10}+\lambda^M_{11})(\lambda^Y_{01}+\lambda^Y_{11})\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X1Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{00}+\lambda^Y_{01}) + 0.5\lambda^X_1(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{00}+\lambda^M_{10})(\lambda^Y_{10}+\lambda^Y_{11}) + 0.5\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span> +</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(X0M0Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{00}+\lambda^M_{01}))(\lambda^Y_{00}+\lambda^Y_{01})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X0M1Y0\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_0(\lambda^M_{11}+\lambda^M_{10}))(\lambda^Y_{00}+\lambda^Y_{10})\)</span></td>
</tr>
<tr class="odd">
<td>…</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(X1M1Y1\)</span></td>
<td><span class="math inline">\(0.5\lambda^X_1(\lambda^M_{11}+\lambda^M_{01})(\lambda^Y_{11}+\lambda^Y_{01})\)</span></td>
</tr>
</tbody>
</table>
<p>In the single multinomial view we have the probability of seeing data with <span class="math inline">\(X=Y=0\)</span> in one case and <span class="math inline">\(X=1, M=0, Y=1\)</span> in another is now:</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>In the conditional strategy view we have</p>
<ul>
<li><span class="math inline">\(2P(X=0, Y=0)P(X=1, Y=1)P(M=0 | X=1, Y=1)\)</span></li>
</ul>
<p>In the two strategy view we have</p>
<ul>
<li><span class="math inline">\(P(X=0, Y=0)P(X=1, M=0, Y=1)\)</span></li>
</ul>
<p>which is the same up to a constant.</p>
<!-- ## Illustration  -->
<!-- Consider a generalization of the models introduced in Chapter 6 in which a treatment $X$ is a cause of both $K$ and $Y$, and outcome $Y$ is a product of both $X$ and $K$. Though $K$ is both a mediator and a moderator for the effect of $X$. There are now 16 nodal types for $Y$, 4 for $K$ and 2 for $X$, yielding 32 causal types. -->
<!-- To allow for the possibility of non-random selection of $X$ we will assume that the assignment probability for $X$ depends on $U^Y$. This is a feature shared also in the baseline model when we specify $\pi$ as a function of types $a$,$b$,$c$,$d$. -->
<!-- Our piors requires specifying: -->
<!-- 1. A distribution over the 15-dimensional simplex representing possible values of $\lambda^Y$--which in turn determine types $u^Y$. -->
<!-- 2. A distribution over the 3-dimensional vector representing possible values of $\lambda^K$,  which in turn determine types $u^K$. -->
<!-- The model is restricted in various ways. We assume now confounding in the assignemnt of $X$. Less obviously we implicitly assume that $K$ is independent of $\theta^Y$ conditional on $X$. -->
<!-- With these elements in hand, however, all we need now is to provide a mapping from these fundamental parameters to the parameters used in the baseline model to form the likelihood.  -->
<!-- The key transformation is the identification of causal types resulting from the 64 combinations of $\lambda^Y$ and $\lambda^K$. These are shown below. -->
<!-- TABLE TO SHOW CAUSAL TYPES -->
<!-- Consider the following matrices of values for $u_Y$ and $u_K$, where $\lambda_{pq}^{rs}$ is the probability that $u^Y = t_{pq}^{rs}$, meaning that $Y$ would take the value $p$ when $X=0, K=0$,  $q$ when $X=0, K=1$,  $r$ when $X=1, K=0$,  and $s$ when $X=1, K=1$. Similarly $\lambda_{w}^{z}$ is the probability that $u^K$ takes value  $t_{w}^{z}$  meaning that $K$ takes the value $w$ when $X=0$ and $z$ when $X=1$. -->
<!-- TABLE TO SHOW CONDITIONAL PROBABILITIES OF K GIVEN X=1 AND TYPE -->
<!-- These types are the *transformed parameters*; the probability of a type is just the sum of the probabilities of the fundamental types that compose it, formed by taking the product of the $\lambda^Y$ and $\lambda^K$ values marked in the rows and columns of  table \ref{tab:types}.  -->
<!-- Similarly $\phi_{tx}$ can be constructed as the probability of observing $K$ conditional on this type (again, sums of products of probabilities associated with cells in table  \ref{tab:types}). For instance, using the row and column indices in exponents (GIVE FULL LABELS) from table \ref{tab:types}: -->
<!-- $$\phi_{b1}=\frac{\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}{ -->
<!-- \lambda_K^1(\lambda_Y^3+\lambda_Y^4+\lambda_Y^7+\lambda_Y^8)+\lambda_K^2(\lambda_Y^2+\lambda_Y^4+\lambda_Y^6+\lambda_Y^8)+\lambda_K^3(\lambda_Y^3+\lambda_Y^4+\lambda_Y^11+\lambda_Y^{12})+\lambda_K^4(\lambda_Y^2+\lambda_Y^4+\lambda_Y^{10}+\lambda_Y^{12})}$$ -->
<!-- With these transformed parameters in hand, the likelihood is exactly the same as that specified in the baseline model. -->
</div>
<div id="case-inference-following-population-updating" class="section level4" number="9.2.3.3">
<h4><span class="header-section-number">9.2.3.3</span> Case inference following population updating</h4>
<p>We are often in situations in which we observe patterns in <span class="math inline">\(n\)</span> units and then seek to make an inference about one or more of the <span class="math inline">\(n\)</span> cases conditional on <em>both</em> the case level data and the broader patterns in the full data.</p>
<p>Divide cases into set <span class="math inline">\(S^0, S^1\)</span> where <span class="math inline">\(S^0\)</span> is the set for which we wish to make case level inferences and <span class="math inline">\(S^1\)</span> is the collection of other cases for which we have data.</p>
<p>In such cases should one use the data from <span class="math inline">\(S^0\)</span> when updating on population estimands or rather update using <span class="math inline">\(S^1\)</span> only and use information on <span class="math inline">\(S^1\)</span> for the case level inferences only?</p>
<p>The surprising answer is that it is possible to do both, though exactly how queries are calculated depends on the method used.</p>
<p>Let <span class="math inline">\(\Lambda\)</span> denote a collection of possible population parameters with typical element <span class="math inline">\(\lambda^i\)</span>. Let <span class="math inline">\(p\)</span> denote a distribution over <span class="math inline">\(\Lambda\)</span> (after updating on data from set <span class="math inline">\(S^1\)</span>), with typical element <span class="math inline">\(\lambda^i\)</span>. Let <span class="math inline">\(X\)</span> denote possible data for cases in <span class="math inline">\(S^0\)</span> with realization <span class="math inline">\(x\)</span>.</p>
<p>Let <span class="math inline">\(d^i\)</span> denote the probability of observing data <span class="math inline">\(X = x\)</span> for a case (or set of cases) given <span class="math inline">\(\lambda^i\)</span>.</p>
<p>Let <span class="math inline">\(\tau^{|x}\)</span> denote a query of interest—where the query is conditional in the sense that it relates to cases with data <span class="math inline">\(x\)</span>. An example might be: what is the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a case in which <span class="math inline">\(M=1\)</span> and <span class="math inline">\(Y=1\)</span>. Let <span class="math inline">\(q^i_j\)</span> denote the probability that <span class="math inline">\(\tau^{|x} = \tau_j^{|x}\)</span> when <span class="math inline">\(\lambda = \lambda^i\)</span> for a case with data <span class="math inline">\(X=x\)</span>. Note <span class="math inline">\(q^i_j\)</span> can be written <span class="math inline">\(z^i/d^i\)</span> where <span class="math inline">\(z^i_j = \Pr(\tau^{|x} = \tau^{|x}_j, X=x | \lambda^i)\)</span>.</p>
<p>To illustrate say in an <span class="math inline">\(X\rightarrow Y\)</span> model we were interested the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a case with <span class="math inline">\(X=1, Y=1\)</span>. Then <span class="math inline">\(d^i = (\lambda^i)^X_1((\lambda^i)^Y_{01} + (\lambda^i)^Y_{11})\)</span> is the probability of observeing (<span class="math inline">\((X=1, Y=1)\)</span>. Then for query <span class="math inline">\(\tau^{|x}_j = 1\)</span> (did <span class="math inline">\(X\)</span> cause <span class="math inline">\(Y\)</span>) we have <span class="math inline">\(z^i_j = (\lambda^i)^X_1((\lambda^i)^Y_{01})\)</span>, and so the probability of this query for this case given <span class="math inline">\(\lambda^i\)</span> is: <span class="math inline">\(q^i_j = \frac{(\lambda^i)^Y_{01}}{(\lambda^i)^Y_{01} + (\lambda^i)^Y_{11}}\)</span></p>
<p>The posterior on <span class="math inline">\(\tau^{S^0}\)</span> for the cases in <span class="math inline">\(S^0\)</span> that provide data <span class="math inline">\(x\)</span>, is then:</p>
<p><span class="math display">\[\Pr(\tau^{|x} = \tau_j^{|x}) = \frac{p^iz^i_j}{\sum_k p^kd^k}\]</span></p>
<p>This can be calculated from the prior <span class="math inline">\(p\)</span> (that is the distribution on <span class="math inline">\(\Theta\)</span> after updating on cases in <span class="math inline">\(S^1\)</span> only).</p>
<p>Notice however that (a) the <em>posterior</em> distribution on <span class="math inline">\(\lambda^i\)</span> given observation of <span class="math inline">\(x\)</span> in the <span class="math inline">\(S^0\)</span> set is <span class="math inline">\(\frac{p^id^i}{\sum_k p^kd^k}\)</span> and (b) <span class="math inline">\(p^iz^i_j = p^id^iq^i\)</span>. It follows that this quantity can also be interpreted as the posterior mean of <span class="math inline">\(q^i\)</span>, after observing both <span class="math inline">\(S^0\)</span> and <span class="math inline">\(S^1\)</span>.</p>
<p>We therefore have two approaches to calculatin these sample quantities: either take the posterior mean (posterior to <span class="math inline">\(S^0\)</span> and <span class="math inline">\(S^1\)</span>), over the distrubution of <span class="math inline">\(\lambda\)</span> of the conditional probability of the estimand given the case data in <span class="math inline">\(S^0\)</span>, or take the expected probability of <span class="math inline">\(\tau\)</span> given the prior (after observing <span class="math inline">\(S^1\)</span> only) and condition on the probability of the case level data in <span class="math inline">\(S^0\)</span>).</p>
<div class="headerbox">
<div class="center">

</div>
<p><strong>Box: Case inference and population data</strong></p>
<p>When calculating queries in <code>CausalQueries</code> you can specify whether you are interested in “case level” inquiries or population inquiries. A case level inquiry of the form <span class="math inline">\(\tau^{|X}\)</span> is calculated (<code>case_level = TRUE</code>) via <span class="math inline">\(\frac{\int_{\lambda}p(\tau, x|\lambda)p(\lambda)d\lambda}{\int_{\lambda}p(x|\lambda)p(\lambda)d\lambda}\)</span>. In contrast, the mean of population query (<code>case_level = FALSE</code>) is <span class="math inline">\(\int_{\lambda} \frac{p(\tau, x|\lambda)}{p(x|\lambda)}p(\lambda)d\lambda\)</span>.</p>
<!-- * DISCUSS SHARE INTERPRETATION -->
<!-- * HIGHLIGHT FOURTH ROW HAS DOUBLE COUNTING   -->
<p>The example below shows a case where these differ and illustrates two ways in which inferences on sample queries can be made.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="mixing.html#cb7-1" aria-hidden="true" tabindex="-1"></a> <span class="fu">make_model</span>(<span class="st">&quot;X -&gt; Y &lt;- W&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-2"><a href="mixing.html#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_restrictions</span>(<span class="at">labels  =</span> <span class="fu">list</span>(<span class="at">Y =</span> <span class="fu">c</span>(<span class="st">&quot;0101&quot;</span>, <span class="st">&quot;0111&quot;</span>)), <span class="at">keep =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-3"><a href="mixing.html#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_priors</span>(<span class="at">alpha =</span> <span class="dv">100000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-4"><a href="mixing.html#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_priors</span>(<span class="at">node =</span> <span class="st">&quot;W&quot;</span>, <span class="at">alpha =</span> <span class="fu">c</span>(.<span class="dv">5</span>, .<span class="dv">5</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-5"><a href="mixing.html#cb7-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-6"><a href="mixing.html#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(<span class="fu">data.frame</span>(<span class="at">X=</span><span class="dv">1</span>,<span class="at">Y=</span><span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-7"><a href="mixing.html#cb7-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-8"><a href="mixing.html#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">query_model</span>(<span class="st">&quot;Y[X=1] &gt; Y[X=0]&quot;</span>, </span>
<span id="cb7-9"><a href="mixing.html#cb7-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">given =</span> <span class="st">&quot;X==1 &amp; Y==1&quot;</span>, </span>
<span id="cb7-10"><a href="mixing.html#cb7-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">case_level =</span> <span class="fu">c</span>(<span class="cn">FALSE</span>, <span class="cn">TRUE</span>),</span>
<span id="cb7-11"><a href="mixing.html#cb7-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">using =</span> <span class="fu">c</span>(<span class="st">&quot;priors&quot;</span>, <span class="st">&quot;posteriors&quot;</span>),</span>
<span id="cb7-12"><a href="mixing.html#cb7-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">expand_grid =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-13">Table 9.5: </span>The same answers are found using the prior distribution and setting <code>case_estimand</code> to <code>TRUE</code>, and using the posterior distribution but setting <code>case.estimand</code> to <code>FALSE</code>. Other answers are incorrect</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="left">Case.estimand</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">priors</td>
<td align="left">FALSE</td>
<td align="right">0.412</td>
<td align="right">0.347</td>
</tr>
<tr class="even">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">posteriors</td>
<td align="left">FALSE</td>
<td align="right">0.335</td>
<td align="right">0.329</td>
</tr>
<tr class="odd">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">priors</td>
<td align="left">TRUE</td>
<td align="right">0.332</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">Q 1</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">posteriors</td>
<td align="left">TRUE</td>
<td align="right">0.264</td>
<td align="right"></td>
</tr>
</tbody>
</table>
</div>
<p>`</p>
</div>
</div>
</div>
<div id="mixed-methods" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Mixed methods</h2>
<p>We do not need data on all nodes in order to implement the procedure. If we have data on only some of the nodes in a model, we follow the same basic logic as with partial process-tracing data. In calculating the probability of a pattern of partial data, we use all columns (data types) in the ambiguity matrix that are consistent with the partial data.</p>
<p>So, for instance, if we have an <span class="math inline">\(X \rightarrow Y\)</span> model but observe only <span class="math inline">\(Y=1\)</span>, then we would retain both the <span class="math inline">\(X=0, Y=1\)</span> column and the <span class="math inline">\(X=1, Y=1\)</span> column. We then calculate the probability of this data type by summing causal-type probabilities for all causal types that can produce <em>either</em> <span class="math inline">\(X=0, Y=1\)</span> <em>or</em> <span class="math inline">\(X=1, Y=1\)</span>.</p>
<p>What if our data have been collected via a mixture of search strategies? Suppose, for instance, that we have collected <span class="math inline">\(X,Y\)</span> data for a set of cases, and have additionally collected data on <span class="math inline">\(M\)</span> for a random subset of these. We can think of this mixed strategy as akin to conducting quantitative analysis on a large sample while conducting in-depth process tracing on part of the large-<span class="math inline">\(N\)</span> sample. We can then summarize our data in two vectors, an 8-element <span class="math inline">\(n_{XYM}\)</span> vector (<span class="math inline">\((n_{000},n_{001},\dots n_{111}\)</span>) for the cases with process-tracing (<span class="math inline">\(M\)</span>) observations, and a 4-element vector <span class="math inline">\(n_{XY*} = (n_{00*},n_{10*},n_{01*},n_{11*}\)</span> for the partial data on those cases on which we did not conduct process tracing. Likewise, we now have two sets of data probabilities: an 8-element vector for the set of cases with complete data, <span class="math inline">\(w_{XYM}\)</span>, and a 4-element vector for those with partial data, <span class="math inline">\(w_{XY*}\)</span>.</p>
<p>Let <span class="math inline">\(n\)</span> denote the total number of cases examined, and <span class="math inline">\(k\)</span> the number for which we have data on <span class="math inline">\(M\)</span>. Assuming that each observed case represents an independent, random draw from the population, we can form the likelihood function as a <em>product</em> of multinomial distributions, one representing the complete-data (process-traced) cases and one representing those with only <span class="math inline">\(X,Y\)</span> data:</p>
<p><span class="math display">\[\Pr(\mathcal{D}|\theta) = 
  \text{Multinom}\left(n_{XY*}|n-k, w_{XY*}\right) \times \text{Multinom}\left(n_{XYM}|k, w_{XYM}\right)\]</span></p>
<p>We can construct likelihood functions in a similar fashion for any arbitrary mixture of search strategies.</p>
<!-- Illustration -->
</div>
<div id="considerations" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Considerations</h2>
<div id="probative-value-can-be-derived-from-a-causal-structure-plus-data" class="section level3" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Probative value can be derived from a causal structure plus data</h3>
<p>In Chapter <a href="pt.html#pt">7</a>, we discussed the fact that a DAG by itself is insufficient to generate learning about causal effects from data on a single case; we also need informative prior beliefs about population-level shares of nodal types.</p>
<p>When working with multiple cases, however, we <em>can</em> learn about causal relations when starting with nothing more than the DAG and data. In particular, we can simultaneously learn about case-level queries and justify our inferences from population-level data patterns.</p>
<!-- AJ: Reading this now, the wording "and justify our inferences from population-level data patterns" is confusing. Are the *inferences* coming from the pop-level data? Or is the *justifying* coming from the pop-level data? Also, I think this is kind of a backwards way of saying it? I'd think we'd want to say, we can simultaneously learn about population-level queries and justify our inferences about case-level queries. Agreed? -->
<p>For instance, in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, even if we start with flat priors over <span class="math inline">\(M\)</span>’s nodal types, observing a correlation (or no correlation) between <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> across multiple cases provides information about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(M\)</span>. Simply, a stronger, positive (negative) <span class="math inline">\(X, M\)</span> correlation implies a stronger positive (negative) effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span>. In turn, a stronger <span class="math inline">\(X,M\)</span> correlation implies a stronger effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> since, under this model, that effect has to run through an effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span>.</p>
<p>What’s more, data from multiple cases can <em>provide</em> probative value for within-case inference. Suppose, for the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, that we start with flat priors over all nodal types. As discussed in Chapter <a href="pt.html#pt">7</a>, observing <span class="math inline">\(M\)</span> in a single case cannot be informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> in that case. If we have no idea of the direction of the intermediate causal effects, then we have no idea which value of <span class="math inline">\(M\)</span> is more consistent with an <span class="math inline">\(X \rightarrow M\)</span> effect or with an <span class="math inline">\(M \rightarrow Y\)</span> effect. But suppose that we first observe data on <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> for a group of cases and find a strong positive correlation between the two variables. We now update to a belief that any effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> is more likely to be positive than negative. Now, let’s say we look at one of our other cases in which <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span> and want to know if <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Knowing now that any such effect would most likely have operated via a positive <span class="math inline">\(X \rightarrow M\)</span> effect means that observing <span class="math inline">\(M\)</span> will be informative: seeing <span class="math inline">\(M=1\)</span> in this case will be more consistent with an <span class="math inline">\(X \rightarrow Y\)</span> effect than will <span class="math inline">\(M=0\)</span>. The same logic, of course, also holds for observing cross-case correlations between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>Our ability to draw probative value from cross-case data will depend on the causal model we start with. For instance, if our model allows <span class="math inline">\(X\)</span> also to have a direct effect on <span class="math inline">\(Y\)</span>, our ability to learn from <span class="math inline">\(M\)</span> will be more limited. We explore this issue in much greater detail in Chapter @ref(#caseselection).</p>
</div>
<div id="learning-without-identification" class="section level3" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Learning without identification</h3>
<p>Some causal queries are <em>identified</em> while others are not. When a query is identified, each true value for the query is associated with a unique data distribution given infinite data. Thus, as we gather more and more data, our posterior on the query should converge on the true value. When a query is not identified, multiple true values of the query will be associated with the same data distribution given infinite data. With a non-identified query, our posterior will never converge on a unique value regardless of how much data we collect since multiple answers will be equally consistent with the data. A key advantage of causal model framework, however, is that we can <em>learn</em> about queries that are not identified.</p>
<p>We can illustrate the difference between identified and non-identified causal questions by comparing an <span class="math inline">\(ATE\)</span> query to a probability of causation (<span class="math inline">\(PC\)</span>) query for a simple <span class="math inline">\(X \rightarrow Y\)</span> model. When asking about the <span class="math inline">\(ATE\)</span>, we are asking about the average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, or the difference between <span class="math inline">\(\lambda^Y_{01}\)</span> (the share of units with positive effects) and <span class="math inline">\(\lambda^Y_{10}\)</span> (share with negative effects). When asking about the <span class="math inline">\(PC\)</span>, we are asking, for a case with given values of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, about the probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in that case. And a <span class="math inline">\(PC\)</span> query is defined by a different set of parameters. For, say, an <span class="math inline">\(X=1, Y=1\)</span> case and a <span class="math inline">\(X \rightarrow Y\)</span> model, the probability of causation is given by just <span class="math inline">\(\lambda^Y_{01}\)</span>.</p>
<p>Let us assume a “true” set of parameters, unknown to the researcher, such that <span class="math inline">\(\lambda^Y_{01} = 0.6\)</span>, <span class="math inline">\(\lambda^Y_{10} = 0.1\)</span> while we set <span class="math inline">\(\lambda^Y_{00} = 0.2\)</span> and <span class="math inline">\(\lambda^Y_{11} = 0.1\)</span>. Thus, the true average causal effect is <span class="math inline">\(0.5\)</span>. We now use the parameters and the model to simulate a large amount of data (<span class="math inline">\(N=10,000\)</span>). We then return to the model, set flat priors over nodal types, and update the model using the simulated data. We graph the posterior on our two queries, the <span class="math inline">\(ATE\)</span> and the probability of positive causation in an <span class="math inline">\(X=1, Y=1\)</span> case, in Figure <a href="mixing.html#fig:PChist">9.3</a>.</p>
<div class="figure"><span style="display:block;" id="fig:PChist"></span>
<img src="ii_files/figure-html/PChist-1.png" alt="ATE is identified, PC is not identified but has informative bounds" width="672" />
<p class="caption">
Figure 9.3: ATE is identified, PC is not identified but has informative bounds
</p>
</div>
<p>The figure illustrates nicely the difference between an identified and non-identified query. While the <span class="math inline">\(ATE\)</span> converges on the right answer, the probability of causation fails to converge even with a massive amount of data. We see instead a range of values for this query on which our updated model places roughly equal posterior probability.</p>
<p>Importantly, however, we see that we <em>do</em> learn about the probability of causation. Despite the lack of convergence, our posterior rules out a wide range of values. While our prior on the query was 0.5, we have correctly updated toward a range of values that includes (and happens to be fairly well centered over) the true value (<span class="math inline">\(\approx 0.86\)</span>).</p>
<p>A distinctive feature of updating a causal model is that it allows us to learn about non-identified quantities in this manner. We will end up with “ridges” in our posterior distributions: ranges or combinations of parameter values that are equally likely given the data. But our posterior weight can nonetheless shift toward the right answer.</p>
<p>At the same time, for non-identified queries, we have to be cautious about the impact of our priors. As <span class="math inline">\(N\)</span> becomes large, the remaining curvature we see in our posteriors may simply be function of those priors. One way to inspect for this is to simulate a very large dataset and see whether the curvature remainsXXXXXXXXXX A second approach would be to do sensitivity analyses by updating the model on the same data with different sets of priors to see how this affects the shape of the posterior.</p>
<!-- Identified quantity is that each true theta, with infinite data, has a unique data distribution associated with it. If not identified, multiple different thetas will have different infinite-data distributions associated with them. E.g., COE. If it's the same, you won't know which it is. This is why we'll get ridges in the posteriors. So as you scale up data, you might rule out other things, but those theta's will always scale up together. So you'll never discriminate between those, but you'll learn about those things relative other things. -->
<!-- Use Fig. 6.1 from Causal Models guide. -->
<!-- So that's still learning. We can learn about unidentified quantities.   -->
<!-- But the bad news is that, for a not-identified quantity, your priors will matter: the curvature that gives us a maximum in our posterior will be driven by the posteriors. To distinguish between what part of the posterior is from the data and what's from the data would be to simulate infinite data and see what happens to the  -->
<!-- Can also do sensitivity analyses by changing priors. -->
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="mixing.html#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">make_model</span>(<span class="st">&quot;X1 -&gt; M1 -&gt; Y &lt;- M2 &lt;- X2&quot;</span>)</span>
<span id="cb8-2"><a href="mixing.html#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="mixing.html#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># restrict such that *only* M1 OR M2 could cause Y -- can we create a DD test? / achieve identification</span></span></code></pre></div>
</div>
<div id="beyond-binary-data" class="section level3" number="9.4.3">
<h3><span class="header-section-number">9.4.3</span> Beyond binary data</h3>
<p>While the setup used in this book involves only binary nodes, the approach readily generalizes to non-binary data. Moving beyond binary nodes allows for considerably greater flexibility in response functions. For instance, moving from binary to merely 3-level ordinal <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables allows us to represent non-linear and even non-monotonic relationships. It also allows us pose more complex queries, such as, “What is the probability that <span class="math inline">\(Y\)</span> is linear in <span class="math inline">\(X\)</span>?” “What is the probability that <span class="math inline">\(Y\)</span> is concave in <span class="math inline">\(X\)</span>?” or “What is the probability that <span class="math inline">\(Y\)</span> is monotonic in <span class="math inline">\(X\)</span>?”</p>
<p>To move to non-binary measurement, we need to be able to expand the nodal-type space to accommodate the richer range of possible relations between nodes that can take on more than two possible values. Suppose, for instance, that we want to operate with variables with 4 ordinal categories. In an <span class="math inline">\(X \rightarrow Y\)</span> model, <span class="math inline">\(Y\)</span>’s nodal types have to accommodate 4 possible values that <span class="math inline">\(X\)</span> can take on, and 4 possible values that <span class="math inline">\(Y\)</span> can take on for any value of <span class="math inline">\(X\)</span>. This yields <span class="math inline">\(4^4 = 256\)</span> nodal types for <span class="math inline">\(Y\)</span> and 1024 causal types (compared to just 8 in a binary setup).</p>
<p>The <code>CausalQueries</code> package, set up to work most naturally with binary nodes, can be used to represent non-binary data as well. The trick, as it were, is to express integers in base-2 and then represent the integer as a series of 0’s and 1’s on multiple nodes. In base-2 counting we would represent four integer values for <span class="math inline">\(X\)</span> (say, 0, 1, 2,3) using <span class="math inline">\(00, 01, 10, 11\)</span>. If we use one binary node, <span class="math inline">\(X_1\)</span> to represent the first digit, and a second node <span class="math inline">\(X_2\)</span> to represent the second, we have enough information to capture the four values of <span class="math inline">\(X\)</span>. The mapping then is: <span class="math inline">\(X_1 = 0, X_2 = 0\)</span> represents <span class="math inline">\(X=0\)</span>; <span class="math inline">\(X_1 = 0, X_2 = 1\)</span> represents <span class="math inline">\(X=1\)</span>; <span class="math inline">\(X_1 = 1, X_2 = 0\)</span> represents <span class="math inline">\(X=2\)</span>; and <span class="math inline">\(X_1 = 1, X_2 = 1\)</span> represents <span class="math inline">\(X=3\)</span>. We construct <span class="math inline">\(Y\)</span> in the same way. We can then represent a simple <span class="math inline">\(X \rightarrow Y\)</span> relation as a model with two <span class="math inline">\(X\)</span> nodes each pointing into two <span class="math inline">\(Y\)</span> nodes: <span class="math inline">\(Y_1 \leftarrow X_1 \rightarrow Y_2, Y_1 \leftarrow X_2 \rightarrow Y_2\)</span>. To allow for the full range of nodal types we need to allow a joint distribution over <span class="math inline">\(\theta^{X_1}\)</span> and <span class="math inline">\(\theta^{X_2}\)</span> and over <span class="math inline">\(\theta^{Y_1}\)</span> and <span class="math inline">\(\theta^{Y_2}\)</span>, which results in 3 degrees of freedom for <span class="math inline">\(X\)</span> and 255 for <span class="math inline">\(Y\)</span>, as required.</p>
<p>In the illustration below with two 4-level variables, we generate data (<span class="math inline">\(N=100\)</span>) from a non-monotonic process with the following potential outcomes: <span class="math inline">\(Y(0)=0, Y(1)=1, Y(2)=3, Y(3) = 2\)</span>. We then update and report on posteriors on potential outcomes.</p>
<p>We make use of a couple of helper functions to simplify working with conversions from statements on integers to statements on the binary representation of the integers.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="mixing.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A function to generate an integer from values on 2 binary nodes</span></span>
<span id="cb9-2"><a href="mixing.html#cb9-2" aria-hidden="true" tabindex="-1"></a>to_int <span class="ot">&lt;-</span> <span class="cf">function</span>(X1, X2) <span class="fu">strtoi</span>(<span class="fu">paste0</span>(X1, X2), <span class="at">base =</span> <span class="dv">2</span>)</span>
<span id="cb9-3"><a href="mixing.html#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="mixing.html#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># A function to express a query on integer nodes into a query on</span></span>
<span id="cb9-5"><a href="mixing.html#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># binary nodes</span></span>
<span id="cb9-6"><a href="mixing.html#cb9-6" aria-hidden="true" tabindex="-1"></a>Y_x <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb9-7"><a href="mixing.html#cb9-7" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> R.utils<span class="sc">::</span><span class="fu">intToBin</span>(x) </span>
<span id="cb9-8"><a href="mixing.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">case_when</span>(X <span class="sc">==</span>  <span class="st">&quot;0&quot;</span> <span class="sc">~</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), X <span class="sc">==</span> <span class="st">&quot;1&quot;</span>  <span class="sc">~</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb9-9"><a href="mixing.html#cb9-9" aria-hidden="true" tabindex="-1"></a>                 X <span class="sc">==</span> <span class="st">&quot;10&quot;</span> <span class="sc">~</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), X <span class="sc">==</span> <span class="st">&quot;11&quot;</span> <span class="sc">~</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb9-10"><a href="mixing.html#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(<span class="st">&quot;to_int(Y1[X1=&quot;</span>, X[<span class="dv">1</span>], </span>
<span id="cb9-11"><a href="mixing.html#cb9-11" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;, X2=&quot;</span>, X[<span class="dv">2</span>], <span class="st">&quot;], Y2[X1=&quot;</span>, X[<span class="dv">1</span>], <span class="st">&quot;, X2=&quot;</span>, X[<span class="dv">2</span>], <span class="st">&quot;])&quot;</span>)}</span></code></pre></div>
<p>Data from this model looks like this:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="mixing.html#cb10-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb10-2"><a href="mixing.html#cb10-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-3"><a href="mixing.html#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">make_model</span>(<span class="st">&quot;X1 -&gt; Y1 &lt;- X2; X1 -&gt; Y2 &lt;- X2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-4"><a href="mixing.html#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_parameters</span>(<span class="at">node =</span> <span class="st">&quot;Y1&quot;</span>, <span class="at">label =</span> <span class="st">&quot;0101&quot;</span>, <span class="at">parameters =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="mixing.html#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_parameters</span>(<span class="at">node =</span> <span class="st">&quot;Y2&quot;</span>, <span class="at">label =</span> <span class="st">&quot;0110&quot;</span>, <span class="at">parameters =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="mixing.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-7"><a href="mixing.html#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">make_data</span>(<span class="dv">100</span>, <span class="at">using =</span> <span class="st">&quot;parameters&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-8"><a href="mixing.html#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">X =</span> <span class="fu">to_int</span>(X1, X2), <span class="at">Y =</span> <span class="fu">to_int</span>(Y1, Y2))</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-17">Table 9.6: </span>Data from non binary model (selection of rows)</caption>
<thead>
<tr class="header">
<th align="right">X1</th>
<th align="right">X2</th>
<th align="right">Y1</th>
<th align="right">Y2</th>
<th align="right">X</th>
<th align="right">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>Updating and querying is done in the usual way:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="mixing.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">make_model</span>(<span class="st">&quot;X1 -&gt; Y1 &lt;- X2;  X1 -&gt; Y2 &lt;- X2; X1 &lt;-&gt; X2; Y1 &lt;-&gt; Y2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-2"><a href="mixing.html#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(data) <span class="sc">%&gt;%</span></span>
<span id="cb11-3"><a href="mixing.html#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">query_model</span>(<span class="fu">list</span>(<span class="fu">Y_x</span>(<span class="dv">0</span>), <span class="fu">Y_x</span>(<span class="dv">1</span>), <span class="fu">Y_x</span>(<span class="dv">2</span>), <span class="fu">Y_x</span>(<span class="dv">3</span>)), <span class="at">using =</span> <span class="st">&quot;posteriors&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-19">Table 9.7: </span>Posteriors on potential outcomes for non binary model</caption>
<thead>
<tr class="header">
<th align="left">Q</th>
<th align="left">Using</th>
<th align="right">True value</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Y(0)</td>
<td align="left">posteriors</td>
<td align="right">0</td>
<td align="right">0.37</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td align="left">Y(1)</td>
<td align="left">posteriors</td>
<td align="right">1</td>
<td align="right">0.98</td>
<td align="right">0.07</td>
</tr>
<tr class="odd">
<td align="left">Y(2)</td>
<td align="left">posteriors</td>
<td align="right">3</td>
<td align="right">2.60</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td align="left">Y(3)</td>
<td align="left">posteriors</td>
<td align="right">2</td>
<td align="right">2.02</td>
<td align="right">0.07</td>
</tr>
</tbody>
</table>
<p>We see that the model performs well. As in the binary setup, the posterior reflects both the data and the priors. And, as usual, we have access to a full posterior distribution over all nodal types and can thus ask arbitrary queries of the updated model.</p>
<p>The greatest challenge posed by the move to non-binary data is computational. If <span class="math inline">\(Y\)</span> takes on <span class="math inline">\(m\)</span> possible values and has <span class="math inline">\(k\)</span> parents, each taking on <span class="math inline">\(r\)</span> possible values, we then have <span class="math inline">\(m^{r^k}\)</span> nodal types for <span class="math inline">\(Y\)</span>. Thus, the cost of more granular measurement is complexity – an explosion of the parameter space – as the nodal type space expands rapidly with the granularity of measurement and the number of explanatory variables With three 3-level ordinal variables pointing into the same outcome, for instance, we have <span class="math inline">\(3^{27} = 7.6\)</span> <em>trillion</em> nodal types!</p>
<p>We expect that, as measurement becomes more granular, researchers will want to manage the complexity by placing structure onto the possible patterns of causal effects. Structure, imposed through model restrictions, can quite rapidly tame the complexity. For some substantive problems, one form of structure we might be willing to impose is monotonicity. In a <span class="math inline">\(X \rightarrow Y\)</span> model with 3-level variables, excluding non-monotonic effects brings down the number of nodal types from 27 to 17. Alternatively, we may have a strong reason to rule out effects in one direction: disallowing negative effects, for instance, brings us down to 10 nodal types. If we are willing to assume linearity, the number of nodal types falls further to 5.</p>
<!-- REMOVE REFERENCE TO OLS; SAY WE DEAL WITH THIS ELSEWHERE IN THE CONCLUSION. -->
<!-- Of course, standard approaches to empirical modeling typically impose a great deal of structure -- consider, for instance, the ubiquity of the linearity assumption in regression modeling -- for precisely the same reason: to simplify the parameter space. As with other forms of empirical modeling, researchers working with causal models will need to decide how they want to trade off model fit and complexity of the parameter space in the choices they make about nodal measurement and model restrictions.  -->
<!-- We can still think in terms of types -->
<!-- With 3 levels of X and 3 levels of Y, you have 27 possible types. But if you impose linearity, only 5 types. If it's non-negative, there will be a few more. -->
<!-- Warning: gets very complicated -->
<!-- Possible strategy is to impose structure, which other approaches also do.  -->
<!-- Asymptotically approaches linearity -->
</div>
<div id="measurement-error" class="section level3" number="9.4.4">
<h3><span class="header-section-number">9.4.4</span> Measurement error</h3>
<p>One potential application of the approach we have described in this chapter to integrating differing forms of data is to addressing the problem of measurement error. The conceptual move to address measurement error in a causal model setup is quite simple: we incorporate the error-generating process into our model.</p>
<p>Consider, for instance, a model in which we build in a process generating measurement error on the dependent variable.</p>
<p><span class="math display">\[X \rightarrow Y  \rightarrow Y_\text{measured} \leftarrow \text{source of measurement error}\]</span></p>
<p>Here <span class="math inline">\(X\)</span> has an effect on the true value of our outcome of interest, <span class="math inline">\(Y\)</span>. The true value of <span class="math inline">\(Y\)</span>, in turn, has an effect on the value of <span class="math inline">\(Y\)</span> that we measure, but so too does a potential problem with our coding process. Thus, the measured value of <span class="math inline">\(Y\)</span> is a function of both the true value and error.</p>
<p>To motivate the setup, imagine that we are interested in the effect of a rule restricting long-term care staff to working at a single site (<span class="math inline">\(X\)</span>) on outbreaks of the novel coronavirus in long-term care facilities (<span class="math inline">\(Y\)</span>), defined as infections among two or more staff or residents. We do not directly observe infections, however; rather, we observe positive results of PCR tests. We also know that testing is neither comprehensive nor uniform. For some units, regular random testing is carried out on staff and residents while in others only symptomatic individuals are tested. It is the latter arrangement that potentially introduces measurement error.</p>
<p>If we approach the problem naively, ignoring measurement error and treating <span class="math inline">\(Y_\text{measured}\)</span> as though it were identical to <span class="math inline">\(Y\)</span>, a differences in means approach might produce attenuation bias—insofar as we are averaging between the true relationship and 0.</p>
<p>We can do better with a causal model, however. Without any additional data, we can update on both <span class="math inline">\(\lambda_Y\)</span> and <span class="math inline">\(\lambda^{Y_\text{measured}}\)</span>, and our posterior uncertainty would reflect uncertainty in measurement. We could go further if, for instance, we could reasonably exclude negative effects of <span class="math inline">\(Y\)</span> on <span class="math inline">\(Y_\text{measured}\)</span>. Then, if we observe (say) a negative correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_\text{measured}\)</span>, we can update on the substantive effect of interest – <span class="math inline">\(\lambda^Y\)</span> – in the direction of a larger share of negative effects: it is only <em>via</em> negative effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> that a negative correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_\text{measured}\)</span> could emerge. At the same time, we learn about the measure itself as we update on <span class="math inline">\(\lambda^{Y_\text{measured}}\)</span>: the negative observed correlation <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_\text{measured}\)</span> is an indicator of the degree to which <span class="math inline">\(Y_\text{measured}\)</span> is picking up true <span class="math inline">\(Y\)</span>.</p>
<p>We can do better still if we can collect more detailed information on at least some units. One data strategy would be to invest in observing <span class="math inline">\(Y\)</span>, the true outbreak status of each unit, for a subset of units for which we already have data on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_\text{measured}\)</span> — perhaps by implementing a random-testing protocol at a subset of facilities. Getting better measures of <span class="math inline">\(Y\)</span> for some cases will allow us to update more directly on <span class="math inline">\(\lambda^Y\)</span>, the true effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, for those cases. But just as importantly, observing true <span class="math inline">\(Y\)</span> will allow us to update on measurement <em>quality</em>, <span class="math inline">\(\lambda^{Y_\text{measured}}\)</span>, and thus help us make better use of the data we have for those cases where we only observe <span class="math inline">\(Y_\text{measured}\)</span>. This strategy, of course, parallels a commonly prescribed use of mixed methods, in which qualitative research takes place in a small set of units to generate more credible measures for large-<span class="math inline">\(n\)</span> analysis (see, e.g., <span class="citation"><a href="#ref-seawrightbook" role="doc-biblioref">Seawright</a> (<a href="#ref-seawrightbook" role="doc-biblioref">2016</a>)</span>).</p>
<!-- A second data strategy (which could be combined with the first) would be to collect data, for some subset of units, on the source of the measurement error. If we collected data on the use of random vs. symptomatic-only testing, we could then update on two further parameters: $\lambda^\text{source of measurement error}$ and on the part of $\lambda^{Y_\text{measured}}$ representing response of $Y_\text{measured}$. In other words, we would learn both about how prevalent the conditions generating measurement error are and about much they throw off our measure.  -->
<p>In the illustration below, we posit a true average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> of 0.6. We also posit an average “effect” of <span class="math inline">\(Y\)</span> on measured <span class="math inline">\(Y\)</span> of just 0.7, allowing for measurement error.</p>
<p>In this setup, with a large amount of data, we would arrive at a differences-in-means estimate of the effect of <span class="math inline">\(X\)</span> on <em>measured</em> <span class="math inline">\(Y\)</span> of about 0.42. Importantly, this would be the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y_{\text{measured}}\)</span> — not the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> — but if we were not thinking about the possibility of measurement error, we would likely conflate the two, arriving at an estimate far from the true value.</p>
<p>We can improve on this “naive” estimate in a number of ways using a causal model, as shown in Table <a href="mixing.html#tab:measurmenterror">9.8</a>. First, we can do much better simply by undertaking the estimation within a causal model framework, even if we simply make use of the exact same data. We write down the following simple model <span class="math inline">\(X \rightarrow Y \rightarrow Y_\text{measured}\)</span>, and we build in a monotonicity restriction that disallows negative effects of <span class="math inline">\(Y\)</span> on <span class="math inline">\(Y_{\text{measured}}\)</span>. As we can see from the first row in Table <a href="mixing.html#tab:measurmenterror">9.8</a>, our mean estimate of the <span class="math inline">\(ATE\)</span> moves much closer to the true value of 0.6.</p>
<p>Second, we can add data by gathering measures of “true” <span class="math inline">\(Y\)</span> for 20% of our sample. As we can see from the second row in the table, this investment in additional data does not change our posterior mean much but yields a dramatic increase in precision. In fact, as we can see by comparison to the third row, partial data on “true” <span class="math inline">\(Y\)</span> yields an estimate that is almost the same and almost as precise as the one we would arrive it with data on “true” <span class="math inline">\(Y\)</span> for <em>all</em> cases.</p>
<table>
<caption><span id="tab:measurmenterror">Table 9.8: </span>Inferences on effects on true Y given measurement error (true ATE = .6)</caption>
<thead>
<tr class="header">
<th align="left">Data</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Data on Y measured only</td>
<td align="left">posteriors</td>
<td align="right">0.64</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td align="left">Data on true Y for 20% of units</td>
<td align="left">posteriors</td>
<td align="right">0.63</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td align="left">Data on true Y</td>
<td align="left">posteriors</td>
<td align="right">0.61</td>
<td align="right">0.02</td>
</tr>
</tbody>
</table>
<!-- * What if we are naive: attenuation bias with binary -->
<!-- * What if we are aware of risks but don't know how bad bad coding is -->
<!-- * What if we observed bad coding in a subsample -->
<!-- We have assumed no measurement error; in applications there could be considerable interest in measurement error. On one hand clue information may contain information about possible mismeasurement on $X$ and $Y$; on the other hand there might interest in whether measured clues adequately capture those features of a causal process that is thought to be measureable.   -->
<!-- The probability of different types of measurement error can be included among the set of parameters of interest, with likelihood functions adjusted accordingly. Suppose, for instance, that with probability $\epsilon$ a $Y=0$ case is recorded as a $Y=1$ case (and vice versa). Then the event probability of observing an $X=1$,$Y=1$ case, for example, is $\epsilon \lambda_a \pi_a + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_c \pi_c + (1-\epsilon) \lambda_d \pi_d$. %If instead there were measurement error on $X$ but not on $Y$, then the event probability would be: $\epsilon \lambda_a (1-\pi_a) + (1-\epsilon) \lambda_b \pi_b + \epsilon \lambda_d (1-\pi_d) + (1-\epsilon) \lambda_d \pi_d$.  -->
<!-- Similar expressions can be derived for measurement error on $X$ or $K$. Specifying the problem in this way allows us both to take account of measurement error and learn about it. -->
<p>An alternative strategy might involve gathering multiple measures of <span class="math inline">\(Y\)</span>, each with their own independent source of error. Consider the model, <span class="math inline">\(X \rightarrow Y \rightarrow Y_\text{measured[1]}; Y \rightarrow Y_\text{measured[2]}\)</span>. Assume again a true <span class="math inline">\(ATE\)</span> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> of 0.6, that <span class="math inline">\(Y\)</span> has an average effect of 0.7 on both <span class="math inline">\(Y_\text{measured[1]\)</span> and <span class="math inline">\(Y_\text{measured[2]\)</span>, and no negative effects of true <span class="math inline">\(Y\)</span> on the measures.<a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a> In this setup, updating on the true <span class="math inline">\(Y\)</span> can be thought of as a Bayesian version of “triangulation,” or factor analysis. The results in Table <a href="#tab:measurmenterror2"><strong>??</strong></a> are based the same data as in the previous example but now augmented with the second noisy measure for <span class="math inline">\(Y\)</span>.</p>
<table>
<caption><span id="tab:measurementerror2">Table 9.9: </span>Inferences on effects on true Y given two noisy measures (true ATE = .6)</caption>
<thead>
<tr class="header">
<th align="left">Data</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Two noisy measures</td>
<td align="left">posteriors</td>
<td align="right">0.61</td>
<td align="right">0.02</td>
</tr>
</tbody>
</table>
<p>As we can see, two noisy measures perform about as well as access to full data on the true <span class="math inline">\(Y\)</span> (as in Table <a href="mixing.html#tab:measurmenterror">9.8</a>).</p>
<p>The main point here is that measurement error matters for inference and can be taken directly into account within a causal model framework. Confusing measured variables for variables of interest will obviously lead to false conclusions. But if measurement concerns loom large, we can respond by making them part of our model and learning about them. We have illustrated this point for simple setups, but more complex structures could be just as well envisioned, such as those where error is related to <span class="math inline">\(X\)</span> or, more perniciously, to the effects of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="spillovers" class="section level3" number="9.4.5">
<h3><span class="header-section-number">9.4.5</span> Spillovers</h3>
<p>A common threat to causal inference is the possibility of spillovers: a given unit’s outcome being affected by the treatment status of another (e.g., possibly neighboring) unit. We can readily set up a causal model to allow for estimation of various quantities related to spillovers.</p>
<p>Consider, for instance, the causal model represented in Figure <a href="#fig:spillover"><strong>??</strong></a>. We consider here a cluster of 3 units across which spillovers might occur. We might imagine, for instance, a cluster of geographically proximate villages separated from other clusters such that spillovers might occur between villages within a cluster, but can be ruled out across clusters. Here <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> represent village <span class="math inline">\(i\)</span>’s treatment status and outcome, respectively. The pattern of directed edges indicates that each village’s outcome might be affected both by its own and by its neighbors’ treatment status.</p>
<p>We now simulate data that allow for spillovers. Specifically, while independently assigning <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> to treatment <span class="math inline">\(50 \%\)</span> of the time, we (a) set <span class="math inline">\(Y_1\)</span> equal to <span class="math inline">\(X_1\)</span>, meaning that Unit 1 is affected only by its own treatment status and (b) set <span class="math inline">\(Y_2\)</span> equal to <span class="math inline">\(X_1 \times X_2\)</span>, meaning that Unit 2 is equally affected by its own treatment status and that of its neighbor, such that <span class="math inline">\(Y_2 = 1\)</span> only if both Unit 2 and its neighbor are assigned to treatment.</p>
<p>We simulate 100 observations from this data-generating process and then update a model (with flat priors over all nodal types).</p>
<p>Now we can extract a number of spillover-relevant causal quantities from the updated model. First we ask: what is the average effect of exposing a unit <em>directly</em> to treatment (“only_self_treated”) when the neighboring unit is untreated? Under the data-generating process that we have posited, we know that this effect will be <span class="math inline">\(1\)</span> for Unit 1 (which always has a positive treatment effect) and <span class="math inline">\(0\)</span> for Unit 2 (which sees a positive effect of <span class="math inline">\(X_2\)</span> only when <span class="math inline">\(X_1 = 1\)</span>), yielding an average across the two units of <span class="math inline">\(0.5\)</span>. We see from Table XXXX that we update, given our 100 observations, from a prior of 0 to a posterior mean of 0.371, approaching the right answer.</p>
<p>A second question we can ask is about the spillover by itself: what is the average treatment effect for a unit of its neighbor being assigned to treatment when the unit itself is not assigned to treatment (“only_other_treated”)? We know that the correct answer is <span class="math inline">\(0\)</span> since Unit 1 responds only to its own treatment status, and Unit 2 requires that both units be assigned to treatment to see an effect. Our posterior estimate of this effect is right on target, at 0.</p>
<p>We can then ask about the average effect of <em>any</em> one unit being treated, as compared to no units being treated (“one_treated”). This is a more complex quantity. To estimate it, we have to consider what happens to the outcome in Unit 1 when only <span class="math inline">\(X_1\)</span> shifts from control to treatment, with <span class="math inline">\(X_2\)</span> at control (true effect is <span class="math inline">\(1\)</span>); what happens to Unit 1 when only <span class="math inline">\(X_2\)</span> shifts from control to treatment, with <span class="math inline">\(X_1\)</span> at control (true effect is <span class="math inline">\(0\)</span>); and the same two effects for Unit 2 (both true effects are <span class="math inline">\(0\)</span>). We then average across both the treatment conditions and units. We arrive at a posterior mean of <span class="math inline">\(0.186\)</span>, not far from the true value of <span class="math inline">\(0.25\)</span>.</p>
<p>Finally, we can ask about the average effect of both treatments going from control to treatment (“both_treated”). The true value of this effect is <span class="math inline">\(1\)</span> for both units, and the posterior has shifted quite far in the direction of this value.</p>
<p>Obviously, more complex setups are possible. We can also model the process in a way that allows for more learning (pooling) across units. In the present model, learning about effects for Unit 1 in a cluster tells us nothing about effects for Unit 2 in a cluster because they are set up to have completely independent nodal types. We could instead treat all units as drawn from the same population: we could represent this, for instance, in a graph with just one <span class="math inline">\(Y\)</span> and two treatment nodes pointing into it, one for the unit’s own treatment status and one for its neighbor’s treatment status.</p>
<!-- AJ: Can we substitute some other word for "cluster" above to avoid confusion with the concept of clusters as we discuss them in the next subsection? -->
<!-- The dataset will now be structured such that the "unit" of analysis is the *cluster*. WAIT, I AM NOT SURE THIS IS RIGHT. CAN'T WE HAVE THE UNITS BE VILLAGES, WITH THE COLUMNS IN THE DATASET BEING X1, X2, X3, Y_i FOR ALL VILLAGES? -->
<!-- AJ: Fig above isn't displaying. -->
<p><img src="ii_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<table>
<caption><span id="tab:unnamed-chunk-23">Table 9.10: </span>Spillovers queries</caption>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Using</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">only_self_treated</td>
<td align="left">posteriors</td>
<td align="right">0.37</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td align="left">only_other_treated</td>
<td align="left">posteriors</td>
<td align="right">0.00</td>
<td align="right">0.04</td>
</tr>
<tr class="odd">
<td align="left">one_treated</td>
<td align="left">posteriors</td>
<td align="right">0.19</td>
<td align="right">0.04</td>
</tr>
<tr class="even">
<td align="left">both_treated</td>
<td align="left">posteriors</td>
<td align="right">0.75</td>
<td align="right">0.05</td>
</tr>
</tbody>
</table>
<!-- Spillovers may also be addressed through an appropriate definition of causal types. For example a unit $i$ that is affected either by receiving treatment or via the treatment of a neighbor, $j$, might have potential outcomes $Y_i(X_i,X_j)=\max(X_i,X_j)$ while another type that is not influenced by neighbor treatment status has  $Y_i(X_i,X_j)=\max(X_i)$. With such a set-up, relevant clue information might discriminate between units affected by spillovers and those unaffected.    -->
<!-- - With current structure, you can estimate various spillover relevant quantities -->
<!-- - Can think about a dataset in which columns are individuals: a column for each individual's treatment status and a column for each individual's outcome status. A unit is a cluster of individuals in a "closed" system without spillovers beyond them,. -->
<!-- - Units are now groups. Can ask what's the difference in outcome for a unit if $N$ of its neighbors are treated vs. no neighbors treated.  -->
<!-- - Could model an assignment process for spillover experiments:  -->
</div>
<div id="clustering" class="section level3" number="9.4.6">
<h3><span class="header-section-number">9.4.6</span> Clustering</h3>
<p>We can also represent some forms of clustering, understood as the presence of an exogenous but unobserved factor that influences outcomes for some subgroup of units. For instance, we might be interested in the effects of training on individuals’ employment prospects, while recognizing that individuals living in the same neighborhood will be affected by common neighborhood-level features that we cannot directly observe.</p>
<p>We can capture some forms of clustering by placing the cluster-level factor on the graph.<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a> Let us imagine that we are studying the effect of providing public health insurance coverage on health outcomes for individuals in two-adult households that have a single earner. Our units of analysis are individuals, but these units are clustered into pairs within households.</p>
<p>We can represent this situation via the following structural model:</p>
<p><img src="ii_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Let Unit 1 be the adult in paid employment and Unit 2 the adult not in paid employment, with <span class="math inline">\(X_i\)</span> indicating the provision of public health insurance to Unit <span class="math inline">\(i\)</span> and <span class="math inline">\(W\)</span> representing an unobserved household-level factor that moderates causal effects for both units. We restrict the model such that, more specifically, <span class="math inline">\(W\)</span> shuts off effects of health insurance for both individuals. By representing earners and non-earners separately on the graph, we allow for different effects of health insurance for these two different kinds of individuals. By representing the cluster-level factor, <span class="math inline">\(W\)</span>, on the graph, we also allow for <em>learning</em> across types of units: seeing effects (or non-effects) for one kind of unit allows us to update on <span class="math inline">\(W\)</span>’s value, which in turn provides information about effects for the other type of unit.</p>
<p>One question we can ask with this setup is: would we learn more from concentrating our observations within a smaller number of clusters or spreading them out across clusters? In Table <a href="mixing.html#tab:cluster">9.11</a>, we show results from two different data-collection strategies. In one instance, we observe both Unit 1 and Unit 2 in two clusters. In the other instance, we observe only Unit 1 in two clusters and only Unit 2 in two clusters. Both sets of data are drawn from a process in which the true treatment effect is XXXXXX. In both situations, we calculate the same estimand, the average treatment effect, defined as the effect of providing health insurance, averaged across the two unit types.</p>
<!-- AJ: Is the true ATE here just from flat priors? So 0? -->
<!-- AJ: Needs a final paragraph speaking to the results. WHY DO WE THINK THE SECOND STRATEGY IS BETTER? SEEM VERY SIMILAR. -->
<table>
<caption><span id="tab:cluster">Table 9.11: </span>Data from many pairs is more informative than the same data from fewer pairs.</caption>
<thead>
<tr class="header">
<th align="left">Data</th>
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2 obs from each of 2 clusters</td>
<td align="right">0.018</td>
<td align="right">0.094</td>
</tr>
<tr class="even">
<td align="left">1 obs from each of 4 clusters</td>
<td align="right">0.020</td>
<td align="right">0.095</td>
</tr>
</tbody>
</table>
</div>
<div id="parameteric-models" class="section level3" number="9.4.7">
<h3><span class="header-section-number">9.4.7</span> Parameteric models</h3>
<!-- AJ: Needs writing -- or cut?? -->
</div>
<div id="prior-databeliefs-channel-the-learning-from-new-data" class="section level3" number="9.4.8">
<h3><span class="header-section-number">9.4.8</span> Prior data/beliefs “channel” the learning from new data</h3>
<p>When we learn from new data, we always update <em>conditional</em> on any prior information. Consider the following example. Suppose that we are working with our familiar <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. We first observe a large amount of <span class="math inline">\(X,Y\)</span> data in which the two variables are strongly and positively correlated, thus indicative of a positive <span class="math inline">\(ATE\)</span> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Next, we turn to process tracing a small number of cases: suppose we collect data on <span class="math inline">\(M\)</span> in one <span class="math inline">\(X=1, Y=1\)</span> case and one <span class="math inline">\(X=0, Y=0\)</span> case, and we observe <span class="math inline">\(M=1\)</span> in both cases. Well, <span class="math inline">\(M\)</span> is uncorrelated with <span class="math inline">\(X\)</span> across these two cases, constituting evidence against an effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Since these are both cases in which a positive effect <em>could</em> have been operating, this finding will reduce our posterior on the share of positive effects in the population and, in turn, on the <span class="math inline">\(ATE\)</span>.</p>
<p>However, the strong prior information on the <span class="math inline">\(ATE\)</span> that we began with still anchors our updating. Our downward updating on the <span class="math inline">\(ATE\)</span> will be modest since our posterior is always a compromise between our (here, strong) priors and new information. More precisely, we will update less on the <span class="math inline">\(ATE\)</span>, about which we had strong prior information, than we will update about the share of positive effects, about which our prior data provided weaker information.</p>
<p>In addition, there is a knock-on effect for our beliefs about the share of negative effects in the population. If we have a strong prior about the value of the <span class="math inline">\(ATE\)</span>, and our beliefs about the share of positive effects goes down substantially, then our beliefs about the share of negative effects must <em>also</em> fall. (Recall that the <span class="math inline">\(ATE\)</span> is simply the share of positive effects minus the share of negative effects.) Intuitively, we can think of our beliefs about negative effects as updating to “preserve” our beliefs about the <span class="math inline">\(ATE\)</span>. And note that, if we had had <em>no</em> prior information about average effects, then learning about positive effects would have have had no implications for our beliefs about negative effects since there would be no overall constraint on the relationship between positive- and negative effect shares.</p>
<p>A more general way to describe this dynamic is that learning about a kind of case that we directly observe can generate “second-hand” learning about a kind of case that we do not directly observe <em>through</em> the constraint on our beliefs imposed by the our priors. This is, really, just a special instance of our priors generating probative value: our prior on the <span class="math inline">\(ATE\)</span> can make evidence about positive effects informative about negative effects. If we had flat priors on the <span class="math inline">\(ATE\)</span>, learning about positive effects would have no impact on our beliefs about negative effects.</p>
<p>A parallel example arises when we want to learn about a model with multiple causal pathways. Consider the model <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow N \leftarrow X\)</span>, where <span class="math inline">\(X\)</span> can have an effect on <span class="math inline">\(Y\)</span> through either <span class="math inline">\(M\)</span> or <span class="math inline">\(N\)</span>. And let us set priors such that we believe the the two paths to be equally likely. Suppose that, as before, we have started with a substantial amount of <span class="math inline">\(X,Y\)</span> data indicative of a large positive <span class="math inline">\(ATE\)</span>. Now, we look for data on <span class="math inline">\(M\)</span> in a handful of cases and find an <span class="math inline">\(M\)</span> pattern inconsistent with any kind of effect through <span class="math inline">\(M\)</span>. What happens to our beliefs about the <span class="math inline">\(ATE\)</span>? In general, finding evidence against one way an effect can happen should reduce our confidence in the effect happening at all. However, if we have started out with a strong prior on the <span class="math inline">\(ATE\)</span> but equal prior weight on the <span class="math inline">\(M\)</span> and <span class="math inline">\(N\)</span> pathways, then what we will see is countervailing updating across the two pathways: while our confidence in the operation of the <span class="math inline">\(M\)</span> pathway will fall substantially, our posterior on effects operating via the <span class="math inline">\(N\)</span> pathway will <em>rise</em> — because of the constraint on the total effect imposed by our strong priors on the <span class="math inline">\(ATE\)</span>. And our <span class="math inline">\(ATE\)</span> beliefs will fall only modestly. Evidence against the <span class="math inline">\(M\)</span>-pathway effect will function as evidence for the <span class="math inline">\(N\)</span>-pathway effects and, to a limited degree, as evidence against a total effect.</p>
<p>A further implication for process tracing is that there will generally be sharp limits to what we can learn about total effects if we study mediators along only <em>some</em> of the theorized pathways if we already have some prior information about total effects. The difficulty is that whatever we learn from the mediators we <em>do</em> observe will be offset by countervailing shifts in our beliefs about other pathways, generated by the constraint in our prior knowledge about the total effect. Suppose, for instance, that we start with some belief that economic development makes democracy more likely, and we believe that there may be two mechanisms: one operating through a rising middle class and one operating through a more robust and organized working class. Suppose then that we examine data on the organization of the working class and find that it does not vary with per capita GDP. We will then, of course, reduce our confidence in the working-class pathway. However, we must also <em>increase</em> our confidence in the operation of the middle-class pathway — because (a) we have prior reason to believe that the overall development <span class="math inline">\(\rightarrow\)</span> democracy effect exists and (b) we have not observed a mediator along the middle-class pathway. On balance, then, learning about just the one pathway will not have a large impact on beliefs about the overall effect of GDP on democratization. The larger lesson here is that, if our process tracing strategy involves the examination of mediators to learn about total <span class="math inline">\(X \rightarrow Y\)</span> effects, then how much we stand to learn depends on how comprehensively our examination of mediators covers the plausible pathways connecting <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>.</p>
<p>To be clear, we do not need to collect mediator clues on all <em>possible</em> pathways. If we have strong priors that one or more possible pathways are very unlikely, then we might safely be able to avoid collecting observations along those pathways without substantially reducing the prospects for learning.</p>
<p>Also, the specific point that we are making here applies to using mediator data to answer queries about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. If instead we want to know which <em>particular pathway</em> is operating, then the lesson here is quite different, and more encouraging. For one thing, collecting evidence on just one pathway can be highly informative about the operation of that pathway. For another, if we do have strong priors on the <span class="math inline">\(ATE\)</span>, then learning about one pathway can <em>also</em> be informative about other pathways, just as we saw in our <span class="math inline">\(M\)</span>- and <span class="math inline">\(N\)</span>-pathway example.</p>
<!-- ## Principles of reasoning about learning -->
<!-- As we did in Chapter \@ref(pt), we provide here some guidance in how to reason about the learning that arises from mixed data. We focus especially on ways in which learning from multiple cases differs from learning from a single case. -->
<!-- AJ: We'd discussed this going here, but I think it would be better placed in a substantive chapter. This is where people will be more likely to look for it.  -->
<!-- 1. Learning requires uncertainty. And expected learning goes up as you become more uncertain about what you’ll find.  If your causal model puts a very high probability on X having a positive effect on M, and you already know X’s value, you should expect to learn very little from observing M since you’re very likely to see exactly the M value you expect given X. (Currently in Chap. 12)((And we want to make research design choices based on expected learning, not based on the mere possibility of learning: yes, our beliefs will shift if we look for M and find the unexpected value. But because that data-realization is highly unlikely, we expect the learning from observing M to be minimal.  -->
<!-- 2. Pure within-case (or n=1) learning requires informative priors about the nodes to be observed. For instance, in a chain model, where we want to go and observe M, it’s not enough to have an informative prior about the X->Y relationship. We need an informative prior about the X->M or M->Y link in order to learn from M. For instance, are positive X->M effects more common than negative ones? -->
<!-- 4. If there are different ways a query can be satisfied, evidence against one of those ways is evidence against the query as a whole. Say we have a two-path model — with one direct and one indirect path — and we want to know if X affects Y. We observe a mediator, M, along the indirect path in a set of cases. If the M data pattern is inconsistent with an indirect effect, then this is also evidence against an overall effect. In general, finding evidence against one way the effect can happen reduces our confidence in the effect happening at all.  -->
<!-- Moreover, the degree to which prior data constrains learning depends, of course, on how much prior data we have. In the $X \rightarrow M \rightarrow Y$ model, if we have observed only a small amount of prior $X,Y$ data, then observing $M$ in a handful of cases will lead us to update more strongly on the $ATE$ in the above examples, then observing the M data in the on-the-regression-line cases will have a weaker impact on our beliefs about negative effects, and a bigger impact on our beliefs about ATE. Ditto for the 2-path model example. However, where prior data/beliefs on the ATE are strong, we’ll learn less about the ATE, and more about negative effects (or the direct path).  -->
<!-- 7. If there are different ways in which a query can be satisfied, evidence against the likelier way is stronger evidence against the query than is evidence against an unlikelier way. In the 2-path model, if we started out thinking that the indirect effect was more likely than the direct effect, then evidence against the direct effect will have a bigger impact on our beliefs about the overall model.  -->
<!-- 8. It is difficult to get empirical leverage on very unlikely queries. And queries may be unlikelier than they appear. Suppose we start with the 2-path model, and want to know if X has a positive effect on Y that rests on a chain of positive effects via M. And suppose, importantly, that we begin with flat priors over all nodal types. Our intuitions likely tell us that this is exactly the kind of question for which an observation of M is the perfect empirical strategy. And that intuition is, in a sense, correct: we can indeed learn about the query by observing M. Seeing M=1 in an X=Y=1 case, for instance. would be evidence consistent with the query while M=0 would be inconsistent. Fine. ((But we will only learn a little from this observation. The reason is that the query itself has a very low prior probability. It may actually not be obvious at first glance just how unlikely our query is to be true. (After all, the model has two causal paths, and we’re asking if positive effects run through one of them, right? Not quite.) Seeing this requires us to think about the joint probabilities implied by the query. First, the query requires X to have a positive effect on M, which we think there’s only a 25% chance of. In addition, the query puts a very narrow constraint on Y’s possible nodal types:  Y has to have a nodal type in which M has a positive effect on Y when X does not change, and in which X does not have a positive effect on Y unless M changes from 0 to 1. This pair of conditions is met by only 2 of Y’s 16 nodal types, implying a 12.5% chance. The prior on the query is thus 0.25 x 0.125 = 0.03125. Thus, while observing M=0 takes the probability of the query down to 0%, we started out very close to 0%! And observing M=1 results in only a small uptick, to about 6% because there remain many type combinations consistent with M=1 but that do not fit through the needle-eye of this query. -->
<!-- ADD REFERENCE TO TABLE 1 OF FOR MIXED DATA "Ability and Achievement" Otis Duncan -->

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-humphreys2015mixing" class="csl-entry">
Humphreys, Macartan, and Alan M Jacobs. 2015. <span>“Mixing Methods: A Bayesian Approach.”</span> <em>American Political Science Review</em> 109 (04): 653–73.
</div>
<div id="ref-king1994designing" class="csl-entry">
King, G., R. O. Keohane, and S. Verba. 1994. <em>Designing Social Inquiry: Scientific Inference in Qualitative Research</em>. Princeton University Press. <a href="http://books.google.de/books?id=A7VFF-JR3b8C">http://books.google.de/books?id=A7VFF-JR3b8C</a>.
</div>
<div id="ref-seawrightbook" class="csl-entry">
Seawright, Jason. 2016. <em>Multi-Method Social Science: Combining Qualitative and Quantitative Tools</em>. New York: Cambridge University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="62">
<li id="fn62"><p>Representing node values in vector forms like this allows for vector-level mappings that imply more complex dependencies between units. For instance we might imagine instead that we observe <span class="math inline">\(K=1\)</span> if and only if <span class="math inline">\(\theta^Y = (b,b)\)</span>, in which case observation of <span class="math inline">\(K\)</span> lets us distinguish between <span class="math inline">\(\tau = 1\)</span> and <span class="math inline">\(\tau = .5\)</span> but not between <span class="math inline">\(\tau = .5\)</span> and <span class="math inline">\(\tau = 0\)</span>.<a href="mixing.html#fnref62" class="footnote-back">↩︎</a></p></li>
<li id="fn63"><p>Importantly, this model assumes nodal types for <span class="math inline">\(Y_\text{measured[1]\)</span> and <span class="math inline">\(Y_\text{measured[2]\)</span> are independent of one another (no unobserved confounding), implying independent sources of measurement error in this setup.<a href="mixing.html#fnref63" class="footnote-back">↩︎</a></p></li>
<li id="fn64"><p>In this illustration the two units in each pair are treated as separate nodes rather than as repeated instances of realizations of the same node. Implicitly then the effect for one unit type (men, say) can be quite independent of the effect of another type (women, say). Indeed, here they are linked only through the unobserved variable <span class="math inline">\(W\)</span>.<a href="mixing.html#fnref64" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ptapp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixingapp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
