<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Where does probative value come from? | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Where does probative value come from? | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Where does probative value come from? | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="caseselection.html">
<link rel="next" href="evaluation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Integrands</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-centrality-of-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Centrality of Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.1</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.2</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.2</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#features-of-causal-models"><i class="fa fa-check"></i><b>2.2.1</b> Features of causal models</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.3</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#causal-models-from-the-literature"><i class="fa fa-check"></i><b>2.3</b> Causal models from the literature</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#pierson-on-dismantling-the-welfare-state"><i class="fa fa-check"></i><b>2.3.1</b> Pierson on dismantling the welfare state</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4</b> Steps for constructing causal models</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#abstract-procedure"><i class="fa fa-check"></i><b>2.4.1</b> Abstract procedure</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#inequalitytheory"><i class="fa fa-check"></i><b>3.1</b> Two theories of inequality’s effects on democratization</a><ul>
<li class="chapter" data-level="3.1.1" data-path="theory.html"><a href="theory.html#theory-as-causal-functions"><i class="fa fa-check"></i><b>3.1.1</b> Theory as causal functions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.2</b> Theory as a “lower-level” model</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#disggregating-nodes"><i class="fa fa-check"></i><b>3.2.1</b> Disggregating nodes</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#generalizing-a-model"><i class="fa fa-check"></i><b>3.2.2</b> Generalizing a model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#mappings-are-not-one-to-one"><i class="fa fa-check"></i><b>3.3.1</b> Mappings are not one-to-one</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#permissible-moves-across-levels"><i class="fa fa-check"></i><b>3.3.2</b> Permissible moves across levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#beneath-the-graph-causal-types-in-lower-level-models"><i class="fa fa-check"></i><b>3.4</b> Beneath the Graph: Causal Types in Lower-Level Models</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#medtheory"><i class="fa fa-check"></i><b>3.4.1</b> Mediation as Theory</a></li>
<li class="chapter" data-level="3.4.2" data-path="theory.html"><a href="theory.html#modtheory"><i class="fa fa-check"></i><b>3.4.2</b> Moderation as Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
<li class="chapter" data-level="3.6" data-path="theory.html"><a href="theory.html#appendix-illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.6</b> Appendix: Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#causal-queries"><i class="fa fa-check"></i><b>4.1</b> Causal queries</a><ul>
<li class="chapter" data-level="4.1.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.1.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.1.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.1.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.1.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.1.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.1.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.1.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.1.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#illustration-with-the-running-example"><i class="fa fa-check"></i><b>4.2</b> Illustration with the Running Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> Bayes’ Rule for Continuous Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Inference on Queries</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayesian-correlational-inference"><i class="fa fa-check"></i><b>5.2.2</b> Bayesian correlational inference</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.3</b> Simple Bayesian Process Tracing</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneoues-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneoues, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="clues.html"><a href="clues.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="clues.html"><a href="clues.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="clues.html"><a href="clues.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="clues.html"><a href="clues.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="clues.html"><a href="clues.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="clues.html"><a href="clues.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clues.html"><a href="clues.html#conditional-independence-alone-does-not-provide-probative-value"><i class="fa fa-check"></i><b>6.2.1</b> Conditional independence alone does not provide probative value</a></li>
<li class="chapter" data-level="6.2.2" data-path="clues.html"><a href="clues.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.2</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.3" data-path="clues.html"><a href="clues.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.3</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.4" data-path="clues.html"><a href="clues.html#probative-value"><i class="fa fa-check"></i><b>6.2.4</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a><ul>
<li class="chapter" data-level="7.3.1" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.3.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.3.2" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.3.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.4</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.5" data-path="application-process-tracing-with-a-causal-model.html"><a href="application-process-tracing-with-a-causal-model.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.5</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#the-parameter-matrix"><i class="fa fa-check"></i><b>8.2.1</b> The parameter matrix</a></li>
<li class="chapter" data-level="8.2.2" data-path="mixing.html"><a href="mixing.html#the-ambiguity-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The ambiguity matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="mixing.html"><a href="mixing.html#likelihood"><i class="fa fa-check"></i><b>8.2.3</b> Likelihood</a></li>
<li class="chapter" data-level="8.2.4" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.4</b> Estimation</a></li>
<li class="chapter" data-level="8.2.5" data-path="mixing.html"><a href="mixing.html#mixed-data"><i class="fa fa-check"></i><b>8.2.5</b> Mixed data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.5</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="10" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>10</b> Elements of Design</a><ul>
<li class="chapter" data-level="10.1" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-process-tracing-design"><i class="fa fa-check"></i><b>10.1</b> Declaring a process tracing design</a><ul>
<li class="chapter" data-level="10.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#steps"><i class="fa fa-check"></i><b>10.1.1</b> Steps</a></li>
<li class="chapter" data-level="10.1.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-in-code"><i class="fa fa-check"></i><b>10.1.2</b> Illustration in code</a></li>
<li class="chapter" data-level="10.1.3" data-path="elements-of-design.html"><a href="elements-of-design.html#diagnosands-evaluating-a-model"><i class="fa fa-check"></i><b>10.1.3</b> Diagnosands: Evaluating a model</a></li>
<li class="chapter" data-level="10.1.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-measures-of-a-gain-from-a-theory"><i class="fa fa-check"></i><b>10.1.4</b> Other measures of a gain from a theory</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="elements-of-design.html"><a href="elements-of-design.html#declaring-a-mixed-methods-design"><i class="fa fa-check"></i><b>10.2</b> Declaring a mixed methods design</a><ul>
<li class="chapter" data-level="10.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model"><i class="fa fa-check"></i><b>10.2.1</b> Model</a></li>
<li class="chapter" data-level="10.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#data-strategies"><i class="fa fa-check"></i><b>10.2.2</b> Data strategies</a></li>
<li class="chapter" data-level="10.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#estimands"><i class="fa fa-check"></i><b>10.2.3</b> Estimands</a></li>
<li class="chapter" data-level="10.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#answer-strategies"><i class="fa fa-check"></i><b>10.2.4</b> Answer Strategies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html"><i class="fa fa-check"></i><b>11</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="11.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#a-strategic-approach"><i class="fa fa-check"></i><b>11.1</b> A strategic approach</a></li>
<li class="chapter" data-level="11.2" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-running-example"><i class="fa fa-check"></i><b>11.2</b> Clue selection for the running example</a><ul>
<li class="chapter" data-level="11.2.1" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#dynamic-strategies"><i class="fa fa-check"></i><b>11.2.1</b> Dynamic Strategies</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#clue-selection-for-the-democracy-model"><i class="fa fa-check"></i><b>11.3</b> Clue selection for the Democracy model</a></li>
<li class="chapter" data-level="11.4" data-path="clue-selection-as-a-decision-problem.html"><a href="clue-selection-as-a-decision-problem.html#conclusion-2"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>12</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="12.1" data-path="wide.html"><a href="wide.html#intuitions-does-a-sufficiently-large-n-always-trump-k"><i class="fa fa-check"></i><b>12.1</b> Intuitions: Does a sufficiently large <span class="math inline">\(N\)</span> always trump <span class="math inline">\(K\)</span>?</a></li>
<li class="chapter" data-level="12.2" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>12.2</b> Evaluating strategies</a></li>
<li class="chapter" data-level="12.3" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>12.3</b> Varieties of mixing</a></li>
<li class="chapter" data-level="12.4" data-path="wide.html"><a href="wide.html#AppSimNotes"><i class="fa fa-check"></i><b>12.4</b> Notes on Simulations</a><ul>
<li class="chapter" data-level="12.4.1" data-path="wide.html"><a href="wide.html#AppE1"><i class="fa fa-check"></i><b>12.4.1</b> Probative values</a></li>
<li class="chapter" data-level="12.4.2" data-path="wide.html"><a href="wide.html#AppE2"><i class="fa fa-check"></i><b>12.4.2</b> Effect heterogeneity</a></li>
<li class="chapter" data-level="12.4.3" data-path="wide.html"><a href="wide.html#AppE3"><i class="fa fa-check"></i><b>12.4.3</b> Uncertainty about assignment processes</a></li>
<li class="chapter" data-level="12.4.4" data-path="wide.html"><a href="wide.html#AppE4"><i class="fa fa-check"></i><b>12.4.4</b> Uncertainty regarding the probative value of clues</a></li>
<li class="chapter" data-level="12.4.5" data-path="wide.html"><a href="wide.html#details-on-simulation-experiments"><i class="fa fa-check"></i><b>12.4.5</b> Details on simulation experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>13.1</b> Explorations</a><ul>
<li class="chapter" data-level="13.1.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>13.1.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#in-code"><i class="fa fa-check"></i><b>13.2</b> In code</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#compare-multiple-data-strategies"><i class="fa fa-check"></i><b>13.3</b> Compare multiple data strategies</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#experiments"><i class="fa fa-check"></i><b>13.4</b> Experiments</a></li>
<li class="chapter" data-level="13.5" data-path="caseselection.html"><a href="caseselection.html#chapter-appendix-accounting-for-case-selection"><i class="fa fa-check"></i><b>13.5</b> Chapter Appendix: Accounting for case selection</a><ul>
<li class="chapter" data-level="13.5.1" data-path="caseselection.html"><a href="caseselection.html#independent-case-selection-strategy"><i class="fa fa-check"></i><b>13.5.1</b> Independent case selection strategy</a></li>
<li class="chapter" data-level="13.5.2" data-path="caseselection.html"><a href="caseselection.html#conditional-random-case-selection"><i class="fa fa-check"></i><b>13.5.2</b> Conditional random case selection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="14" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html"><i class="fa fa-check"></i><b>14</b> Where does probative value come from?</a><ul>
<li class="chapter" data-level="14.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#causal-discovery"><i class="fa fa-check"></i><b>14.1</b> Causal discovery</a></li>
<li class="chapter" data-level="14.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#the-possibility-of-identification-of-probative-value-from-experimental-data"><i class="fa fa-check"></i><b>14.2</b> The possibility of identification of probative value from experimental data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#moderator"><i class="fa fa-check"></i><b>14.2.1</b> Moderator</a></li>
<li class="chapter" data-level="14.2.2" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#mediator"><i class="fa fa-check"></i><b>14.2.2</b> Mediator</a></li>
<li class="chapter" data-level="14.2.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#generally-not-so-easy"><i class="fa fa-check"></i><b>14.2.3</b> Generally not so easy</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#bounds-on-causes-of-effects"><i class="fa fa-check"></i><b>14.3</b> Bounds on causes of effects</a></li>
<li class="chapter" data-level="14.4" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#qualitative-beliefs-and-sensitivity-analyses"><i class="fa fa-check"></i><b>14.4</b> Qualitative beliefs and Sensitivity Analyses</a></li>
<li class="chapter" data-level="14.5" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#conditional-claims"><i class="fa fa-check"></i><b>14.5</b> Conditional claims</a></li>
<li class="chapter" data-level="14.6" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-about-parameters-within-a-model"><i class="fa fa-check"></i><b>14.6</b> Learning about parameters within a model</a></li>
<li class="chapter" data-level="14.7" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-from-observational-and-experimental-mixtures"><i class="fa fa-check"></i><b>14.7</b> Learning from observational and experimental mixtures</a></li>
<li class="chapter" data-level="14.8" data-path="where-does-probative-value-come-from.html"><a href="where-does-probative-value-come-from.html#learning-across-populations"><i class="fa fa-check"></i><b>14.8</b> Learning across populations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>15</b> Robustness and Model-Evaluation</a><ul>
<li class="chapter" data-level="15.1" data-path="evaluation.html"><a href="evaluation.html#tools-for-evaluating-models"><i class="fa fa-check"></i><b>15.1</b> Tools for evaluating models</a></li>
<li class="chapter" data-level="15.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>15.2</b> Evaluating the Democracy-Inequality model</a></li>
<li class="chapter" data-level="15.3" data-path="evaluation.html"><a href="evaluation.html#prior-check"><i class="fa fa-check"></i><b>15.3</b> Prior check</a></li>
<li class="chapter" data-level="15.4" data-path="evaluation.html"><a href="evaluation.html#monotonic-restrictions"><i class="fa fa-check"></i><b>15.4</b> Monotonic restrictions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>16</b> Final Words</a><ul>
<li class="chapter" data-level="16.1" data-path="final-words.html"><a href="final-words.html#some-conclusions"><i class="fa fa-check"></i><b>16.1</b> Some conclusions</a></li>
<li class="chapter" data-level="16.2" data-path="final-words.html"><a href="final-words.html#words-of-warning"><i class="fa fa-check"></i><b>16.2</b> Words of warning</a></li>
<li class="chapter" data-level="16.3" data-path="final-words.html"><a href="final-words.html#general-and-specific-knowledge"><i class="fa fa-check"></i><b>16.3</b> General and specific knowledge</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="17" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>17</b> Analysis of canonical models with <code>gbiqq</code></a><ul>
<li class="chapter" data-level="17.1" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-no-confounding"><i class="fa fa-check"></i><b>17.1</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, no confounding</a></li>
<li class="chapter" data-level="17.2" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-unmodelled-confounding"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with unmodelled confounding</a></li>
<li class="chapter" data-level="17.3" data-path="examplesappendix.html"><a href="examplesappendix.html#x-causes-y-with-confounding-modelled"><i class="fa fa-check"></i><b>17.3</b> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, with confounding modelled</a></li>
<li class="chapter" data-level="17.4" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-mediation-model"><i class="fa fa-check"></i><b>17.4</b> Simple mediation model</a></li>
<li class="chapter" data-level="17.5" data-path="examplesappendix.html"><a href="examplesappendix.html#simple-moderator-model"><i class="fa fa-check"></i><b>17.5</b> Simple moderator model</a></li>
<li class="chapter" data-level="17.6" data-path="examplesappendix.html"><a href="examplesappendix.html#an-iv-model"><i class="fa fa-check"></i><b>17.6</b> An IV model</a></li>
<li class="chapter" data-level="17.7" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-that-allows-application-of-the-frontdoor-criterion"><i class="fa fa-check"></i><b>17.7</b> A model that allows application of the frontdoor criterion</a></li>
<li class="chapter" data-level="17.8" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-with-a-violation-of-sequential-ignorability"><i class="fa fa-check"></i><b>17.8</b> A model with a violation of sequential ignorability</a></li>
<li class="chapter" data-level="17.9" data-path="examplesappendix.html"><a href="examplesappendix.html#learning-from-a-collider"><i class="fa fa-check"></i><b>17.9</b> Learning from a collider</a></li>
<li class="chapter" data-level="17.10" data-path="examplesappendix.html"><a href="examplesappendix.html#a-model-mixing-observational-and-experimental-data"><i class="fa fa-check"></i><b>17.10</b> A model mixing observational and experimental data</a></li>
<li class="chapter" data-level="17.11" data-path="examplesappendix.html"><a href="examplesappendix.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>17.11</b> Transportation of findings across contexts</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="where-does-probative-value-come-from" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Where does probative value come from?</h1>
<hr />
<p>We outline strategies to reduce reliance on unfounded beliefs about the probative value of clues.</p>
<hr />
<p>Everything we have talked about so far assume that researchers are able to state priors on all the primitives entering into the analysis.</p>
<p>But what if they cannot?</p>
<p>As we have noted, learning in the framework we have described can occur even with “flat” priors over causal effects and assignment probabilities. However priors on the probative value of clues have to be informative. We also suspect, however, that researchers usually have—or could readily formulate—a rough idea of where they believe the parameter values lie. They have approximate prior beliefs about whether a causal effect is very common or not very common; whether confounding is likely or unlikely; and whether a given feature of a process is highly likely to be observed, moderately likely to be observed or very unlikely to observed under a given causal theory. Indeed, beliefs about these last two parameters already play a central role in standard approaches to correlational analysis and process tracing. This means that researchers should be in a position to specify a limited range of plausible values for each of the model’s primitives. They can then use the model to explore the consequences of different values in this plausible range either for their findings (given a set of collected data) or for their research design choices (prior to collecting data). And they can express their conclusions explicitly as <em>conditional</em> on their priors, or report findings for a range of prior values. Even where researchers are reluctant to quantify their beliefs, we believe that the principles underlying the BIQQ approach can nonetheless offer valuable, heuristic guidance on how to interpret mixes of qualitative and quantitative evidence in ways that are internally consistent and make more complete use of the available information.</p>
<p>At the same time, it is consequential where researchers’ priors—in particular, their priors on the probabilities of clues—come from: whether they reflect some form of empirical knowledge or derive purely from theory. If a theory <span class="math inline">\(T\)</span> suggests that clue <span class="math inline">\(K\)</span> will be observed if and only if <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, then the presence of <span class="math inline">\(K\)</span> provides evidence that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> <em>only to the extent that <span class="math inline">\(T\)</span> provides a true account of the causal logic through which <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span></em>. If <span class="math inline">\(T\)</span> captures the wrong mechanism of causation, for instance, then clue probabilities that derive from the theory may be wrong and causal inferences that are based on the observation of these clues will be wrong. To use process data to make claims about causal effects that are <em>not</em> conditional on theories, researchers need empirical support for claims on the probative value of clues. This may often be difficult to obtain. In particular, it requires that {knowledge travel}: whereas in traditional Bayesian analysis researchers often employ uninformative (flat) priors, the use of clue-based data contributes to analysis <em>only if</em> priors are informative.</p>
<p>Finally, we believe that the model is useful in part <em>because</em> it places such high demands on scholars’ beliefs about the probative value of within case data: that is, because it clearly identifies the required inputs into the process of drawing integrated causal inferences. Put differently, to the extent that scholars are unable to specify even approximate ranges on these parameters, this is a problem for causal inference, not a problem for the model. The framework thus has implications for research agendas in identifying the kinds of knowledge that scholars need to generate if they are to use mixed methods to provide causal accounts of the world.</p>
<div id="causal-discovery" class="section level2">
<h2><span class="header-section-number">14.1</span> Causal discovery</h2>
<p>We start with a model with three variables, <span class="math inline">\(X,M,Y\)</span> where <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> directly and indirectly through <span class="math inline">\(M\)</span>. We simulate data from this model – assuming monotonicity but otherwise a flat distribution on types, and then try to recover the structure from this model.</p>
<p>In this case the data structure did not impse restrictions on the skeleton. The true graph can however be recovered with knowledge of the temporal ordering of variables.</p>
<p>Next we consider the model in which X causes Y through M but not directly. In this case we have a restriction — specifically there is no arrow pointing directly from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>. Again we impose monotonicity, draw data, and try to recover the model:</p>
<p>Again we have the correct skeleton and knowldge of timing is enough to recover the graph.</p>
<p>Finally we consider the model in which <span class="math inline">\(Y\)</span> has two causes that do not influence each other. Again we impose monotonicity, draw data, and try to recover the model:</p>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="ii_files/figure-html/unnamed-chunk-6-1.png" alt="DAGs from Data" width="480" />
<p class="caption">
Figure 14.1: DAGs from Data
</p>
</div>
</div>
<div id="the-possibility-of-identification-of-probative-value-from-experimental-data" class="section level2">
<h2><span class="header-section-number">14.2</span> The possibility of identification of probative value from experimental data</h2>
<p>Imagine we had access to infinite experimental data on the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> and we want to know for a case (exchangeable with any other in this population) with <span class="math inline">\(X=Y=1\)</span>, whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>— PC. Our experimental data can be written as a transition matrix as follows:</p>
<p><span class="math display">\[P^{u}=\left( \begin{array}{cc} 0.50 &amp; 0.50 \\ 0.25 &amp; 0.75 \end{array}\right)\]</span>
If we have prior beliefs about the distribution of causal types, then PC would be simply <span class="math inline">\(\frac{\lambda^u_b}{\lambda^u_b + \lambda^u_d}\)</span>.</p>
<p>But let’s assume we cannot justify such beliefs. In this case, from results in MURTAS REF, we can still place bounds on PC:</p>
<p><span class="math display">\[\frac13 \leq PC \leq \frac23 \]</span>
For intuition note that <span class="math inline">\(P^{xy}\)</span> implies a causal effect of .25 and so the lowest value of <span class="math inline">\(\lambda_b^u\)</span> consistent with <span class="math inline">\(P^{xy}\)</span> arises when <span class="math inline">\(\lambda_b^u = .25\)</span> and <span class="math inline">\(\lambda_a^u = 0\)</span>, in which case <span class="math inline">\(\lambda_c^u = .25\)</span> and <span class="math inline">\(\lambda_d^u = .5\)</span>. In this case <span class="math inline">\(\lambda_b^u/(\lambda_b^u+ \lambda_d^u)=\frac{1}{3}\)</span>. The highest consistent value of <span class="math inline">\(\lambda_b^u\)</span> arises when <span class="math inline">\(\lambda_b^u = .5\)</span> and <span class="math inline">\(\lambda_a^u = .25\)</span>, in which case <span class="math inline">\(\lambda_c^u = 0\)</span> and <span class="math inline">\(\lambda_d^u = .25\)</span>. In this case <span class="math inline">\(\lambda_b^u/(\lambda_b^u+ \lambda_d^u)=\frac{2}{3}\)</span>.</p>
<p>Say now we have access to auxiliary data <span class="math inline">\(K\)</span> and plan to make inferences based on <span class="math inline">\(K\)</span>.</p>
<p>We will suppose first that <span class="math inline">\(K\)</span> is a moderator and second that <span class="math inline">\(K\)</span> is a mediator.</p>
<div id="moderator" class="section level3">
<h3><span class="header-section-number">14.2.1</span> Moderator</h3>
<p>Consider first a situation in which our case is drawn from a set of cases for which <span class="math inline">\(X\)</span> adn <span class="math inline">\(K\)</span> were each randomly assigned. Say then that the transition matrices, conditionl on <span class="math inline">\(K\)</span> look as follows:</p>
<p><span class="math display">\[P^{K=0}=\left( \begin{array}{cc} 0 &amp; 1 \\ 0.5 &amp; 0.5 \end{array}\right), P^{K=1}=\left( \begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \end{array}\right)\]</span>
In this case we can now identify PC, even before observing <span class="math inline">\(K\)</span>. If <span class="math inline">\(K=0\)</span>, PC is 0—there are no cases with positive effects in this condition. If <span class="math inline">\(K=1\)</span> PC = 1. We have a prior that <span class="math inline">\(K=1\)</span> of .5 and after observing <span class="math inline">\(X=Y=1\)</span> we raise this to <span class="math inline">\(2/3\)</span>. Thus our prior belief on <span class="math inline">\(PC\)</span> — before seeing <span class="math inline">\(K\)</span>— is <span class="math inline">\(2/3 * 1 + 1/3 * 0 = 2/3\)</span>.</p>
<p>How about <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span>?</p>
<p>Here positive effects only arise when <span class="math inline">\(K=1\)</span> and so <span class="math inline">\(\phi_{b1} = 1\)</span>. <span class="math inline">\(Y=1\)</span> without being cause by <span class="math inline">\(X\)</span> only if <span class="math inline">\(K=0\)</span> and so <span class="math inline">\(\phi_{b0} = 0\)</span>. Thus we have a double decisive clue.</p>
</div>
<div id="mediator" class="section level3">
<h3><span class="header-section-number">14.2.2</span> Mediator</h3>
<p>Consider now a case with mediation. Say now that <em>in addition</em> we know from experimental data, that <span class="math inline">\(K\)</span> mediates the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; indeed we will assume that we have a case of complete mediation, such that, conditional on <span class="math inline">\(K\)</span>, <span class="math inline">\(Y\)</span> does not depend on <span class="math inline">\(X\)</span>. The transition matrices from <span class="math inline">\(X\)</span> to <span class="math inline">\(K\)</span> and <span class="math inline">\(K\)</span> to <span class="math inline">\(Y\)</span> are:</p>
<p><span class="math display">\[P^{xk}=\left( \begin{array}{cc} 1 &amp; 0 \\ 1/2 &amp; 1/2\end{array}\right), P^{ky}=\left( \begin{array}{cc} 1/2 &amp; 1/2 \\ 0 &amp; 1\end{array}\right)\]</span>
Even without observing <span class="math inline">\(K\)</span>, this information is sufficient to place a prior on PC of <span class="math inline">\(p=\frac13\)</span>.</p>
<p>To see this, note that we can calculate:</p>
<ul>
<li><span class="math inline">\(\lambda_a^K =0\)</span>, <span class="math inline">\(\lambda_b^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^K = \frac{1}{2}\)</span>, <span class="math inline">\(\lambda_d^K = 0\)</span></li>
<li><span class="math inline">\(\lambda_a^Y =0\)</span>, <span class="math inline">\(\lambda_b^Y=\frac{1}{2}\)</span>, <span class="math inline">\(\lambda_c^Y=0\)</span>, <span class="math inline">\(\lambda_d^Y=\frac{1}{2}\)</span></li>
</ul>
<p>and so:</p>
<ul>
<li><span class="math inline">\(\lambda_b^u = \lambda_b^K\lambda_b^Y = \frac{1}4\)</span></li>
<li><span class="math inline">\(\lambda_d^u = \lambda_d^Y\)</span></li>
<li><span class="math inline">\(p = \frac{\lambda_b^u}{\lambda_b^u + \lambda_d^u} = \frac{1}3\)</span>.</li>
</ul>
<p>whence:</p>
<ul>
<li><span class="math inline">\(\phi_{b1} = 1\)</span></li>
<li><span class="math inline">\(\phi_{d1} = \lambda_d^K + \lambda_b^K = \frac{1}{2}\)</span></li>
</ul>
</div>
<div id="generally-not-so-easy" class="section level3">
<h3><span class="header-section-number">14.2.3</span> Generally not so easy</h3>
<p>Thus we can <em>in principle</em> calculate the <span class="math inline">\(\phi\)</span>s from experimental data given a mediation process. In this case we get a strong hoop test.</p>
<p>Note that this agrees with the calculation of <span class="math inline">\(PC|K\)</span> in MURTAS REF, which does not make use of a calculation of <span class="math inline">\(\phi\)</span>s.</p>
<p><span class="math display">\[PC | K = 1 = \frac{\phi_b p}{\phi_b p + \phi_d (1-p)} = \frac{1 \times\frac13}{1 \times\frac13 + \frac{1}{2} \times \frac23}  = \frac{1}{2}\]</span></p>
</div>
</div>
<div id="bounds-on-causes-of-effects" class="section level2">
<h2><span class="header-section-number">14.3</span> Bounds on causes of effects</h2>
<p>We are interested in quantities such as <span class="math inline">\(\phi_{b1}, \phi_{d1}\)</span>—the probability that <span class="math inline">\(K=1\)</span> given <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> and <span class="math inline">\(X=Y=1\)</span> in a model with mediation. <a href="#eq:phis_from_lambdas">Equation</a> gave expressions for this when the <span class="math inline">\(\lambda\)</span>s were known.</p>
<p>What if they are not?</p>
<p>In this case it can be possible to calculate the bounds on <span class="math inline">\(\phi_{b1}, \phi_{d1}\)</span>. Consider a chain with transition matrices <span class="math inline">\(P(\tau_1, \sigma_1), P(\tau_2, \sigma_2)\)</span>. We are interested in:</p>
<p><span class="math display">\[\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + \lambda_{a}^K\lambda_{a}^Y}\]</span></p>
<p>Noting that <span class="math inline">\(\tau_j = \lambda_{b_j} - \lambda_{a_j}\)</span>, and <span class="math inline">\(\tau\)</span> is known.</p>
<p><span class="math display">\[\phi_{b1} = \frac{\lambda_{b}^K\lambda_{b}^Y}{\lambda_{b}^K\lambda_{b}^Y + (\lambda_{b}^K-\tau_1)(\lambda_{b}^Y - \tau_2)}\]</span>
which we can see is decreasing in <span class="math inline">\(\lambda_{b_j}\)</span> (this may seem counterintuitive, but hte reason is that with <span class="math inline">\(\tau_j\)</span> fixed, lower <span class="math inline">\(\lambda_{b_j}\)</span> also means lower <span class="math inline">\(\lambda_{a_j}\)</span> which means less ambiguity about <em>how</em> <span class="math inline">\(X\)</span> affects <span class="math inline">\(Y\)</span> (ie through positive or negative effects on <span class="math inline">\(K\)</span>).</p>
<p><!-- $$\phi_{1} = \frac{\lambda_{b}^Y}{2\lambda_{b}^Y -\tau_2 - \tau_1(\lambda_{b}^Y - \tau_2)/\lambda_{b}}^K$$ --></p>
<p>The lowest permissible value of <span class="math inline">\(\lambda_{b_j}\)</span> is <span class="math inline">\(\tau_j\)</span>, yielding <span class="math inline">\(\phi_1 = 1\)</span>.</p>
<p>The highest value obtainable by <span class="math inline">\(\lambda_{b_j}\)</span> is when <span class="math inline">\(\lambda_{a_j} = \frac{1-\tau_j+\rho_j}2\)</span> and so <span class="math inline">\(\lambda_{b_j} = \frac{1+\tau_j+\rho_j}2\)</span>.</p>
<p>In this case:
<span class="math display">\[\phi_{b1} = \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2) + (1-\tau_1+\rho_1)(1-\tau_2+\rho_2)}= \frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau}\]</span></p>
<p>And so:</p>
<p><span class="math display">\[\frac{(1+\tau_1+\rho_1)(1+\tau_2+\rho_2)}{2(1+\rho_1)(1+\rho_2) + 2\tau_1\tau_2} \leq \phi_{b1} \leq 1\]</span>
These are the bounds on <span class="math inline">\(\phi_{b1}\)</span>. We can calculate bounds on <span class="math inline">\(\phi_{d1}\)</span> in a similar way—though of course these are not independent.</p>
<p><img src="ii_files/figure-html/unnamed-chunk-7-1.png" width="768" /><img src="ii_files/figure-html/unnamed-chunk-7-2.png" width="768" /></p>
<p><span class="math display">\[\phi_{d1} = \frac{\lambda_{b}^K\lambda_{d}^Y}{(\lambda_{a}^K + \lambda_{b}^K + \lambda_{c}^K)\lambda_{d}^Y+ \lambda_{c}^K\lambda_{a}^Y}\]</span></p>
<p>For the smoking gun, <span class="math inline">\(\phi_{b1}\)</span> is .5 because <span class="math inline">\(\lambda_a^j = \lambda_b^j\)</span> exactly; <span class="math inline">\(\phi_{d1}\)</span> might be low as <span class="math inline">\(d\)</span> types mostly arise because of <span class="math inline">\(c\)</span> types in the first step and <span class="math inline">\(a\)</span> types in the second.
.</p>
<p>this is achived with a low value of <span class="math inline">\(\lambda_{d}^Y\)</span></p>
<p>Whether the bounds map into useful probabitve value depends in part on whether causal effects are better identified in the first or the second stage.</p>
<p><img src="ii_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="qualitative-beliefs-and-sensitivity-analyses" class="section level2">
<h2><span class="header-section-number">14.4</span> Qualitative beliefs and Sensitivity Analyses</h2>
<p>A first strategy to address concerns around weak foundations for claims on probative value—even after attempting to introduce information on uncertainty around probative value, is to assess the extent to which conclusions depend on the details of information provided. In some cases conclusions may be very sensitive to details provided; in other cases not so much.</p>
<p>For a simple illustration, say one’s prior is that it is equally likely that a case is a <span class="math inline">\(B\)</span> or <span class="math inline">\(D\)</span> type. Say one thinks that <span class="math inline">\(\phi_D=0\)</span> and so seeing a clue provides a smoking gun test. Then conditional on seeing the clue, the conclusion is the same no matter what the actual value of <span class="math inline">\(\phi_B\)</span>—as long as <span class="math inline">\(\phi_B&gt;0\)</span>. The details do not matter in this (albeit extreme case). In this case if a clue is not see then the conclusions can depend quite strongly on the value of <span class="math inline">\(\phi_B\)</span> however: the posterior could range from <span class="math inline">\(0.5\)</span> in the case where <span class="math inline">\(\phi_B=0\)</span> (and so the clue is not informative at all) to <span class="math inline">\(0\)</span> in the case where <span class="math inline">\(\phi_B = 1\)</span> (and so the clue is double decisive). Thus how sensitive conclusions are to beliefs depend very much on the data at hand.</p>
<p>For a larger <span class="math inline">\(n\)</span> illustration, refer back to our example of large <span class="math inline">\(n\)</span> data in chapter 9 where we saw that when there is confidence around assignment probabilities (as for example in an RCT) then, with large <span class="math inline">\(N\)</span>, conclusions do not depend strongly on clue information about a handful of cases, no matter what the probative value.</p>
<p>More generally there is a literature on probabilistic causal models that assess the scope for inferences when researchers provide ranges of plausible values for parameters (perhaps intervals, perhaps only signs, positive negative, zero), rather than specifying a probability distribution. For a comprehensive treatment of qualitative algebras, see <span class="citation">Parsons (<a href="#ref-parsons2001qualitative">2001</a>)</span>. Applied to the example above we might imagine a researcher willing to say that they think <span class="math inline">\(\phi_B\)</span> is not plausibly greater than .5, but unwilling to make a statement about their beliefs about where in the <span class="math inline">\(0\)</span> to <span class="math inline">\(0.5\)</span> range it lies. In this case, with the other parameter values outlined above the conclusions will lie in <span class="math inline">\(0.5\)</span> and <span class="math inline">\(0.33\)</span>—ruling out half the possible ranges on the parameter results in a ruling out of a two thirds of the possible range of the conclusion.</p>
</div>
<div id="conditional-claims" class="section level2">
<h2><span class="header-section-number">14.5</span> Conditional claims</h2>
<p>A second response is to clearly communicate the contingent nature of claims. As we outlined in Chapter 4, some causal models might reasonably reflect actual beliefs about the world—for example one might, be convinced that a treatment was randomly assigned, that there is no interference, and that units are independently sampled from a distribution of types. All of these beliefs may be unwise. But if help, then the simple DAG in chapter 4 (REF) can be taken to represents beliefs about the world rather than a model of the world, in the sense of a simplified representation. But as we noted in Chapter 4, for an even modestly more complex situation, it seems inevitable that the model being used is truly a model and not a faithful summary of beliefs.</p>
<p>Owning the model in this way results in a useful reposing of the question: the question becomes not whether the assumptions are correct but whether the model is useful <span class="citation">(Clarke and Primo <a href="#ref-clarke2012model">2012</a>)</span>. That is the subject of Chapter 13.</p>
</div>
<div id="learning-about-parameters-within-a-model" class="section level2">
<h2><span class="header-section-number">14.6</span> Learning about parameters within a model</h2>
<p>The general approach outlined in the literature on probabilistic graph allows for considerable flexibility on what is fixed and what is not. As we described in Chapter 2, any seemingly fixed feature of a structural equation can become a quantity of interest in a lower level model. In our baseline model<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> for instance the probative value of clues, as captured by terms <span class="math inline">\(\phi_{tx}\)</span>, are parameters over which researchers update; they do not uniquely derive from external information.</p>
<p>How much external information has to be brought in to learn from clues? Does any external information need to be brought in? We address the question by considering situations where researcher have <em>uninformative</em> priors about treatment effects <em>and</em> over the probative value of clues. We simplify the problem by assuming that assignment probabilities are known (specifically we set these at 0.5 for all units) and we assume that there is infinite data available for analysis. Note that under these conditions the average treatment effect (<span class="math inline">\(b-a\)</span>) can be estimated with certainty using information about <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> only.</p>
<p>We are interested in whether data on clues, <span class="math inline">\(K\)</span> can be used to make estimates of the size of the causal types, <span class="math inline">\(a,b,c,d\)</span> and whether the data allows us to estimate the probative value of clues. Let <span class="math inline">\(\theta\)</span> denote our parameter vector containing causal types, <span class="math inline">\((\lambda)\)</span> and probative values <span class="math inline">\(\phi_{tx}\)</span>.</p>
<p>We find that when priors over clue probabilities do not discriminate between causal types, then learning clue values does not affect learning over other parameters when <span class="math inline">\(n=1\)</span>.</p>
</div>
<div id="learning-from-observational-and-experimental-mixtures" class="section level2">
<h2><span class="header-section-number">14.7</span> Learning from observational and experimental mixtures</h2>
</div>
<div id="learning-across-populations" class="section level2">
<h2><span class="header-section-number">14.8</span> Learning across populations</h2>
<p>Now consider strategies to learn about clues from observing patterns in different populations under an assumption that clue patterns travel across cases even if causal types differ. We consider a population independence assumption (“population invariant probative values”") on the <span class="math inline">\(\phi\)</span> values, we show that data from multiple populations can allow for both tighter assessment of <span class="math inline">\(\phi\)</span> values and identification of fundamental causal parameters.</p>
<p>A consideration of heterogeneous treatment effects communicates the basic idea. Consider a large randomized trial in some population where it is found that a treatment is effective in subgroup <span class="math inline">\(K\)</span> of subjects but not among others. Then we might think that <span class="math inline">\(K\)</span> is a marker for a <span class="math inline">\(B\)</span> type.</p>
<p>As a more concrete illustration consider first the data from “Population 1”, given in table . From this population we see that treatment is assigned in half of all cases and that outcomes are equally likely to be positive or negative, independent of treatment status.</p>

<p>Note that for or any <span class="math inline">\(b\)</span> in <span class="math inline">\([0,0.5]\)</span> the observed <span class="math inline">\(X,Y\)</span> data are consistent with <span class="math inline">\(a = b\)</span>, <span class="math inline">\(c = d = .5 - b\)</span>. Thus although the average treatment effect is 0, the share of units for which there is a positive treatment effect could range anywhere between 0 and .5.</p>
<p>Note that <span class="math inline">\(K\)</span> is only observed when <span class="math inline">\(X=Y = 1\)</span>. This fact provides a lot of information on <span class="math inline">\(\phi\)</span>; in particular:
<span class="math inline">\(\phi_{j0} = 0\)</span> for all <span class="math inline">\(j\)</span>. Moreover <span class="math inline">\(\phi_{a1} = 0\)</span> and <span class="math inline">\(\phi_{c1} = 0\)</span>. The only positive possibilities are <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span>.</p>
<p>Unfortunately however, constraining <span class="math inline">\(\phi\)</span> in this way does nothing to better estimate causal quantities.</p>
<p>Since the share of cases for which <span class="math inline">\(K\)</span> is observed in <span class="math inline">\(1/8\)</span>, the observed data impose the following constraint on <span class="math inline">\(b\)</span>, <span class="math inline">\(\phi_{b1}\)</span>, <span class="math inline">\(\phi_{d1}\)</span>:
<span class="math display">\[\begin{equation}
.5b q_{b1}  + .5d q_{d1}  = 1/8 \label{C1}
\end{equation}\]</span>
Substituting for <span class="math inline">\(d\)</span> we have:
<span class="math display">\[2b \phi_{b1} +(1-2b) q\phi_{d1} = 1/2\]</span> </p>
<p><span class="math display">\[b = \frac{.25 - .5\phi_{d1}}{\phi_{b1} - \phi_{d1}}\]</span> </p>
<p>Note that from this condition, that if we knew <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span> then we could figure out <span class="math inline">\(b\)</span> exactly.
If only one of these is known then we can figure <span class="math inline">\(b\)</span> only up to some range. If neither is known then <em>any</em> value of <span class="math inline">\(b\)</span> in <span class="math inline">\((0,.5)\)</span> is consistent with the data.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>That is the bad news: what we learn about <span class="math inline">\(\phi\)</span> does nothing to pin down causal effects of interest: for any stipulated causal effect there is a belief about the probative value of clues that is consistent with it.</p>
<p>Nevertheless although the learning on <span class="math inline">\(\phi\)</span> does not rule out any values on <span class="math inline">\(a,b,c,d\)</span> for any given population, learning is possible across populations, at least under the assumption that <span class="math inline">\(\phi\)</span> is invariant to population. Assume specifically that the distribution of types varies across populations but that the values of <span class="math inline">\(\phi\)</span> conditional on type is constant. Thus for this illustration, the data table for Population 2, Table  is identical to that for population 1 except for the observations on <span class="math inline">\(K\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-10"></span>
<img src="ii_files/figure-html/unnamed-chunk-10-1.png" alt="\label{fig:somethingfig} Combinations of $\phi_{b1}$, $\phi_{d1}$ and $b$ values consistent with data from three populations. Populations are assumed to differ in the sizes of groups $A,B,C,D$ but not in the $\phi$ values. Furthermore it is assumed in this illustration that observed data is identical across populations with respect to $X$ and $Y$ but differs with respect to $K$." width="768" />
<p class="caption">
Figure 14.2:  Combinations of <span class="math inline">\(\phi_{b1}\)</span>, <span class="math inline">\(\phi_{d1}\)</span> and <span class="math inline">\(b\)</span> values consistent with data from three populations. Populations are assumed to differ in the sizes of groups <span class="math inline">\(A,B,C,D\)</span> but not in the <span class="math inline">\(\phi\)</span> values. Furthermore it is assumed in this illustration that observed data is identical across populations with respect to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> but differs with respect to <span class="math inline">\(K\)</span>.
</p>
</div>
<p>The top left panel of figure  summarizes the learning that is possible from the first population. The axes indicate possible values of <span class="math inline">\(\phi_{b1}\)</span> and <span class="math inline">\(\phi_{d1}\)</span>; the numbers marked inside the figure are the possible values of <span class="math inline">\(a\)</span> implied by these values. Note that values are marked only when they collectively satisfy the constraint given in Equation .</p>
<p>Key features of the graph are that both <span class="math inline">\(\phi_{d1}\)</span> and <span class="math inline">\(\phi_{b1}\)</span> span the whole range between 0 and 1: that is, the constraint does not limit the range of either of these on their own. Second, values of <span class="math inline">\(b\)</span> range from 0 to 0.5: thus the constraint does not rule out any value for <span class="math inline">\(b\)</span> not already determined by <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> data alone.</p>
<p>However the combinations of possible values are clearly strongly constrained and these combinations depend on the data.</p>
<p>The second and third figures show the analogous set of constraints for two more populations that are identical to the first except that <span class="math inline">\(K\)</span> is observed in very few of the <span class="math inline">\(X=Y=1\)</span> cases in the second population and in very many of the <span class="math inline">\(X=Y=1\)</span> cases in the third. Under the assumption that <span class="math inline">\(\phi\)</span> is invariant to population, the feasible values of <span class="math inline">\(\phi\)</span> consists of those values that are admissible in <em>all</em> populations. These values are shown in the bottom right figure (they can in fact be identified by considering the intersection of the admissible values from any two of the populations).</p>
<p>From the bottom right figure we learn two things: first, although we have now greatly constrained the set of possible values of <span class="math inline">\(\phi\)</span>, quite distinct values remain possible. Secondly, whatever the true values of <span class="math inline">\(\phi\)</span> we have in the final figure, we have tightly limited the possible values of <span class="math inline">\(b\)</span>, which we now believe to be approximately 0.25.</p>
<p>The intuition for this result is the following. From population 2 we learn that <span class="math inline">\(\phi\)</span> cannot be high for both <span class="math inline">\(b\)</span> and <span class="math inline">\(d\)</span> types, it must be low for one or the other or both. From population 3 we learn that <span class="math inline">\(\phi\)</span> cannot be low for both types; it must high for one or the other or both. Together these imply that <span class="math inline">\(\phi\)</span> must be high for either <span class="math inline">\(b\)</span> or <span class="math inline">\(d\)</span> and low for the other. However since in population 1 there is a middling level of <span class="math inline">\(K\)</span> then there must be a middling frequency of <span class="math inline">\(b\)</span>s and <span class="math inline">\(d\)</span>s.</p>
<p>Note finally that in this example, our learning on the level of <span class="math inline">\(b\)</span> in populations 2 and 3 is less precise: we learn only that <span class="math inline">\(b\)</span> is either very high or very low, and that it is <em>not</em> middling in these populations.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-clarke2012model">
<p>Clarke, Kevin A, and David M Primo. 2012. <em>A Model Discipline: Political Science and the Logic of Representations</em>. New York: Oxford University Press.</p>
</div>
<div id="ref-parsons2001qualitative">
<p>Parsons, Simon. 2001. <em>Qualitative Methods for Reasoning Under Uncertainty</em>. Vol. 13. Mit Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Some individuals are observed to have received a treatment (<span class="math inline">\(X\)</span>) while others have not. Assume that, subsequently, a researcher observes outcomes (<span class="math inline">\(Y\)</span>) for all units. Assume that each unit belongs to one of four unobserved ‘’types,’’ <span class="math inline">\(A\)</span> (adverse), <span class="math inline">\(B\)</span> (beneficial), <span class="math inline">\(C\)</span> (chronic), <span class="math inline">\(D\)</span> (destined) with potential outcomes <span class="math inline">\(Y(0)=1, Y(1)=0\)</span> for type <span class="math inline">\(A\)</span>; <span class="math inline">\(Y(0)=0, Y(1)=1\)</span> for type <span class="math inline">\(B\)</span>; <span class="math inline">\(Y(0)=0, Y(1)=0\)</span> for type <span class="math inline">\(C\)</span>; and <span class="math inline">\(Y(0)=1, Y(1)=1\)</span> for type <span class="math inline">\(D\)</span>. As in the canonical model, researchers have access to data on a third variable, <span class="math inline">\(K\)</span> and we let <span class="math inline">\(\phi_{tx}\)</span> denote the probability of observing <span class="math inline">\(K\)</span> for type <span class="math inline">\(t\)</span> given <span class="math inline">\(X=x\)</span>.<a href="where-does-probative-value-come-from.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>For example, for <span class="math inline">\(b \in [1/4,1]\)</span> set <span class="math inline">\(\phi_{d1}=0\)</span> and <span class="math inline">\(\phi_{b1} = 1/(4b)\)</span> otherwise set <span class="math inline">\(\phi_{b1}=0\)</span> and <span class="math inline">\(\phi_{d1} = 1/(2(1-2b))\)</span><a href="where-does-probative-value-come-from.html#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="caseselection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="evaluation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
