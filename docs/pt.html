<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Process Tracing with Causal Models | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Process Tracing with Causal Models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Process Tracing with Causal Models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayeschapter.html"/>
<link rel="next" href="ptapp.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#illustrations"><i class="fa fa-check"></i><b>2.3</b> Illustrations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>2.3.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>2.3.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>2.3.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.4</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.4.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.4.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.4.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.4.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.4.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theories as causal models</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>3.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>3.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>3.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>3.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>3.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>3.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>3.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>3.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>3.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>3.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="3.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>3.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Questions</a><ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>4.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="6" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>6</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="6.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>6.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>6.1.1</b> The intuition</a></li>
<li class="chapter" data-level="6.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>6.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="6.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>6.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>6.2</b> Five principles</a><ul>
<li class="chapter" data-level="6.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>6.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="6.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>6.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="6.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>6.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="6.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>6.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="6.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>6.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>7</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="7.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>7.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="7.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>7.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>7.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>7.3</b> Results</a></li>
<li class="chapter" data-level="7.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>7.4</b> Pathways</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>7.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>7.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>7.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="7.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>7.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>8</b> Integrated inferences</a><ul>
<li class="chapter" data-level="8.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>8.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="8.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>8.2</b> General procedure</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>8.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>8.3</b> Illustration</a></li>
<li class="chapter" data-level="8.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>8.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>8.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>8.5</b> Considerations</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>8.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="8.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>8.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="8.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>8.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="8.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>8.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="8.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>8.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="8.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>8.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>9</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="9.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>9.1</b> A trained model</a></li>
<li class="chapter" data-level="9.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>9.2</b> Data</a></li>
<li class="chapter" data-level="9.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>9.3</b> Inference</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>9.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>9.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixingapp.html"><a href="mixingapp.html#prior-posterior-comparison-for-multiple-estimands"><i class="fa fa-check"></i><b>9.4</b> Prior / posterior comparison for multiple estimands</a></li>
<li class="chapter" data-level="9.5" data-path="mixingapp.html"><a href="mixingapp.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>10</b> Mixing models</a><ul>
<li class="chapter" data-level="10.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>10.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="10.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>10.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="10.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>10.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="10.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>10.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="11" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>11</b> Elements of Design</a><ul>
<li class="chapter" data-level="11.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>11.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="11.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>11.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>11.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="11.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>11.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="11.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-variance-almost-always-goes-down"><i class="fa fa-check"></i><b>11.2.2</b> Expected variance (almost) always goes down</a></li>
<li class="chapter" data-level="11.2.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>11.2.3</b> Illustration</a></li>
<li class="chapter" data-level="11.2.4" data-path="elements-of-design.html"><a href="elements-of-design.html#other-loss-functions"><i class="fa fa-check"></i><b>11.2.4</b> Other loss functions</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>11.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>12.1</b> Core logic</a></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>12.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>12.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>13</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="13.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a></li>
<li class="chapter" data-level="13.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>13.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="13.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>13.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="13.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>13.3.1</b> 1-path model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="wide.html"><a href="wide.html#evaluating-strategies"><i class="fa fa-check"></i><b>13.4</b> Evaluating strategies</a></li>
<li class="chapter" data-level="13.5" data-path="wide.html"><a href="wide.html#varieties"><i class="fa fa-check"></i><b>13.5</b> Varieties of mixing</a></li>
<li class="chapter" data-level="13.6" data-path="wide.html"><a href="wide.html#probative-value-of-clues"><i class="fa fa-check"></i><b>13.6</b> Probative value of clues</a></li>
<li class="chapter" data-level="13.7" data-path="wide.html"><a href="wide.html#effect-heterogeneity"><i class="fa fa-check"></i><b>13.7</b> Effect Heterogeneity</a></li>
<li class="chapter" data-level="13.8" data-path="wide.html"><a href="wide.html#uncertainty-regarding-assignment-processes"><i class="fa fa-check"></i><b>13.8</b> Uncertainty Regarding Assignment Processes</a></li>
<li class="chapter" data-level="13.9" data-path="wide.html"><a href="wide.html#uncertainty-regarding-the-probative-value-of-clues"><i class="fa fa-check"></i><b>13.9</b> Uncertainty regarding the probative value of clues</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>14</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="14.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>14.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="14.2" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>14.2</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="14.3" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>14.3</b> Explorations</a><ul>
<li class="chapter" data-level="14.3.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>14.3.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>14.4</b> Principles</a><ul>
<li class="chapter" data-level="14.4.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>14.4.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="14.4.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>14.4.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="14.4.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>14.4.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a><ul>
<li class="chapter" data-level="15.1" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="15.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
<li class="chapter" data-level="15.5" data-path="justifying-models.html"><a href="justifying-models.html#exercise"><i class="fa fa-check"></i><b>15.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a><ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>16.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>16.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>17</b> Final Words</a><ul>
<li class="chapter" data-level="17.1" data-path="final-words.html"><a href="final-words.html#general-lessons"><i class="fa fa-check"></i><b>17.1</b> General lessons</a></li>
<li class="chapter" data-level="17.2" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>17.2</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="17.3" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>17.3</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="17.4" data-path="final-words.html"><a href="final-words.html#a-world-of-models-practical-steps-forward-for-collective-cumulation"><i class="fa fa-check"></i><b>17.4</b> A world of models: Practical steps forward for collective cumulation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pt" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Process Tracing with Causal Models</h1>
<hr />
<p>We connect the literature on causal models to qualitative inference strategies used in process tracing. We provide a procedure for inference on case level queries from causal models. In addition we extract a set of implications for process tracing. We show how a key result from the causal models literature provides a condition for when clues may be (or certainly will not be) informative.</p>
<hr />
<!-- FLAG: Change causal type to unit type throughout (though note I've introduced this already in the **"unit causal type"** paragraph.) -->
<div id="process-tracing-and-causal-models" class="section level2">
<h2><span class="header-section-number">6.1</span> Process tracing and causal models</h2>
<p>This chapter demonstrates how we can use causal models to conduct confirmatory process tracing: that is, to draw causal inferences about a single case from case-level data.</p>
<div id="the-intuition" class="section level3">
<h3><span class="header-section-number">6.1.1</span> The intuition</h3>
<p>We first walk through the basic intuition and then provide a more formal account.</p>
<p>When we undertake process tracing, we seek to answer a causal query about a given case.
The key insight driving our approach is that <strong>the inference about a causal estimand for a case is a claim about what causal types are both likely ex ante (given prior knowledge) and consistent with the data</strong>.<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a></p>
<p>The estimand of interest can be a statement about any number of case-level causal features, including a case-level causal effect, the pathway through which an effect operates, an actual cause, or causal attribution. We will use observations from the case itself to address this query. We do so via a procedure in which we first encode prior knowledge in the form of a causal model, use data to learn about features of the model, and then take what we have learned about the model and map it into our query.</p>
<p>Given a causal model, we form posteriors over estimands as follows:</p>
<ol style="list-style-type: decimal">
<li><strong>Specify all causal types</strong>. A causal type, recall, specifies the values that a unit is expected to take, absent any interventions, but also the values it would take given some interventions on some variables. Examples of types might be:</li>
</ol>
<ul>
<li>Type 1: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 2: (<span class="math inline">\(X=0\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 3: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=0\)</span>).</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Specify priors over causal types.</strong> Report how likely you think it is that a given unit is of a particular causal type. In the simplest case one might place 0 weight on some causal types (that might be ruled out by theory, for example) and equal weight on the others.</p></li>
<li><p><strong>Specify the estimand in terms of causal types.</strong> For instance the estimand “<span class="math inline">\(Y\)</span> responds positively to <span class="math inline">\(X\)</span>” can be thought of as a collection of causal types: Q={Type 1, Type 2}.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a></p></li>
<li><p><strong>Specify the set of causal types that are consistent with the data.</strong> For instance if we observe <span class="math inline">\(X=1, Y=1\)</span> we might specify the data-consistent set as {Type 1, Type 3.}.</p></li>
<li><p><strong>Update.</strong> Updating is done then by adding up the prior probabilities on all causal types that are consistent with both the data and the estimand, and dividing this by the sum of prior probabilities on all causal types that are consistent with the data (whether or not they are consistent with the estimand).</p></li>
</ol>
<!-- 1. **Draw a DAG.** We begin by constructing a causal model in graphical form, a DAG, expressing which variables in the domain of interest we think can have a direct effect on which other variables. As we have discussed, the causal model we start with may be derived from theory, from data on other cases, or some combination of the two. (We show, for instance, in Chapter \@ref(mixing) how data from a larger set of cases can inform the priors we bring to single-case process tracing.)  -->
<!-- 2. **Identify causal types**. A DAG, in turn, defines a set of possible causal types: all of the different possible combinations of nodal types that any case might have.  -->
<!-- 3. **Form priors**. We draw further on background knowledge, about the population to which the case belongs, to formulate prior beliefs about the probability that the case is of different causal types. We can generate these priors by ruling out certain nodal types as inconsistent with prior knowledge. Where our prior knowledge supports doing so, we can also place differential quantitative weights on those nodal types that we believe to be more or less common in the population. -->
<!-- 4. **Observe data**. We observe data on some or all of the nodes in the graph. -->
<!-- 5. **Eliminate causal types inconsistent with the data**. Check the consistency of each causal type with the data. Eliminate from contention any causal type that could not have generated the data pattern that we observe. -->
<!-- 6. **Form posteriors**. We now scale up the probabilities on all remaining causal types, providing a posterior probability on each type. -->
<!-- 7. **Map from causal types to query**. As any causal query can be formulated as a question about causal types (see Chapter \@ref(questions)), we can now map from our posteriors on causal types to a posterior probability on the estimand of interest: whether a causal effect, a causal pathway, causakl attribution, or some other case-level causal quantity. -->
<div class="figure" style="text-align: center"><span id="fig:ptvenn"></span>
<img src="ii_files/figure-html/ptvenn-1.png" alt="Logic of simple updating on arbitrary estimands." width="50%" />
<p class="caption">
Figure 6.1: Logic of simple updating on arbitrary estimands.
</p>
</div>
<p>This process is represented graphically with Figure <a href="pt.html#fig:ptvenn">6.1</a>, where we can think of probabilities as proportionate to areas. Our causal model defines the causal type space. We then proceed by a process of elimination. Only some of the causal types in the model are consistent with prior knowledge. Only some are consistent with the data that we observe. Finally, any query itself maps onto a subset of the possible causal types. The causal types that remain in contention once we have observed the evidence are those at the intersection of consistency with priors and consistency with the data. <span class="math inline">\(A\)</span> represents those types that are <em>also</em> consistent with a given answer to the query (say, <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>).</p>
<p>Thus, our belief about the query before we have seen the data is the probability of all causal types consistent with our priors and with the query (<span class="math inline">\(A + B\)</span>) as a proportion of all types consistent with our priors. Once we have seen the data, we have reduced the permissible types to <span class="math inline">\(A + C\)</span>. Our posterior belief on the query is, then, the probabilities of those remaining types that are consistent with the query as a share of the probabilities of <em>all</em> remaining types, or <span class="math inline">\(A/(A+C)\)</span>.</p>
<p>What we are doing here is straightforward: assessing causal possibilities for their compatibility with both the evidence at hand and our prior knowledge of how the world works. The formalization that we will present ensures that prior knowledge and evidence are all recorded explicitly while forcing logical consistency on the inferences that emerge from them.</p>
</div>
<div id="a-formalization-of-the-general-approach" class="section level3">
<h3><span class="header-section-number">6.1.2</span> A formalization of the general approach</h3>
<p>More formally, the general approach to inference draws on the components we outlined in chapters 2 to 4: graphical causal models (DAGs), nodal and causal types, and priors. We now show how these elements formally interact with data to generate causal inferences. We continue to focus on a situation with binary variables, though suggest later in the chapter how this can be extended. Though we walk through the procedure for simple models, the approach outlined here can be applies to <em>any</em> causal model with binary variables and to any estimands defined over the model.</p>
<p>The process tracing procedure operates as follows:</p>
<p><strong>A DAG</strong>. We begin with a DAG, or graphical causal model. As we know, a DAG identifies a set of variables and describes the parent-child relations between them, indicating for each variable which other variables are its direct (possible) causes. These relationship, in turn, tell us which (non-descendant) variables a given variable is <em>not</em> independent of given the other variables in the model.</p>
<p><strong>Nodal types</strong>. Once we have specified a DAG, we have defined the full set of possible nodal types: the types defining the value that a variable will take on given the values of its parents, which we have denoted with <span class="math inline">\(\theta\)</span> values. At each node, the range and number of nodal types is defined by the number of parents that that node has and the number of values the variables can take on. For instance, assuming all variables to be binary, if <span class="math inline">\(Y\)</span> has parents <span class="math inline">\(X\)</span> and <span class="math inline">\(W\)</span> (so <span class="math inline">\(k=2\)</span>), then there are <span class="math inline">\(2^{\left(2^2\right)}=16\)</span>) possible causal types for the <span class="math inline">\(Y\)</span> node. There are <span class="math inline">\(2^2\)</span> possible combinations of values that two binary causal variables can take on—-<span class="math inline">\((X=0,W=0), (X=0,W=1), (X=1,W=0), (X=1,W=1)\)</span>—which implies four possible causal conditions over which <span class="math inline">\(Y\)</span>’s possible responses must be defined. For instance, as we have seen, with two causal variables, we can have <span class="math inline">\(\theta^Y_{0000}\)</span>, where <span class="math inline">\(Y\)</span> is always 0; <span class="math inline">\(\theta^Y_{0001}\)</span>, where <span class="math inline">\(Y\)</span> is 0 unless both <span class="math inline">\(X\)</span> and <span class="math inline">\(W\)</span> are 1; and so on.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a> To get the total number of nodal types, we simply raise <span class="math inline">\(2\)</span> (since <span class="math inline">\(Y\)</span> is binary) to the number of causal conditions (4), giving the number of possible patterns of <span class="math inline">\(Y\)</span> values that could be generated across these four conditions (16). (The full set of nodal types for two causal variables in a binary setup is given in <a href="models.html#tab:PO16">2.3</a>.)<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a></p>
<p>All variables in a model have nodal types defining the value they take on given the value of their parents, including those variables without substantive parents. Suppose that <span class="math inline">\(X\)</span> and <span class="math inline">\(W\)</span>, in this model, have no substantively defined parents. We nonetheless define a nodal type for each of them, which simply captures their exogenous assignment to some value. With <span class="math inline">\(X\)</span> binary, for instance, there are two nodal types, <span class="math inline">\(\theta^X_{0}\)</span>, where <span class="math inline">\(X\)</span> is set to <span class="math inline">\(0\)</span>, and <span class="math inline">\(\theta^X_{1}\)</span>, where <span class="math inline">\(X\)</span> is set to <span class="math inline">\(1\)</span>.</p>
<p><strong>Unit causal types</strong>. We will want to be able to conceive not just of types for individual nodes but of the full collection of nodal types across all nodes in a model. We refer to a unit’s full set of nodal types as its <em>unit causal type</em> — or, more simply, unit type — which we represent as <span class="math inline">\(\theta\)</span>. A unit type is simply a listing that contains one nodal type for each node in the model. For instance, with a model with variable <span class="math inline">\(X\)</span>, <span class="math inline">\(W\)</span>, and <span class="math inline">\(Y\)</span>, each unit has a <em>causal</em> type composed of its <em>nodal</em> types on each of the three nodes.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> Thus, one causal type in this model could be <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_1, \theta^Y = \theta^Y_{1101})\)</span>. Another could be <span class="math inline">\(\theta = (\theta^X = \theta^X_0, \theta^W = \theta^W_1, \theta^Y = \theta^Y_{0001})\)</span>. And so on.</p>
<p>We show the mapping between nodal and causal types, for a simply <span class="math inline">\(X \rightarrow Y\)</span> model, in Table <a href="pt.html#tab:nodalcausalmatrix">6.1</a>. The column headings represent the <span class="math inline">\(8\)</span> permissible causal types, each expressed simply as a concatenated strings of nodal types. The row headings represent the nodal types. In each interior cell, a <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span> indicates whether or not a given nodal type is a component of a given causal type. As can be seen, each causal type has two nodal types that are its components since there are two nodes in this model. Each <span class="math inline">\(X\)</span>-nodal type is part of four causal types since it can be combined with four different <span class="math inline">\(Y\)</span>-nodal types, while each <span class="math inline">\(Y\)</span>-nodal type is part of two causal types since it can be combined with two <span class="math inline">\(X\)</span>-nodal types.</p>
<table style="width:100%;">
<caption><span id="tab:nodalcausalmatrix">Table 6.1: </span>. A mapping between nodal types and causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model.</caption>
<colgroup>
<col width="15%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="right"><strong>Causal Types <span class="math inline">\(\rightarrow\)</span></strong></th>
<th align="center"><span class="math inline">\(\theta^X_0\)</span>.<span class="math inline">\(\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1\)</span>.<span class="math inline">\(\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0\)</span>.<span class="math inline">\(\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1\)</span>.<span class="math inline">\(\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0\)</span>.<span class="math inline">\(\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1\)</span>.<span class="math inline">\(\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0\)</span>.<span class="math inline">\(\theta^Y_{11}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1\)</span>.<span class="math inline">\(\theta^Y_{11}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Nodal types <span class="math inline">\(\downarrow\)</span></strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\theta^X_0\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\theta^X_1\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<!-- |                                    **Causal Types $\rightarrow$** | $\theta^X_0$.$\theta^Y_{00}$ | $\theta^X_1$.$\theta^Y_{00}$ | $\theta^X_0$.$\theta^Y_{10}$ | $\theta^X_1$.$\theta^Y_{10}$ | $\theta^X_0$.$\theta^Y_{01}$ | $\theta^X_1$.$\theta^Y_{01}$ | $\theta^X_0$.$\theta^Y_{11}$ | $\theta^X_1$.$\theta^Y_{11}$ | -->
<!-- |------------------------------------------------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:| -->
<!-- |                    **Parameters $\downarrow$**                    |                              |                              |                              |                              |                              |                              |                              |                              | -->
<!-- |               $\theta^X_0 | \theta^Y= \theta^Y_{01}$              |               0              |               0              |               0              |               0              |               1              |               0              |               0              |               0              | -->
<!-- | $\theta^X_1 | \theta^Y_{01}$$\theta^X_1 | \theta^Y= \theta^Y_{01}$ |               0              |               0              |               0              |               0              |               0              |               1              |               0              |               0              | -->
<!-- |             $\theta^X_0| \theta^Y \neq \theta^Y_{01}$             |               1              |               0              |               1              |               0              |               0              |               0              |               1              |               0              | -->
<!-- |             $\theta^X_1 | \theta^Y \neq \theta^Y_{01}$            |               0              |               1              |               0              |               1              |               0              |               0              |               0              |               1              | -->
<!-- |                          $\theta^Y_{00}$                          |               1              |               1              |               0              |               0              |               0              |               0              |               0              |               0              | -->
<!-- |                          $\theta^Y_{10}$                          |               0              |               0              |               1              |               1              |               0              |               0              |               0              |               0              | -->
<!-- |                          $\theta^Y_{01}$                          |               0              |               0              |               0              |               0              |               1              |               1              |               0              |               0              | -->
<!-- |                          $\theta^Y_{11}$                          |               0              |               0              |               0              |               0              |               0              |               0              |               1              |               1              | -->
<!-- |                            | $\theta^X_0$.$\theta^Y_{00}$ | $\theta^X_1$.$\theta^Y_{00}$ | $\theta^X_0$.$\theta^Y_{10}$ | $\theta^X_1$.$\theta^Y_{10}$ | $\theta^X_0$.$\theta^Y_{01}$ | $\theta^X_1$.$\theta^Y_{01}$ | $\theta^X_0$.$\theta^Y_{11}$ | $\theta^X_1$.$\theta^Y_{11}$ | -->
<!-- |-----------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------| -->
<!-- | $\theta^X_0 | \theta^Y= \theta^Y_{01}$ | 0                            | 0                            | 0                            | 0                            | 1                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^X_1 | \theta^Y= \theta^Y_{01}$ | 0                            | 0                            | 0                            | 0                            | 0                            | 1                            | 0                            | 0                            | -->
<!-- | $\theta^X_0| \theta^Y \neq \theta^Y_{01}$                | 1                            | 0                            | 1                            | 0                            | 0                            | 0                            | 1                            | 0                            | -->
<!-- | $\theta^X_1 | \theta^Y \neq \theta^Y_{01}$                | 0                            | 1                            | 0                            | 1                            | 0                            | 0                            | 0                            | 1                            | -->
<!-- | $\theta^Y_{00}$             | 1                            | 1                            | 0                            | 0                            | 0                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{10}$             | 0                            | 0                            | 1                            | 1                            | 0                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{01}$             | 0                            | 0                            | 0                            | 0                            | 1                            | 1                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{11}$             | 0                            | 0                            | 0                            | 0                            | 0                            | 0                            | 1                            | 1                            | -->
<p><strong>Priors</strong>: Our background beliefs about a causal domain will usually consist of more than just beliefs about which variables have causal connections; they will also typically contain beliefs about what <em>kinds</em> of effects operate between variables. That is, they will contain beliefs about which types are possible or, more generally, are more or less common in the world. We express these beliefs over causal effects as either restrictions on nodal types or as probability distributions over the nodal types.</p>
<p>In general, when doing process tracing in this framework, we think of a given case of interest – the one we are studying and seek to learn about – as being drawn at random from a population. Thus, our prior beliefs about a <em>single</em> case – before we do the process tracing – are really beliefs about that population. So, for instance, our prior belief about the probability that inequality has a positive effect on democratization in Mexico in 1999 is our belief about how commonly inequality has a positive effect on democratization in the population of cases that are “like” Mexico in 1999.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></p>
<p>We let <span class="math inline">\(\lambda^j\)</span> denote our belief about the population distribution of nodal types at node <span class="math inline">\(j\)</span>. A <span class="math inline">\(\lambda^j\)</span> is simply a vector of proportions, one for each possible nodal type, with the proportions adding up to <span class="math inline">\(1\)</span>. So, for instance, <span class="math inline">\(\lambda^Y\)</span> for our current example would be a vector with four values, each of which expresses a proportion for one of the four nodal types at <span class="math inline">\(Y\)</span>. So we might have <span class="math inline">\(\lambda^Y_{01}=0.1\)</span>, <span class="math inline">\(\lambda^Y_{11}=0.05\)</span>, and so on – with the <span class="math inline">\(\lambda^Y\)</span> values summing to <span class="math inline">\(1\)</span> because these values are defined over the full set of possible nodal types for <span class="math inline">\(Y\)</span>.</p>
<p>We can, in turn, use these population parameters – these beliefs about nodal-type proportions in the population – to create prior probabilities over the <em>causal</em> type for the case at hand. Since causal types are merely combinations of nodal types, and our case has been drawn at random from the population, we can take a set of posited proprtions of nodal types in the population and readily calculate the probability that our case is of any given causal type. To do so, we need to join together <span class="math inline">\(\lambda\)</span>’s across the nodes in a model.</p>
<p>Let us first see how this works in a situation in which we assume that the nodal types are independent of one another. We can think of this as a situation in which there is no confounding that is not captured in the graph – no variable missing from the model that is a common ancestor of multiple nodes in the model. Here, our beliefs over causal types are simply the product of our beliefs over the component nodal types (since the joint probability of independent events is simply the product of their individual probabilities). For instance, one causal type might be “a unit in which <span class="math inline">\(X=1\)</span> and in which <span class="math inline">\(Y=1\)</span> no matter what value <span class="math inline">\(X\)</span> takes.” In this case the probability that a case is of this causal type might be written <span class="math inline">\(\Pr(\theta^X = \theta^X_1)\Pr(\theta^Y = \theta^Y_{11}) = \lambda^X_1\lambda^Y_{11}\)</span>.</p>
<p>The simplest way in which we can express beliefs about the differential probabilities of different causal possibilities is by <em>eliminating</em> nodal types that we do not believe to be possible—setting their parameter values to <span class="math inline">\(0\)</span>. Suppose, for instance, that we are examining the effect of ethnic diversity on civil war in a case. We might not know whether ethnic diversity causes civil war in this case, but we might have sufficient background knowledge to believe that ethnic diversity never has a <em>negative</em> effect on civil war: it never prevents a civil war from happening that would have happened in the absence of ethnic diversity. We would thus want to set the parameter value for a negative causal effect to <span class="math inline">\(0\)</span>. If we then know nothing about the relative frequencies of the three remaining nodal types for <span class="math inline">\(Y\)</span>, we may (following the principle of indifference), frequency of positive effects, null effects with civil war destined to happen, and null effects with civil war never going to happen, assigning a weight of <span class="math inline">\(\frac{1}{3}\)</span> to each of them.</p>
<p>In a situation of unobserved confounding, our beliefs over causal types are still well defined, though they are no longer the simple product of beliefs over nodal types. Let us imagine for instance, in a simple <span class="math inline">\(X \rightarrow Y\)</span> model, that we believe that some unobserved factor both makes cases more likely to have <span class="math inline">\(X = 1\)</span> and makes it more likely that <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. This is the same as saying that the probability that <span class="math inline">\(\theta^X = \theta^X_1\)</span> is positively correlated with the probability that <span class="math inline">\(\theta^Y = \theta^Y_{01}\)</span>. Now, our probability that <em>both</em> <span class="math inline">\(X=1\)</span> and <span class="math inline">\(X\)</span> has a positive effect must be calculated using the joint probability formula, <span class="math inline">\(\Pr(A, B) = \Pr(A)\Pr(B|A)\)</span>.<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a> Thus, <span class="math inline">\(\Pr(\theta^Y = \theta^Y_{01}, \theta^X = \theta^X_1) = \Pr(\theta^Y = \theta^Y_{01})\Pr(\theta^X = \theta^X_1 | \theta^Y = \theta^Y_{01})\)</span>. To form priors over causal types in this situation, we need to posit beliefs about a set of more complex, conditional proportions for <span class="math inline">\(X\)</span>’s type. Specifically, we need to posit, <em>for those cases</em> with a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, what proportion are “assigned” to <span class="math inline">\(X=1\)</span>; and, separately, what proportion are assigned to <span class="math inline">\(X=1\)</span> among those cases <em>without</em> a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>These conditional proportions may, of course, be difficult for the researcher to form beliefs about. Forming a belief about them amounts to saying that we do not know what generates confounding, but we know the correlations it generates in the data. We may wonder how often we will be in that epistemological position. An alternative way to parse the problem, then, is to <em>model</em> the confounding by including the confounder (say, <span class="math inline">\(Z\)</span>) as a new node in the graph. In the above example, <span class="math inline">\(Z\)</span> would point into both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. We would then posit population proportions for a set of nodal types for <span class="math inline">\(X\)</span> – representing <span class="math inline">\(X\)</span>’s possible responses to <span class="math inline">\(Z\)</span> – and for <span class="math inline">\(Y\)</span> – representing <span class="math inline">\(Y\)</span>’s possible responses to both <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>. We may find it easier to reason and form beliefs about these more complex nodal types than about the conditional proportions involved in unobserved confounding. The two approaches work out to be analytically equivalent given equivalent underlying beliefs, so the choice between them will be a matter of researcher preference.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a></p>
<p>Importantly, in process tracing, we are focused on drawing case-level inferences and, as such, we treat the population-level parameters as given and fixed. In general, these parameters derive from our beliefs about how the world works, and those beliefs will typically be uncertain. The key point, however, is that in process tracing, the population parameters serve as an <em>input</em> into the analysis, conditioning our inferences from the evidence; but we do not <em>update</em> on these population-level beliefs once we see the data from a single case. Importantly, as we show later in the book, we <em>do</em> update on population-level inferences in the more general setup that we introduce in Chapter <a href="mixing.html#mixing">8</a> for analyzing mixed data in multiple cases. We also show in Chapter <a href="evaluation.html#evaluation">16</a> how we can test the sensitivity of conclusions to the values at which we set population parameters. Interestingly, as we also show, process-tracing inferences, including uncertainty about conclusions, are unaffected by the level of uncertainty we might have about population parameters; we thus do not specify this uncertainty for the purposes of process tracing.</p>
<p>The relationship between causal types, nodal types, and the correlation among nodal types is captured in what we call a <em>parameter matrix.</em> We show a parameter matrix for a simple <span class="math inline">\(X \rightarrow Y\)</span> model with no unobserved confounding in Table <a href="#tab:parammatrix"><strong>??</strong></a>. Here each column label (except the last) represents the probability that a case is of a given causal type. Each row label represents a population-level parameter: a belief about the proportions of different nodal types in the population. We indicate a set of possible parameter values in the final column.</p>
<table>
<caption><span id="tab:parammmatrix">Table 6.2: </span>. A mapping between nodal types and causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model (with no unobserved confounding).</caption>
<colgroup>
<col width="13%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Causal types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></th>
<th align="center">Parameter values (population proportions)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Population parameters</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^X_1\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.5</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^X_0\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.4</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.2</td>
</tr>
</tbody>
</table>
<p>To start with the first two rows, these represent the population proportions of each of <span class="math inline">\(X\)</span>’s nodal types. For instance, <span class="math inline">\(\lambda^X_{0}\)</span> is our belief about the proportion of cases in the population that are of nodal type <span class="math inline">\(\theta^X_{0}\)</span>. The first row, <span class="math inline">\(\lambda^X_{1}\)</span>, represents our belief about the inverse: the proportion of cases in the population of type <span class="math inline">\(\theta^X_{1}\)</span>. We posit beliefs about these parameters in the final column, indicating that we think that half of cases in the population are “assigned” to <span class="math inline">\(X=0\)</span> and half to <span class="math inline">\(X=1\)</span>. Note that, since there are only two possible nodal types for <span class="math inline">\(X\)</span>, and their proportions must sum to 1, there is actually just one degree of freedom here: once we’ve specified one of these parameter values, the other is defined as well.</p>
<p>The last four rows represent the proportion of cases in the population with different <span class="math inline">\(Y\)</span>-nodal types: in order, the proportion in which <span class="math inline">\(X\)</span> has no effect on <span class="math inline">\(Y\)</span>, with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(0\)</span>; the proportion in which <span class="math inline">\(X\)</span> has a negative effect; the proportion in which <span class="math inline">\(X\)</span> has a positive effect; and the proportion in which <span class="math inline">\(X\)</span> has no effect, with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>. Again, in the last column, we provide possible values for these proportions, the four of which must also sum to <span class="math inline">\(1\)</span>. Here we are stating that positive <span class="math inline">\(X \rightarrow Y\)</span> effects are twice as common in the population as the other three nodal types, which we set at equal prevalence.</p>
<p>The interior cells indicate whether a given population parameter enters into the prior probability of a given causal type. Thus, for instance, to calculate the prior probability of the causal type <span class="math inline">\(\theta^X_1, \theta^Y_{10}\)</span>, we need to multiply the two parameters values corresponding to the <span class="math inline">\(1\)</span>’s in this causal type’s column: <span class="math inline">\(\lambda^X_1\)</span> by <span class="math inline">\(\lambda^Y_{10}\)</span>. Given the parameter values we have assigned for this example, then, the prior on this causal type is simply <span class="math inline">\(0.5 \times 0.2 = 0.1\)</span>.</p>
<p>The prior probability that a case is of a given causal type thus comes directly from our beliefs about how nodal types are distributed in the population. All we know before we study a case is whatever we know about cases “like” it in general. It is then these causal-type probabilities – which represent probabilities that a <em>given case</em> is of a particular causal type – that we will update on once we see the data for this case.</p>
<p>We show the somewhat more complex situation of unobserved confounding in Table <a href="#tab:parammatrixconf"><strong>??</strong></a>. It is the first four rows that allow for unobserved confounding—the correlations across types. In a potential outcomes framework, we could think of these rows as capturing differential “assignment propensities” for <span class="math inline">\(X\)</span>. Here, we allow for different probabilities of <span class="math inline">\(X\)</span>’s type being <span class="math inline">\(\theta^X_1\)</span> depending on what <span class="math inline">\(Y\)</span>’s type is. Thus, <span class="math inline">\(\lambda^X_0 | \theta^Y= \theta^Y_{01}\)</span> is the proportion of <span class="math inline">\(\theta^X_0\)</span> types among cases with <span class="math inline">\(\theta^Y_{01}\)</span> type: put differently, it is the probability of <span class="math inline">\(X\)</span> being assigned to <span class="math inline">\(0\)</span> when <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. The second row represents the inverse proportion: the proportion of a <span class="math inline">\(\theta^X_1\)</span> types among <span class="math inline">\(\theta^Y_{01}\)</span> types. The next two rows then capture the proportions of the <span class="math inline">\(X\)</span>-types among all <em>other</em> <span class="math inline">\(Y\)</span>-types (i.e., among those cases for which <span class="math inline">\(X\)</span> does <em>not</em> have a positive effect on <span class="math inline">\(Y\)</span>).</p>
<p>Unobserved confounding in this setup takes the form of a difference in the proportions of a given <span class="math inline">\(X\)</span> type among different <span class="math inline">\(Y\)</span> types. Thus, if <span class="math inline">\(\lambda^X_1, | \theta^Y_{01}\)</span> is not the same as <span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span>, we have unobserved confounding. Imagine, for instance, if we are studying the effect of faster economic growth (<span class="math inline">\(X\)</span>) on democratization (<span class="math inline">\(Y\)</span>), and we believe that there is some unobserved factor that both makes some countries’ economies grow more quickly and also makes economic growth more likely to have a positive effect on democratization. This belief amounts to a belief that the probability of a case being assigned to <span class="math inline">\(X=1\)</span> is higher if <span class="math inline">\(Y\)</span>’s nodal type is <span class="math inline">\(\theta^Y_{01}\)</span> than if it is not. In other words, in terms of the rows in Table <a href="#tab:parammatrix"><strong>??</strong></a>, we believe here that <span class="math inline">\(\lambda^X_1 | \theta^Y=\theta^Y_{01}\)</span> is greater than <span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span>. To illustrate, we provide parameter values along these lines in the final column.</p>
<p>Again, however, a researcher might prefer to specify the confounder (say, <span class="math inline">\(Z\)</span>) as a node in the model. The rows in the parameter matrix would then be a set of population parameters defined as proportions of <em>un</em>conditional nodal types, with four <span class="math inline">\(X\)</span>-types representing possible responses to <span class="math inline">\(Z\)</span>, and 16 <span class="math inline">\(Y\)</span> types, representing <span class="math inline">\(Y\)</span>’s possible responses to <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.</p>
<table>
<caption><span id="tab:parammmatrixconf">Table 6.3: </span>. A mapping between nodal types and causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model <em>with</em> unobserved confounding.</caption>
<colgroup>
<col width="16%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="right"><strong>Causal Types <span class="math inline">\(\rightarrow\)</span></strong></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Population parameters <span class="math inline">\(\downarrow\)</span></strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^X_0 | \theta^Y= \theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^X_1 | \theta^Y=\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^X_0| \theta^Y \neq \theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<!-- In this case the number of parameters may exceed the number of nodal types, with, for instance parameters $\hat{\lambda}^Y_{11}$ representing $\Pr(\theta^Y = \theta^Y_{11}|\theta^X = \theta^X_1)$  and $\tilde{\lambda}^Y_{11}$ representing $\Pr(\theta^Y = \theta^Y_{11}|\theta^X = \theta^X_0)$.   -->
<p>One special kind of prior that we might wish to set is to disallow a particular (conditional) type altogether. For instance, if studying the effect of we may believe that</p>
<p><strong>Possible data types.</strong> A <em>data type</em> is a particular pattern of data that we could potentially observe for a given case. More specifically, a data type is a set of values, one for each node in a model. For instance, in our <span class="math inline">\(X, W, Y\)</span> setup, <span class="math inline">\(X=1, W=0, Y=0\)</span> would be one data type.</p>
<p>Importantly, each possible causal type <em>maps into a single data type.</em> One intuitive way to think about why this is the case is that a causal type tells us (a) the values to which all exogenous variables in a model are assigned and (b) how all endogenous variables respond to their parents. Given these two components, only one set of node values is possible. For example, causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_0, \theta^Y = \theta^Y_{0100})\)</span> imples data <span class="math inline">\(X=1, W=0, Y=1\)</span>. There is no other set of data that can be generated by this causal type.</p>
<p>Equally importantly, however, <em>the mapping from causal types to data types is not one-to-one.</em> More than one causal type can generate the same case-level data pattern. For instance, the causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_0, \theta^Y = \theta^Y_{1101})\)</span> will <em>also</em> generate the data type, <span class="math inline">\(X=1, W=0, Y=1\)</span>. Thus, observing this data type leaves us with ambiguity about the causal type by which it was generated.</p>
<p>A full mapping between causal types and data types can be summarized by an “ambiguity matrix.” In Table <a href="pt.html#tab:ambigmatrix">6.4</a>, we provide an example of such a matrix, derived directly from the parameter matrix in Table <a href="#tab:parammatrix"><strong>??</strong></a>. Here, the rows represent causal types and the columns (except for the last) represent data types. The notation for data types is straightforward, with for instance <span class="math inline">\(X0Y0\)</span> meaning that <span class="math inline">\(X=0, Y=0\)</span> has been observed. In the interior cells, the <span class="math inline">\(1\)</span>’s and <span class="math inline">\(0\)</span>’s indicate whether or not a given data type could arise from a given causal type. We can readily see here that each causal type can generate only one data type.</p>
<p>We can also see the ambiguity of the data, however, since each data type can be generated by two causal types. For instance, if we observe <span class="math inline">\(X=1, Y=1\)</span>, we know that the case is either of causal type <span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span> or of causal type <span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span> – but do not know which.</p>
<table>
<caption><span id="tab:ambigmatrix">Table 6.4: </span>. An ambiguity matrix, mapping from data types to causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model.</caption>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X0Y0</th>
<th align="center">X1Y0</th>
<th align="center">X0Y1</th>
<th align="center">X1Y1</th>
<th align="center">Priors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.1</td>
</tr>
</tbody>
</table>
<p>In the last column, we provide prior probabilities for each of the causal types. These have been calculated directly from the parameter matrix (Table <a href="#tab:parammatrix"><strong>??</strong></a>). To see how the calculation works, start with a causal type in the parameter matrix – say, <span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span>. We go down that causal type’s column and select the rows with <span class="math inline">\(1\)</span>’s, representing the parameters for the included nodal types, <span class="math inline">\(\lambda^X_0\)</span> and <span class="math inline">\(\lambda^Y_{01}\)</span>. As we want the joint probability of these two nodal types (and a parameter matrix is constructed such that the rows represent independent events),<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a> we simply multiply together the values for these included parameters: <span class="math inline">\(0.5 \times 0.4 = 0.2\)</span>. As noted, our prior belief about whether the case at hand is of a given causal type is a straightforward function of our beliefs about how prevalent each of the component nodal types is in the population.</p>
<p>As models get more complex, the numbers of causal and data types simply multiply. In Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, we show the ambiguity matrix for a simple mediation model (<span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>). Here, the causal types are combinations of three nodal types, one for each variable in the model. Similarly, the data types have three elements, one for each variable. We now have 8 data types and 32 causal types.</p>
<table>
<caption><span id="tab:ambigmatrixmed">Table 6.5: </span>. An ambiguity matrix, mapping from data types to causal types for a simpe mediation model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>.</caption>
<colgroup>
<col width="31%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="18%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X0M0Y0</th>
<th align="center">X1M0Y0</th>
<th align="center">X0M1Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">X0M0Y1</th>
<th align="center">X1M0Y1</th>
<th align="center">X0M1Y1</th>
<th align="center">X1M1Y1</th>
<th align="center">Priors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.08</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.08</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
</tr>
</tbody>
</table>
<p>Again, the ambiguities arising from data patterns are apparent. For instance, if we observe <span class="math inline">\(X=1, M=0, Y=0\)</span>, we see that there are four causal types that could have generated this pattern. To unpack the situation a bit, these data tell us that <span class="math inline">\(\theta^X = \theta^X_1\)</span>. But they do not tell us whether <span class="math inline">\(M\)</span>’s type is such that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(M\)</span> (<span class="math inline">\(\theta^M_{10}\)</span>) or <span class="math inline">\(X\)</span> has no effect with <span class="math inline">\(M\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^M_{00}\)</span>). Similarly, we do not know whether <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (<span class="math inline">\(\theta^Y_{01}\)</span>) or no effect with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^Y_{00}\)</span>). This leaves four combinations of nodal types—four causal types—that are consistent with the data.</p>
<p>Our priors here derive from a set of parameter values, much like in the previous example, in which the <span class="math inline">\(X\)</span> types are equally common (0.5 each); a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> is twice as common (0.4) as the other <span class="math inline">\(M\)</span> types (all set to 0.2); and a positive effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> is twice as common (0.4) as all other <span class="math inline">\(Y\)</span> types (all at 0.2). We can then easily see why we thus get priors on some causal types are higher than those on others: for instance, the two causal types with priors of 0.08 both have two positive effects (at the <span class="math inline">\(X \rightarrow Y\)</span> and <span class="math inline">\(M \rightarrow Y\)</span> stages) while the causal types with priors of 0.02 include no positive effects at either stage.</p>
<!-- ```{r ambigmatrix, echo = FALSE} -->
<!-- ambXY_with_priors <- data.frame(cbind(ambiguityXY, prior = draw_type_prob(XY, using = "parameters"))) -->
<!-- kable(ambXY_with_priors), caption = "Ambiguity matrix for X -> Y model. Rows are causal types, columns are data types. Last column shows possible priors over rows.") -->
<!-- ``` -->
<!-- For an $X \rightarrow Y$ model: -->
<div id="htmlwidget-c1840433e9538d82403c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-c1840433e9538d82403c">{"x":{"filter":"none","caption":"<caption>Ambiguity matrix for X -&gt; M -&gt; Y model. Rows are causal types, columns are data types. Last column shows possible priors over rows.<\/caption>","data":[["X0M00Y00","X1M00Y00","X0M10Y00","X1M10Y00","X0M01Y00","X1M01Y00","X0M11Y00","X1M11Y00","X0M00Y10","X1M00Y10","X0M10Y10","X1M10Y10","X0M01Y10","X1M01Y10","X0M11Y10","X1M11Y10","X0M00Y01","X1M00Y01","X0M10Y01","X1M10Y01","X0M01Y01","X1M01Y01","X0M11Y01","X1M11Y01","X0M00Y11","X1M00Y11","X0M10Y11","X1M10Y11","X0M01Y11","X1M01Y11","X0M11Y11","X1M11Y11"],[1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,1],[0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02,0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02,0.04,0.04,0.04,0.04,0.08,0.08,0.04,0.04,0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>X0M0Y0<\/th>\n      <th>X1M0Y0<\/th>\n      <th>X0M1Y0<\/th>\n      <th>X1M1Y0<\/th>\n      <th>X0M0Y1<\/th>\n      <th>X1M0Y1<\/th>\n      <th>X0M1Y1<\/th>\n      <th>X1M1Y1<\/th>\n      <th>prior<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","sDom":"<\"top\">lrt<\"bottom\">ip","scrollY":true,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><strong>Updating on types given the data.</strong> Once we observe actual data in a case, we can then update on the probabilities assigned to each causal type. The logic is simple. When we observe a set of data from a case, we place <span class="math inline">\(0\)</span> probability on all causal types that could not have produced these data; we then scale up the probabilities on all causal types that could have.</p>
<p>We can see how this works within an ambiguity matrix. Let’s return to the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrix">6.4</a>. We start out with a set of probability weights on all rows (causal types). Now, suppose that we observe the data <span class="math inline">\(X=1, Y=1\)</span>, i.e., data type <span class="math inline">\(X1Y1\)</span>. We then look down the <span class="math inline">\(X1Y1\)</span> column, and we know that all rows with a <span class="math inline">\(0\)</span> in them represent causal types that <em>could not have</em> generated these data. These causal types are thus excluded. What is left are two rows: <span class="math inline">\(\theta^X_1, \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1, \theta^Y_{11}\)</span>. Returning now to the probabilities, we put 0 weight on all of the excluded rows; and then we scale up the remaining probabilities so that they sum to 1 (preserving the ratio between them). The priors of 0.2 and 0.1 in the retained rows scale up to <span class="math inline">\(\frac{2}{3}\)</span> and <span class="math inline">\(\frac{1}{3}\)</span>, which become our <em>posterior</em> probabilities on the causal types. We display an updated ambiguity matrix, with excluded data types and causal types removed, in Table <a href="pt.html#tab:ambigupdate">6.6</a>.</p>
<p>Before we see any data on the case at hand, then, we believe (based on our beliefs about the population to which the case belongs) that there is a 0.2 probability that the case is one in which <span class="math inline">\(X\)</span> is assigned to <span class="math inline">\(1\)</span> and has a positive effect on <span class="math inline">\(Y\)</span>; and 0.1 probability that it’s a case in which <span class="math inline">\(X\)</span> gets assigned to <span class="math inline">\(1\)</span> and has no effect on <span class="math inline">\(Y\)</span> with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>. Seeing the <span class="math inline">\(X=1, Y=1\)</span> data, we now believe that there is a 0.667 probability that the case is of the former type, and a 0.333 probability that it is of the latter type.</p>
<table>
<caption><span id="tab:ambigupdate">Table 6.6: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrix">6.4</a>, after observing <span class="math inline">\(X=1, Y=1\)</span> in a case.</caption>
<colgroup>
<col width="34%" />
<col width="6%" />
<col width="26%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1Y1</th>
<th align="center">Priors on causal types</th>
<th>Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.2</td>
<td>0.6667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.1</td>
<td>0.3333</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- ambXY_with_priors%>% -->
<!--     mutate(type = rownames(ambXY_with_priors)) %>% -->
<!--     select(type, X1Y1, prior) %>% -->
<!--     filter(X1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable() -->
<!-- ``` -->
<p>We can also see how this works for our <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, and the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>. If we observe the data <span class="math inline">\(X=1, M=0, Y=0\)</span>, for instance, this exercise would yield the updated ambiguity matrix in Table (tab:ambigmedupdate). Here we have eliminated all rows (causal types) with a <span class="math inline">\(0\)</span> in the relevant data-type column (<span class="math inline">\(X1M0Y0\)</span>) and formed the posteriors by scaling up the priors in the retained rows.</p>
<table>
<caption><span id="tab:ambigmedupdate">Table 6.7: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, after observing <span class="math inline">\(X=1, M=0, Y=0\)</span> in a case.</caption>
<colgroup>
<col width="40%" />
<col width="7%" />
<col width="23%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1667</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.3333</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.3333</td>
</tr>
</tbody>
</table>
<p>A notable feature of the logic of single-case process tracing is that the relative probabilities on the retained causal types never change. If we start out believing that causal type <span class="math inline">\(A\)</span> is twice as likely as causal type <span class="math inline">\(B\)</span>, and both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are retained once we see the data, then <span class="math inline">\(A\)</span> will be twice as likely as <span class="math inline">\(B\)</span> in our posteriors. All updating occurs by <em>eliminating</em> causal types from consideration and zeroing in on those that remain.</p>
<table>
<thead>
<tr class="header">
<th align="left">type</th>
<th align="right">X1M0Y0</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M00Y00</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1667</td>
</tr>
<tr class="even">
<td align="left">X1M10Y00</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1667</td>
</tr>
<tr class="odd">
<td align="left">X1M00Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.3333</td>
</tr>
<tr class="even">
<td align="left">X1M10Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.3333</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- data.frame(cbind(ambiguityXMY)) %>% -->
<!--     mutate(type = rownames(ambiguityXMY), prior = draw_type_prob(XMY)) %>% -->
<!--     select(type, X1M1Y1, prior) %>% -->
<!--     filter(X1M1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable(digits = 2) -->
<!-- ``` -->
<p>A similar logic applies if partial data are observed: that is, if we do not collect data for all nodes in the model. The one difference is that, now, rather than reducing to one column we entertain the possibility of any data <em>type</em> consistent with the <em>observed data</em>. In general, more than one data type will be consistent with partial data. For instance, suppose that we observe <span class="math inline">\(X=1, Y=0\)</span> but do not observe <span class="math inline">\(M\)</span>’s value. These are data that are consistent with both the data type <span class="math inline">\(X1M0Y0\)</span> and the data type <span class="math inline">\(X1M1Y0\)</span> (since the unobserved <span class="math inline">\(M\)</span> could be either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>). We thus retain both of these data-type columns as well as all causal types consistent with <em>either</em> of these data types. This gives the updated ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdatepartial">6.8</a>. We note that, with these partial data, we are not able to update as strongly. For instance, for the causal type <span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span>, instead of updating to a posterior probability of 0.1667, we update to a posterior of only 0.0833 – because there is a larger set of causal types with which these partial data are consistent.</p>
<table>
<caption><span id="tab:ambigmedupdatepartial">Table 6.8: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.</caption>
<colgroup>
<col width="37%" />
<col width="7%" />
<col width="7%" />
<col width="22%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left">type</th>
<th align="right">X1M0Y0</th>
<th align="right">X1M1Y0</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M00Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.02</td>
<td align="right">0.0833</td>
</tr>
<tr class="even">
<td align="left">X1M10Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.02</td>
<td align="right">0.0833</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.1667</td>
</tr>
<tr class="even">
<td align="left">X1M11Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.0833</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.1667</td>
</tr>
<tr class="even">
<td align="left">X1M11Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.0833</td>
</tr>
<tr class="odd">
<td align="left">X1M00Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.04</td>
<td align="right">0.1667</td>
</tr>
<tr class="even">
<td align="left">X1M10Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.04</td>
<td align="right">0.1667</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- data.frame(cbind(ambiguityXMY)) %>% -->
<!--     mutate(type = rownames(ambiguityXMY), prior = draw_type_prob(XMY)) %>% -->
<!--     select(type, X1M0Y1, X1M1Y1, prior) %>%  -->
<!--     filter(X1M1Y1 ==1 | X1M0Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable(digits = 2) -->
<!-- ``` -->
<p><strong>Updating on estimands.</strong> We now have a posterior probability for each causal type for the case at hand. The causal question we are interested in answering, our estimand, may not be about causal types <em>per se.</em> It is about an estimand that can be expressed as a <em>combination</em> of causal types.</p>
<p>For instance, suppose we are working with the model <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>; and that our question is, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?”. This question is asking both:</p>
<ol style="list-style-type: decimal">
<li><p>Does <span class="math inline">\(X=1\)</span> in this case?</p></li>
<li><p>Does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> in this case?</p></li>
</ol>
<p>The causal types that qualify are those, and only those, in which the answer to both is “yes.”</p>
<p>Meeting condition (1) requires that <span class="math inline">\(\theta^X=\theta^X_1\)</span>.</p>
<p>Meeting condition (2) requires that <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span> are such that <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(M\)</span> that yields a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. This could occur via a positive <span class="math inline">\(X \rightarrow M\)</span> effect linked to a positive <span class="math inline">\(M \rightarrow Y\)</span> effect or via a negative <span class="math inline">\(X \rightarrow M\)</span> effect linked to a negative <span class="math inline">\(M \rightarrow Y\)</span> effect.</p>
<p>Thus, the qualifying causal types in this model are:</p>
<ul>
<li><span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span></li>
<li><span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span></li>
</ul>
<p>Our <em>prior</em> on the estimand—what we believe before we collect data on the case at hand—is given simply by summing up the prior probabilities on each of the causal types that correspond to the estimand. Note that we must calculate the prior from the full ambiguity matrix, before excluding types for inconsistency with the data. Returning to the full ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, we see that the priors on these two types (given the population parameters assumed there) are 0.08 and 0.02, respectively, giving a prior for the estimand of 0.1.</p>
<p>The posterior on any estimand is, likewise, given by summing up the posterior probabilities on each of the causal types that correspond to the estimand, drawing of course from the updated ambiguity matrix. For instance, if we observe the data <span class="math inline">\(X=1, M=1, Y=1\)</span>, we update to the ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdate2">6.9</a>. Our posterior on the estimand, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?” is the sum of the posteriors on the above two causal types. Since <span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span> is excluded by the data, this just leaves the posterior on <span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span>, 0.4444, which is the posterior belief on our estimand.</p>
<p>If we observe only the partial data, <span class="math inline">\(X=1, Y=1\)</span>, then we update to the ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdatepartial2">6.10</a>. Now both corresponding causal types are included, and we sum their posteriors to get the posterior on the estimand: <span class="math inline">\(0.0769 + 0.3077 = 0.3846\)</span>.</p>
<!-- FLAG: Briefly discuss other estimand(s) one could do, though don't show in detail here. Will do pathways in Chap. 7. -->
<table>
<thead>
<tr class="header">
<th align="left">type</th>
<th align="right">X1M1Y1</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M01Y01</td>
<td align="right">1</td>
<td align="right">0.08</td>
<td align="right">0.4444</td>
</tr>
<tr class="even">
<td align="left">X1M11Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.2222</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y11</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.2222</td>
</tr>
<tr class="even">
<td align="left">X1M11Y11</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1111</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:ambigmedupdate2">Table 6.9: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, after observing <span class="math inline">\(X=1, M=1, Y=1\)</span> in a case.</caption>
<colgroup>
<col width="40%" />
<col width="7%" />
<col width="23%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M1Y1</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.08</td>
<td align="center">0.4444</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.2222</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.2222</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1111</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:ambigmedupdatepartial2">Table 6.10: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">6.5</a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.</caption>
<colgroup>
<col width="37%" />
<col width="7%" />
<col width="7%" />
<col width="22%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.08</td>
<td align="center">0.3077</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1538</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1538</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- ambXMY_with_priors%>% -->
<!--     mutate(type = rownames(ambXMY_with_priors)) %>% -->
<!--     select(type, X1M0Y1, X1M1Y1, prior) %>% -->
<!--     filter(X1M0Y1 ==1 | X1M1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable() -->
<!-- ``` -->
<p>For more complex models and estimands, it can be more difficult to eyeball the corresponding causal types. In practice, therefore, we use the <code>get_query_types</code> function in the <code>CausalQueries</code> package to do this for us.</p>
<!-- For example, supposer we want to know whether $X$ has some causal effect on $Y$ in our simple mediation model. The estimand, "$X$ haa a causal effect on $Y$" maps onto a relatively large, though still easily calculated, collection of types. Using `gbiqq`'s get_types function, we would define our query as a search for all causal types in which $Y$'s potential outcome when $X=1$ is different from $Y$'s potential outcome when $X=0$. The function then reports back all causal types meeting this condition: -->
<!-- ```{r, eval = FALSE} -->
<!-- get_types(XMY, "Y[X=1] != Y[X=0]") -->
<!-- ``` -->
<pre><code>X0.M10.Y10, X1.M10.Y10, X0.M01.Y10, X1.M01.Y10, X0.M10.Y01, X1.M10.Y01, X0.M01.Y01, X1.M01.Y01</code></pre>
<p>This completes the abstract representation of the process tracing procedure. We now build up the intuition by walking through the procedure for simple mediation and moderation models.</p>
</div>
<div id="illustration-with-code" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Illustration with code</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="pt.html#cb3-1"></a>XMY &lt;-<span class="st"> </span><span class="kw">make_model</span>(<span class="st">&quot;X -&gt; M -&gt; Y&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-2"><a href="pt.html#cb3-2"></a><span class="st">       </span><span class="kw">set_parameters</span> (<span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.5</span>, <span class="fl">.2</span>, <span class="fl">.2</span>, <span class="fl">.4</span>, <span class="fl">.2</span>, <span class="fl">.2</span>, <span class="fl">.2</span>, <span class="fl">.4</span>, <span class="fl">.2</span>))</span>
<span id="cb3-3"><a href="pt.html#cb3-3"></a></span>
<span id="cb3-4"><a href="pt.html#cb3-4"></a><span class="kw">query_model</span>(<span class="dt">model =</span> XMY, </span>
<span id="cb3-5"><a href="pt.html#cb3-5"></a>              <span class="dt">queries =</span> <span class="kw">list</span>(<span class="dt">PC =</span> <span class="st">&quot;Y[X=1] &gt; Y[X=0]&quot;</span>), </span>
<span id="cb3-6"><a href="pt.html#cb3-6"></a>              <span class="dt">given =</span> <span class="kw">list</span>(<span class="ot">TRUE</span>, <span class="st">&quot;X==1 &amp; Y==1&quot;</span>, <span class="st">&quot;X==1 &amp; Y==1 &amp; M==0&quot;</span>, <span class="st">&quot;X==1 &amp; Y==1 &amp; M==1&quot;</span>),</span>
<span id="cb3-7"><a href="pt.html#cb3-7"></a>              <span class="dt">using =</span> <span class="st">&quot;parameters&quot;</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PC</td>
<td align="left">-</td>
<td align="left">parameters</td>
<td align="right">0.200</td>
</tr>
<tr class="even">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">parameters</td>
<td align="right">0.385</td>
</tr>
<tr class="odd">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1 &amp; M==0</td>
<td align="left">parameters</td>
<td align="right">0.250</td>
</tr>
<tr class="even">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1 &amp; M==1</td>
<td align="left">parameters</td>
<td align="right">0.444</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="five-principles" class="section level2">
<h2><span class="header-section-number">6.2</span> Five principles</h2>
<div id="classic-qualitative-tests-are-special-cases-of-updating-on-a-model" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Classic qualitative tests are special cases of updating on a model</h3>
<p>The approach we have described here updates on the model given data on all variables, and from the model makes inferences to estimands.</p>
<p>This procedure appears different to the approach described, for example, in <span class="citation">Collier, Brady, and Seawright (<a href="#ref-collier2004sources" role="doc-biblioref">2004</a>)</span> and in Chapter 5, in which one seeks specific evidence that is directly informative about causal propositions: “clues” that are arise with different probabilities if one proposition or another is true. In fact however the approaches are deeply connected. This “probative value of clues” approach can indeed be <em>justified</em> by reference to more fully elaborated models of the world.</p>
<p>To see this we can write down the probability of observing <span class="math inline">\(K=1\)</span> conditional on causal type <span class="math inline">\(X\)</span>, using the <span class="math inline">\(\phi\)</span> notation from <span class="citation">Humphreys and Jacobs (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span> and introduced in Chapter 5. Here <span class="math inline">\(\phi_{jx}\)</span> refers to the probability of observing a clue in a case of type <span class="math inline">\(j\)</span> when <span class="math inline">\(X=x\)</span>. Starting with our prior distribution over the lower-level causal types (the <span class="math inline">\(\lambda\)</span>’s), we can derive, for an <span class="math inline">\(X=1\)</span> case, the probability of seeing the clue if the case is of type <span class="math inline">\(b\)</span> (positive effect) or of type <span class="math inline">\(d\)</span> (no effect, <span class="math inline">\(Y\)</span> always <span class="math inline">\(1\)</span>):</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\phi_{b1} &amp; = \frac{\lambda_{01}^{K}\lambda_{01}^{Y}}{\lambda_{01}^{K}\lambda_{01}^{Y}+\lambda_{10}^{K}\lambda_{10}^{Y}}\\ 
\phi_{d1} &amp; = \frac{\lambda_{11}^{Y}(\lambda_{01}^{K}+\lambda_{11}^{K})+\lambda_{11}^{K}\lambda_{01}^{Y}}{\lambda_{11}^{Y} + \lambda_{00}^{K}\lambda_{10}^{Y} + \lambda_{11}^{K}\lambda_{01}^{Y}}
\end{split}
\label{eqn:phisfromlambdas}
\end{equation}\]</span></p>
<p>These quantities allow for easy mapping between our prior beliefs about our causal query—as expressed in the lower level model—and the classic process-tracing tests in <span class="citation">Van Evera (<a href="#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span>. Figure <a href="pt.html#fig:phis">6.2</a> illustrates. In each panel, we manipulate a prior for one or more of the lower-level causal effects, keeping all other priors flat, and we see how probative value changes. As the curves for <span class="math inline">\(\phi_b\)</span> and <span class="math inline">\(\phi_d\)</span> diverge, probative value is increasing since there is an increasing difference between the probability of seeing the clue if <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> and the probability of seeing the clue if <span class="math inline">\(X\)</span> has no effect.</p>
<p>In the left panel, we see that as we place a lower prior probability on <span class="math inline">\(K\)</span>’s being negatively affected by <span class="math inline">\(X\)</span>,<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a> seeking <span class="math inline">\(K=1\)</span> increasingly takes on the quality of a hoop test for <span class="math inline">\(X\)</span>’s having a positive effect on <span class="math inline">\(Y\)</span>. The clue, that is, increasingly becomes something we must see if <span class="math inline">\(X\)</span> positively affects <span class="math inline">\(Y\)</span>, with the clue remaining moderately probable if there is no effect. Why? The less likely we believe it is that <span class="math inline">\(K=0\)</span> was caused by <span class="math inline">\(X=1\)</span>, the less consistent the observation of <span class="math inline">\(K=0\)</span> is with <span class="math inline">\(X\)</span> having a positive causal effect on <span class="math inline">\(Y\)</span> via <span class="math inline">\(K\)</span> (since, to have such an effect, if <span class="math inline">\(X=1\)</span> and <span class="math inline">\(K=0\)</span>, would precisely have to mean that <span class="math inline">\(X=1\)</span> <em>caused</em> <span class="math inline">\(K=0\)</span>).</p>
<p>In the second graph, we simultaneously change the prior probabilities of zero effects at both stages in the sequence: of <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span> being <span class="math inline">\(1\)</span> regardless of the values of <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span>, respectively.<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a> We see here that, as the probabilities of zero effects jointly diminish, seeking <span class="math inline">\(K=1\)</span> increasingly becomes a smoking-gun test for a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>: the probability of seeing the clue if the case is a <span class="math inline">\(d\)</span> type diminishes. The reason is that, as zero effects at the lower level become less likely, it becomes increasingly unlikely that <span class="math inline">\(K=1\)</span> could have occurred without a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(K\)</span>, and that <span class="math inline">\(Y=1\)</span> could have occurred (given that we have seen <span class="math inline">\(K=1\)</span>) without a posiitve effect of <span class="math inline">\(K\)</span> on <span class="math inline">\(Y\)</span>.</p>
<!-- This example also helps clarify the kind of theoretical knowledge required for drawing inferences from clues. As we have emphasized, the structural equations comprising a causal model can be fully non-parametric. As the example illustrates, $\theta_Y$ can be a type variable that determines different the equation for an endogenous variable in a causal model can  can take the form of beliefs about the proportions of  -->
<div class="figure" style="text-align: center"><span id="fig:phis"></span>
<img src="ii_files/figure-html/phis-1.png" alt="The probability of observing $K$ given causal type for different beliefs on lower-level causal effects. In the left figure, priors on all lower-level causal effects are flat except for the probability that $X$ has a negative effect on $K$. If we believe that it is unlikely that $X$ has a negative effect on $K$, $K$ becomes a `hoop' test for the proposition that a case is of type $b$. The righthand figure considers simultaneous changes in $\lambda_{11}^K$ and  $\lambda_{11}^Y$---the probabilities that $K=1$ regardless of $X$, and that $Y=1$  regardless of $K$, with flat distributions on all other lower-level effects. With $\lambda_{11}^K$, $\lambda_{11}^Y$ both close to 0, $K$ becomes a 'smoking gun' test for the proposition that $X$ has a positive effect on $Y$ ($b$ type)." width=".85\textwidth" />
<p class="caption">
Figure 6.2: The probability of observing <span class="math inline">\(K\)</span> given causal type for different beliefs on lower-level causal effects. In the left figure, priors on all lower-level causal effects are flat except for the probability that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(K\)</span>. If we believe that it is unlikely that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(K\)</span>, <span class="math inline">\(K\)</span> becomes a `hoop’ test for the proposition that a case is of type <span class="math inline">\(b\)</span>. The righthand figure considers simultaneous changes in <span class="math inline">\(\lambda_{11}^K\)</span> and <span class="math inline">\(\lambda_{11}^Y\)</span>—the probabilities that <span class="math inline">\(K=1\)</span> regardless of <span class="math inline">\(X\)</span>, and that <span class="math inline">\(Y=1\)</span> regardless of <span class="math inline">\(K\)</span>, with flat distributions on all other lower-level effects. With <span class="math inline">\(\lambda_{11}^K\)</span>, <span class="math inline">\(\lambda_{11}^Y\)</span> both close to 0, <span class="math inline">\(K\)</span> becomes a ‘smoking gun’ test for the proposition that <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (<span class="math inline">\(b\)</span> type).
</p>
</div>
</div>
<div id="a-dag-alone-does-not-get-you-probative-value" class="section level3">
<h3><span class="header-section-number">6.2.2</span> A DAG alone does not get you probative value</h3>
<p>Suppose that we start with the belief that any effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> must run through <span class="math inline">\(M\)</span>, and that there is no confounding at any stage. This implies the simple <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. Suppose, further, that we have no prior knowledge about the distribution of nodal types and thus posit flat priors over <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span>. Now we would like to conduct process tracing and observe <span class="math inline">\(M\)</span> to tell us about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. In an <span class="math inline">\(X=Y=1\)</span> case, for instance, is this model sufficient to allow the observation of <span class="math inline">\(M\)</span> to provide leverage on whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>?</p>
<p>It is not. We can learn nothing from about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> from <span class="math inline">\(M\)</span>. Observing a process is <em>uninformative</em> if all that we know is the structure of relations of conditional independence.</p>
<p>To see why at an inuitive level, consider that there are two causal types that will satisfy the query, <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Those are the types <span class="math inline">\(\theta^X_1 \theta^M_{01} \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1 \theta^M_{10} \theta^Y_{10}\)</span>: either linked positive effects or linked negative effects could generate an overall positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Moreover, with flat priors over nodal types, these causal types are equally likely. Now, think about what we would conclude if we collected process data and observed <span class="math inline">\(M=1\)</span> in the <span class="math inline">\(X=Y=1\)</span> case. This observation would rule out one way in which the query could be satisfied: the causal type with linked negative effects. And what if we observed, instead, <span class="math inline">\(M=0\)</span>? This would rule out the other way in which the query could be satisfued: linked positive effects. But since each of these causal types started out with equal weights in our priors, there can be no updating from eliminating one or the other.</p>
</div>
<div id="uncertainty-does-not-alter-inference-for-single-case-causal-inference" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Uncertainty does not alter inference for single case causal inference</h3>
<p>In the procedure described for process tracing in this chapter (and different to what we introduce in Chapter 8) we assume that <span class="math inline">\(\lambda\)</span> is known and we do not place uncertainty around it.</p>
<p>This might appear somewhat heroic, but in fact for single case inference it is without loss of generality. The expected inferences we would make for any estimand accounting for priors is the same as the inferences we if we use the expectation only.</p>
<p>To see this, let <span class="math inline">\(\pi_j\)</span> denote the probability of observing causal type <span class="math inline">\(j\)</span> and <span class="math inline">\(p(D)\)</span> te probability of observing data realization <span class="math inline">\(D\)</span>. Say that <span class="math inline">\(j \in D\)</span> if type <span class="math inline">\(j\)</span> produces data type <span class="math inline">\(D\)</span> and say <span class="math inline">\(j \in E\)</span> if casual type <span class="math inline">\(j\)</span> is an element of the estimand set of interest. For instance in an <span class="math inline">\(X \rightarrow Y\)</span> model, if we observe <span class="math inline">\(X=Y=1\)</span> then <span class="math inline">\(D\)</span> consists of causal types <span class="math inline">\(D={(\theta^X_1, \theta^Y_{01}), (\theta^X_1, \theta^Y_{11})})\)</span> and the estimand set for “<span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>” consists of <span class="math inline">\(E={(\theta^X_1, \theta^Y_{01}), (\theta^X_0, \theta^Y_{01})})\)</span>.</p>
<p>The posterior on an estimand <span class="math inline">\(E\)</span> given data <span class="math inline">\(D\)</span> given prior over <span class="math inline">\(\pi\)</span>, <span class="math inline">\(p(\pi)\)</span> is:</p>
<p><span class="math display">\[\Pr(E | D) = \int_\pi  \frac{\sum_{j \in E \cap D}\pi_j}{\sum_{j \in D}\pi_j} f(\pi)d\pi\]</span></p>
<p>However, since for any <span class="math inline">\(\pi\)</span>, <span class="math inline">\(\sum_{j \in D}\pi_j = p(D)\)</span> we have:</p>
<p><span class="math display">\[\Pr(E | D) = \int_\pi  \sum_{j \in E \cap D}\pi_j f(\pi)d\pi/p(D) = \sum_{j \in  E \cap D} \overline{\pi}_j/p(D)\]</span></p>
</div>
<div id="probative-value-requires-d-connection" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Probative value requires <span class="math inline">\(d-\)</span>connection</h3>
<!-- Rules for inferring information about one variable from another are th stuff of graphoids  [@pearl1985graphoids] see also [@geiger1987non] and [@pearl1987logic]...  -->
<p>As we have argued, causal estimands can be expressed as the values of exogenous nodes in a causal graph. Case-level causal effects and causal paths can be defined in terms of response-type nodes; average effects and notable causes in terms of population-level parameter nodes (e.g., <span class="math inline">\(\pi\)</span> or <span class="math inline">\(\lambda\)</span> terms); and questions about actual causes in terms of exogenous conditions that yield particular endogenous values (conditioning on which makes some variable a counterfactual cause).</p>
<p>We thus define causal inference more generally as <em>the assessment of the value of one or more unobserved (possibly unobservable) exogenous nodes on a causal graph, given observable data.</em> To think through the steps in this process, it is useful to distinguish among three different features of the world, as represented in our causal model: there are the things we want to learn about; the things we have already observed; and the things we could observe. As notation going forward, let:</p>
<ul>
<li><span class="math inline">\(\mathcal Q\)</span> denote the exogenous variables that define our <em>query</em>; we generally assume that <span class="math inline">\(\mathcal Q\)</span> cannot be directly observed so that its values must be inferred</li>
<li><span class="math inline">\(\mathcal W\)</span> denote a set of previously observed nodes in the causal model, and</li>
<li><span class="math inline">\(\mathcal K\)</span> denote a set of additional variables—clues—that we have not yet observed but could observe.</li>
</ul>
<p>Now suppose that we seek to design a research project to investigate a causal question. How should the study be designed? Given that there are some features of the world that we have already observed, which additional clues should we seek to collect to shed new light on our question? In terms of the above notation, what we need to figure out is whether a given <span class="math inline">\(\mathcal K\)</span> might be informative about—might provide additional leverage on—<span class="math inline">\(\mathcal Q\)</span> given the prior observation of <span class="math inline">\(\mathcal W\)</span>.</p>
<p>To ask whether one variable (or set of variables) is informative about another is to ask whether the two (sets of) variables are, on average, <em>correlated</em> with one another, given whatever we already know. Likewise, if two variables’ distributions are fully <em>independent</em> of one another (conditional on what else we have observed), then knowing the value of one variable can provide no new information about the value of the other.</p>
<p>Thus, asking whether a set of clues, <span class="math inline">\(\mathcal K\)</span>, is informative about <span class="math inline">\(\mathcal Q\)</span> given the prior observation of <span class="math inline">\(\mathcal W\)</span>, is equivalent to asking whether <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are conditionally independent given <span class="math inline">\(\mathcal W\)</span>. That is, <span class="math inline">\(\mathcal K\)</span> can be informative about <span class="math inline">\(\mathcal Q\)</span> given <span class="math inline">\(\mathcal W\)</span> only if <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <em>not</em> conditionally independent of one another given <span class="math inline">\(\mathcal W\)</span>.</p>
<p>As we have shown, as long as we have built <span class="math inline">\(\mathcal Q\)</span>, <span class="math inline">\(\mathcal K\)</span>, and <span class="math inline">\(\mathcal W\)</span> into our causal model of the phenomenon of interest, we can answer this kind of question by inspecting the structure of the model’s DAG. In particular, what we need to go looking for are relationships of <em><span class="math inline">\(d\)</span>-separation</em>. The following proposition, with only the names of the variable sets altered, is from <span class="citation">Pearl (<a href="#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span> (Proposition 1.2.4):</p>
<p><strong>Proposition 1:</strong> If sets <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span> in a DAG, <span class="math inline">\(\mathcal G\)</span>, then <span class="math inline">\(\mathcal Q\)</span> is independent of <span class="math inline">\(\mathcal K\)</span> conditional on <span class="math inline">\(\mathcal W\)</span> in every distribution compatible with <span class="math inline">\(\mathcal G\)</span>. Conversely, if <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are <em>not</em> <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span> in DAG <span class="math inline">\(\mathcal W\)</span>, then <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are dependent conditional on <span class="math inline">\(\mathcal W\)</span> in at least one distribution compatible with <span class="math inline">\(\mathcal G\)</span>.</p>
<p>We begin with a causal graph and a set of nodes on the graph (<span class="math inline">\(W\)</span>) that we have already observed. Given what we have already observed, <em>a collection of clue nodes, <span class="math inline">\(\mathcal K\)</span>, will be uninformative about the query nodes, <span class="math inline">\(\mathcal Q\)</span>, if <span class="math inline">\(\mathcal K\)</span> is <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\mathcal Q\)</span> by <span class="math inline">\(\mathcal W\)</span> on the graph.</em> When <span class="math inline">\(\mathcal W\)</span> <span class="math inline">\(d\)</span>-separates <span class="math inline">\(\mathcal K\)</span> from <span class="math inline">\(\mathcal Q\)</span>, this means that what we have already observed already captures all information that the clues might yield about our query. On the other hand, if <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <span class="math inline">\(d\)</span>-connected (i.e., not <span class="math inline">\(d\)</span>-separated) by <span class="math inline">\(W\)</span>, then <span class="math inline">\(K\)</span> is <em>possibly</em> informative about <span class="math inline">\(Q\)</span>.<span class="math inline">\(K\)</span> is not <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\mathcal Q\)</span> by <span class="math inline">\(\mathcal W\)</span>.<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a> Note, moreover, that under quite general conditions (referred to in the literature as the <em>faithfulness</em> of a probability distribution) then there are at least <em>some</em> values of <span class="math inline">\(\mathcal W\)</span> for which <span class="math inline">\(\mathcal K\)</span> <em>will</em> be informative about <span class="math inline">\(\mathcal Q\)</span>.<a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a></p>
<!-- ^[In Pearl's terminonology, the graph may *represent* the probability distribution but not be *faithful* to it.] -->
<!-- This can be put another way. An $I$-map of $M$ is a model with no extra independencies; a $D$-map is a model that contains all of $M$ with,  possibly aditional independencies; a *perfect* map is a model with the same set of dependencies. Given an independency model $M$, a DAG, $G$, may be an $I$-map of $M$ in the sense that whenever $D$ separates $K$ from $Q$ then $I(K,D,Q)_M$, yet there may still be indepenencies in $M$ not captured by $G$; that is, it may also be htat $I(K,D,Q)_M$ but not $I(K,D,Q)_G$. Pearl refers to such cases as instances of a violation of *stability*, though in simple graphs with discrete variables such violations may be plausible.  -->
<!-- In the example given by Pearl with two matching pennies, $X_1$ and $X_2$ and $Y$ is 1 if the pennies match, $X_1$ adn $X_2$ are probabilisitcally independent of $Y$, yet $Y$ depends on both of them.  -->
<!-- The problem is that $d$-separation satisfies composition, that is, if $I(X_1, D, Q)$ and $I(X_2, D, Q)$ then $I(X_1X_2, D, Q)$; but since we cannot have $I(X_1X_2, D, Q)$ then we cannot have   $I(X_1, D, Q)$ and $I(X_2, D, Q)$ either (see also [@bouckaert1994conditional]). -->
<!-- Note that this example depends on infomration about the probability distribution over $V$, that is, the functional equations, and cannot be inferred from the structure of $S$ alone.   -->
<!-- [Note for us: We seek a  related proposition holds however using $d-separation$ on partially discovered submodels.] -->
<p>Let us examine Proposition 1 in practice. We begin with the simplest case possible, and then move on to more complex models.</p>
<p>The very simplest probabilistic causal graph has <span class="math inline">\(X\)</span> influencing <span class="math inline">\(Y\)</span>, with <span class="math inline">\(X\)</span> determined by a coin flip. Assuming that there is some causal heterogeneity—that is, it is unknown in any particular case whether <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>—we also include a response-type variable, <span class="math inline">\(Q\)</span>, pointing into <span class="math inline">\(Y\)</span>, as shown in Figure . Here, <span class="math inline">\(Q^Y\)</span> determines the value of <span class="math inline">\(Y\)</span> that will be generated by <span class="math inline">\(X\)</span>. Asking about the causal effect of <span class="math inline">\(X\)</span> in a case thus means learning the value of <span class="math inline">\(Q^Y\)</span> in that case. As will be recalled, in a binary setup with one causal variable, a response-type variable can take on one of four values, <span class="math inline">\(q^Y_{00}\)</span>, <span class="math inline">\(q^Y_{10}\)</span>, <span class="math inline">\(q^Y_{01}\)</span> and <span class="math inline">\(q^Y_{11}\)</span>,<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a> corresponding to the four possible causal types in this setting.</p>
<div class="figure" style="text-align: center"><span id="fig:sepsimple"></span>
<img src="ii_files/figure-html/sepsimple-1.png" alt="\label{fig:d-sepsimple} A simple causal setup in which the effect of $X$ on $Y$ in a given case depends on the case's response type for $Y$." width=".5\textwidth" />
<p class="caption">
Figure 6.3:  A simple causal setup in which the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a given case depends on the case’s response type for <span class="math inline">\(Y\)</span>.
</p>
</div>
<p>Let us assume that we have observed nothing yet in this case and then ask what clue(s) might be informative about <span class="math inline">\(Q^Y\)</span>, the node of interest. The other two nodes in the graph are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>: these are thus the possible clues that we might go looking for in our effort to learn about <span class="math inline">\(Q^Y\)</span> (i.e., they are the possible members of <span class="math inline">\(\mathcal K\)</span>).</p>
<p>First, can we learn about <span class="math inline">\(Q^Y\)</span> by observing <span class="math inline">\(X\)</span>? We can answer this question by asking whether <span class="math inline">\(X\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q^Y\)</span> on the graph given what we have already observed (which is nothing). We can see visually that there is no active path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Q^Y\)</span>: the only path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> is blocked by colliding arrow heads. Thus, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q^Y\)</span> are <span class="math inline">\(d\)</span>-separated, meaning that <span class="math inline">\(X\)</span> will not be informative about <span class="math inline">\(Q^Y\)</span>: observing the value that a causal variable takes on in a case—having seen nothing else in the case—tells us nothing whatsoever about that variable’s effect on the outcome. If we want to know whether a case is of a type in which the presence of natural resources would cause civil war, observing only that the case has natural resources does not help answer the question.</p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- In the case where we observe only $X$, the posterior on $Q^Y$ is: -->
<!-- \begin{eqnarray*} -->
<!-- P(Q^Y=q^Y | X=x) &=& \frac{\sum_{j=0}^1p(X=x)P(Q^Y=q^Y)P(Y=j|X=x, Q^Y=q^Y)}{\sum_{q^{Y'}}\sum_{j=0}^1p(X=x)P(Q^Y=q^{Y'})P(Y=j|X=x, Q^Y=q^{Y'})}\\ -->
<!-- &=&\frac{P(Q^Y=q^Y)}{\sum_{q^{Y'}}P(Q^Y=q^{Y'})} -->
<!-- \end{eqnarray*} -->
<!-- which is simply the prior on $Q^Y$. Thus, nothing is learned about $Q^Y$ from observing $X$ only.]  -->
<!-- <!-- &=& \frac{p(Q=q)\sum_{j=0}^1p(Y=j|X=x, Q=q)}{\sum_{q'}p(Q=q')\sum_{j=0}^1p(Y=j|X=x, Q=q')}\\ -->
<p>–&gt;
<!-- **...ENDING HERE** --></p>
<p>What, then, if we instead were to observe only <span class="math inline">\(Y\)</span>? Is <span class="math inline">\(Y\)</span> <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> given what we have already observed (which, again, is nothing)? It is: the arrow from <span class="math inline">\(Q^Y\)</span> to <span class="math inline">\(Y\)</span> is an active path. Observing only the <em>outcome</em> in a case does tell us something about causal effects. Returning to the natural resources and civil war example, observing only that a country has had a civil is informative about the case’s causal type (the value of <span class="math inline">\(Q^Y\)</span>). In particular, it rules out the possibility that this is a case in which nothing could cause a civil war: that is, it excludes <span class="math inline">\(q^Y_{00}\)</span> (i.e., <span class="math inline">\(c\)</span>-type) as a possible value of <span class="math inline">\(Q^Y\)</span>.</p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- In the case where we observe $Y$ only we have: -->
<!-- $$P(Q=q | Y=y) = \frac{\sum_{j=0}^1p(X=j)P(Q=q)P(Y=y|X=j, Q=q)}{\sum_{q'}\sum_{j=0}^1p(X=j)P(Q=q')P(Y=y|X=j, Q=q')}$$ -->
<!-- Here terms involving $Y$ and $Q$ cannot be separated, so the same kind of reduction is not possible. This implies scope for learning about $Q$ from $Y$.  For instance, if  we have $P(Q=j) = 1/4$ for type $j \in \{a,b,c,d\}$  and $P(X=j) = \frac{1}{2}$, then we have $P(Q=a | Y=1)=P(Q=b | Y=1) =\frac{1}{4}$, $P(Q=c | Y=1)=0$ and $P(Q=d | Y=1)=1$. -->
<!-- **...ENDING HERE** -->
<p>Suppose now, having observed <span class="math inline">\(Y\)</span>, that we were to consider also observing <span class="math inline">\(X\)</span>. Would we learn anything further about <span class="math inline">\(Q^Y\)</span> from doing so? We have already seen that observing <span class="math inline">\(X\)</span> alone yields no information about <span class="math inline">\(Q^Y\)</span> because the two nodes are unconditionally <span class="math inline">\(d\)</span>-separated, the path between them blocked by the colliding arrowheads at <span class="math inline">\(Y\)</span>. However, as we have seen, observing a collider variable (or one of its descendants) <em>unblocks</em> the flow of information, generating relations of conditional dependence across the colliding arrowheads. Here, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q^Y\)</span> are <span class="math inline">\(d\)</span>-connected by <span class="math inline">\(Y\)</span>: thus, if we have <em>already</em> observed <span class="math inline">\(Y\)</span>, then observing <span class="math inline">\(X\)</span> does confer additional information about <span class="math inline">\(Q^Y\)</span>. Knowing only that a country has natural resources tells us nothing about those resources’ effect on civil war in that country. But if we already know that the country has a civil war, then learning that the country has natural resources helps narrow down the case’s possible response types. Having already used the observation of <span class="math inline">\(Y=1\)</span> to rule out the possibility that <span class="math inline">\(Q^Y=q^Y_{00}\)</span>, observing <span class="math inline">\(X=1\)</span> <em>together with</em> <span class="math inline">\(Y=1\)</span> allows us to additionally rule out the possibility that natural resources <em>prevent</em> civil war, i.e., that <span class="math inline">\(Q^Y=q^Y_{01}\)</span>.<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a></p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- Where we observe both $Y$ and $X$,  we have: -->
<!-- $$P(Q=q | Y=y, X=x) = \frac{P(X=x)P(Q=q)P(Y=y|X=x, Q=q)}{\sum_{q'}P(X=x)P(Q=q')P(Y=y|X=x, Q=q')}$$ -->
<!-- which does not allow separation either of  $Q$ and $X$ or of $Q$ and $Y$. Thus, there is again learning from $Y$ and, given $Y$, there is *also* learning from $X$. Put differently, we have $P(Q|Y,X) \neq P(Q|Y)$.  -->
<!-- **...ENDING HERE** -->
<p>Finally, what if we observe <span class="math inline">\(X\)</span> first and are considering whether to seek information about <span class="math inline">\(Y\)</span>? Would doing so be informative? <span class="math inline">\(X\)</span> does not <span class="math inline">\(d-\)</span>separate <span class="math inline">\(Q^Y\)</span> from <span class="math inline">\(Y\)</span>; thus, observing <span class="math inline">\(Y\)</span> will be informative about <span class="math inline">\(Q^Y\)</span>. In fact, observing <span class="math inline">\(Y\)</span> if we have already seen <span class="math inline">\(X\)</span> is <em>more</em> informative than observing <span class="math inline">\(Y\)</span> alone. The reasoning follows the logic of collision discussed just above. If we observe <span class="math inline">\(Y\)</span> having already seen <span class="math inline">\(X\)</span>, not only do we reap the information about <span class="math inline">\(Q^Y\)</span> provided by <span class="math inline">\(Y\)</span>’s correlation with <span class="math inline">\(Q^Y\)</span>; we simultaneously open up the path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q^Y\)</span>, learning additionally from the conditional dependence between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q^Y\)</span> given <span class="math inline">\(Y\)</span>.</p>
<p>We put Proposition 1 to work in a slightly more complex set of models in Figure . Here we investigate the informativeness of a clue that is neither <span class="math inline">\(X\)</span> nor <span class="math inline">\(Y\)</span>. Each graph in Figure  has four variables: <span class="math inline">\(X\)</span>; <span class="math inline">\(Y\)</span>; a possible clue, <span class="math inline">\(K\)</span>; and a response-type variable, <span class="math inline">\(Q\)</span>. We draw all 34 possible graphs with variables <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(Q\)</span> for causal models in which (a) all variables are connected to at least one other variable, (b) <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> either directly or indirectly, and (c) <span class="math inline">\(Q\)</span> is a direct cause of <span class="math inline">\(Y\)</span> but is not caused by any other variable in the model and is thus exogenous. The title of each panel reports <span class="math inline">\(K\)</span>’s conditional informativeness using principles of <span class="math inline">\(d\)</span>-separation: it tells us when <span class="math inline">\(K\)</span> is possibly informative about <span class="math inline">\(Q\)</span> depending on whether <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, both or none are observed.<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a></p>
<!-- Above footnote: do we want to say "faithful" rather than stable, as we do earlier? -->
<div class="figure"><span id="fig:34graphs"></span>
<img src="ii_files/figure-html/34graphs-1.png" alt="\label{fig:34graphs} All connected directed acyclic graphs over $X,Y,K,Q$, in which $Q$ is an exogenous variable that directly causes $Y$, and $X$ is a direct or indirect cause of $Y$. The title of each graph indicates the conditions under which $K$ can be informative about (i.e., is not $d$-separated from) $Q$, given the prior observation of $X$, $Y$, both, or neither (...)." width="1056" />
<p class="caption">
Figure 6.4:  All connected directed acyclic graphs over <span class="math inline">\(X,Y,K,Q\)</span>, in which <span class="math inline">\(Q\)</span> is an exogenous variable that directly causes <span class="math inline">\(Y\)</span>, and <span class="math inline">\(X\)</span> is a direct or indirect cause of <span class="math inline">\(Y\)</span>. The title of each graph indicates the conditions under which <span class="math inline">\(K\)</span> can be informative about (i.e., is not <span class="math inline">\(d\)</span>-separated from) <span class="math inline">\(Q\)</span>, given the prior observation of <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, both, or neither (…).
</p>
</div>
</div>
<div id="probative-value" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Probative value</h3>
<p>The results show us not just what kinds of variables can be informative about a case’s response-type but also what combinations of observations yield leverage on case-level causal effects. A number of features the graphs are worth highlighting:</p>
<ul>
<li><p><strong>Clues at many stages.</strong> Process tracing has focused a great deal on observations that lie “along the path” between suspected causes and outcomes. What we see in Figure , however, is that observations at many different locations in a causal model can be informative about causal effects. We see here that <span class="math inline">\(K\)</span> can be informative when it is pre-treatment (causally prior to <span class="math inline">\(X\)</span>—e.g. panel (3)), post-treatment but pre-outcome (that is, “between” <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as, e.g., in panel (20)), an auxiliary effect of <span class="math inline">\(X\)</span> that itself has no effect on <span class="math inline">\(Y\)</span> (e.g., in panel (19)), post-outcome (after <span class="math inline">\(Y\)</span>—e.g., in panel (15)), or a joint effect of both the suspected cause and the outcome (e.g., panel (31)).</p></li>
<li><p><strong>Mediator Clues</strong>. While clues that lie in between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> may be informative, they can only be informative under certain conditions. For instance, when a clue serves <em>only</em> as a mediator in our model (i.e., its only linkages are being caused by <span class="math inline">\(X\)</span> and being affected by <span class="math inline">\(Y\)</span>) and <span class="math inline">\(Q\)</span> only affects <span class="math inline">\(Y\)</span>, as in panels (20) and (21), the clue is only informative about <span class="math inline">\(Q\)</span> if we have also observed the outcome, <span class="math inline">\(Y\)</span>. Of course, this condition may commonly be met—qualitative researchers usually engage in retrospective research and learn the outcome of the cases they are studying early on—but it is nonetheless worth noting why it matters: in this setup, <span class="math inline">\(K\)</span> is unconditionally <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(Q\)</span> by the collision at <span class="math inline">\(Y\)</span>; it is only by observing <span class="math inline">\(Y\)</span> (the collider) that the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> becomes unblocked. (As we saw above, the very same is true for observing <span class="math inline">\(X\)</span>; it is only when we know <span class="math inline">\(Y\)</span> that <span class="math inline">\(X\)</span> is informative about <span class="math inline">\(Q\)</span>.)</p></li>
</ul>
<p>In short, observations along causal paths are more helpful in identifying causal effects to the extent that we have measured the outcome. Importantly, this is not the same as saying that mediator clues are <em>only</em> informative about causal effects where we have observed the outcome. Observing <span class="math inline">\(Y\)</span> is necessary for the mediator to be informative about a <span class="math inline">\(Q\)</span> term that is connected only to <span class="math inline">\(Y\)</span>. Observing a mediator without the outcome, however, could still be informative about the overall effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> by providing leverage on how the mediator responds to <span class="math inline">\(X\)</span>, which is itself informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> via the mediator.<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a> Moreover, observing the mediator could be informative without the observation of <span class="math inline">\(Y\)</span> if, for instance, <span class="math inline">\(Q\)</span> also points into <span class="math inline">\(K\)</span> itself or into a cause of <span class="math inline">\(K\)</span>. As we discuss below, the clue then is informative as a “symptom” of the case’s response type, generating learning that does not hinge on observing the outcome.</p>
<ul>
<li><strong>Symptoms as clues.</strong> Some clues may themselves be affected by <span class="math inline">\(Q\)</span>: that is to say, they may be symptoms of the same conditions that determine causal effects in a case. For instance, in our illustrative model involving government survival, government sensitivity functions as a response-type variable for the effect of a free press (<span class="math inline">\(X\)</span>) on government removal (<span class="math inline">\(Y\)</span>): a free press only generates government removal when the government is non-sensitive to public opinion. Sensitivity to public opinion thus represents our query variable, <span class="math inline">\(Q\)</span>, if we seek to learn whether a free press causes government removal in a case. While it may not be possible to observe or otherwise measure the government’s sensitivity, there may be <em>consequences</em> of government sensitivity that are observable: for instance, whether government officials regularly consult with civil-society actors on policy issues. While consultations would not be part of the causal chain generating the free press’s effect, observing consultations (or the lack of them) would be informative about that effect because consultations are a symptom of the same conditions that enable the effect.</li>
</ul>
<p>We see that <span class="math inline">\(K\)</span> is a child or descendant of <span class="math inline">\(Q\)</span> in several of the graphs in Figure : <span class="math inline">\(Q\)</span> directly causes <span class="math inline">\(K\)</span> in panels (7) through (14), (17), (18), (25)-(30), (33), and (34); <span class="math inline">\(Q\)</span> causes (K) only indirectly through <span class="math inline">\(X\)</span> in panels (22) through (24); <span class="math inline">\(Q\)</span> causes (K) only indirectly through <span class="math inline">\(Y\)</span> in panels (15), (16), and (31); and <span class="math inline">\(Q\)</span> causes <span class="math inline">\(K\)</span> only indirectly through <span class="math inline">\(X\)</span> and through <span class="math inline">\(Y\)</span> in panel (32). We can then use the principle of <span class="math inline">\(d\)</span>-separation to figure out when the symptom clue is potentially informative, given what we have already observed. It is easy to see that <span class="math inline">\(K\)</span> is potentially informative, no matter what we have already observed, if <span class="math inline">\(K\)</span> is directly affected by <span class="math inline">\(Q\)</span>; there is nothing we could observe that would block the <span class="math inline">\(Q \rightarrow K\)</span> path. Thus, <span class="math inline">\(Q\)</span>’s “symptom” can, in this setup, contain information about type above and beyond that contained in the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values. However, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> only through some other variable, observing that other variable renders <span class="math inline">\(K\)</span> uninformative by blocking the <span class="math inline">\(Q\)</span>-to-<span class="math inline">\(K\)</span> path. For instance, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> indirectly through <span class="math inline">\(X\)</span>, once we observe <span class="math inline">\(X\)</span>, we already have all the information about <span class="math inline">\(Q\)</span> that would be contained in <span class="math inline">\(K\)</span>.</p>
<ul>
<li><strong>Surrogates as clues.</strong> Clues may be consequences of the outcome, as in graphs (15) and (16). If <span class="math inline">\(K\)</span> is a consequence <em>only</em> of <span class="math inline">\(Y\)</span>, then it will contain no new information about <span class="math inline">\(Q\)</span> where <span class="math inline">\(Y\)</span> is already known. However, in situations where the outcome has not been observed, <span class="math inline">\(K\)</span> can act as a “surrogate” for the outcome and thus yield leverage on <span class="math inline">\(Q\)</span> (<span class="citation">Frangakis and Rubin (<a href="#ref-frangakis2002principal" role="doc-biblioref">2002</a>)</span>). A researcher might, for instance, seek to understand causal effects on an outcome that is difficult to directly observe: consider, for instance, studies that seek to explain ideational change. Ideas themselves, the <span class="math inline">\(Y\)</span> in such studies, are not directly observable. However, their consequences—such as statements by actors or policy decisions—will be observable and can thus serve as informative surrogates for the outcome of interest.</li>
</ul>
<p>Clues may similarly serve as surrogates of a cause, as in graphs (19) and (22). Here <span class="math inline">\(X\)</span> causes <span class="math inline">\(K\)</span>, but <span class="math inline">\(K\)</span> plays no role in the causal process generating <span class="math inline">\(Y\)</span>. <span class="math inline">\(K\)</span> is of no help if we can directly measure <span class="math inline">\(X\)</span> since the latter <span class="math inline">\(d\)</span>-separates <span class="math inline">\(K\)</span> from <span class="math inline">\(Q\)</span>. But if an explanatory variable cannot be directly measured—consider, e.g., ideas or preferences as causes—then its consequences, including those that have no relationship to the outcome of interest, can provide leverage on the case-level causal effect.</p>
<p>Clues can also be a consequence of both our suspected cause and the outcome of interest, thus serving as what we might call “double surrogates,” as in panels (31) and (32). Here <span class="math inline">\(X\)</span> is a direct cause of <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K\)</span> is a joint product of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. A double surrogate can be informative as long as we have not already observed both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Where data on either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> are missing, there is an open path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>. If we have already observed both, however, then there is nothing left to be learned from <span class="math inline">\(K\)</span>.</p>
<ul>
<li><strong>Instruments as clues.</strong> Clues that are causally prior to an explanatory variable, and have no other effect on the outcome, can sometimes be informative. Consider, for instance, graph (3). Here <span class="math inline">\(K\)</span> is the only cause of <span class="math inline">\(X\)</span>. It can thus serve as a proxy. If we have seen <span class="math inline">\(X\)</span>, then <span class="math inline">\(X\)</span> blocks the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, and so <span class="math inline">\(K\)</span> is unhelpful. <span class="math inline">\(K\)</span> can be informative, though, if we have <em>not</em> observed <span class="math inline">\(X\)</span>. Note that informativeness here still requires that we observe <span class="math inline">\(Y\)</span>. Since <span class="math inline">\(Y\)</span> is a collider for <span class="math inline">\(Q\)</span> and the <span class="math inline">\(K \rightarrow X \rightarrow\)</span> chain, we need to observe <span class="math inline">\(Y\)</span> in order to <span class="math inline">\(d\)</span>-connect <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>.</li>
</ul>
<p>A rather different setup appears in graph (5), where both <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> cause <span class="math inline">\(X\)</span>. Now the conditions for <span class="math inline">\(K\)</span>’s informativeness are broader. Observing <span class="math inline">\(X\)</span> still makes <span class="math inline">\(K\)</span> uninformative as a proxy for <span class="math inline">\(X\)</span> itself. However, because <span class="math inline">\(X\)</span> is a collider for <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, observing <span class="math inline">\(X\)</span> <em>opens up</em> a path from <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>, rendering a dependency between them. Still, we have to observe at least one of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> for the instrument to be informative here. This is because both of <span class="math inline">\(K\)</span>’s paths to <span class="math inline">\(Q\)</span> run through a collision that we need to unblock by observing the collider. For one path, the collider is <span class="math inline">\(X\)</span>; for the other path, the collider is <span class="math inline">\(Y\)</span>.<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a></p>
<!-- Graph (5) is similar to one discussed in [@hausman1999independence] in which there is learning from a pretreatment clue because $X$ is a collider for $K$ and $Q$.  -->
<!-- To return to our government-removal model, government sensitivity to public opinion is a response-type variable (a $Q$ term), with non-sensitivity a pre-condition for the positive effect of a free press on removal. Yet it is possible (though we did not include it in our original model) that government sensitivity also affects whether or not a government gets a free press: more sensitive governments may impose tighter media restrictions. In that case, when governments are not sensitive, we would expect to see a free press and government removal.   -->
<p>Other patterns involving instrumentation are also imaginable, though not graphed here. For example, we might have a causal structure that combines instrumentation and surrogacy. Suppose that <span class="math inline">\(X\)</span> is affected by <span class="math inline">\(Q\)</span> and by an unobservable variable <span class="math inline">\(\theta_X\)</span>; and that <span class="math inline">\(\theta_X\)</span> has an observable consequence, <span class="math inline">\(K\)</span>. Then <span class="math inline">\(K\)</span>, though not a cause of <span class="math inline">\(X\)</span>, is a “surrogate instrument” <span class="citation">(Hernán and Robins <a href="#ref-hernan2006instruments" role="doc-biblioref">2006</a>)</span> as it is a descendant of an unobserved instrument, <span class="math inline">\(U\)</span>, and thus allows us to extract inferences similar to those that we could draw from a true instrument.</p>
<ul>
<li><strong>Confounders as clues.</strong> In several of the graphs, <span class="math inline">\(K\)</span> is a confounder in that it is a direct cause of both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (panels (4), (6), (12), and (14)). Let us focus on graph (4), which isolates <span class="math inline">\(K\)</span>’s role as a confounder. Here <span class="math inline">\(K\)</span> can be informative via two possible paths. First, if <span class="math inline">\(X\)</span> is not observed but <span class="math inline">\(Y\)</span> is, then <span class="math inline">\(K\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> along the path <span class="math inline">\(K \rightarrow X \rightarrow Y \leftarrow Q\)</span>. <span class="math inline">\(K\)</span> is in this sense serving as a proxy for <span class="math inline">\(X\)</span>, with its path to <span class="math inline">\(Q\)</span> opened up by the observation of the collider, <span class="math inline">\(Y\)</span>. Second, with <span class="math inline">\(Y\)</span> observed, <span class="math inline">\(K\)</span> can provide information on <span class="math inline">\(Q\)</span> via the more direct collision, <span class="math inline">\(K \rightarrow Y \leftarrow Q\)</span>. If <span class="math inline">\(X\)</span> <em>is</em> observed, then the first path is blocked, but the second still remains active. As with any pre-outcome variable, for a confounder clue to provide purchase on <span class="math inline">\(Y\)</span>’s response type, <span class="math inline">\(Y\)</span> itself must be observed.</li>
</ul>
<p>In a sense, then, the role of confounders as clues in case-level inference is the mirror image of the role of confounders as covariates in cross-case correlational inference. In a correlational inferential framework, controlling for a variable in <span class="math inline">\(K\)</span>’s position in graph (5) renders the <span class="math inline">\(X, Y\)</span> correlation (which we assume to be observed) informative about <span class="math inline">\(X\)</span>’s average causal effect. When we use confounders as evidence in within-case inference, it is our observations of other variables that determine how informative the confounder <em>itself</em> will be about <span class="math inline">\(X\)</span>’s causal effect.</p>
<p>It is important to be precise about the kinds of claims that one can make from graphs like those in Figure {fig:34graphs}. The graphs in this figure allow us to identify informativeness about an unobserved node <span class="math inline">\(Q\)</span> that is a parent of <span class="math inline">\(Y\)</span>. This setup does not, however, capture all ways in which clues can be informative about the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> or about other causal estimands of interest. For instance, as noted above, even if a clue is uninformative about a <span class="math inline">\(Q\)</span> node pointing into <span class="math inline">\(Y\)</span>, it may still help establish whether <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>: the statement that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> will for some graphs be a statement about a <em>collection</em> of nodes that form the set of query variables <span class="math inline">\(\mathcal Q\)</span>. This is the case, for instance, in any graph of the form <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, where we are interested not just in <span class="math inline">\(Y\)</span>’s response to <span class="math inline">\(M\)</span> (the mediator) but also in <span class="math inline">\(M\)</span>’s response to <span class="math inline">\(X\)</span>. Of interest, thus, are not just a <span class="math inline">\(Q^Y\)</span> response-type node pointing into <span class="math inline">\(Y\)</span> but also a <span class="math inline">\(Q^M\)</span> response-type node that is a parent of <span class="math inline">\(M\)</span>. Observations that provide leverage on either <span class="math inline">\(Q\)</span> term will thus aid an inference about the overall causal effect. A clue <span class="math inline">\(K\)</span> that is <span class="math inline">\(d-\)</span>separated from <span class="math inline">\(Q^Y\)</span> may nevertheless be informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> if it is not <span class="math inline">\(d-\)</span>separated from <span class="math inline">\(Q^M\)</span>; this opens up a broader range of variables as informative clues.</p>
<p>Additionally, as our discussion in Chapter 2 makes clear, estimands other than the case-level causal effect—such as average causal effects, actual causes, and causal paths—involve particular features of context: particular sets of exogenous nodes as members of our query set, <span class="math inline">\(\mathcal Q\)</span>. Thus, even for the same causal model, informativeness will be defined differently for each causal question that we seek to address. The broader point is that we can identify what kinds of observations may address our estimand if we can place that estimand on a causal graph and then assess the graph for relationships of <span class="math inline">\(d\)</span>-separation and -connection.</p>
<p>Further, we emphasize that a DAG can only tell us when a clue <em>may</em> be informative (conditional some prior observation): <span class="math inline">\(d-\)</span>connectedness is necessary but not sufficient for informativeness. This fact derives directly from the rules for drawing a causal graph: the absence of an arrow between two variables implies that they are <em>not</em> directly causally related, while the presence of an arrow does not imply that they always are. As we saw in our analysis of the government-removal example in Chapter 2, whether variables connected to one another by arrows in the original DAG were in fact linked by a causal effect depended on the context. Likewise, whether a clue <span class="math inline">\(K\)</span> is in fact informative may depend on particular values of <span class="math inline">\(\mathcal W\)</span>—the variables that have already been observed. As a simple example, let <span class="math inline">\(q = k_1w + (1-w)k_2\)</span>, where <span class="math inline">\(W\)</span> is a variable that we have already observed and <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span> are clues that we might choose to observe next. Here, if <span class="math inline">\(w=1\)</span> then learning <span class="math inline">\(K_1\)</span> will be informative about <span class="math inline">\(Q\)</span>, and learning <span class="math inline">\(K_2\)</span> will not; but if <span class="math inline">\(w=0\)</span>, then <span class="math inline">\(K_1\)</span> will be uninformative (and <span class="math inline">\(K_2\)</span> informative).</p>
<p>In general, then, graphical analysis alone can help us exclude unhelpful research designs, given our prior observations and a fairly minimal set of prior beliefs about causal linkages. This is no small feat. But identifying those empirical strategies that will yield the greatest leverage requires engaging more deeply with our causal model, as we explore next.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-collier2004sources">
<p>Collier, David, Henry E Brady, and Jason Seawright. 2004. “Sources of Leverage in Causal Inference: Toward an Alternative View of Methodology.” In <em>Rethinking Social Inquiry: Diverse Tools, Shared Standards</em>, edited by David Collier and Henry E Brady, 229–66. Lanham, MD: Rowman &amp; Littlefield.</p>
</div>
<div id="ref-frangakis2002principal">
<p>Frangakis, Constantine E, and Donald B Rubin. 2002. “Principal Stratification in Causal Inference.” <em>Biometrics</em> 58 (1): 21–29.</p>
</div>
<div id="ref-hernan2006instruments">
<p>Hernán, Miguel A, and James M Robins. 2006. “Instruments for Causal Inference: An Epidemiologist’s Dream?” <em>Epidemiology</em> 17 (4): 360–72.</p>
</div>
<div id="ref-humphreys2015mixing">
<p>Humphreys, Macartan, and Alan M Jacobs. 2015. “Mixing Methods: A Bayesian Approach.” <em>American Political Science Review</em> 109 (04): 653–73.</p>
</div>
<div id="ref-pearl2009causality">
<p>Pearl, Judea. 2009. <em>Causality</em>. Cambridge university press.</p>
</div>
<div id="ref-Van-Evera:1997">
<p>Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="42">
<li id="fn42"><p>This differs from the task for mixed methods that we will address in Chapter 8 as these concern claims about the distribution of causal types in populations.<a href="pt.html#fnref42" class="footnote-back">↩︎</a></p></li>
<li id="fn43"><p>More generally an estimand might be a function of the distribution of causal types.<a href="pt.html#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p>These nodal types can require many indices–<span class="math inline">\(2^k\)</span> for a node with <span class="math inline">\(k\)</span> parents—and the rule we follow is that the <span class="math inline">\(i\)</span>th subscript indicates the value the node takes when parent <span class="math inline">\(j \in {1, 2, ..., k}\)</span> take values <span class="math inline">\(\mod(floor((i-1)/(2^{j-1})), 2)\)</span> For instance for <code>Y0111</code> the first index means that Y takes the value 0 where both parents are 0, in all other cases it takes value 1.<a href="pt.html#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>More generally, let us say that any node <span class="math inline">\(j\)</span> can take on <span class="math inline">\(r_j\)</span> possible values and has parents belonging to set <span class="math inline">\(PA_j\)</span> and that each parent, <span class="math inline">\(i \in PA_j\)</span>, can take on <span class="math inline">\(r_i\)</span> values. Then the number of nodal types for node <span class="math inline">\(j\)</span> is equal to <span class="math inline">\(r_j^{\prod_{i \in PA_j}r_i}\)</span>. Informally, the exponent in this expression simply multiplies by one another the number of values that each of <span class="math inline">\(j\)</span>’s parents can take on. This product tells us the number of causal conditions across which <span class="math inline">\(j\)</span>’s responses must be defined. We then raise the number of values that <span class="math inline">\(j\)</span> can take on to the power of the number of causal conditions. With all variables binary, this expression translates to <span class="math inline">\(2^{\left(2^k\right)}\)</span> nodal types for a node with <span class="math inline">\(k\)</span> parents.<a href="pt.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>A model in which each node <span class="math inline">\(j\)</span> has <span class="math inline">\(k_j\)</span> parents has <span class="math inline">\(\prod_j2^{\left(2^{k_j}\right)}\)</span> causal types that uniquely determine what data will be observed for a type under all possible interventions on its exogenous nodes.<a href="pt.html#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>The reference population for a case is defined based on whatever we already know about the case. Thus, for instance, if we already know that the case has <span class="math inline">\(Y=1\)</span> before we begin process tracing, then the relevant population for the formation of prior beliefs is all cases in which <span class="math inline">\(Y=1\)</span>.<a href="pt.html#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>In words, the probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring is equal to the probability of <span class="math inline">\(A\)</span> occurring times the probability of <span class="math inline">\(B\)</span> occurring <em>given</em> that <span class="math inline">\(A\)</span> occurs.<a href="pt.html#fnref48" class="footnote-back">↩︎</a></p></li>
<li id="fn49"><p>As we will see later in the book, another approach is to gather data on additional cases. When analyzing multiple cases, we can set up our priors to allow for the possibility of unobserved confounding and then, potentially, learn about that confounding from the data. This is not possible under our procedure for single-case process tracing, where we treat the population parameters as given and fixed.<a href="pt.html#fnref49" class="footnote-back">↩︎</a></p></li>
<li id="fn50"><p>That is, when there is unobserved confounding, we express conditional proportions, making all of the proportions conditionally independent of one another.<a href="pt.html#fnref50" class="footnote-back">↩︎</a></p></li>
<li id="fn51"><p>For a given value of <span class="math inline">\(\lambda^K_{01}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span> values equal by assigning a value of <span class="math inline">\((1-\lambda^K_{01})/3\)</span> to each.<a href="pt.html#fnref51" class="footnote-back">↩︎</a></p></li>
<li id="fn52"><p>For a given value of <span class="math inline">\(\lambda^K_{11}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span>’s equal by assigning a value of <span class="math inline">\((1-\lambda^K_{11})/3\)</span> to each; likewise for <span class="math inline">\(\lambda^Y_{11}\)</span> and the other <span class="math inline">\(\lambda^Y\)</span> values.<a href="pt.html#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>This proposition is almost coextensive with the definition of a DAG. A DAG is a particular kind of dependency model (“graphoid”) that is a summary of a collection of “independency statements”, <span class="math inline">\((I)\)</span>, over distinct subsets of <span class="math inline">\(\mathcal V\)</span> (Pearl and Verma 1987), where <span class="math inline">\(I(\mathcal Q,\mathcal W,\mathcal K)\)</span> means “we learn nothing about <span class="math inline">\(\mathcal Q\)</span> from <span class="math inline">\(\mathcal K\)</span> if we already know <span class="math inline">\(\mathcal W\)</span>”. More formally:
<span class="math inline">\(I(\mathcal K, \mathcal W,\mathcal Q) \leftrightarrow P(\mathcal K,\mathcal Q|\mathcal W)=P(\mathcal K|\mathcal W)P(\mathcal Q|\mathcal W)\)</span>. A Directed Acyclic Graph Dependency model is one where the set of independencies corresponds exactly to the relations that satisfy <span class="math inline">\(d\)</span>-separation (Pearl and Verma 1987, p376). Thus on DAG <span class="math inline">\(\mathcal G\)</span>, <span class="math inline">\(I(\mathcal K,\mathcal W,\mathcal Q)_{\mathcal G}\)</span> implies that <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span>.<a href="pt.html#fnref53" class="footnote-back">↩︎</a></p></li>
<li id="fn54"><p>Put differently, there will not be any conditional independencies that are <em>not</em> captured in the DAG.<a href="pt.html#fnref54" class="footnote-back">↩︎</a></p></li>
<li id="fn55"><p>As a reminder, we read <span class="math inline">\(q^Y_{ij}\)</span> (when <span class="math inline">\(X\)</span> is binary) as meaning that <span class="math inline">\(Y\)</span> will take on value <span class="math inline">\(i\)</span> when <span class="math inline">\(X=0\)</span> and value <span class="math inline">\(j\)</span> when <span class="math inline">\(X=1\)</span>.<a href="pt.html#fnref55" class="footnote-back">↩︎</a></p></li>
<li id="fn56"><p>That is, we can rule out that the case is an <span class="math inline">\(a\)</span> type, or one with a negative causal effect.<a href="pt.html#fnref56" class="footnote-back">↩︎</a></p></li>
<li id="fn57"><p>Note the “possibly” can be dropped under the assumption that the underlying probability model is “stable” (Pearl 2009, section 2.9.1) and with the interpretation that <span class="math inline">\(K\)</span> is informative about <span class="math inline">\(Q\)</span> for some, but not necessarily all, values of <span class="math inline">\(W\)</span>.<a href="pt.html#fnref57" class="footnote-back">↩︎</a></p></li>
<li id="fn58"><p>In other words, the clue would then be providing leverage on a response-type variable pointing into the mediator itself.<a href="pt.html#fnref58" class="footnote-back">↩︎</a></p></li>
<li id="fn59"><p>As a simple example one might imagine a system in which <span class="math inline">\(X = K\)</span> if <span class="math inline">\(q \in {a,b}\)</span> and <span class="math inline">\(X = 1-K\)</span> if <span class="math inline">\(q \in {c,d}\)</span>. Then if we observe, say, <span class="math inline">\(X=Y=K=1\)</span>, we can infer that <span class="math inline">\(q = b\)</span>. Another way to think about what is happening in graph (5) is that <span class="math inline">\(K\)</span> is providing information about the <em>assignment process</em>. In this graph, the causal effect (<span class="math inline">\(Y\)</span>’s potential outcomes, determined by <span class="math inline">\(Q\)</span>) is also a partial determinant of the assignment of cases to values on <span class="math inline">\(X\)</span>. In terms of cross-case correlational inference, then, we would think of this as a situation of confounding. Observing another cause of <span class="math inline">\(X\)</span>, then, allows us to more fully characterize the process of assignment.<a href="pt.html#fnref59" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayeschapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ptapp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
