<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Process Tracing with Causal Models | Integrated Inferences</title>
  <meta name="description" content="Bayesian causal models for integrated inferences." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Process Tracing with Causal Models | Integrated Inferences" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://macartan.github.io/integrated_inferences/" />
  <meta property="og:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />
  <meta property="og:description" content="Bayesian causal models for integrated inferences." />
  <meta name="github-repo" content="macartan/integrated_inferences" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Process Tracing with Causal Models | Integrated Inferences" />
  
  <meta name="twitter:description" content="Bayesian causal models for integrated inferences." />
  <meta name="twitter:image" content="https://macartan.github.io/integrated_inferences//images/plot.png" />

<meta name="author" content="Macartan Humphreys and Alan M. Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="theory.html"/>
<link rel="next" href="ptapp.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.19/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="headers/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Integrated Inferences</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#counterfactualmodel"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#potential-outcomes"><i class="fa fa-check"></i><b>2.1.1</b> Potential outcomes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#generalization"><i class="fa fa-check"></i><b>2.1.2</b> Generalization</a></li>
<li class="chapter" data-level="2.1.3" data-path="models.html"><a href="models.html#summaries-of-potential-outcomes"><i class="fa fa-check"></i><b>2.1.3</b> Summaries of potential outcomes</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#graphing-models-and-using-graphs"><i class="fa fa-check"></i><b>2.3</b> Graphing models and using graphs</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#graphing"><i class="fa fa-check"></i><b>2.3.1</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.3.2</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#simplifying-models"><i class="fa fa-check"></i><b>2.3.3</b> Simplifying models</a></li>
<li class="chapter" data-level="2.3.4" data-path="models.html"><a href="models.html#retaining-probabilistic-relations"><i class="fa fa-check"></i><b>2.3.4</b> Retaining probabilistic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#conc2"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.5</b> Chapter Appendix</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.5.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.5.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.5.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.5.3" data-path="models.html"><a href="models.html#rules-for-moving-between-levels"><i class="fa fa-check"></i><b>2.5.3</b> Rules for moving between levels</a></li>
<li class="chapter" data-level="2.5.4" data-path="models.html"><a href="models.html#reading-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.5.4</b> Reading conditional independence from a graph</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform"><i class="fa fa-check"></i><b>3.1</b> Welfare state reform</a></li>
<li class="chapter" data-level="3.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions"><i class="fa fa-check"></i><b>3.2</b> Military Interventions</a></li>
<li class="chapter" data-level="3.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization"><i class="fa fa-check"></i><b>3.3</b> Development and Democratization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>4</b> Causal Queries</a>
<ul>
<li class="chapter" data-level="4.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>4.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="4.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>4.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="4.3" data-path="questions.html"><a href="questions.html#actual-causes"><i class="fa fa-check"></i><b>4.3</b> Actual causes</a></li>
<li class="chapter" data-level="4.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>4.4</b> Average causal effects</a></li>
<li class="chapter" data-level="4.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>4.5</b> Causal Paths</a></li>
<li class="chapter" data-level="4.6" data-path="questions.html"><a href="questions.html#general-procedure"><i class="fa fa-check"></i><b>4.6</b> General procedure</a></li>
<li class="chapter" data-level="4.7" data-path="questions.html"><a href="questions.html#appendix"><i class="fa fa-check"></i><b>4.7</b> Appendix</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>5</b> Bayesian Answers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>5.1</b> Bayes Basics</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>5.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>5.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="5.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>5.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="5.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>5.1.4</b> Moments</a></li>
<li class="chapter" data-level="5.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>5.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>5.2</b> Bayes applied</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>5.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>5.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayeschapter.html"><a href="bayeschapter.html#features-of-bayesian-updating"><i class="fa fa-check"></i><b>5.3</b> Features of Bayesian updating</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>5.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>5.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="5.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>5.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>6</b> Theories as causal models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="theory.html"><a href="theory.html#models-as-theories-of"><i class="fa fa-check"></i><b>6.1</b> Models as <em>theories of</em></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="theory.html"><a href="theory.html#implications-of-structural-causal-models"><i class="fa fa-check"></i><b>6.1.1</b> Implications of structural causal models</a></li>
<li class="chapter" data-level="6.1.2" data-path="theory.html"><a href="theory.html#probabilistic-causal-models"><i class="fa fa-check"></i><b>6.1.2</b> Probabilistic causal models</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="theory.html"><a href="theory.html#theorygains"><i class="fa fa-check"></i><b>6.2</b> Gains from theory</a></li>
<li class="chapter" data-level="6.3" data-path="theory.html"><a href="theory.html#formal-theories-and-causal-models"><i class="fa fa-check"></i><b>6.3</b> Formal theories and causal models</a></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="7" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>7</b> Process Tracing with Causal Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>7.1</b> Process tracing and causal models</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>7.1.1</b> The intuition</a></li>
<li class="chapter" data-level="7.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>7.1.2</b> A formalization of the general approach</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pt.html"><a href="pt.html#mapping-from-models-to-classic-qualitative-tests"><i class="fa fa-check"></i><b>7.2</b> Mapping from models to classic qualitative tests</a></li>
<li class="chapter" data-level="7.3" data-path="pt.html"><a href="pt.html#principles-of-learning"><i class="fa fa-check"></i><b>7.3</b> Principles of learning</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-us-probative-value"><i class="fa fa-check"></i><b>7.3.1</b> A DAG alone does not get us probative value</a></li>
<li class="chapter" data-level="7.3.2" data-path="pt.html"><a href="pt.html#learning-requires-uncertainty"><i class="fa fa-check"></i><b>7.3.2</b> Learning requires uncertainty</a></li>
<li class="chapter" data-level="7.3.3" data-path="pt.html"><a href="pt.html#multiple-ways-for-queries-to-be-satisfied"><i class="fa fa-check"></i><b>7.3.3</b> Multiple ways for queries to be satisfied</a></li>
<li class="chapter" data-level="7.3.4" data-path="pt.html"><a href="pt.html#beware-of-highly-unlikely-queries"><i class="fa fa-check"></i><b>7.3.4</b> Beware of highly unlikely queries</a></li>
<li class="chapter" data-level="7.3.5" data-path="pt.html"><a href="pt.html#population-level-uncertainty-does-not-alter-case-level-causal-inference"><i class="fa fa-check"></i><b>7.3.5</b> Population-level uncertainty does not alter case-level causal inference</a></li>
<li class="chapter" data-level="7.3.6" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>7.3.6</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>8</b> Application: Process Tracing with a Causal Model</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>8.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="8.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>8.2</b> A Structural Causal Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>8.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>8.3</b> Results</a></li>
<li class="chapter" data-level="8.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>8.4</b> Pathways</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>8.4.1</b> Inferences for cases with observed democratization</a></li>
<li class="chapter" data-level="8.4.2" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>8.4.2</b> Cases with incomplete data</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>8.5</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>9</b> Integrated inferences</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mixing.html"><a href="mixing.html#sample-inference"><i class="fa fa-check"></i><b>9.1</b> Sample inference</a></li>
<li class="chapter" data-level="9.2" data-path="mixing.html"><a href="mixing.html#from-sample-queries-to-general-processes"><i class="fa fa-check"></i><b>9.2</b> From sample queries to general processes</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="mixing.html"><a href="mixing.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="mixing.html"><a href="mixing.html#inference"><i class="fa fa-check"></i><b>9.2.2</b> Inference</a></li>
<li class="chapter" data-level="9.2.3" data-path="mixing.html"><a href="mixing.html#wrinkles"><i class="fa fa-check"></i><b>9.2.3</b> Wrinkles</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mixing.html"><a href="mixing.html#mixed-methods"><i class="fa fa-check"></i><b>9.3</b> Mixed methods</a></li>
<li class="chapter" data-level="9.4" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>9.4</b> Considerations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="mixing.html"><a href="mixing.html#probative-value-can-be-derived-from-a-causal-structure-plus-data"><i class="fa fa-check"></i><b>9.4.1</b> Probative value can be derived from a causal structure plus data</a></li>
<li class="chapter" data-level="9.4.2" data-path="mixing.html"><a href="mixing.html#learning-without-identification"><i class="fa fa-check"></i><b>9.4.2</b> Learning without identification</a></li>
<li class="chapter" data-level="9.4.3" data-path="mixing.html"><a href="mixing.html#beyond-binary-data"><i class="fa fa-check"></i><b>9.4.3</b> Beyond binary data</a></li>
<li class="chapter" data-level="9.4.4" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>9.4.4</b> Measurement error</a></li>
<li class="chapter" data-level="9.4.5" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>9.4.5</b> Spillovers</a></li>
<li class="chapter" data-level="9.4.6" data-path="mixing.html"><a href="mixing.html#clustering"><i class="fa fa-check"></i><b>9.4.6</b> Clustering</a></li>
<li class="chapter" data-level="9.4.7" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>9.4.7</b> Parameteric models</a></li>
<li class="chapter" data-level="9.4.8" data-path="mixing.html"><a href="mixing.html#prior-databeliefs-channel-the-learning-from-new-data"><i class="fa fa-check"></i><b>9.4.8</b> Prior data/beliefs “channel” the learning from new data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>10</b> Mixed-Method Application: Inequality and Democracy Revisited</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>10.1</b> A trained model</a></li>
<li class="chapter" data-level="10.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="mixingapp.html"><a href="mixingapp.html#inference-1"><i class="fa fa-check"></i><b>10.3</b> Inference</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democratization"><i class="fa fa-check"></i><b>10.3.1</b> Did inequality <em>cause</em> democratization?</a></li>
<li class="chapter" data-level="10.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>10.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="mixingapp.html"><a href="mixingapp.html#from-cases-to-population"><i class="fa fa-check"></i><b>10.4</b> From cases to population</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="mixingapp.html"><a href="mixingapp.html#contribution-to-case-level-inference"><i class="fa fa-check"></i><b>10.4.1</b> Contribution to case-level inference</a></li>
<li class="chapter" data-level="10.4.2" data-path="mixingapp.html"><a href="mixingapp.html#how-much-do-we-get-from-the-model-vs.-the-data"><i class="fa fa-check"></i><b>10.4.2</b> How much do we get from the model vs. the data?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>11</b> Mixing models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>11.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="11.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>11.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="11.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>11.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="11.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>11.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="12" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>12</b> Clue Selection as a Decision Problem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="clue.html"><a href="clue.html#a-model-informed-approach-to-clue-selection"><i class="fa fa-check"></i><b>12.1</b> A model-informed approach to clue-selection</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>12.1.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="12.1.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>12.1.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="12.1.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>12.1.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>12.2</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="12.3" data-path="clue.html"><a href="clue.html#conclusion"><i class="fa fa-check"></i><b>12.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>13</b> Mixed methods data strategies</a>
<ul>
<li class="chapter" data-level="13.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-strategies"><i class="fa fa-check"></i><b>13.1</b> Case selection strategies</a></li>
<li class="chapter" data-level="13.2" data-path="caseselection.html"><a href="caseselection.html#no-general-rules"><i class="fa fa-check"></i><b>13.2</b> No general rules</a></li>
<li class="chapter" data-level="13.3" data-path="caseselection.html"><a href="caseselection.html#specific-case-walk-through"><i class="fa fa-check"></i><b>13.3</b> Specific case walk through</a></li>
<li class="chapter" data-level="13.4" data-path="caseselection.html"><a href="caseselection.html#case-selection-from-causal-models-a-simulation-based-approach"><i class="fa fa-check"></i><b>13.4</b> Case selection from causal models: a simulation-based approach</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wideordeep.html"><a href="wideordeep.html"><i class="fa fa-check"></i><b>14</b> Going wide, going deep</a>
<ul>
<li class="chapter" data-level="14.1" data-path="wideordeep.html"><a href="wideordeep.html#walk-through-of-a-simple-comparison"><i class="fa fa-check"></i><b>14.1</b> Walk-through of a simple comparison</a></li>
<li class="chapter" data-level="14.2" data-path="wideordeep.html"><a href="wideordeep.html#a-simulation-based-approach-to-choosing-mixes"><i class="fa fa-check"></i><b>14.2</b> A simulation-based approach to choosing mixes</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="wideordeep.html"><a href="wideordeep.html#approach"><i class="fa fa-check"></i><b>14.2.1</b> Approach</a></li>
<li class="chapter" data-level="14.2.2" data-path="wideordeep.html"><a href="wideordeep.html#simulation-results"><i class="fa fa-check"></i><b>14.2.2</b> Simulation results</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="wideordeep.html"><a href="wideordeep.html#factoring-in-the-cost-of-data"><i class="fa fa-check"></i><b>14.3</b> Factoring in the cost of data</a></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="15" data-path="justifying.html"><a href="justifying.html"><i class="fa fa-check"></i><b>15</b> Justifying models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="justifying.html"><a href="justifying.html#nothing-from-nothing"><i class="fa fa-check"></i><b>15.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="15.2" data-path="justifying.html"><a href="justifying.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>15.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="15.3" data-path="justifying.html"><a href="justifying.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>15.3</b> Justification from experimental designs</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="justifying.html"><a href="justifying.html#mediator"><i class="fa fa-check"></i><b>15.3.1</b> Mediator</a></li>
<li class="chapter" data-level="15.3.2" data-path="justifying.html"><a href="justifying.html#moderator"><i class="fa fa-check"></i><b>15.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="justifying.html"><a href="justifying.html#causal-discovery"><i class="fa fa-check"></i><b>15.4</b> Causal discovery</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>16</b> Evaluating models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="evaluation.html"><a href="evaluation.html#four-strategies"><i class="fa fa-check"></i><b>16.1</b> Four Strategies</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>16.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="16.1.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>16.1.2</b> Bayesian <span class="math inline">\(p-\)</span>value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="16.1.3" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>16.1.3</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="16.1.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>16.1.4</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>16.2</b> Evaluating the Democracy-Inequality model</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>16.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="16.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>16.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="16.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>16.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="16.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>16.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="conclusionchapter.html"><a href="conclusionchapter.html"><i class="fa fa-check"></i><b>17</b> Final Words</a>
<ul>
<li class="chapter" data-level="17.1" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-benefits"><i class="fa fa-check"></i><b>17.1</b> The benefits</a></li>
<li class="chapter" data-level="17.2" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-worries"><i class="fa fa-check"></i><b>17.2</b> The worries</a></li>
<li class="chapter" data-level="17.3" data-path="conclusionchapter.html"><a href="conclusionchapter.html#the-future"><i class="fa fa-check"></i><b>17.3</b> The future</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="18" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>18</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/CausalQueries/" target="blank">Uses CausalQueries</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pt" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Process Tracing with Causal Models</h1>
<div class="headerbox">
<div class="center">

</div>
<p>We connect the literature on causal models to qualitative inference strategies used in process tracing. We provide a procedure for inference on case level queries from causal models. In addition we extract a set of implications for process tracing. We show how a key result from the causal models literature provides a condition for when clues may be (or certainly will not be) informative.</p>
</div>
<p><br></p>
<!-- FLAG: Change causal type to unit type throughout (though note I've introduced this already in the **"unit causal type"** paragraph.) -->
<div id="process-tracing-and-causal-models" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Process tracing and causal models</h2>
<p>This chapter demonstrates how we can use causal models to conduct confirmatory process tracing: that is, to draw causal inferences about a single case from a causal model with data provided at the case-level.</p>
<div id="the-intuition" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> The intuition</h3>
<p>We first walk through the basic intuition and then provide a more formal account.</p>
<p>When we undertake process tracing, we seek to answer a causal question about a given case.
The key insight driving our approach is that the inference about a causal question for a case is a claim about <strong>which causal types (collections of nodal types) are both likely ex ante (given prior knowledge) and consistent with the data</strong>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>The question of interest can be about any number of case-level causal features, including questions about a case-level causal effect, the pathway through which an effect operates, an actual cause, or causal attribution. We use observations from the case itself to address this query. We do so via a procedure in which we first encode prior knowledge in the form of a causal model, then use data to learn about features of the model, and finally take what we have learned about the model and map it into our query.</p>
<p>Given a causal model, we form posteriors over queries as follows:</p>
<ol style="list-style-type: decimal">
<li><strong>Specify all possible causal types for a model</strong>. A causal type, recall, is a particular combination of nodal types for all nodes in a unit. That is, a single causal type specifies both a specific set of values of all exogenous variables in a model and the values that all endogenous variables <em>would</em> potentially take on for all possible values of the exogenous variables. For a simple, binary <span class="math inline">\(X \rightarrow Y\)</span> model, the number of possible causal types will be 2 (the number of possbile values <span class="math inline">\(X\)</span>, the exogenous node, can take on) times 4 (the number of possible nodal types for <span class="math inline">\(Y\)</span>, the endogenous node). Three of these causal types would be:</li>
</ol>
<ul>
<li>Type 1: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 2: (<span class="math inline">\(X=0\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 3: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=0\)</span>).</li>
</ul>
<p>Whatever the model, we generate a complete set of all possible causal types.</p>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Specify priors over causal types.</strong> We report how likely we think it is that a given unit is of a particular causal type. In the simplest situation, we might place 0 weight on some causal types (which might be ruled out by background theory, for example) and equal weight on the others.</p></li>
<li><p><strong>Specify the query in terms of causal types.</strong> For instance, for the simple <span class="math inline">\(X \rightarrow Y\)</span> model, the query “<span class="math inline">\(Y\)</span> responds positively to <span class="math inline">\(X\)</span>” can be thought of as a collection of causal types: Q={Type 1, Type 2}.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p></li>
<li><p><strong>Once we observe the data, specify the set of causal types that are consistent with those data.</strong> For instance, if we observe <span class="math inline">\(X=1, Y=1\)</span> we might specify the data-consistent set as {Type 1, Type 3}, excluding Type 2 with which these data are inconsistent.</p></li>
<li><p><strong>Update.</strong> Updating is then done by adding up the prior probabilities on all causal types that are consistent with both the data and the query, and dividing this sum by the sum of prior probabilities on all causal types that are consistent with the data (whether or not they are consistent with the query).</p></li>
</ol>
<!-- 1. **Draw a DAG.** We begin by constructing a causal model in graphical form, a DAG, expressing which variables in the domain of interest we think can have a direct effect on which other variables. As we have discussed, the causal model we start with may be derived from theory, from data on other cases, or some combination of the two. (We show, for instance, in Chapter \@ref(mixing) how data from a larger set of cases can inform the priors we bring to single-case process tracing.)  -->
<!-- 2. **Identify causal types**. A DAG, in turn, defines a set of possible causal types: all of the different possible combinations of nodal types that any case might have.  -->
<!-- 3. **Form priors**. We draw further on background knowledge, about the population to which the case belongs, to formulate prior beliefs about the probability that the case is of different causal types. We can generate these priors by ruling out certain nodal types as inconsistent with prior knowledge. Where our prior knowledge supports doing so, we can also place differential quantitative weights on those nodal types that we believe to be more or less common in the population. -->
<!-- 4. **Observe data**. We observe data on some or all of the nodes in the graph. -->
<!-- 5. **Eliminate causal types inconsistent with the data**. Check the consistency of each causal type with the data. Eliminate from contention any causal type that could not have generated the data pattern that we observe. -->
<!-- 6. **Form posteriors**. We now scale up the probabilities on all remaining causal types, providing a posterior probability on each type. -->
<!-- 7. **Map from causal types to query**. As any causal query can be formulated as a question about causal types (see Chapter \@ref(questions)), we can now map from our posteriors on causal types to a posterior probability on the query of interest: whether a causal effect, a causal pathway, causakl attribution, or some other case-level causal quantity. -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ptvenn"></span>
<img src="ii_files/figure-html/ptvenn-1.png" alt="Logic of simple updating on arbitrary queries." width="50%" />
<p class="caption">
Figure 7.1: Logic of simple updating on arbitrary queries.
</p>
</div>
<p>This process is represented graphically in Figure <a href="pt.html#fig:ptvenn">7.1</a>, where we can think of probabilities as proportionate to areas. Our causal model defines the causal-type space. We then proceed by a process of elimination. Only some of the causal types in the model are consistent with prior knowledge. Only some are consistent with the data that we observe. Finally, any query itself maps onto a subset of the possible causal types. The causal types that remain in contention once we have observed the evidence are those at the intersection of consistency with priors and consistency with the data. <span class="math inline">\(A\)</span> represents those types that are <em>also</em> consistent with a given answer to the query (say, <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>).</p>
<p>Thus, our belief about the query before we have seen the data is the probability of all causal types consistent with our priors and with the query (<span class="math inline">\(A + B\)</span>) as a proportion of all types consistent with our priors. Once we have seen the data, we have reduced the permissible types to <span class="math inline">\(A + C\)</span>. Our posterior belief on the query is, then, the probabilities of those remaining types that are consistent with the query as a share of the probabilities of <em>all</em> remaining types, or <span class="math inline">\(A/(A+C)\)</span>.</p>
<p>What we are doing here is straightforward: assessing causal possibilities for their compatibility with both the evidence at hand and our prior knowledge of how the world works. The formalization that we will present ensures that prior knowledge and evidence are all recorded explicitly while forcing logical consistency on the inferences that emerge from them.</p>
</div>
<div id="a-formalization-of-the-general-approach" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> A formalization of the general approach</h3>
<p>More formally, the general approach to inference draws on the components we outlined in chapters 2 to 4: graphical causal models (DAGs), nodal and causal types, and priors. We now show how these elements formally interact with data to generate causal inferences. We continue to focus on a situation with binary variables, though suggest later in the chapter how this can be extended. Though we walk through the procedure for simple models, the approach outlined here can be applies to <em>any</em> causal model with binary variables and to any queries defined over the model.</p>
<p>The process tracing procedure operates as follows:</p>
<p><strong>A DAG</strong>. We begin with a DAG, or graphical causal model. As we know, a DAG identifies a set of variables and describes the parent-child relations between them, indicating for each variable which other variables are its direct (possible) causes. These relationship, in turn, tell us which (non-descendant) variables a given variable is <em>not</em> independent of given the other variables in the model.</p>
<p><strong>Nodal types</strong>. Once we have specified a DAG, we have defined the full set of possible nodal types: the types defining the value that a variable will take on given the values of its parents, which we have denoted with <span class="math inline">\(\theta^j\)</span> values for node <span class="math inline">\(j\)</span>, as in <span class="math inline">\(\theta^X_{0}\)</span> or <span class="math inline">\(\theta^Y_{10}\)</span>. At each node, the range and number of possible nodal types is defined by the number of parents that that node has and the number of values the variables can take on. For instance, assuming all variables to be binary, if <span class="math inline">\(Y\)</span> has parents <span class="math inline">\(X\)</span> and <span class="math inline">\(W\)</span>, then there are <span class="math inline">\(2^{\left(2^2\right)}=16\)</span>) possible causal types for the <span class="math inline">\(Y\)</span> node.</p>
<!-- There are $2^2$ possible combinations of values that two binary causal variables can take on----$(X=0,W=0), (X=0,W=1), (X=1,W=0), (X=1,W=1)$---which implies four possible causal conditions over which $Y$'s possible responses must be defined. For instance, as we have seen, with two causal variables, we can have $\theta^Y_{0000}$, where $Y$ is always 0; $\theta^Y_{0001}$, where $Y$ is 0 unless both $X$ and $W$ are 1; and so on.^[These nodal types can require many indices--$2^k$ for a node with $k$ parents---and the rule we follow is that the $i$th subscript indicates the value the node takes when parent $j \in {1, 2, ..., k}$ take values $\mod(floor((i-1)/(2^{j-1})), 2)$ For instance for `Y0111` the first index means that Y takes the value 0 where both parents are 0,  in all other cases it takes value 1.] To get the total number of nodal types, we simply raise $2$ (since $Y$ is binary) to the number of causal conditions (4), giving the number of possible patterns of $Y$ values that could be generated across these four conditions (16). (The full set of nodal types for two causal variables in a binary setup is given in \@ref(tab:PO16).)^[More generally, let us say that any node $j$ can take on $r_j$ possible values and has parents belonging to set $PA_j$ and that each parent, $i \in PA_j$, can take on $r_i$ values. Then the number of nodal types for node $j$ is equal to $r_j^{\prod_{i \in PA_j}r_i}$. Informally, the exponent in this expression simply multiplies by one another the number of values that each of $j$'s parents can take on. This product tells us the number of causal conditions across which $j$'s responses must be defined. We then raise the number of values that $j$ can take on to the power of the number of causal conditions. With all variables binary, this expression translates to $2^{\left(2^k\right)}$ nodal types for a node with $k$ parents.] -->
<!-- All variables in a model have nodal types defining the value they take on given the value of their parents, including those variables without substantive parents. Suppose that $X$ and $W$, in this model, have no substantively defined parents. We nonetheless define a nodal type for each of them, which simply captures their exogenous assignment to some value. With $X$ binary, for instance, there are two nodal types, $\theta^X_{0}$, where $X$ is set to $0$, and $\theta^X_{1}$, where $X$ is set to $1$. -->
<p><strong>Causal types</strong>. From the set of all possible nodal types for a DAG, we get the set of all possible causal types by simply elaborating all possible permutations of nodal types.</p>
<!-- We will want to be able to conceive not just of types for individual nodes but of the full collection of nodal types across all nodes in a model. We refer to a unit's full set of nodal types as its *unit causal type* --- or, more simply, causal type --- which we represent as $\theta$.  A causal type is simply a listing that contains one nodal type for each node in the model. For instance, with a model with variable $X$, $W$, and $Y$, each unit has a *causal* type composed of its *nodal* types on each of the three nodes.^[A model in which each node $j$ has $k_j$ parents has $\prod_j2^{\left(2^{k_j}\right)}$ causal types that uniquely determine what data will be observed for a type under all possible interventions on its exogenous nodes.]  Thus, one causal type in this model could be $\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_1, \theta^Y = \theta^Y_{1101})$. Another could be $\theta = (\theta^X = \theta^X_0, \theta^W = \theta^W_1, \theta^Y = \theta^Y_{0001})$. And so on. -->
<!-- We show the mapping between nodal and causal types, for a simply $X \rightarrow Y$ model, in Table \@ref(tab:nodalcausalmatrix). The column headings represent the $8$ permissible causal types, each expressed simply as a concatenated strings of nodal types. The row headings represent the nodal types. In each interior cell, a $1$ or $0$ indicates whether or not a given nodal type is a component of a given causal type. As can be seen, each causal type has two nodal types that are its components since there are two nodes in this model. Each $X$-nodal type is part of four causal types since it can be combined with four different $Y$-nodal types, while each $Y$-nodal type is part of two causal types since it can be combined with two $X$-nodal types. -->
<!-- |             **Causal Types $\rightarrow$** | $\theta^X_0$.$\theta^Y_{00}$ | $\theta^X_1$.$\theta^Y_{00}$ | $\theta^X_0$.$\theta^Y_{10}$ | $\theta^X_1$.$\theta^Y_{10}$ | $\theta^X_0$.$\theta^Y_{01}$ | $\theta^X_1$.$\theta^Y_{01}$ | $\theta^X_0$.$\theta^Y_{11}$ | $\theta^X_1$.$\theta^Y_{11}$ | -->
<!-- |-------------------------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:| -->
<!-- |         **Nodal types $\downarrow$**        |                              |                              |                              |                              |                              |                              |                              |                              | -->
<!-- |  $\theta^X_0$ |               1              |               0              |               1              |               0              |               1              |               0              |               1              |               0              | -->
<!-- | $\theta^X_1$ |               0              |               1              |               0              |               1              |               0              |               1              |               0              |               1              | -->
<!-- |               $\theta^Y_{00}$              |               1              |               1              |               0              |               0              |               0              |               0              |               0              |               0              | -->
<!-- |               $\theta^Y_{10}$              |               0              |               0              |               1              |               1              |               0              |               0              |               0              |               0              | -->
<!-- |               $\theta^Y_{01}$              |               0              |               0              |               0              |               0              |               1              |               1              |               0              |               0              | -->
<!-- |               $\theta^Y_{11}$              |               0              |               0              |               0              |               0              |               0              |               0              |               1              |               1              | -->
<!-- Table: (\#tab:nodalcausalmatrix). A mapping between nodal types and causal types for a simple $X \rightarrow Y$ model. -->
<!-- |                                    **Causal Types $\rightarrow$** | $\theta^X_0$.$\theta^Y_{00}$ | $\theta^X_1$.$\theta^Y_{00}$ | $\theta^X_0$.$\theta^Y_{10}$ | $\theta^X_1$.$\theta^Y_{10}$ | $\theta^X_0$.$\theta^Y_{01}$ | $\theta^X_1$.$\theta^Y_{01}$ | $\theta^X_0$.$\theta^Y_{11}$ | $\theta^X_1$.$\theta^Y_{11}$ | -->
<!-- |------------------------------------------------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:|:----------------------------:| -->
<!-- |                    **Parameters $\downarrow$**                    |                              |                              |                              |                              |                              |                              |                              |                              | -->
<!-- |               $\theta^X_0 | \theta^Y= \theta^Y_{01}$              |               0              |               0              |               0              |               0              |               1              |               0              |               0              |               0              | -->
<!-- | $\theta^X_1 | \theta^Y_{01}$$\theta^X_1 | \theta^Y= \theta^Y_{01}$ |               0              |               0              |               0              |               0              |               0              |               1              |               0              |               0              | -->
<!-- |             $\theta^X_0| \theta^Y \neq \theta^Y_{01}$             |               1              |               0              |               1              |               0              |               0              |               0              |               1              |               0              | -->
<!-- |             $\theta^X_1 | \theta^Y \neq \theta^Y_{01}$            |               0              |               1              |               0              |               1              |               0              |               0              |               0              |               1              | -->
<!-- |                          $\theta^Y_{00}$                          |               1              |               1              |               0              |               0              |               0              |               0              |               0              |               0              | -->
<!-- |                          $\theta^Y_{10}$                          |               0              |               0              |               1              |               1              |               0              |               0              |               0              |               0              | -->
<!-- |                          $\theta^Y_{01}$                          |               0              |               0              |               0              |               0              |               1              |               1              |               0              |               0              | -->
<!-- |                          $\theta^Y_{11}$                          |               0              |               0              |               0              |               0              |               0              |               0              |               1              |               1              | -->
<!-- |                            | $\theta^X_0$.$\theta^Y_{00}$ | $\theta^X_1$.$\theta^Y_{00}$ | $\theta^X_0$.$\theta^Y_{10}$ | $\theta^X_1$.$\theta^Y_{10}$ | $\theta^X_0$.$\theta^Y_{01}$ | $\theta^X_1$.$\theta^Y_{01}$ | $\theta^X_0$.$\theta^Y_{11}$ | $\theta^X_1$.$\theta^Y_{11}$ | -->
<!-- |-----------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------| -->
<!-- | $\theta^X_0 | \theta^Y= \theta^Y_{01}$ | 0                            | 0                            | 0                            | 0                            | 1                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^X_1 | \theta^Y= \theta^Y_{01}$ | 0                            | 0                            | 0                            | 0                            | 0                            | 1                            | 0                            | 0                            | -->
<!-- | $\theta^X_0| \theta^Y \neq \theta^Y_{01}$                | 1                            | 0                            | 1                            | 0                            | 0                            | 0                            | 1                            | 0                            | -->
<!-- | $\theta^X_1 | \theta^Y \neq \theta^Y_{01}$                | 0                            | 1                            | 0                            | 1                            | 0                            | 0                            | 0                            | 1                            | -->
<!-- | $\theta^Y_{00}$             | 1                            | 1                            | 0                            | 0                            | 0                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{10}$             | 0                            | 0                            | 1                            | 1                            | 0                            | 0                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{01}$             | 0                            | 0                            | 0                            | 0                            | 1                            | 1                            | 0                            | 0                            | -->
<!-- | $\theta^Y_{11}$             | 0                            | 0                            | 0                            | 0                            | 0                            | 0                            | 1                            | 1                            | -->
<p><strong>Priors</strong>: Our background beliefs about a causal domain will usually consist of more than just beliefs about which variables have causal connections; they will also typically contain beliefs about what <em>kinds</em> of effects operate between variables. That is, they will contain beliefs about which types are possible or, more generally, are more or less common in the world. We express these beliefs over causal effects as either (a) restrictions on nodal types or (b) probability distributions over the nodal types.</p>
<p>In general, when doing process tracing in this framework, we think of a given case of interest – the one we are studying and seek to learn about – as being drawn at random from a population. Thus, our prior beliefs about a <em>single</em> case – before we do the process tracing – are really beliefs about that population. So, for instance, our prior belief about the probability that inequality has a positive effect on democratization in Mexico in 1999 is our belief about how commonly inequality has a positive effect on democratization in the population of cases that are “like” Mexico in 1999.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>We let <span class="math inline">\(\lambda^j\)</span> denote our beliefs over <span class="math inline">\(\theta^j\)</span>—nodal types at node <span class="math inline">\(j\)</span>. We sometimes think of <span class="math inline">\(\lambda^j\)</span> as the population distribution of <span class="math inline">\(\theta^j\)</span>, but this interpretation is not necessary for case level inference. A <span class="math inline">\(\lambda^j\)</span> is simply a vector of numbers (or proportions), one for each possible nodal type, with all numbers non negative and summing to <span class="math inline">\(1\)</span>. So, for instance, <span class="math inline">\(\lambda^Y\)</span> for our current example would be a vector with four values, each of which expresses a probability on one of the four nodal types at <span class="math inline">\(Y\)</span>. So we might have <span class="math inline">\(\lambda^Y_{01}=0.1\)</span>, <span class="math inline">\(\lambda^Y_{11}=0.05\)</span>, and so on – with the <span class="math inline">\(\lambda^Y\)</span> values summing to <span class="math inline">\(1\)</span> because these values are defined over the full set of possible nodal types for <span class="math inline">\(Y\)</span>.</p>
<p>We can, in turn, use these beliefs about nodal-type probabilities – to create prior probabilities over the <em>causal</em> type for the case at hand. Since causal types are merely combinations of nodal types we can take a set of probabilities on nodal types and calculate the probability that our case is of any given causal type. To do so, we need to join together <span class="math inline">\(\lambda\)</span>’s across the nodes in a model.</p>
<p>Let us first see how this works in a situation in which we assume that the nodal types are independent of one another. We can think of this as a situation in which there is no confounding that is not captured in the graph – no variable missing from the model that is a common ancestor of multiple nodes in the model. Here, our beliefs over causal types are simply the product of our beliefs over the component nodal types (since the joint probability of independent events is simply the product of their individual probabilities). For instance, one causal type might be “a unit in which <span class="math inline">\(X=1\)</span> and in which <span class="math inline">\(Y=1\)</span> no matter what value <span class="math inline">\(X\)</span> takes.” In this case the probability that a case is of this causal type might be written <span class="math inline">\(\Pr(\theta^X = \theta^X_1)\Pr(\theta^Y = \theta^Y_{11}) = \lambda^X_1\lambda^Y_{11}\)</span>.</p>
<p>The simplest way in which we can express beliefs about the differential probabilities of different causal possibilities is by <em>eliminating</em> nodal types that we do not believe to be possible—setting their parameter values to <span class="math inline">\(0\)</span>. Suppose, for instance, that we are examining the effect of ethnic diversity on civil war in a case. We might not know whether ethnic diversity causes civil war in this case, but we might have sufficient background knowledge to believe that ethnic diversity never has a <em>negative</em> effect on civil war: it never prevents a civil war from happening that would have happened in the absence of ethnic diversity. We would thus want to set the parameter value for a negative causal effect to <span class="math inline">\(0\)</span>. If we then know nothing about the relative frequencies of the three remaining nodal types for <span class="math inline">\(Y\)</span>, we may (following the principle of indifference), frequency of positive effects, null effects with civil war destined to happen, and null effects with civil war never going to happen, assigning a weight of <span class="math inline">\(\frac{1}{3}\)</span> to each of them.</p>
<p>In a situation of unobserved confounding, our beliefs over causal types are still well defined, though they are no longer the simple product of beliefs over nodal types. Let us imagine for instance, in a simple <span class="math inline">\(X \rightarrow Y\)</span> model, that we believe that some unobserved factor both affects both the likelihood of <span class="math inline">\(X = 1\)</span> and also <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>: maybe, for instance, <span class="math inline">\(X\)</span> is more likely to be assigned to 1 where <span class="math inline">\(X\)</span> has a positive effect. This is the same as saying that the probability that <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\theta^Y\)</span> are correlated. Now, the probability of any combination of <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\theta^Y\)</span> must be calculated using the joint probability formula, <span class="math inline">\(\Pr(A, B) = \Pr(A)\Pr(B|A)\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> Thus, for instance, <span class="math inline">\(\Pr(\theta^Y = \theta^Y_{01}, \theta^X = \theta^X_1) = \Pr(\theta^Y = \theta^Y_{01})\Pr(\theta^X = \theta^X_1 | \theta^Y = \theta^Y_{01})\)</span>. To form priors over causal types in this situation, we need to posit beliefs about a set of more complex, conditional proportions for <span class="math inline">\(X\)</span>’s type. Specifically, we need to posit, <em>for those cases</em> with a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, what proportion are “assigned” to <span class="math inline">\(X=1\)</span>; <em>for those cases</em> with a negative effect, what proportion are assigned to <span class="math inline">\(X=1\)</span>; and so on, conditioning on each of <span class="math inline">\(Y\)</span>’s nodal types.</p>
<p>These conditional proportions may, of course, be difficult for the researcher to form beliefs about. Forming a belief about them amounts to saying that we do not know what generates confounding, but we know the correlations it generates in the data. We may wonder how often we will be in that epistemological position. An alternative way to parse the problem, then, is to <em>model</em> the confounding by including the confounder (say, <span class="math inline">\(Z\)</span>) as a new node in the graph. In the above example, <span class="math inline">\(Z\)</span> would point into both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. We would then posit probabilities (or population proportions) for a set of nodal types for <span class="math inline">\(X\)</span> – representing <span class="math inline">\(X\)</span>’s possible responses to <span class="math inline">\(Z\)</span> – and for <span class="math inline">\(Y\)</span> – representing <span class="math inline">\(Y\)</span>’s possible responses to both <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>. We may find it easier to reason and form beliefs about these more complex nodal types than about the conditional proportions involved in unobserved confounding. The two approaches work out to be analytically equivalent given equivalent underlying beliefs, so the choice between them will be a matter of researcher preference.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>Importantly, in process tracing, we are focused on drawing case-level inferences and, as such, we treat the population-level parameters as given and fixed. In general, these parameters derive from our beliefs about how the world works, and those beliefs will typically be uncertain. The key point, however, is that in process tracing, the population parameters serve as an <em>input</em> into the analysis, conditioning our inferences from the evidence: we interpret a case in light of what we know about general causal relations. But, in the process-tracing setup, we do not <em>update</em> on these population-level beliefs once we see the data from a single case. Importantly, as we show later in the book, we <em>do</em> update on population-level inferences in the more general setup that we introduce in Chapter <a href="mixing.html#mixing">9</a> for analyzing mixed data in multiple cases. We also show in Chapter <a href="evaluation.html#evaluation">16</a> how we can test the sensitivity of conclusions to the values at which we set population parameters. Interestingly, as we also show, process-tracing inferences, including uncertainty about conclusions, are unaffected by the level of uncertainty we might have about population parameters; we thus do not specify this uncertainty for the purposes of process tracing.</p>
<p>The relationship between causal types, nodal types, and the correlation among nodal types can be represented in a <em>parameter matrix.</em> We show a parameter matrix for a simple <span class="math inline">\(X \rightarrow Y\)</span> model with no unobserved confounding in Table <a href="pt.html#tab:parammmatrix">7.1</a>. Here each column label (except the last) represents the probability that a case is of a given causal type. Each row label represents a population-level parameter: a belief about the proportions of different nodal types in the population. We indicate a set of possible parameter values in the final column.</p>
<table>
<caption><span id="tab:parammmatrix">Table 7.1: </span>. A mapping between nodal types and causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model (with no unobserved confounding).</caption>
<colgroup>
<col width="13%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Causal types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></th>
<th align="center">Parameter values (population proportions)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Population parameters</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^X_1\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.5</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^X_0\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.4</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.2</td>
</tr>
</tbody>
</table>
<p>To start with the first two rows, these represent the population proportions of each of <span class="math inline">\(X\)</span>’s nodal types. For instance, <span class="math inline">\(\lambda^X_{0}\)</span> is our belief about the proportion of cases in the population that are of nodal type <span class="math inline">\(\theta^X_{0}\)</span>. The first row, <span class="math inline">\(\lambda^X_{1}\)</span>, represents our belief about the inverse: the proportion of cases in the population of type <span class="math inline">\(\theta^X_{1}\)</span>. We posit beliefs about these parameters in the final column, indicating that we think that half of cases in the population are “assigned” to <span class="math inline">\(X=0\)</span> and half to <span class="math inline">\(X=1\)</span>. Note that, since there are only two possible nodal types for <span class="math inline">\(X\)</span>, and their proportions must sum to 1, there is actually just one degree of freedom here: once we’ve specified one of these parameter values, the other is defined as well.</p>
<p>The last four rows represent the proportion of cases in the population with different <span class="math inline">\(Y\)</span>-nodal types: in order, the proportion in which <span class="math inline">\(X\)</span> has no effect on <span class="math inline">\(Y\)</span>, with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(0\)</span>; the proportion in which <span class="math inline">\(X\)</span> has a negative effect; the proportion in which <span class="math inline">\(X\)</span> has a positive effect; and the proportion in which <span class="math inline">\(X\)</span> has no effect, with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>. Again, in the last column, we provide possible values for these proportions, the four of which must also sum to <span class="math inline">\(1\)</span>. Here we are stating that positive <span class="math inline">\(X \rightarrow Y\)</span> effects are twice as common in the population as the other three nodal types, which we set at equal prevalence.</p>
<p>The interior cells indicate whether a given population parameter enters into the prior probability of a given causal type. Thus, for instance, to calculate the prior probability of the causal type <span class="math inline">\(\theta^X_1, \theta^Y_{10}\)</span>, we need to multiply the two parameters values corresponding to the <span class="math inline">\(1\)</span>’s in this causal type’s column: <span class="math inline">\(\lambda^X_1\)</span> by <span class="math inline">\(\lambda^Y_{10}\)</span>. Given the parameter values we have assigned for this example, then, the prior on this causal type is simply <span class="math inline">\(0.5 \times 0.2 = 0.1\)</span>.</p>
<p>The prior probability that a case is of a given causal type thus comes directly from our beliefs about how nodal types are distributed in the population. All we know before we study a case is whatever we know about cases “like” it in general. It is then these causal-type probabilities – which represent probabilities that a <em>given case</em> is of a particular causal type – that we will update on once we see the data for this case.</p>
<p>We show the somewhat more complex situation of unobserved confounding in Table <a href="#tab:parammatrixconf"><strong>??</strong></a>. We capture unobserved confounding in the first four rows; we can think of these rows as capturing differential “assignment propensities” for <span class="math inline">\(X\)</span>. Rather than representing different assignment propensities for each of <span class="math inline">\(Y\)</span>’s nodal types, simplify the representation here by allowing for different propensities depending on whether or not <span class="math inline">\(Y\)</span>’s type is <span class="math inline">\(\theta^Y_{01}\)</span> or not.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> Thus, <span class="math inline">\(\lambda^X_0 | \theta^Y= \theta^Y_{01}\)</span> is the proportion of <span class="math inline">\(\theta^X_0\)</span> types among cases with <span class="math inline">\(\theta^Y_{01}\)</span> type: put differently, it is the probability of <span class="math inline">\(X\)</span> being assigned to <span class="math inline">\(0\)</span> when <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. The second row represents the inverse proportion: the proportion of a <span class="math inline">\(\theta^X_1\)</span> types among <span class="math inline">\(\theta^Y_{01}\)</span> types. The next two rows then capture the proportions of the <span class="math inline">\(X\)</span>-types among all <em>other</em> <span class="math inline">\(Y\)</span>-types (i.e., among those cases for which <span class="math inline">\(X\)</span> does <em>not</em> have a positive effect on <span class="math inline">\(Y\)</span>).</p>
<p>Unobserved confounding in this setup takes the form of a difference in the proportions of a given <span class="math inline">\(X\)</span> type among different <span class="math inline">\(Y\)</span> types. Thus, if <span class="math inline">\(\lambda^X_1, | \theta^Y_{01}\)</span> is not the same as <span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span>, we have unobserved confounding. Imagine, for instance, if we are studying the effect of faster economic growth (<span class="math inline">\(X\)</span>) on democratization (<span class="math inline">\(Y\)</span>), and we believe that there is some unobserved factor that both makes some countries’ economies grow more quickly and also makes economic growth more likely to have a positive effect on democratization. This belief amounts to a belief that the probability of a case being assigned to <span class="math inline">\(X=1\)</span> is higher if <span class="math inline">\(Y\)</span>’s nodal type is <span class="math inline">\(\theta^Y_{01}\)</span> than if it is not. In other words, in terms of the rows in Table <a href="#tab:parammatrix"><strong>??</strong></a>, we believe here that <span class="math inline">\(\lambda^X_1 | \theta^Y=\theta^Y_{01}\)</span> is greater than <span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span>. To illustrate, we provide parameter values along these lines in the final column.</p>
<p>Again, however, a researcher might prefer to specify the confounder (say, <span class="math inline">\(Z\)</span>) as a node in the model. The rows in the parameter matrix would then be a set of population parameters defined as proportions of <em>un</em>conditional nodal types, with four <span class="math inline">\(X\)</span>-types representing possible responses to <span class="math inline">\(Z\)</span>, and 16 <span class="math inline">\(Y\)</span> types, representing <span class="math inline">\(Y\)</span>’s possible responses to <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.</p>
<table>
<caption><span id="tab:parammmatrixconf">Table 7.2: </span>. A mapping between nodal types and causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model <em>with</em> unobserved confounding.</caption>
<colgroup>
<col width="16%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="right"><strong>Causal Types <span class="math inline">\(\rightarrow\)</span></strong></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></th>
<th align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Population parameters <span class="math inline">\(\downarrow\)</span></strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^X_0 | \theta^Y= \theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^X_1 | \theta^Y=\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^X_0| \theta^Y \neq \theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^X_1 | \theta^Y \neq \theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\lambda^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\lambda^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<!-- In this case the number of parameters may exceed the number of nodal types, with, for instance parameters $\hat{\lambda}^Y_{11}$ representing $\Pr(\theta^Y = \theta^Y_{11}|\theta^X = \theta^X_1)$  and $\tilde{\lambda}^Y_{11}$ representing $\Pr(\theta^Y = \theta^Y_{11}|\theta^X = \theta^X_0)$.   -->
<!-- One special kind of prior that we might wish to set is to disallow a particular (conditional) type altogether. For instance, if studying the effect of we may believe that  -->
<p><strong>Possible data types.</strong> A <em>data type</em> is a particular pattern of data that we could potentially observe for a given case. More specifically, a data type is a set of values, one for each node in a model. For instance, in our <span class="math inline">\(X, W, Y\)</span> setup, <span class="math inline">\(X=1, W=0, Y=0\)</span> would be one data type.</p>
<p>Importantly, each possible causal type <em>maps into a single data type.</em> One intuitive way to think about why this is the case is that a causal type tells us (a) the values to which all exogenous variables in a model are assigned and (b) how all endogenous variables respond to their parents. Given these two components, only one set of node values is possible. For example, causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_0, \theta^Y = \theta^Y_{0100})\)</span> imples data <span class="math inline">\(X=1, W=0, Y=1\)</span>. There is no other set of data that can be generated by this causal type.</p>
<p>Equally importantly, however, <em>the mapping from causal types to data types is not one-to-one.</em> More than one causal type can generate the same case-level data pattern. For instance, the causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^W = \theta^W_0, \theta^Y = \theta^Y_{1101})\)</span> will <em>also</em> generate the data type, <span class="math inline">\(X=1, W=0, Y=1\)</span>. Thus, observing this data type leaves us with ambiguity about the causal type by which it was generated.</p>
<p>A full mapping between causal types and data types can be summarized in an <em>ambiguity matrix.</em> In Table <a href="pt.html#tab:ambigmatrix">7.3</a>, we provide an example of such a matrix, derived directly from the parameter matrix in Table <a href="#tab:parammatrix"><strong>??</strong></a>. Here, the rows represent causal types and the columns (except for the last) represent data types. The notation for data types is straightforward, with for instance <span class="math inline">\(X0Y0\)</span> meaning that <span class="math inline">\(X=0, Y=0\)</span> has been observed. In the interior cells, the <span class="math inline">\(1\)</span>’s and <span class="math inline">\(0\)</span>’s indicate whether or not a given data type could arise from a given causal type. We can readily see here that each causal type can generate only one data type.</p>
<p>We can also see the ambiguity of the data, however, since each data type can be generated by two causal types. For instance, if we observe <span class="math inline">\(X=1, Y=1\)</span>, we know that the case is either of causal type <span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span> or of causal type <span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span> – but do not know which.</p>
<table>
<caption><span id="tab:ambigmatrix">Table 7.3: </span>. An ambiguity matrix, mapping from data types to causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model.</caption>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X0Y0</th>
<th align="center">X1Y0</th>
<th align="center">X0Y1</th>
<th align="center">X1Y1</th>
<th align="center">Priors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.1</td>
</tr>
</tbody>
</table>
<p>In the last column, we provide prior probabilities for each of the causal types. These have been calculated directly from the parameter matrix (Table <a href="#tab:parammatrix"><strong>??</strong></a>). To see how the calculation works, start with a causal type in the parameter matrix – say, <span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span>. We go down that causal type’s column and select the rows with <span class="math inline">\(1\)</span>’s, representing the parameters for the included nodal types, <span class="math inline">\(\lambda^X_0\)</span> and <span class="math inline">\(\lambda^Y_{01}\)</span>. As we want the joint probability of these two nodal types (and a parameter matrix is constructed such that the rows represent independent events),<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> we simply multiply together the values for these included parameters: <span class="math inline">\(0.5 \times 0.4 = 0.2\)</span>. As noted, our prior belief about whether the case at hand is of a given causal type is a straightforward function of our beliefs about how prevalent each of the component nodal types is in the population.</p>
<p>As models get more complex, the numbers of causal and data types simply multiply. In Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, we show the ambiguity matrix for a simple mediation model (<span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>). Here, the causal types are combinations of three nodal types, one for each variable in the model. Similarly, the data types have three elements, one for each variable. We now have 8 data types and 32 causal types.</p>
<table>
<caption><span id="tab:ambigmatrixmed">Table 7.4: </span>. An ambiguity matrix, mapping from data types to causal types for a simpe mediation model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>.</caption>
<colgroup>
<col width="31%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="18%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X0M0Y0</th>
<th align="center">X1M0Y0</th>
<th align="center">X0M1Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">X0M0Y1</th>
<th align="center">X1M0Y1</th>
<th align="center">X0M1Y1</th>
<th align="center">X1M1Y1</th>
<th align="center">Priors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.08</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.08</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_0,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
</tr>
</tbody>
</table>
<p>Again, the ambiguities arising from data patterns are apparent. For instance, if we observe <span class="math inline">\(X=1, M=0, Y=0\)</span>, we see that there are four causal types that could have generated this pattern. To unpack the situation a bit, these data tell us that <span class="math inline">\(\theta^X = \theta^X_1\)</span>. But they do not tell us whether <span class="math inline">\(M\)</span>’s type is such that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(M\)</span> (<span class="math inline">\(\theta^M_{10}\)</span>) or <span class="math inline">\(X\)</span> has no effect with <span class="math inline">\(M\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^M_{00}\)</span>). Similarly, we do not know whether <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (<span class="math inline">\(\theta^Y_{01}\)</span>) or no effect with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^Y_{00}\)</span>). This leaves four combinations of nodal types—four causal types—that are consistent with the data.</p>
<p>Our priors here derive from a set of parameter values, much like in the previous example, in which the <span class="math inline">\(X\)</span> types are equally common (0.5 each); a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> is twice as common (0.4) as the other <span class="math inline">\(M\)</span> types (all set to 0.2); and a positive effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> is twice as common (0.4) as all other <span class="math inline">\(Y\)</span> types (all at 0.2). We can then easily see why we thus get priors on some causal types are higher than those on others: for instance, the two causal types with priors of 0.08 both have two positive effects (at the <span class="math inline">\(X \rightarrow Y\)</span> and <span class="math inline">\(M \rightarrow Y\)</span> stages) while the causal types with priors of 0.02 include no positive effects at either stage.</p>
<!-- ```{r ambigmatrix, echo = FALSE} -->
<!-- ambXY_with_priors <- data.frame(cbind(ambiguityXY, prior = draw_type_prob(XY, using = "parameters"))) -->
<!-- kable(ambXY_with_priors), caption = "Ambiguity matrix for X -> Y model. Rows are causal types, columns are data types. Last column shows possible priors over rows.") -->
<!-- ``` -->
<!-- For an $X \rightarrow Y$ model: -->
<div id="htmlwidget-af2dffec79d7e9bb2564" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-af2dffec79d7e9bb2564">{"x":{"filter":"none","vertical":false,"caption":"<caption>Ambiguity matrix for X -&gt; M -&gt; Y model. Rows are causal types, columns are data types. Last column shows possible priors over rows.<\/caption>","data":[["X0M00Y00","X1M00Y00","X0M10Y00","X1M10Y00","X0M01Y00","X1M01Y00","X0M11Y00","X1M11Y00","X0M00Y10","X1M00Y10","X0M10Y10","X1M10Y10","X0M01Y10","X1M01Y10","X0M11Y10","X1M11Y10","X0M00Y01","X1M00Y01","X0M10Y01","X1M10Y01","X0M01Y01","X1M01Y01","X0M11Y01","X1M11Y01","X0M00Y11","X1M00Y11","X0M10Y11","X1M10Y11","X0M01Y11","X1M01Y11","X0M11Y11","X1M11Y11"],[1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,1],[0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02,0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02,0.04,0.04,0.04,0.04,0.08,0.08,0.04,0.04,0.02,0.02,0.02,0.02,0.04,0.04,0.02,0.02]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>X0M0Y0<\/th>\n      <th>X1M0Y0<\/th>\n      <th>X0M1Y0<\/th>\n      <th>X1M1Y0<\/th>\n      <th>X0M0Y1<\/th>\n      <th>X1M0Y1<\/th>\n      <th>X0M1Y1<\/th>\n      <th>X1M1Y1<\/th>\n      <th>prior<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","sDom":"<\"top\">lrt<\"bottom\">ip","scrollY":true,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><strong>Updating on types given the data.</strong> Once we observe actual data in a case, we can then update on the probabilities assigned to each causal type. The logic is simple. When we observe a set of data from a case, we place <span class="math inline">\(0\)</span> probability on all causal types that could not have produced these data; we then scale up the probabilities on all causal types that could have.</p>
<p>We can see how this works within an ambiguity matrix. Let’s return to the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrix">7.3</a>. We start out with a set of probability weights on all rows (causal types). Now, suppose that we observe the data <span class="math inline">\(X=1, Y=1\)</span>, i.e., data type <span class="math inline">\(X1Y1\)</span>. We then look down the <span class="math inline">\(X1Y1\)</span> column, and we know that all rows with a <span class="math inline">\(0\)</span> in them represent causal types that <em>could not have</em> generated these data. These causal types are thus excluded. What is left are two rows: <span class="math inline">\(\theta^X_1, \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1, \theta^Y_{11}\)</span>. Returning now to the probabilities, we put 0 weight on all of the excluded rows; and then we scale up the remaining probabilities so that they sum to 1 (preserving the ratio between them). The priors of 0.2 and 0.1 in the retained rows scale up to <span class="math inline">\(\frac{2}{3}\)</span> and <span class="math inline">\(\frac{1}{3}\)</span>, which become our <em>posterior</em> probabilities on the causal types. We display an updated ambiguity matrix, with excluded data types and causal types removed, in Table <a href="pt.html#tab:ambigupdate">7.5</a>.</p>
<p>Before we see any data on the case at hand, then, we believe (based on our beliefs about the population to which the case belongs) that there is a 0.2 probability that the case is one in which <span class="math inline">\(X\)</span> is assigned to <span class="math inline">\(1\)</span> and has a positive effect on <span class="math inline">\(Y\)</span>; and 0.1 probability that it’s a case in which <span class="math inline">\(X\)</span> gets assigned to <span class="math inline">\(1\)</span> and has no effect on <span class="math inline">\(Y\)</span> with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(1\)</span>. Seeing the <span class="math inline">\(X=1, Y=1\)</span> data, we now believe that there is a 0.667 probability that the case is of the former type, and a 0.333 probability that it is of the latter type.</p>
<table>
<caption><span id="tab:ambigupdate">Table 7.5: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrix">7.3</a>, after observing <span class="math inline">\(X=1, Y=1\)</span> in a case.</caption>
<colgroup>
<col width="34%" />
<col width="6%" />
<col width="26%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1Y1</th>
<th align="center">Priors on causal types</th>
<th>Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.2</td>
<td>0.6667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.1</td>
<td>0.3333</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- ambXY_with_priors%>% -->
<!--     mutate(type = rownames(ambXY_with_priors)) %>% -->
<!--     select(type, X1Y1, prior) %>% -->
<!--     filter(X1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable() -->
<!-- ``` -->
<p>We can also see how this works for our <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, and the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>. If we observe the data <span class="math inline">\(X=1, M=0, Y=0\)</span>, for instance, this exercise would yield the updated ambiguity matrix in Table (tab:ambigmedupdate). Here we have eliminated all rows (causal types) with a <span class="math inline">\(0\)</span> in the relevant data-type column (<span class="math inline">\(X1M0Y0\)</span>) and formed the posteriors by scaling up the priors in the retained rows.</p>
<table>
<caption><span id="tab:ambigmedupdate">Table 7.6: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, after observing <span class="math inline">\(X=1, M=0, Y=0\)</span> in a case.</caption>
<colgroup>
<col width="40%" />
<col width="7%" />
<col width="23%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1667</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.3333</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.3333</td>
</tr>
</tbody>
</table>
<p>A notable feature of the logic of single-case process tracing is that the relative probabilities on the retained causal types never change. If we start out believing that causal type <span class="math inline">\(A\)</span> is twice as likely as causal type <span class="math inline">\(B\)</span>, and both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are retained once we see the data, then <span class="math inline">\(A\)</span> will be twice as likely as <span class="math inline">\(B\)</span> in our posteriors. All updating occurs by <em>eliminating</em> causal types from consideration and zeroing in on those that remain.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">type</th>
<th align="right">X1M0Y0</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M00Y00</td>
<td align="left">X1M00Y00</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1666667</td>
</tr>
<tr class="even">
<td align="left">X1M10Y00</td>
<td align="left">X1M10Y00</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1666667</td>
</tr>
<tr class="odd">
<td align="left">X1M00Y01</td>
<td align="left">X1M00Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.3333333</td>
</tr>
<tr class="even">
<td align="left">X1M10Y01</td>
<td align="left">X1M10Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.3333333</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- data.frame(cbind(ambiguityXMY)) %>% -->
<!--     mutate(type = rownames(ambiguityXMY), prior = draw_type_prob(XMY)) %>% -->
<!--     select(type, X1M1Y1, prior) %>% -->
<!--     filter(X1M1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable(digits = 2) -->
<!-- ``` -->
<p>A similar logic applies if partial data are observed: that is, if we do not collect data for all nodes in the model. The one difference is that, now, rather than reducing to one column we entertain the possibility of any data <em>type</em> consistent with the <em>observed data</em>. In general, more than one data type will be consistent with partial data. For instance, suppose that we observe <span class="math inline">\(X=1, Y=0\)</span> but do not observe <span class="math inline">\(M\)</span>’s value. These are data that are consistent with both the data type <span class="math inline">\(X1M0Y0\)</span> and the data type <span class="math inline">\(X1M1Y0\)</span> (since the unobserved <span class="math inline">\(M\)</span> could be either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>). We thus retain both of these data-type columns as well as all causal types consistent with <em>either</em> of these data types. This gives the updated ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdatepartial">7.7</a>. We note that, with these partial data, we are not able to update as strongly. For instance, for the causal type <span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span>, instead of updating to a posterior probability of 0.1667, we update to a posterior of only 0.0833 – because there is a larger set of causal types with which these partial data are consistent.</p>
<table>
<caption><span id="tab:ambigmedupdatepartial">Table 7.7: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.</caption>
<colgroup>
<col width="37%" />
<col width="7%" />
<col width="7%" />
<col width="22%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0833</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1667</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">type</th>
<th align="right">X1M0Y0</th>
<th align="right">X1M1Y0</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M00Y00</td>
<td align="left">X1M00Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.02</td>
<td align="right">0.0833333</td>
</tr>
<tr class="even">
<td align="left">X1M10Y00</td>
<td align="left">X1M10Y00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.02</td>
<td align="right">0.0833333</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y00</td>
<td align="left">X1M01Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.1666667</td>
</tr>
<tr class="even">
<td align="left">X1M11Y00</td>
<td align="left">X1M11Y00</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.0833333</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y10</td>
<td align="left">X1M01Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.1666667</td>
</tr>
<tr class="even">
<td align="left">X1M11Y10</td>
<td align="left">X1M11Y10</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.0833333</td>
</tr>
<tr class="odd">
<td align="left">X1M00Y01</td>
<td align="left">X1M00Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.04</td>
<td align="right">0.1666667</td>
</tr>
<tr class="even">
<td align="left">X1M10Y01</td>
<td align="left">X1M10Y01</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.04</td>
<td align="right">0.1666667</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- data.frame(cbind(ambiguityXMY)) %>% -->
<!--     mutate(type = rownames(ambiguityXMY), prior = draw_type_prob(XMY)) %>% -->
<!--     select(type, X1M0Y1, X1M1Y1, prior) %>%  -->
<!--     filter(X1M1Y1 ==1 | X1M0Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable(digits = 2) -->
<!-- ``` -->
<p><strong>Updating on queries.</strong> We now have a posterior probability for each causal type for the case at hand. The causal question we are interested in answering, our query, may not be about causal types <em>per se.</em> It is about a query that can be expressed as a <em>combination</em> of causal types, as decribed in Chapter <a href="questions.html#questions">4</a>.</p>
<p>For instance, suppose we are working with the model <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>; and that our question is, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?” This question is asking both:</p>
<ol style="list-style-type: decimal">
<li><p>Does <span class="math inline">\(X=1\)</span> in this case?</p></li>
<li><p>Does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> in this case?</p></li>
</ol>
<p>The causal types that qualify are those, and only those, in which the answer to both is “yes.”</p>
<p>Meeting condition (1) requires that <span class="math inline">\(\theta^X=\theta^X_1\)</span>.</p>
<p>Meeting condition (2) requires that <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span> are such that <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(M\)</span> that yields a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. This could occur via a positive <span class="math inline">\(X \rightarrow M\)</span> effect linked to a positive <span class="math inline">\(M \rightarrow Y\)</span> effect or via a negative <span class="math inline">\(X \rightarrow M\)</span> effect linked to a negative <span class="math inline">\(M \rightarrow Y\)</span> effect.</p>
<p>Thus, the qualifying causal types in this model are:</p>
<ul>
<li><span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span></li>
<li><span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span></li>
</ul>
<p>Our <em>prior</em> on the query—what we believe before we collect data on the case at hand—is given simply by summing up the prior probabilities on each of the causal types that correspond to the query. Note that we must calculate the prior from the full ambiguity matrix, before excluding types for inconsistency with the data. Returning to the full ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, we see that the priors on these two types (given the population parameters assumed there) are 0.08 and 0.02, respectively, giving a prior for the query of 0.1.</p>
<p>The posterior on any query is, likewise, given by summing up the posterior probabilities on each of the causal types that correspond to the query, drawing of course from the updated ambiguity matrix. For instance, if we observe the data <span class="math inline">\(X=1, M=1, Y=1\)</span>, we update to the ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdate2">7.8</a>. Our posterior on the query, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?” is the sum of the posteriors on the above two causal types. Since <span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span> is excluded by the data, this just leaves the posterior on <span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span>, 0.4444, which is the posterior belief on our query.</p>
<p>If we observe only the partial data, <span class="math inline">\(X=1, Y=1\)</span>, then we update to the ambiguity matrix in Table <a href="pt.html#tab:ambigmedupdatepartial2">7.9</a>. Now both corresponding causal types are included, and we sum their posteriors to get the posterior on the query: <span class="math inline">\(0.0769 + 0.3077 = 0.3846\)</span>.</p>
<!-- FLAG: Briefly discuss other query(s) one could do, though don't show in detail here. Will do pathways in Chap. 7. -->
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">type</th>
<th align="right">X1M1Y1</th>
<th align="right">prior</th>
<th align="right">posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X1M01Y01</td>
<td align="left">X1M01Y01</td>
<td align="right">1</td>
<td align="right">0.08</td>
<td align="right">0.4444444</td>
</tr>
<tr class="even">
<td align="left">X1M11Y01</td>
<td align="left">X1M11Y01</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.2222222</td>
</tr>
<tr class="odd">
<td align="left">X1M01Y11</td>
<td align="left">X1M01Y11</td>
<td align="right">1</td>
<td align="right">0.04</td>
<td align="right">0.2222222</td>
</tr>
<tr class="even">
<td align="left">X1M11Y11</td>
<td align="left">X1M11Y11</td>
<td align="right">1</td>
<td align="right">0.02</td>
<td align="right">0.1111111</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:ambigmedupdate2">Table 7.8: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, after observing <span class="math inline">\(X=1, M=1, Y=1\)</span> in a case.</caption>
<colgroup>
<col width="40%" />
<col width="7%" />
<col width="23%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M1Y1</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.08</td>
<td align="center">0.4444</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.2222</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.2222</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.1111</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:ambigmedupdatepartial2">Table 7.9: </span>. An updated version of the ambiguity matrix in Table <a href="pt.html#tab:ambigmatrixmed">7.4</a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.</caption>
<colgroup>
<col width="37%" />
<col width="7%" />
<col width="7%" />
<col width="22%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span></th>
<th align="center">X1M0Y0</th>
<th align="center">X1M1Y0</th>
<th align="center">Priors on causal types</th>
<th align="center">Posteriors on causal types</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.08</td>
<td align="center">0.3077</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.04</td>
<td align="center">0.1538</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.04</td>
<td align="center">0.1538</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0.02</td>
<td align="center">0.0769</td>
</tr>
</tbody>
</table>
<!-- ```{r, echo = FALSE} -->
<!-- ambXMY_with_priors%>% -->
<!--     mutate(type = rownames(ambXMY_with_priors)) %>% -->
<!--     select(type, X1M0Y1, X1M1Y1, prior) %>% -->
<!--     filter(X1M0Y1 ==1 | X1M1Y1 ==1)%>% -->
<!--    mutate(posterior = prior/sum(prior)) %>% -->
<!--    kable() -->
<!-- ``` -->
<p>For more complex models and queries, it can be more difficult to eyeball the corresponding causal types. In practice, therefore, we use the <code>get_query_types</code> function in the <code>CausalQueries</code> package to do this for us.</p>
<!-- For example, supposer we want to know whether $X$ has some causal effect on $Y$ in our simple mediation model. The query, "$X$ haa a causal effect on $Y$" maps onto a relatively large, though still easily calculated, collection of types. Using `gbiqq`'s get_types function, we would define our query as a search for all causal types in which $Y$'s potential outcome when $X=1$ is different from $Y$'s potential outcome when $X=0$. The function then reports back all causal types meeting this condition: -->
<!-- ```{r, eval = FALSE} -->
<!-- get_types(XMY, "Y[X=1] != Y[X=0]") -->
<!-- ``` -->
<pre><code>X0.M10.Y10, X1.M10.Y10, X0.M01.Y10, X1.M01.Y10, X0.M10.Y01, X1.M10.Y01, X0.M01.Y01, X1.M01.Y01</code></pre>
<!-- This completes the abstract representation of the process tracing procedure. We now build up the intuition by walking through the procedure for simple mediation and moderation models. -->
<div class="headerbox">
<div class="center">

</div>
<p><strong>Illustration of Process Tracing with Code</strong></p>
<p>We illustrate process tracing for a simple mediation model. First, we define the structure of the model using the <code>make_model</code> function. We then use <code>set_parameters</code> to specify our beliefs about population-level shares of nodal types for each node, entering one proportion for each nodal type in the model. The ordering of nodal types can be viewed within the model summary (<code>summary(XMY)</code>). We then query the model to find out what we should believe about the query of interest given different possible data-realizations. Here we define the query (PC) as the probability that <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. We then use the <code>given</code> argument to list the possible data-realizations for which we want to report an estimate for this query. Finally, we tell <code>CausalQueries</code> to use the parameter values that we have specified to generate the estimates.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="pt.html#cb2-1" aria-hidden="true" tabindex="-1"></a>XMY <span class="ot">&lt;-</span> <span class="fu">make_model</span>(<span class="st">&quot;X -&gt; M -&gt; Y&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb2-2"><a href="pt.html#cb2-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">set_parameters</span> (<span class="fu">c</span>(.<span class="dv">5</span>, .<span class="dv">5</span>, .<span class="dv">2</span>, .<span class="dv">2</span>, .<span class="dv">4</span>, .<span class="dv">2</span>, .<span class="dv">2</span>, .<span class="dv">2</span>, .<span class="dv">4</span>, .<span class="dv">2</span>))</span>
<span id="cb2-3"><a href="pt.html#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="pt.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">query_model</span>(<span class="at">model =</span> XMY, </span>
<span id="cb2-5"><a href="pt.html#cb2-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">queries =</span> <span class="fu">list</span>(<span class="at">PC =</span> <span class="st">&quot;Y[X=1] &gt; Y[X=0]&quot;</span>), </span>
<span id="cb2-6"><a href="pt.html#cb2-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">given =</span> <span class="fu">list</span>(<span class="cn">TRUE</span>, <span class="st">&quot;X==1 &amp; Y==1&quot;</span>, <span class="st">&quot;X==1 &amp; Y==1 &amp; M==0&quot;</span>, <span class="st">&quot;X==1 &amp; Y==1 &amp; M==1&quot;</span>),</span>
<span id="cb2-7"><a href="pt.html#cb2-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">using =</span> <span class="st">&quot;parameters&quot;</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Query</th>
<th align="left">Given</th>
<th align="left">Using</th>
<th align="left">Case.estimand</th>
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PC</td>
<td align="left">-</td>
<td align="left">parameters</td>
<td align="left">FALSE</td>
<td align="right">0.2000000</td>
</tr>
<tr class="even">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1</td>
<td align="left">parameters</td>
<td align="left">FALSE</td>
<td align="right">0.3846154</td>
</tr>
<tr class="odd">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1 &amp; M==0</td>
<td align="left">parameters</td>
<td align="left">FALSE</td>
<td align="right">0.2500000</td>
</tr>
<tr class="even">
<td align="left">PC</td>
<td align="left">X==1 &amp; Y==1 &amp; M==1</td>
<td align="left">parameters</td>
<td align="left">FALSE</td>
<td align="right">0.4444444</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
</div>
</div>
<div id="mapping-from-models-to-classic-qualitative-tests" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Mapping from models to classic qualitative tests</h2>
<p>The approach we have elaborated here appears different from that described in the literature on process-tracing tests – such as <span class="citation"><a href="#ref-collier2011understanding" role="doc-biblioref">Collier</a> (<a href="#ref-collier2011understanding" role="doc-biblioref">2011</a>)</span>, <span class="citation"><a href="#ref-BennettBayes" role="doc-biblioref">Bennett</a> (<a href="#ref-BennettBayes" role="doc-biblioref">2008</a>)</span>, or <span class="citation"><a href="#ref-humphreys2015mixing" role="doc-biblioref">Humphreys and Jacobs</a> (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span> – in which one seeks specific evidence that is directly informative about causal propositions: “clues” that are arise with different probabilities if one proposition or another is true. In fact, however, the approaches are deeply connected. Specifically, we can think of causal models as providing a <em>justification</em> for the probative value that researchers assign to clues in the classic approach.</p>
<p>To see this, let’s write down the probability of observing a given clue conditional on a unit’s causal type using the <span class="math inline">\(\phi\)</span> notation from <span class="citation"><a href="#ref-humphreys2015mixing" role="doc-biblioref">Humphreys and Jacobs</a> (<a href="#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>. Here <span class="math inline">\(\phi_{jx}\)</span> refers to the probability of observing a clue in a case of type <span class="math inline">\(j\)</span> when <span class="math inline">\(X=x\)</span>. Starting with our prior distribution over the lower-level causal types (the <span class="math inline">\(\lambda\)</span>’s), we can derive, for an <span class="math inline">\(X=1\)</span> case, the probability of seeing the clue if the case is of type <span class="math inline">\(b\)</span> (positive effect) or of type <span class="math inline">\(d\)</span> (no effect, <span class="math inline">\(Y\)</span> always <span class="math inline">\(1\)</span>):</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\phi_{b1} &amp; = \frac{\lambda_{01}^{K}\lambda_{01}^{Y}}{\lambda_{01}^{K}\lambda_{01}^{Y}+\lambda_{10}^{K}\lambda_{10}^{Y}}\\ 
\phi_{d1} &amp; = \frac{\lambda_{11}^{Y}(\lambda_{01}^{K}+\lambda_{11}^{K})+\lambda_{11}^{K}\lambda_{01}^{Y}}{\lambda_{11}^{Y} + \lambda_{00}^{K}\lambda_{10}^{Y} + \lambda_{11}^{K}\lambda_{01}^{Y}}
\end{split}
\label{eqn:phisfromlambdas}
\end{equation}\]</span></p>
<p>These quantities allow for easy mapping between our prior beliefs about our causal query—as expressed in the lower-level model—and the classic process-tracing tests in <span class="citation"><a href="#ref-Van-Evera:1997" role="doc-biblioref">Van Evera</a> (<a href="#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span>. Figure <a href="pt.html#fig:phis">7.2</a> illustrates. In each panel, we manipulate a prior for one or more of the lower-level causal effects, keeping all other priors flat, and we see how probative value changes. As the curves for <span class="math inline">\(\phi_b\)</span> and <span class="math inline">\(\phi_d\)</span> diverge, probative value is increasing since there is an increasing difference between the probability of seeing the clue if <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> and the probability of seeing the clue if <span class="math inline">\(X\)</span> has no effect.</p>
<p>In the left panel, we see that as we place a lower prior probability on <span class="math inline">\(K\)</span>’s being negatively affected by <span class="math inline">\(X\)</span>,<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> seeking <span class="math inline">\(K=1\)</span> increasingly takes on the quality of a hoop test for <span class="math inline">\(X\)</span>’s having a positive effect on <span class="math inline">\(Y\)</span>. The clue, that is, increasingly becomes something we must see if <span class="math inline">\(X\)</span> positively affects <span class="math inline">\(Y\)</span>, with the clue remaining moderately probable if there is no effect. Why? The less likely we believe it is that <span class="math inline">\(K=0\)</span> was caused by <span class="math inline">\(X=1\)</span>, the less consistent the observation of <span class="math inline">\(K=0\)</span> is with <span class="math inline">\(X\)</span> having a positive causal effect on <span class="math inline">\(Y\)</span> via <span class="math inline">\(K\)</span> (since, to have such an effect, if <span class="math inline">\(X=1\)</span> and <span class="math inline">\(K=0\)</span>, would precisely have to mean that <span class="math inline">\(X=1\)</span> <em>caused</em> <span class="math inline">\(K=0\)</span>).</p>
<p>In the second graph, we simultaneously change the prior probabilities of zero effects at both stages in the sequence: of <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span> being <span class="math inline">\(1\)</span> regardless of the values of <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span>, respectively.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> We see here that, as the probabilities of zero effects jointly diminish, seeking <span class="math inline">\(K=1\)</span> increasingly becomes a smoking-gun test for a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>: the probability of seeing the clue if the case is a <span class="math inline">\(d\)</span> type diminishes. The reason is that, as zero effects at the lower level become less likely, it becomes increasingly unlikely that <span class="math inline">\(K=1\)</span> could have occurred without a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(K\)</span>, and that <span class="math inline">\(Y=1\)</span> could have occurred (given that we have seen <span class="math inline">\(K=1\)</span>) without a posiitve effect of <span class="math inline">\(K\)</span> on <span class="math inline">\(Y\)</span>.</p>
<!-- This example also helps clarify the kind of theoretical knowledge required for drawing inferences from clues. As we have emphasized, the structural equations comprising a causal model can be fully non-parametric. As the example illustrates, $\theta_Y$ can be a type variable that determines different the equation for an endogenous variable in a causal model can  can take the form of beliefs about the proportions of  -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:phis"></span>
<img src="ii_files/figure-html/phis-1.png" alt="The probability of observing $K$ given causal type for different beliefs on lower-level causal effects. In the left figure, priors on all lower-level causal effects are flat except for the probability that $X$ has a negative effect on $K$. If we believe that it is unlikely that $X$ has a negative effect on $K$, $K$ becomes a `hoop' test for the proposition that a case is of type $b$. The righthand figure considers simultaneous changes in $\lambda_{11}^K$ and  $\lambda_{11}^Y$---the probabilities that $K=1$ regardless of $X$, and that $Y=1$  regardless of $K$, with flat distributions on all other lower-level effects. With $\lambda_{11}^K$, $\lambda_{11}^Y$ both close to 0, $K$ becomes a 'smoking gun' test for the proposition that $X$ has a positive effect on $Y$ ($b$ type)." width=".85\textwidth" />
<p class="caption">
Figure 7.2: The probability of observing <span class="math inline">\(K\)</span> given causal type for different beliefs on lower-level causal effects. In the left figure, priors on all lower-level causal effects are flat except for the probability that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(K\)</span>. If we believe that it is unlikely that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(K\)</span>, <span class="math inline">\(K\)</span> becomes a `hoop’ test for the proposition that a case is of type <span class="math inline">\(b\)</span>. The righthand figure considers simultaneous changes in <span class="math inline">\(\lambda_{11}^K\)</span> and <span class="math inline">\(\lambda_{11}^Y\)</span>—the probabilities that <span class="math inline">\(K=1\)</span> regardless of <span class="math inline">\(X\)</span>, and that <span class="math inline">\(Y=1\)</span> regardless of <span class="math inline">\(K\)</span>, with flat distributions on all other lower-level effects. With <span class="math inline">\(\lambda_{11}^K\)</span>, <span class="math inline">\(\lambda_{11}^Y\)</span> both close to 0, <span class="math inline">\(K\)</span> becomes a ‘smoking gun’ test for the proposition that <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (<span class="math inline">\(b\)</span> type).
</p>
</div>
</div>
<div id="principles-of-learning" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Principles of learning</h2>
<p>While <code>CausalQueries</code> can implement process-tracing inference for us, it is helpful for researchers to be able to reason their way through what is happening “under the hood.” We provide here some core principles and intuitions for thinking through the features of models and queries that influence whether and how much we can learn from within-case observations.</p>
<div id="a-dag-alone-does-not-get-us-probative-value" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> A DAG alone does not get us probative value</h3>
<p>Suppose that we start with the belief that any effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> must run through <span class="math inline">\(M\)</span>, and that there is no confounding at any stage. This implies the simple <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. Suppose, further, that we have no prior knowledge about the distribution of nodal types and thus posit flat priors over <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span>. Now we would like to conduct process tracing and observe <span class="math inline">\(M\)</span> to tell us about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. In an <span class="math inline">\(X=Y=1\)</span> case, for instance, is this model sufficient to allow the observation of <span class="math inline">\(M\)</span> to provide leverage on whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>?</p>
<p>It is not. We can learn nothing from about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> from <span class="math inline">\(M\)</span>. Observing a process is <em>uninformative</em> if all that we know is the structure of relations of conditional independence.</p>
<p>To see why at an intuitive level, consider that there are two causal types that will satisfy the query, <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Those are the types <span class="math inline">\(\theta^X_1 \theta^M_{01} \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1 \theta^M_{10} \theta^Y_{10}\)</span>: either linked positive effects or linked negative effects could generate an overall positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Moreover, with flat priors over nodal types, these causal types are equally likely. Now, think about what we would conclude if we collected process data and observed <span class="math inline">\(M=1\)</span> in the <span class="math inline">\(X=Y=1\)</span> case. This observation would rule out one way in which the query could be satisfied: the causal type with linked negative effects. And what if we observed, instead, <span class="math inline">\(M=0\)</span>? This would rule out the other way in which the query could be satisfued: linked positive effects. But since each of these causal types started out with equal weights in our priors, there can be no updating from eliminating one or the other.</p>
<p>To put the point even more precisely, learning from observing a node requires informative priors about causal effects involving <em>that node.</em> For instance, in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, where we plan to observe <span class="math inline">\(M\)</span>, it would not be sufficient to have an informative prior about the <span class="math inline">\(X \rightarrow Y\)</span> relationship. Such a prior would be cast at the wrong level. Rather, we need an informative prior about the <span class="math inline">\(X \rightarrow M\)</span> or <span class="math inline">\(M \rightarrow Y\)</span> link in order to learn from <span class="math inline">\(M\)</span>.</p>
<p>At the same time, what we need at the level of priors depends on the query. Suppose that we start with the model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, and formulate the following query: does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> that runs through a chain of positive effects via <span class="math inline">\(M\)</span>? We can learn about this query without any informative priors over nodal types because of the way in which the query itself restricts the type space. Since the query is not satisfied if negative mediating effects are operating, we will update to probability 0 on the query for any observation that violates <span class="math inline">\(X=M=Y\)</span>, and we will update upwards on the query for any observation of <span class="math inline">\(X=M=Y\)</span>.</p>
</div>
<div id="learning-requires-uncertainty" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Learning requires uncertainty</h3>
<p>While case-level inference from within-case evidence requires informative priors about nodal types, there is also such a thing as <em>too much</em> information – or, put differently, as insufficient uncertainty about causal relations. Suppose, for instance, that our beliefs are such that <span class="math inline">\(X\)</span> always has a positive effect on <span class="math inline">\(M\)</span> in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. Consider, further, that we already know that <span class="math inline">\(X=1\)</span> in a case. In that situation, nothing can be learned by observing <span class="math inline">\(M\)</span> since the prior observation of <span class="math inline">\(X\)</span> already reveals <span class="math inline">\(M\)</span>’s value given our prior beliefs.</p>
<p>To take a less extreme example, suppose that our priors put a <em>very high probability</em> on <span class="math inline">\(X\)</span>’s having a positive effect on <span class="math inline">\(M\)</span> and that, again, we already know that <span class="math inline">\(X=1\)</span> in a case. In that situation, we should <em>expect</em> to learn very little from observing <span class="math inline">\(M\)</span> since we believe that we are very likely to see <span class="math inline">\(M=1\)</span>, given that we already know <span class="math inline">\(X=1\)</span>. It is true that our beliefs will shift <em>if</em> we look for <span class="math inline">\(M\)</span> and find the unexpected value of <span class="math inline">\(M=0\)</span>. But because that data-realization is highly unlikely, we should expect the learning from observing <span class="math inline">\(M\)</span> to be minimal.</p>
<p>We address the concept of expected learning more systematically in Chapters <a href="clue.html#clue">12</a> and <a href="caseselection.html#caseselection">13</a>, but our general point here is that, we will learn more from process-tracing evidence, to the extent that (a) we know enough about causal relations in a domain to know how to make causal sense of the evidence we find, but (b) we do not know so much that that evidence can be largely predicted from what we have already observed.</p>
</div>
<div id="multiple-ways-for-queries-to-be-satisfied" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Multiple ways for queries to be satisfied</h3>
<p>As we have seen, there will often be multiple causal types consistent with a given query. Back to our <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, for instance, <span class="math inline">\(X=1\)</span> could cause <span class="math inline">\(Y=1\)</span> through either two intermediate negative effects or two intermediate positive effects. Similarly, if we have a model in which <span class="math inline">\(X\)</span> can affect <span class="math inline">\(Y\)</span> through <span class="math inline">\(M\)</span> or through <span class="math inline">\(N\)</span> (<span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow N \leftarrow X\)</span>), the same query could be satisfied via effects operating along either pathway. There are three key points to make about learning about queries that can be satisfied via multiple causal types.</p>
<p>First, evidence for or against one of those causal types – that is, for or against one of the ways in which the query could be true – is evidence for or against (respectively) the query as a whole. In the two-path model, for instance, if we observe an <span class="math inline">\(M\)</span> data pattern that is inconsistent with an an effect along this pathway, then this is also evidence against an overall <span class="math inline">\(X \rightarrow Y\)</span> effect — even though that effect <em>could</em> operate via <span class="math inline">\(N\)</span>. In general, finding evidence against one way the effect can happen reduces our confidence in the effect happening at all.</p>
<p>Second, the more ways there are for a query to be satisfied, the less we learn about the query by learning about only one of those ways. Imagine a model in which <span class="math inline">\(X\)</span> can affect <span class="math inline">\(Y\)</span> only through <span class="math inline">\(M\)</span>. Then compare that to a model in which <span class="math inline">\(X\)</span> can affect <span class="math inline">\(Y\)</span> through four different, equally probably (in our priors) paths: via <span class="math inline">\(M\)</span>, <span class="math inline">\(N\)</span>, <span class="math inline">\(P\)</span>, or <span class="math inline">\(Q\)</span>. In general, <span class="math inline">\(M\)</span> by itself will be much more informative about the <span class="math inline">\(X \rightarrow Y\)</span> effect in the first model than in the second since, in the second model, observing <span class="math inline">\(M\)</span> gives us leverage only on the causal types relevant to a small share of the ways in which the effect of interest could emerge.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>Third, evidence against the <em>likelier</em> way a query could be satisfied constitutes stronger evidence against the query than does evidence against an unlikely way. For instance, if we started out thinking that an effect via <span class="math inline">\(M\)</span> was more likely than an effect via <span class="math inline">\(N\)</span>, then evidence against the effect via <span class="math inline">\(M\)</span> will have a bigger impact on our beliefs about the overall <span class="math inline">\(X \rightarrow Y\)</span> effect. Note that this is a special case of a point that we make in Chapter <a href="bayeschapter.html#bayeschapter">5</a>: we update more strongly in favor of the hypothesis for which the evidence is least damaging to the most-likely ways in which the hypothesis could be true.</p>
</div>
<div id="beware-of-highly-unlikely-queries" class="section level3" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Beware of highly unlikely queries</h3>
<p>It is difficult to get empirical leverage on very unlikely queries, and queries may be unlikelier than they appear.</p>
<p>To illustrate, suppose that we start with the two-path model, <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow X\)</span>, and formulate the following query: does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> that runs through a chain of positive effects via <span class="math inline">\(M\)</span>? And suppose that we begin with flat priors over all nodal types. Intuitively, this seems like exactly the kind of question for which an observation of <span class="math inline">\(M\)</span> is the perfect empirical strategy. And that intuition is, in a sense, correct: we can indeed learn about the query by observing <span class="math inline">\(M\)</span>. Seeing <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=Y=1\)</span> case, for instance, would be evidence consistent with the query while seeing <span class="math inline">\(M=0\)</span> in that same case would be inconsistent with the query.</p>
<p>Yet, we will only learn very modestly about the query from this observation. The reason is that the query itself has a very low prior probability. It may, in fact, not be obvious at first glance just how unlikely our query is in our priors. At first glance, it looks as though all we are asking is whether there exist positive effects running through one of the two causal paths in the model. However, consider the joint nodal-type probabilities implied by the query. First, the query requires <span class="math inline">\(X\)</span> to have a positive effect on <span class="math inline">\(M\)</span>, to which our priors give only a <span class="math inline">\(25\%\)</span> chance In addition, the query puts a very narrow constraint on <span class="math inline">\(Y\)</span>’s possible nodal types: to satisfy the query, <span class="math inline">\(Y\)</span> must have a nodal type in which <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> does not change, and in which <span class="math inline">\(X\)</span> does not have a positive effect on <span class="math inline">\(Y\)</span> unless <span class="math inline">\(M\)</span> changes from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>. This pair of conditions is met by only 2 of <span class="math inline">\(Y\)</span>’s 16 nodal types, implying a <span class="math inline">\(12.5\%\)</span> chance. The prior on the query itself is, thus, <span class="math inline">\(0.25 \times 0.125 = 0.03125\)</span>. Thus, while observing <span class="math inline">\(M=0\)</span> takes the probability of the query down to <span class="math inline">\(0 \%\)</span>, we started out very close to 0%! Observing <span class="math inline">\(M=1\)</span> results in only a small uptick, to about <span class="math inline">\(6\%\)</span> because there remain many type combinations consistent with M=1 but that do not fit through the needle-eye of this query.</p>
<p>In sum, what seems intuitively like a simple question will sometimes be a very unlikely query. What makes this query so unlikely is the interplay between the query itself and the model. The model allows for a <em>wide</em> range of causal combinations (e.g., <span class="math inline">\(Y\)</span>’s 16 nodal types), spreading prior weight thinly across those many possibilities, while the query zeroes in on a couple of <em>particular</em> combinations that, in our priors, each have very low probability.</p>
</div>
<div id="population-level-uncertainty-does-not-alter-case-level-causal-inference" class="section level3" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Population-level uncertainty does not alter case-level causal inference</h3>
<p>In the procedure described for process tracing in this chapter (and different to what we introduce in Chapter 8) we assume that <span class="math inline">\(\lambda\)</span> is known and we do not place uncertainty around it.</p>
<p>This might appear somewhat heroic, but in fact for single case inference it is without loss of generality. The expected inferences we would make for any query accounting for priors is the same as the inferences we if we use the expectation only.</p>
<p>To see this, let <span class="math inline">\(\pi_j\)</span> denote the probability of observing causal type <span class="math inline">\(j\)</span> and <span class="math inline">\(p(D)\)</span> te probability of observing data realization <span class="math inline">\(D\)</span>. Say that <span class="math inline">\(j \in D\)</span> if type <span class="math inline">\(j\)</span> produces data type <span class="math inline">\(D\)</span> and say <span class="math inline">\(j \in E\)</span> if causal type <span class="math inline">\(j\)</span> is an element of the query set of interest.
The posterior on a query <span class="math inline">\(E\)</span> given data <span class="math inline">\(D\)</span> given prior over <span class="math inline">\(\pi\)</span>, <span class="math inline">\(p(\pi)\)</span> is:</p>
<p><span class="math display">\[\Pr(E | D) = \int_\pi  \frac{\sum_{j \in E \cap D}\pi_j}{\sum_{j \in D}\pi_j} f(\pi)d\pi\]</span></p>
<p>However, since for any <span class="math inline">\(\pi\)</span>, <span class="math inline">\(\sum_{j \in D}\pi_j = p(D)\)</span> we have:</p>
<p><span class="math display">\[\Pr(E | D) = \int_\pi  \sum_{j \in E \cap D}\pi_j f(\pi)d\pi/p(D) = \sum_{j \in  E \cap D} \overline{\pi}_j/p(D)\]</span>
For instance in an <span class="math inline">\(X \rightarrow Y\)</span> model, if we observe <span class="math inline">\(X=Y=1\)</span> then <span class="math inline">\(D\)</span> consists of causal types <span class="math inline">\(D={(\theta^X_1, \theta^Y_{01}), (\theta^X_1, \theta^Y_{11})})\)</span> and the query set for “<span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>” consists of <span class="math inline">\(E={(\theta^X_1, \theta^Y_{01}), (\theta^X_0, \theta^Y_{01})})\)</span>. Let <span class="math inline">\(\pi_1\)</span>, <span class="math inline">\(\pi_2\)</span> denote the priors on the two elements of <span class="math inline">\(D\)</span>. We then have:</p>
<p><span class="math display">\[\Pr(E | D) =  \frac{\pi_1}{\pi_1 + \pi_2}\]</span></p>
</div>
<div id="probative-value-requires-d-connection" class="section level3" number="7.3.6">
<h3><span class="header-section-number">7.3.6</span> Probative value requires <span class="math inline">\(d-\)</span>connection</h3>
<!-- Rules for inferring information about one variable from another are th stuff of graphoids  [@pearl1985graphoids] see also [@geiger1987non] and [@pearl1987logic]...  -->
<p>As we have argued, causal queries can be expressed as collections of combinations of nodal types (i.e., as collections of causal types) in a causal model. A nodal type is itself represented as an unobservable node in a model — as a <span class="math inline">\(\theta^j\)</span> pointing into node <span class="math inline">\(j\)</span>. Thus, causal inference in this framework is <em>the use of observable nodes on a causal graph to assess the value of one or more unobserved nodes on a causal graph.</em> Placing our queries on the graph together with the observable nodes has the important advantage of allowing us to graphically identify the possibilities for learning about these queries: that is, to say which observable nodes are potentially informative about a given query.</p>
<!-- Case-level causal effects and causal paths can be defined in terms of response-type nodes; average effects and notable causes in terms of population-level parameter nodes (e.g., $\pi$ or $\lambda$ terms); and questions about actual causes in terms of exogenous conditions that yield particular endogenous values (conditioning on which makes some variable a counterfactual cause).  -->
<!-- We thus define   -->
<p>To think through the logic of potential probative value, it is useful to distinguish among three different features of the world, as represented in our causal model: there are the things we want to learn about; the things we have already observed; and the things we could observe. As notation going forward, we let:</p>
<ul>
<li><span class="math inline">\(\mathcal Q\)</span> denote the collection of <span class="math inline">\(\theta^j\)</span> nodes that define our <em>query</em>; <span class="math inline">\(\mathcal Q\)</span> cannot be directly observed so that its values must be inferred;</li>
<li><span class="math inline">\(\mathcal W\)</span> denote a set of previously observed nodes in the causal model; and</li>
<li><span class="math inline">\(\mathcal K\)</span> denote a set of additional variables—clues—that we have not yet observed but could observe.</li>
</ul>
<p>Now suppose that we seek to design a research project to investigate a causal question. How should the study be designed? Given that there are some features of the world that we have already observed, which additional clues should we seek to collect to shed new light on our question? In terms of the above notation, what we need to figure out is whether a given <span class="math inline">\(\mathcal K\)</span> might be informative about—might provide additional leverage on—<span class="math inline">\(\mathcal Q\)</span> given the prior observation of <span class="math inline">\(\mathcal W\)</span>.</p>
<p>To ask whether one variable (or set of variables) is informative about another is to ask whether the two (sets of) variables are, on average, <em>correlated</em> with one another, given whatever we already know. Likewise, if two variables’ distributions are fully <em>independent</em> of one another (conditional on what else we have observed), then knowing the value of one variable can provide no new information about the value of the other.</p>
<p>Thus, asking whether a set of clues, <span class="math inline">\(\mathcal K\)</span>, is informative about <span class="math inline">\(\mathcal Q\)</span> given the prior observation of <span class="math inline">\(\mathcal W\)</span>, is equivalent to asking whether <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are conditionally independent given <span class="math inline">\(\mathcal W\)</span>. That is, <span class="math inline">\(\mathcal K\)</span> can be informative about <span class="math inline">\(\mathcal Q\)</span> given <span class="math inline">\(\mathcal W\)</span> only if <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <em>not</em> conditionally independent of one another given <span class="math inline">\(\mathcal W\)</span>.</p>
<p>As our discussion of conditional independence in Chapter <a href="models.html#models">2</a> implies, as long as we have built <span class="math inline">\(\mathcal Q\)</span>, <span class="math inline">\(\mathcal K\)</span>, and <span class="math inline">\(\mathcal W\)</span> into our causal model of the phenomenon of interest, we can answer this kind of question by inspecting the structure of the model’s DAG. In particular, what we need to go looking for are relationships of <em><span class="math inline">\(d\)</span>-separation</em>. The following proposition, with only the names of the variable sets altered, is from <span class="citation"><a href="#ref-pearl2009causality" role="doc-biblioref">Pearl</a> (<a href="#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span> (Proposition 1.2.4):</p>
<p><strong>Proposition 1:</strong> If sets <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span> in a DAG, <span class="math inline">\(\mathcal G\)</span>, then <span class="math inline">\(\mathcal Q\)</span> is independent of <span class="math inline">\(\mathcal K\)</span> conditional on <span class="math inline">\(\mathcal W\)</span> in every distribution compatible with <span class="math inline">\(\mathcal G\)</span>. Conversely, if <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are <em>not</em> <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span> in DAG <span class="math inline">\(\mathcal G\)</span>, then <span class="math inline">\(\mathcal Q\)</span> and <span class="math inline">\(\mathcal K\)</span> are dependent conditional on <span class="math inline">\(\mathcal W\)</span> in at least one distribution compatible with DAG <span class="math inline">\(\mathcal G\)</span>.</p>
<p>We begin with a causal graph and a set of nodes on the graph (<span class="math inline">\(W\)</span>) that we have already observed. Given what we have already observed, <em>a collection of clue nodes, <span class="math inline">\(\mathcal K\)</span>, will be uninformative about the query nodes, <span class="math inline">\(\mathcal Q\)</span>, if <span class="math inline">\(\mathcal K\)</span> is <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\mathcal Q\)</span> by <span class="math inline">\(\mathcal W\)</span> on the graph.</em> (Equivalently, <span class="math inline">\(\mathcal K\)</span>, will be uninformative about <span class="math inline">\(\mathcal Q\)</span>, given that we have already observed <span class="math inline">\(\mathcal W\)</span>, if <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are conditionally independent given <span class="math inline">\(\mathcal W\)</span>.) When <span class="math inline">\(\mathcal W\)</span> <span class="math inline">\(d\)</span>-separates <span class="math inline">\(\mathcal K\)</span> from <span class="math inline">\(\mathcal Q\)</span>, this means that what we have already observed already captures all information that the clues might yield about our query. On the other hand, if <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <span class="math inline">\(d\)</span>-connected (i.e., not <span class="math inline">\(d\)</span>-separated) by <span class="math inline">\(W\)</span>, then <span class="math inline">\(K\)</span> is <em>possibly</em> informative about <span class="math inline">\(Q\)</span>.<span class="math inline">\(K\)</span> is not <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\mathcal Q\)</span> by <span class="math inline">\(\mathcal W\)</span>.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> Note, moreover, that under quite general conditions (referred to in the literature as the <em>faithfulness</em> of a probability distribution) then there are at least <em>some</em> values of <span class="math inline">\(\mathcal W\)</span> for which <span class="math inline">\(\mathcal K\)</span> <em>will</em> be informative about <span class="math inline">\(\mathcal Q\)</span>.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<!-- ^[In Pearl's terminonology, the graph may *represent* the probability distribution but not be *faithful* to it.] -->
<!-- This can be put another way. An $I$-map of $M$ is a model with no extra independencies; a $D$-map is a model that contains all of $M$ with,  possibly aditional independencies; a *perfect* map is a model with the same set of dependencies. Given an independency model $M$, a DAG, $G$, may be an $I$-map of $M$ in the sense that whenever $D$ separates $K$ from $Q$ then $I(K,D,Q)_M$, yet there may still be indepenencies in $M$ not captured by $G$; that is, it may also be htat $I(K,D,Q)_M$ but not $I(K,D,Q)_G$. Pearl refers to such cases as instances of a violation of *stability*, though in simple graphs with discrete variables such violations may be plausible.  -->
<!-- In the example given by Pearl with two matching pennies, $X_1$ and $X_2$ and $Y$ is 1 if the pennies match, $X_1$ adn $X_2$ are probabilisitcally independent of $Y$, yet $Y$ depends on both of them.  -->
<!-- The problem is that $d$-separation satisfies composition, that is, if $I(X_1, D, Q)$ and $I(X_2, D, Q)$ then $I(X_1X_2, D, Q)$; but since we cannot have $I(X_1X_2, D, Q)$ then we cannot have   $I(X_1, D, Q)$ and $I(X_2, D, Q)$ either (see also [@bouckaert1994conditional]). -->
<!-- Note that this example depends on infomration about the probability distribution over $V$, that is, the functional equations, and cannot be inferred from the structure of $S$ alone.   -->
<!-- [Note for us: We seek a  related proposition holds however using $d-separation$ on partially discovered submodels.] -->
<p>Let us examine Proposition 1 in practice. We begin with the simplest case possible, and then move on to more complex models.</p>
<p>The very simplest probabilistic causal graph, shown in Figure , has <span class="math inline">\(X\)</span> influencing <span class="math inline">\(Y\)</span>, with <span class="math inline">\(X\)</span> determined by a coin flip. If we want to know <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>, this query is defined solely in terms of <span class="math inline">\(Y\)</span>’s nodal type, <span class="math inline">\(\theta^Y\)</span>. To help us conceptualize the more general point about informativeness for queries, we relabel <span class="math inline">\(\theta^Y\)</span> as <span class="math inline">\(Q\)</span> to emphasize the fact that this node represents our query.</p>
<!-- pointing into $Y$, as shown in . Here, $Q^Y$ determines the value of $Y$ that will be generated by $X$. Asking about the causal effect of $X$ in a case thus means learning the value of $Q^Y$ in that case. As will be recalled, in a binary setup with one causal variable, a response-type variable can take on one of four values, $q^Y_{00}$, $q^Y_{10}$, $q^Y_{01}$ and $q^Y_{11}$,^[As a reminder, we read $q^Y_{ij}$ (when $X$ is binary) as meaning that $Y$ will take on value $i$ when $X=0$ and value $j$ when $X=1$.] corresponding to the four possible causal types in this setting. -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sepsimple"></span>
<img src="ii_files/figure-html/sepsimple-1.png" alt="\label{fig:d-sepsimple} A simple causal setup in which the effect of $X$ on $Y$ in a given case depends on the case's response type for $Y$." width=".5\textwidth" />
<p class="caption">
Figure 7.3:  A simple causal setup in which the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a given case depends on the case’s response type for <span class="math inline">\(Y\)</span>.
</p>
</div>
<p>Let us assume that we have observed nothing yet in this case and then ask what clue(s) might be informative about <span class="math inline">\(Q\)</span>, the node of interest. The other two nodes in the graph are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>: these are thus the possible clues that we might go looking for in our effort to learn about <span class="math inline">\(Q\)</span> (i.e., they are the possible members of <span class="math inline">\(\mathcal K\)</span>).</p>
<p>First, can we learn about <span class="math inline">\(Q\)</span> by observing <span class="math inline">\(X\)</span>? We can answer this question by asking whether <span class="math inline">\(X\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> on the graph given what we have already observed (which is nothing). We can see visually that there is no active path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Q\)</span>: the only path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> is blocked by colliding arrow heads. Thus, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-separated, meaning that <span class="math inline">\(X\)</span> will not be informative about <span class="math inline">\(Q\)</span>: observing the value that a causal variable takes on in a case—having seen nothing else in the case—tells us nothing whatsoever about that variable’s effect on the outcome. If we want to know whether a case is of a type in which the presence of natural resources would cause civil war, for instance, observing only that the case has natural resources does not help answer the question.</p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- In the case where we observe only $X$, the posterior on $Q^Y$ is: -->
<!-- \begin{eqnarray*} -->
<!-- P(Q^Y=q^Y | X=x) &=& \frac{\sum_{j=0}^1p(X=x)P(Q^Y=q^Y)P(Y=j|X=x, Q^Y=q^Y)}{\sum_{q^{Y'}}\sum_{j=0}^1p(X=x)P(Q^Y=q^{Y'})P(Y=j|X=x, Q^Y=q^{Y'})}\\ -->
<!-- &=&\frac{P(Q^Y=q^Y)}{\sum_{q^{Y'}}P(Q^Y=q^{Y'})} -->
<!-- \end{eqnarray*} -->
<!-- which is simply the prior on $Q^Y$. Thus, nothing is learned about $Q^Y$ from observing $X$ only.]  -->
<!-- <!-- &=& \frac{p(Q=q)\sum_{j=0}^1p(Y=j|X=x, Q=q)}{\sum_{q'}p(Q=q')\sum_{j=0}^1p(Y=j|X=x, Q=q')}\\ -->
<p>–&gt;
<!-- **...ENDING HERE** --></p>
<p>What, then, if we instead were to observe only <span class="math inline">\(Y\)</span>? Is <span class="math inline">\(Y\)</span> <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> given what we have already observed (which, again, is nothing)? It is: the arrow from <span class="math inline">\(Q\)</span> to <span class="math inline">\(Y\)</span> is an active path. Observing only the <em>outcome</em> in a case does tell us something about causal effects. Returning to the natural resources and civil war example, observing only that a country has had a civil is informative about the case’s causal type (the value of <span class="math inline">\(Q\)</span>). In particular, it rules out the possibility that this is a case in which nothing could cause a civil war: that is, it excludes <span class="math inline">\(\theta^Y_{00}\)</span> (i.e., <span class="math inline">\(c\)</span>-type) as a possible value of <span class="math inline">\(Q\)</span>.</p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- In the case where we observe $Y$ only we have: -->
<!-- $$P(Q=q | Y=y) = \frac{\sum_{j=0}^1p(X=j)P(Q=q)P(Y=y|X=j, Q=q)}{\sum_{q'}\sum_{j=0}^1p(X=j)P(Q=q')P(Y=y|X=j, Q=q')}$$ -->
<!-- Here terms involving $Y$ and $Q$ cannot be separated, so the same kind of reduction is not possible. This implies scope for learning about $Q$ from $Y$.  For instance, if  we have $P(Q=j) = 1/4$ for type $j \in \{a,b,c,d\}$  and $P(X=j) = \frac{1}{2}$, then we have $P(Q=a | Y=1)=P(Q=b | Y=1) =\frac{1}{4}$, $P(Q=c | Y=1)=0$ and $P(Q=d | Y=1)=1$. -->
<!-- **...ENDING HERE** -->
<p>Suppose now, having observed <span class="math inline">\(Y\)</span>, that we were to consider also observing <span class="math inline">\(X\)</span>. Would we learn anything further about <span class="math inline">\(Q\)</span> from doing so? We have already seen that observing <span class="math inline">\(X\)</span> alone yields no information about <span class="math inline">\(Q\)</span> because the two nodes are unconditionally <span class="math inline">\(d\)</span>-separated, the path between them blocked by the colliding arrowheads at <span class="math inline">\(Y\)</span>. However, as we have seen, observing a collider variable (or one of its descendants) <em>unblocks</em> the flow of information, generating relations of conditional dependence across the colliding arrowheads. Here, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-connected by <span class="math inline">\(Y\)</span>: thus, if we have <em>already</em> observed <span class="math inline">\(Y\)</span>, then observing <span class="math inline">\(X\)</span> does confer additional information about <span class="math inline">\(Q\)</span>. Knowing only that a country has natural resources tells us nothing about those resources’ effect on civil war in that country. But if we already know that the country has a civil war, then learning that the country has natural resources helps narrow down the case’s possible response types. Having already used the observation of <span class="math inline">\(Y=1\)</span> to rule out the possibility of <span class="math inline">\(\theta^Y_{00}\)</span>, observing <span class="math inline">\(X=1\)</span> <em>together with</em> <span class="math inline">\(Y=1\)</span> allows us to additionally rule out the possibility that natural resources <em>prevent</em> civil war, i.e., that <span class="math inline">\(Q=\theta^Y_{01}\)</span>.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<!-- **LONG FOOTNOTE STARTING HERE....** -->
<!-- Where we observe both $Y$ and $X$,  we have: -->
<!-- $$P(Q=q | Y=y, X=x) = \frac{P(X=x)P(Q=q)P(Y=y|X=x, Q=q)}{\sum_{q'}P(X=x)P(Q=q')P(Y=y|X=x, Q=q')}$$ -->
<!-- which does not allow separation either of  $Q$ and $X$ or of $Q$ and $Y$. Thus, there is again learning from $Y$ and, given $Y$, there is *also* learning from $X$. Put differently, we have $P(Q|Y,X) \neq P(Q|Y)$.  -->
<!-- **...ENDING HERE** -->
<p>Finally, what if we observe <span class="math inline">\(X\)</span> first and are considering whether to seek information about <span class="math inline">\(Y\)</span>? Would doing so be informative? <span class="math inline">\(X\)</span> does not <span class="math inline">\(d-\)</span>separate <span class="math inline">\(Q\)</span> from <span class="math inline">\(Y\)</span>; thus, observing <span class="math inline">\(Y\)</span> will be informative about <span class="math inline">\(Q\)</span>. In fact, observing <span class="math inline">\(Y\)</span> if we have already seen <span class="math inline">\(X\)</span> is <em>more</em> informative than observing <span class="math inline">\(Y\)</span> alone. The reasoning follows the logic of collision discussed just above. If we observe <span class="math inline">\(Y\)</span> having already seen <span class="math inline">\(X\)</span>, not only do we reap the information about <span class="math inline">\(Q\)</span> provided by <span class="math inline">\(Y\)</span>’s correlation with <span class="math inline">\(Q\)</span>; we simultaneously open up the path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span>, learning additionally from the conditional dependence between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> given <span class="math inline">\(Y\)</span>.</p>
<p>We put Proposition 1 to work in a slightly more complex set of models in Figure . Here we investigate the informativeness of a clue that is neither <span class="math inline">\(X\)</span> nor <span class="math inline">\(Y\)</span>. Each graph in Figure  has four variables: <span class="math inline">\(X\)</span>; <span class="math inline">\(Y\)</span>; a possible clue, <span class="math inline">\(K\)</span>; and a node, <span class="math inline">\(Q\)</span>, representing the query (which we might also naturally think of as <span class="math inline">\(\theta^Y\)</span>). We draw all 34 possible graphs with variables <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(Q\)</span> for causal models in which (a) all variables are connected to at least one other variable, (b) <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> either directly or indirectly, and (c) <span class="math inline">\(Q\)</span> is a direct cause of <span class="math inline">\(Y\)</span> but is not caused by any other variable in the model and is thus exogenous. The title of each panel reports <span class="math inline">\(K\)</span>’s conditional informativeness using principles of <span class="math inline">\(d\)</span>-separation: it tells us when <span class="math inline">\(K\)</span> is possibly informative about <span class="math inline">\(Q\)</span> depending on whether <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, both or none are observed.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<!-- Above footnote: do we want to say "faithful" rather than stable, as we do earlier? -->
<div class="figure"><span style="display:block;" id="fig:34graphs"></span>
<img src="ii_files/figure-html/34graphs-1.png" alt="\label{fig:34graphs} All connected directed acyclic graphs over $X,Y,K,Q$, in which $Q$ is an exogenous variable that directly causes $Y$, and $X$ is a direct or indirect cause of $Y$. The title of each graph indicates the conditions under which $K$ can be informative about (i.e., is not $d$-separated from) $Q$, given the prior observation of $X$, $Y$, both, or neither (...)." width="1056" />
<p class="caption">
Figure 7.4:  All connected directed acyclic graphs over <span class="math inline">\(X,Y,K,Q\)</span>, in which <span class="math inline">\(Q\)</span> is an exogenous variable that directly causes <span class="math inline">\(Y\)</span>, and <span class="math inline">\(X\)</span> is a direct or indirect cause of <span class="math inline">\(Y\)</span>. The title of each graph indicates the conditions under which <span class="math inline">\(K\)</span> can be informative about (i.e., is not <span class="math inline">\(d\)</span>-separated from) <span class="math inline">\(Q\)</span>, given the prior observation of <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, both, or neither (…).
</p>
</div>
<p>The results show us not just what kinds of variables can be informative about a case’s response-type but also what combinations of observations yield leverage on case-level causal effects. A number of features of the graphs are worth highlighting:</p>
<ul>
<li><p><strong>Clues at many stages.</strong> Process tracing has focused a great deal on observations that lie “along the path” between suspected causes and outcomes. What we see in Figure , however, is that observations at many different locations in a causal model can be informative about causal effects. We see here that <span class="math inline">\(K\)</span> can be informative when it is pre-treatment (causally prior to <span class="math inline">\(X\)</span>—e.g. panel (3)), post-treatment but pre-outcome (that is, “between” <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as, e.g., in panel (20)), an auxiliary effect of <span class="math inline">\(X\)</span> that itself has no effect on <span class="math inline">\(Y\)</span> (e.g., in panel (19)), post-outcome (after <span class="math inline">\(Y\)</span>—e.g., in panel (15)), or a joint effect of both the suspected cause and the outcome (e.g., panel (31)).</p></li>
<li><p><strong>Mediator Clues</strong>. While clues that lie in between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> may be informative, they can only be informative under certain conditions. For instance, when a clue serves <em>only</em> as a mediator in our model (i.e., its only linkages are being caused by <span class="math inline">\(X\)</span> and being affected by <span class="math inline">\(Y\)</span>) and <span class="math inline">\(Q\)</span> only affects <span class="math inline">\(Y\)</span>, as in panels (20) and (21), the clue is only informative about <span class="math inline">\(Q\)</span> if we have also observed the outcome, <span class="math inline">\(Y\)</span>. Of course, this condition may commonly be met—qualitative researchers usually engage in retrospective research and learn the outcome of the cases they are studying early on—but it is nonetheless worth noting why it matters: in this setup, <span class="math inline">\(K\)</span> is unconditionally <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(Q\)</span> by the collision at <span class="math inline">\(Y\)</span>; it is only by observing <span class="math inline">\(Y\)</span> (the collider) that the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> becomes unblocked. (As we saw above, the very same is true for observing <span class="math inline">\(X\)</span>; it is only when we know <span class="math inline">\(Y\)</span> that <span class="math inline">\(X\)</span> is informative about <span class="math inline">\(Q\)</span>.)</p></li>
</ul>
<p>In short, observations along causal paths are more helpful in identifying causal effects to the extent that we have measured the outcome. Importantly, this is not the same as saying that mediator clues are <em>only</em> informative about causal effects where we have observed the outcome. Observing <span class="math inline">\(Y\)</span> is necessary for the mediator to be informative about a <span class="math inline">\(Q\)</span> term that is connected only to <span class="math inline">\(Y\)</span>. Observing a mediator without the outcome, however, could still be informative about the overall effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> by providing leverage on how the mediator responds to <span class="math inline">\(X\)</span>, which is itself informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> via the mediator.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> Moreover, observing the mediator could be informative without the observation of <span class="math inline">\(Y\)</span> if, for instance, <span class="math inline">\(Q\)</span> also points into <span class="math inline">\(K\)</span> itself or into a cause of <span class="math inline">\(K\)</span>. As we discuss below, the clue then is informative as a “symptom” of the case’s response type, generating learning that does not hinge on observing the outcome.</p>
<ul>
<li><strong>Symptoms as clues.</strong> Some clues may themselves be affected by <span class="math inline">\(Q\)</span>: that is to say, they may be symptoms of the same conditions that determine causal effects in a case. For instance, in our illustrative model involving government survival, government sensitivity functions as a response-type variable for the effect of a free press (<span class="math inline">\(X\)</span>) on government removal (<span class="math inline">\(Y\)</span>): a free press only generates government removal when the government is non-sensitive to public opinion. Sensitivity to public opinion thus represents our query variable, <span class="math inline">\(Q\)</span>, if we seek to learn whether a free press causes government removal in a case. While it may not be possible to observe or otherwise measure the government’s sensitivity, there may be <em>consequences</em> of government sensitivity that are observable: for instance, whether government officials regularly consult with civil-society actors on policy issues. While consultations would not be part of the causal chain generating the free press’s effect, observing consultations (or the lack of them) would be informative about that effect because consultations are a symptom of the same conditions that enable the effect.</li>
</ul>
<p>We see that <span class="math inline">\(K\)</span> is a child or descendant of <span class="math inline">\(Q\)</span> in several of the graphs in Figure : <span class="math inline">\(Q\)</span> directly causes <span class="math inline">\(K\)</span> in panels (7) through (14), (17), (18), (25)-(30), (33), and (34); <span class="math inline">\(Q\)</span> causes (K) only indirectly through <span class="math inline">\(X\)</span> in panels (22) through (24); <span class="math inline">\(Q\)</span> causes (K) only indirectly through <span class="math inline">\(Y\)</span> in panels (15), (16), and (31); and <span class="math inline">\(Q\)</span> causes <span class="math inline">\(K\)</span> only indirectly through <span class="math inline">\(X\)</span> and through <span class="math inline">\(Y\)</span> in panel (32). We can then use the principle of <span class="math inline">\(d\)</span>-separation to figure out when the symptom clue is potentially informative, given what we have already observed. It is easy to see that <span class="math inline">\(K\)</span> is potentially informative, no matter what we have already observed, if <span class="math inline">\(K\)</span> is directly affected by <span class="math inline">\(Q\)</span>; there is nothing we could observe that would block the <span class="math inline">\(Q \rightarrow K\)</span> path. Thus, <span class="math inline">\(Q\)</span>’s “symptom” can, in this setup, contain information about type above and beyond that contained in the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values. However, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> only through some other variable, observing that other variable renders <span class="math inline">\(K\)</span> uninformative by blocking the <span class="math inline">\(Q\)</span>-to-<span class="math inline">\(K\)</span> path. For instance, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> indirectly through <span class="math inline">\(X\)</span>, once we observe <span class="math inline">\(X\)</span>, we already have all the information about <span class="math inline">\(Q\)</span> that would be contained in <span class="math inline">\(K\)</span>.</p>
<ul>
<li><strong>Surrogates as clues.</strong> Clues may be consequences of the outcome, as in graphs (15) and (16). If <span class="math inline">\(K\)</span> is a consequence <em>only</em> of <span class="math inline">\(Y\)</span>, then it will contain no new information about <span class="math inline">\(Q\)</span> where <span class="math inline">\(Y\)</span> is already known. However, in situations where the outcome has not been observed, <span class="math inline">\(K\)</span> can act as a “surrogate” for the outcome and thus yield leverage on <span class="math inline">\(Q\)</span> (<span class="citation"><a href="#ref-frangakis2002principal" role="doc-biblioref">Frangakis and Rubin</a> (<a href="#ref-frangakis2002principal" role="doc-biblioref">2002</a>)</span>). A researcher might, for instance, seek to understand causal effects on an outcome that is difficult to directly observe: consider, for instance, studies that seek to explain ideational change. Ideas themselves, the <span class="math inline">\(Y\)</span> in such studies, are not directly observable. However, their consequences—such as statements by actors or policy decisions—will be observable and can thus serve as informative surrogates for the outcome of interest.</li>
</ul>
<p>Clues may similarly serve as surrogates of a cause, as in graphs (19) and (22). Here <span class="math inline">\(X\)</span> causes <span class="math inline">\(K\)</span>, but <span class="math inline">\(K\)</span> plays no role in the causal process generating <span class="math inline">\(Y\)</span>. <span class="math inline">\(K\)</span> is of no help if we can directly measure <span class="math inline">\(X\)</span> since the latter <span class="math inline">\(d\)</span>-separates <span class="math inline">\(K\)</span> from <span class="math inline">\(Q\)</span>. But if an explanatory variable cannot be directly measured—consider, e.g., ideas or preferences as causes—then its consequences, including those that have no relationship to the outcome of interest, can provide leverage on the case-level causal effect.</p>
<p>Clues can also be a consequence of both our suspected cause and the outcome of interest, thus serving as what we might call “double surrogates,” as in panels (31) and (32). Here <span class="math inline">\(X\)</span> is a direct cause of <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K\)</span> is a joint product of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. A double surrogate can be informative as long as we have not already observed both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Where data on either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> are missing, there is an open path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>. If we have already observed both, however, then there is nothing left to be learned from <span class="math inline">\(K\)</span>.</p>
<ul>
<li><strong>Instruments as clues.</strong> Clues that are causally prior to an explanatory variable, and have no other effect on the outcome, can sometimes be informative. Consider, for instance, graph (3). Here <span class="math inline">\(K\)</span> is the only cause of <span class="math inline">\(X\)</span>. It can thus serve as a proxy. If we have seen <span class="math inline">\(X\)</span>, then <span class="math inline">\(X\)</span> blocks the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, and so <span class="math inline">\(K\)</span> is unhelpful. <span class="math inline">\(K\)</span> can be informative, though, if we have <em>not</em> observed <span class="math inline">\(X\)</span>. Note that informativeness here still requires that we observe <span class="math inline">\(Y\)</span>. Since <span class="math inline">\(Y\)</span> is a collider for <span class="math inline">\(Q\)</span> and the <span class="math inline">\(K \rightarrow X \rightarrow\)</span> chain, we need to observe <span class="math inline">\(Y\)</span> in order to <span class="math inline">\(d\)</span>-connect <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>.</li>
</ul>
<p>A rather different setup appears in graph (5), where both <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> cause <span class="math inline">\(X\)</span>. Now the conditions for <span class="math inline">\(K\)</span>’s informativeness are broader. Observing <span class="math inline">\(X\)</span> still makes <span class="math inline">\(K\)</span> uninformative as a proxy for <span class="math inline">\(X\)</span> itself. However, because <span class="math inline">\(X\)</span> is a collider for <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, observing <span class="math inline">\(X\)</span> <em>opens up</em> a path from <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>, rendering a dependency between them. Still, we have to observe at least one of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> for the instrument to be informative here. This is because both of <span class="math inline">\(K\)</span>’s paths to <span class="math inline">\(Q\)</span> run through a collision that we need to unblock by observing the collider. For one path, the collider is <span class="math inline">\(X\)</span>; for the other path, the collider is <span class="math inline">\(Y\)</span>.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<!-- Graph (5) is similar to one discussed in [@hausman1999independence] in which there is learning from a pretreatment clue because $X$ is a collider for $K$ and $Q$.  -->
<!-- To return to our government-removal model, government sensitivity to public opinion is a response-type variable (a $Q$ term), with non-sensitivity a pre-condition for the positive effect of a free press on removal. Yet it is possible (though we did not include it in our original model) that government sensitivity also affects whether or not a government gets a free press: more sensitive governments may impose tighter media restrictions. In that case, when governments are not sensitive, we would expect to see a free press and government removal.   -->
<p>Other patterns involving instrumentation are also imaginable, though not graphed here. For example, we might have a causal structure that combines instrumentation and surrogacy. Suppose that <span class="math inline">\(X\)</span> is affected by <span class="math inline">\(Q\)</span> and by an unobservable variable <span class="math inline">\(\theta_X\)</span>; and that <span class="math inline">\(\theta_X\)</span> has an observable consequence, <span class="math inline">\(K\)</span>. Then <span class="math inline">\(K\)</span>, though not a cause of <span class="math inline">\(X\)</span>, is a “surrogate instrument” <span class="citation">(<a href="#ref-hernan2006instruments" role="doc-biblioref">Hernán and Robins 2006</a>)</span> as it is a descendant of an unobserved instrument, <span class="math inline">\(U\)</span>, and thus allows us to extract inferences similar to those that we could draw from a true instrument.</p>
<ul>
<li><strong>Confounders as clues.</strong> In several of the graphs, <span class="math inline">\(K\)</span> is a confounder in that it is a direct cause of both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (panels (4), (6), (12), and (14)). Let us focus on graph (4), which isolates <span class="math inline">\(K\)</span>’s role as a confounder. Here <span class="math inline">\(K\)</span> can be informative via two possible paths. First, if <span class="math inline">\(X\)</span> is not observed but <span class="math inline">\(Y\)</span> is, then <span class="math inline">\(K\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> along the path <span class="math inline">\(K \rightarrow X \rightarrow Y \leftarrow Q\)</span>. <span class="math inline">\(K\)</span> is in this sense serving as a proxy for <span class="math inline">\(X\)</span>, with its path to <span class="math inline">\(Q\)</span> opened up by the observation of the collider, <span class="math inline">\(Y\)</span>. Second, with <span class="math inline">\(Y\)</span> observed, <span class="math inline">\(K\)</span> can provide information on <span class="math inline">\(Q\)</span> via the more direct collision, <span class="math inline">\(K \rightarrow Y \leftarrow Q\)</span>. If <span class="math inline">\(X\)</span> <em>is</em> observed, then the first path is blocked, but the second still remains active. As with any pre-outcome variable, for a confounder clue to provide purchase on <span class="math inline">\(Y\)</span>’s response type, <span class="math inline">\(Y\)</span> itself must be observed.</li>
</ul>
<p>In a sense, then, the role of confounders as clues in case-level inference is the mirror image of the role of confounders as covariates in cross-case correlational inference. In a correlational inferential framework, controlling for a variable in <span class="math inline">\(K\)</span>’s position in graph (5) renders the <span class="math inline">\(X, Y\)</span> correlation (which we assume to be observed) informative about <span class="math inline">\(X\)</span>’s average causal effect. When we use confounders as evidence in within-case inference, it is our observations of other variables that determine how informative the confounder <em>itself</em> will be about <span class="math inline">\(X\)</span>’s causal effect.</p>
<p>It is important to be precise about the kinds of claims that one can make from graphs like those in Figure {fig:34graphs}. The graphs in this figure allow us to identify informativeness about an unobserved node <span class="math inline">\(Q\)</span> that is a parent of <span class="math inline">\(Y\)</span>. This setup does not, however, capture all ways in which clues can be informative about the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> or about other causal queries of interest. For instance, as noted above, even if a clue is uninformative about a <span class="math inline">\(Q\)</span> node pointing into <span class="math inline">\(Y\)</span>, it may still help establish whether <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>: the statement that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> will for some graphs be a statement about a <em>collection</em> of nodes that form the set of query variables <span class="math inline">\(\mathcal Q\)</span>. This is the case, for instance, in any graph of the form <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, where we are interested not just in <span class="math inline">\(Y\)</span>’s response to <span class="math inline">\(M\)</span> (the mediator) but also in <span class="math inline">\(M\)</span>’s response to <span class="math inline">\(X\)</span>. Of interest, thus, are not just a <span class="math inline">\(Q^Y\)</span> response-type node pointing into <span class="math inline">\(Y\)</span> but also a <span class="math inline">\(Q^M\)</span> response-type node that is a parent of <span class="math inline">\(M\)</span>. Observations that provide leverage on either <span class="math inline">\(Q\)</span> term will thus aid an inference about the overall causal effect. A clue <span class="math inline">\(K\)</span> that is <span class="math inline">\(d-\)</span>separated from <span class="math inline">\(Q^Y\)</span> may nevertheless be informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> if it is not <span class="math inline">\(d-\)</span>separated from <span class="math inline">\(Q^M\)</span>; this opens up a broader range of variables as informative clues.</p>
<p>Additionally, as our discussion in Chapter 2 makes clear, queries other than the case-level causal effect—such as average causal effects, actual causes, and causal paths—involve particular features of context: particular sets of exogenous nodes as members of our query set, <span class="math inline">\(\mathcal Q\)</span>. Thus, even for the same causal model, informativeness will be defined differently for each causal question that we seek to address. The broader point is that we can identify what kinds of observations may address our query if we can place that query on a causal graph and then assess the graph for relationships of <span class="math inline">\(d\)</span>-separation and -connection.</p>
<p>Further, we emphasize that a DAG can only tell us when a clue <em>may</em> be informative (conditional some prior observation): <span class="math inline">\(d-\)</span>connectedness is necessary but not sufficient for informativeness. This fact derives directly from the rules for drawing a causal graph: the absence of an arrow between two variables implies that they are <em>not</em> directly causally related, while the presence of an arrow does not imply that they always are. As we saw in our analysis of the government-removal example in Chapter 2, whether variables connected to one another by arrows in the original DAG were in fact linked by a causal effect depended on the context. Likewise, whether a clue <span class="math inline">\(K\)</span> is in fact informative may depend on particular values of <span class="math inline">\(\mathcal W\)</span>—the variables that have already been observed. As a simple example, let <span class="math inline">\(q = k_1w + (1-w)k_2\)</span>, where <span class="math inline">\(W\)</span> is a variable that we have already observed and <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span> are clues that we might choose to observe next. Here, if <span class="math inline">\(w=1\)</span> then learning <span class="math inline">\(K_1\)</span> will be informative about <span class="math inline">\(Q\)</span>, and learning <span class="math inline">\(K_2\)</span> will not; but if <span class="math inline">\(w=0\)</span>, then <span class="math inline">\(K_1\)</span> will be uninformative (and <span class="math inline">\(K_2\)</span> informative).</p>
<p>In general, then, graphical analysis alone can help us exclude unhelpful research designs, given our prior observations and a fairly minimal set of prior beliefs about causal linkages. This is no small feat. But identifying those empirical strategies that will yield the <em>greatest</em> leverage requires engaging more deeply with our causal model, as we show in detail in our discussion of clue-selection in Chapter <a href="clue.html#clue">12</a>.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-BennettBayes" class="csl-entry">
Bennett, Andrew. 2008. <span>“Process Tracing. A Bayesian Perspective.”</span> In <em>The Oxford Handbook of Political Methodology</em>, edited by Janet M. Box-Steffensmeier, Henry E. Brady, and David Collier, 702–21. Oxford, UK: Oxford University Press.
</div>
<div id="ref-collier2011understanding" class="csl-entry">
Collier, David. 2011. <span>“Understanding Process Tracing.”</span> <em>PS: Political Science &amp; Politics</em> 44 (04): 823–30.
</div>
<div id="ref-frangakis2002principal" class="csl-entry">
Frangakis, Constantine E, and Donald B Rubin. 2002. <span>“Principal Stratification in Causal Inference.”</span> <em>Biometrics</em> 58 (1): 21–29.
</div>
<div id="ref-hernan2006instruments" class="csl-entry">
Hernán, Miguel A, and James M Robins. 2006. <span>“Instruments for Causal Inference: An Epidemiologist’s Dream?”</span> <em>Epidemiology</em> 17 (4): 360–72.
</div>
<div id="ref-humphreys2015mixing" class="csl-entry">
Humphreys, Macartan, and Alan M Jacobs. 2015. <span>“Mixing Methods: A Bayesian Approach.”</span> <em>American Political Science Review</em> 109 (04): 653–73.
</div>
<div id="ref-pearl2009causality" class="csl-entry">
Pearl, Judea. 2009. <em>Causality</em>. Cambridge university press.
</div>
<div id="ref-Van-Evera:1997" class="csl-entry">
Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>This differs from the task for mixed methods that we will address in Chapter 8 as these concern claims about the distribution of causal types in populations.<a href="pt.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>More generally a query might be a function of the distribution of causal types.<a href="pt.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>The reference population for a case is defined based on whatever we already know about the case. Thus, for instance, if we already know that the case has <span class="math inline">\(Y=1\)</span> before we begin process tracing, then the relevant population for the formation of prior beliefs is all cases in which <span class="math inline">\(Y=1\)</span>.<a href="pt.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>In words, the probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring is equal to the probability of <span class="math inline">\(A\)</span> occurring times the probability of <span class="math inline">\(B\)</span> occurring <em>given</em> that <span class="math inline">\(A\)</span> occurs.<a href="pt.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>As we will see later in the book, another approach is to gather data on additional cases. When analyzing multiple cases, we can set up our priors to allow for the possibility of unobserved confounding and then, potentially, learn about that confounding from the data. This is not possible under our procedure for single-case process tracing, where we treat the population parameters as given and fixed.<a href="pt.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>In the <code>CausalQueries</code> package, we can set distinct beliefs about <span class="math inline">\(X\)</span>’s assignment propensities for each of <span class="math inline">\(Y\)</span>’s nodal types.<a href="pt.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>That is, when there is unobserved confounding, we express conditional proportions, making all of the proportions conditionally independent of one another.<a href="pt.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>For a given value of <span class="math inline">\(\lambda^K_{01}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span> values equal by assigning a value of <span class="math inline">\((1-\lambda^K_{01})/3\)</span> to each.<a href="pt.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>For a given value of <span class="math inline">\(\lambda^K_{11}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span>’s equal by assigning a value of <span class="math inline">\((1-\lambda^K_{11})/3\)</span> to each; likewise for <span class="math inline">\(\lambda^Y_{11}\)</span> and the other <span class="math inline">\(\lambda^Y\)</span> values.<a href="pt.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>As we discuss in Chapter <a href="mixing.html#mixing">9</a>, the limits to learning from one pathway are even more severe when we have prior cross-case evidence that informs a prior about the <span class="math inline">\(X \rightarrow Y\)</span> effect.<a href="pt.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>This proposition is almost coextensive with the definition of a DAG. A DAG is a particular kind of dependency model (“graphoid”) that is a summary of a collection of “independency statements,” <span class="math inline">\((I)\)</span>, over distinct subsets of <span class="math inline">\(\mathcal V\)</span> (Pearl and Verma 1987), where <span class="math inline">\(I(\mathcal Q,\mathcal W,\mathcal K)\)</span> means “we learn nothing about <span class="math inline">\(\mathcal Q\)</span> from <span class="math inline">\(\mathcal K\)</span> if we already know <span class="math inline">\(\mathcal W\)</span>.” More formally:
<span class="math inline">\(I(\mathcal K, \mathcal W,\mathcal Q) \leftrightarrow P(\mathcal K,\mathcal Q|\mathcal W)=P(\mathcal K|\mathcal W)P(\mathcal Q|\mathcal W)\)</span>. A Directed Acyclic Graph Dependency model is one where the set of independencies corresponds exactly to the relations that satisfy <span class="math inline">\(d\)</span>-separation (Pearl and Verma 1987, p376). Thus on DAG <span class="math inline">\(\mathcal G\)</span>, <span class="math inline">\(I(\mathcal K,\mathcal W,\mathcal Q)_{\mathcal G}\)</span> implies that <span class="math inline">\(\mathcal K\)</span> and <span class="math inline">\(\mathcal Q\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(\mathcal W\)</span>.<a href="pt.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Put differently, there will not be any conditional independencies that are <em>not</em> captured in the DAG.<a href="pt.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>That is, we can rule out that the case is an <span class="math inline">\(a\)</span> type, or one with a negative causal effect.<a href="pt.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Note the “possibly” can be dropped under the assumption that the underlying probability model is “stable” (Pearl 2009, section 2.9.1) and with the interpretation that <span class="math inline">\(K\)</span> is informative about <span class="math inline">\(Q\)</span> for some, but not necessarily all, values of <span class="math inline">\(W\)</span>.<a href="pt.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>In other words, the clue would then be providing leverage on a response-type variable pointing into the mediator itself.<a href="pt.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>As a simple example one might imagine a system in which <span class="math inline">\(X = K\)</span> if <span class="math inline">\(q \in {a,b}\)</span> and <span class="math inline">\(X = 1-K\)</span> if <span class="math inline">\(q \in {c,d}\)</span>. Then if we observe, say, <span class="math inline">\(X=Y=K=1\)</span>, we can infer that <span class="math inline">\(q = b\)</span>. Another way to think about what is happening in graph (5) is that <span class="math inline">\(K\)</span> is providing information about the <em>assignment process</em>. In this graph, the causal effect (<span class="math inline">\(Y\)</span>’s potential outcomes, determined by <span class="math inline">\(Q\)</span>) is also a partial determinant of the assignment of cases to values on <span class="math inline">\(X\)</span>. In terms of cross-case correlational inference, then, we would think of this as a situation of confounding. Observing another cause of <span class="math inline">\(X\)</span>, then, allows us to more fully characterize the process of assignment.<a href="pt.html#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ptapp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
