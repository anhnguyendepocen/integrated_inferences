<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 Case selection as a Decision Problem | Integrated Inferences</title>
  <meta name="description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 Case selection as a Decision Problem | Integrated Inferences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="dnieperriver.png" />
  <meta property="og:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="github-repo" content="rstudio/ii" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 Case selection as a Decision Problem | Integrated Inferences" />
  
  <meta name="twitter:description" content="Model based strategies for integrating qualitative and quantitative inferences." />
  <meta name="twitter:image" content="dnieperriver.png" />

<meta name="author" content="Macartan Humphreys and Alan Jacobs" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="wide.html"/>
<link rel="next" href="justifying-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="headers\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Model based causal inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-case-for-causal-models"><i class="fa fa-check"></i><b>1.1</b> The Case for Causal Models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#the-limits-to-design-based-inference"><i class="fa fa-check"></i><b>1.1.1</b> The limits to design-based inference</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#qualitative-and-mixed-method-inference"><i class="fa fa-check"></i><b>1.1.2</b> Qualitative and mixed-method inference</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#connecting-theory-and-empirics"><i class="fa fa-check"></i><b>1.1.3</b> Connecting theory and empirics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#key-contributions"><i class="fa fa-check"></i><b>1.2</b> Key contributions</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-road-ahead"><i class="fa fa-check"></i><b>1.3</b> The Road Ahead</a></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#the-counterfactual-model"><i class="fa fa-check"></i><b>2.1</b> The counterfactual model</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#generalizing-to-outcomes-with-many-causes"><i class="fa fa-check"></i><b>2.1.1</b> Generalizing to outcomes with many causes</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#deterministic-relations"><i class="fa fa-check"></i><b>2.1.2</b> Deterministic relations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#causal-models-and-directed-acyclic-graphs"><i class="fa fa-check"></i><b>2.2</b> Causal Models and Directed Acyclic Graphs</a><ul>
<li class="chapter" data-level="2.2.1" data-path="models.html"><a href="models.html#components-of-a-causal-model"><i class="fa fa-check"></i><b>2.2.1</b> Components of a Causal Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="models.html"><a href="models.html#rules-for-graphing-causal-models"><i class="fa fa-check"></i><b>2.2.2</b> Rules for graphing causal models</a></li>
<li class="chapter" data-level="2.2.3" data-path="models.html"><a href="models.html#conditional-independence-from-dags"><i class="fa fa-check"></i><b>2.2.3</b> Conditional independence from DAGs</a></li>
<li class="chapter" data-level="2.2.4" data-path="models.html"><a href="models.html#a-simple-running-example"><i class="fa fa-check"></i><b>2.2.4</b> A simple running example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#chapter-appendix"><i class="fa fa-check"></i><b>2.3</b> Chapter Appendix</a><ul>
<li class="chapter" data-level="2.3.1" data-path="models.html"><a href="models.html#steps-for-constructing-causal-models"><i class="fa fa-check"></i><b>2.3.1</b> Steps for constructing causal models</a></li>
<li class="chapter" data-level="2.3.2" data-path="models.html"><a href="models.html#model-construction-in-code"><i class="fa fa-check"></i><b>2.3.2</b> Model construction in code</a></li>
<li class="chapter" data-level="2.3.3" data-path="models.html"><a href="models.html#test-yourself-can-you-read-conditional-independence-from-a-graph"><i class="fa fa-check"></i><b>2.3.3</b> Test yourself! Can you read conditional independence from a graph?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustratemodels.html"><a href="illustratemodels.html"><i class="fa fa-check"></i><b>3</b> Illustrating Causal Models</a><ul>
<li class="chapter" data-level="3.0.1" data-path="illustratemodels.html"><a href="illustratemodels.html#welfare-state-reform-pierson-1994"><i class="fa fa-check"></i><b>3.0.1</b> Welfare state reform: Pierson (1994)</a></li>
<li class="chapter" data-level="3.0.2" data-path="illustratemodels.html"><a href="illustratemodels.html#military-interventions-saunders-2011"><i class="fa fa-check"></i><b>3.0.2</b> Military Interventions: Saunders (2011)</a></li>
<li class="chapter" data-level="3.0.3" data-path="illustratemodels.html"><a href="illustratemodels.html#development-and-democratization-przeworski-and-limongi-1997"><i class="fa fa-check"></i><b>3.0.3</b> Development and Democratization: Przeworski and Limongi (1997)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>4</b> Theories as causal models</a><ul>
<li class="chapter" data-level="4.1" data-path="theory.html"><a href="theory.html#theory-as-a-lower-level-model"><i class="fa fa-check"></i><b>4.1</b> Theory as a “lower-level” model</a></li>
<li class="chapter" data-level="4.2" data-path="theory.html"><a href="theory.html#illustration-of-unpacking-causal-types"><i class="fa fa-check"></i><b>4.2</b> Illustration of unpacking causal types</a><ul>
<li class="chapter" data-level="4.2.1" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-mediation-model"><i class="fa fa-check"></i><b>4.2.1</b> Type disaggregation in a mediation model</a></li>
<li class="chapter" data-level="4.2.2" data-path="theory.html"><a href="theory.html#type-disaggregation-in-a-moderation-model"><i class="fa fa-check"></i><b>4.2.2</b> Type disaggregation in a moderation model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="theory.html"><a href="theory.html#rules-for-moving-between-higher--and-lower-level-models"><i class="fa fa-check"></i><b>4.3</b> Rules for moving between higher- and lower-level models</a><ul>
<li class="chapter" data-level="4.3.1" data-path="theory.html"><a href="theory.html#moving-down-levels"><i class="fa fa-check"></i><b>4.3.1</b> Moving down levels</a></li>
<li class="chapter" data-level="4.3.2" data-path="theory.html"><a href="theory.html#moving-up-levels"><i class="fa fa-check"></i><b>4.3.2</b> Moving up levels</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="theory.html"><a href="theory.html#conclusion"><i class="fa fa-check"></i><b>4.4</b> Conclusion</a><ul>
<li class="chapter" data-level="4.4.1" data-path="theory.html"><a href="theory.html#quantifying-the-gains-of-a-theory"><i class="fa fa-check"></i><b>4.4.1</b> Quantifying the gains of a theory</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="theory.html"><a href="theory.html#chapter-appendices"><i class="fa fa-check"></i><b>4.5</b> Chapter Appendices</a><ul>
<li class="chapter" data-level="4.5.1" data-path="theory.html"><a href="theory.html#summary-boxes"><i class="fa fa-check"></i><b>4.5.1</b> Summary Boxes</a></li>
<li class="chapter" data-level="4.5.2" data-path="theory.html"><a href="theory.html#illustration-of-a-mapping-from-a-game-to-a-dag"><i class="fa fa-check"></i><b>4.5.2</b> Illustration of a Mapping from a Game to a DAG</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="questions.html"><a href="questions.html"><i class="fa fa-check"></i><b>5</b> Causal Queries</a><ul>
<li class="chapter" data-level="5.1" data-path="questions.html"><a href="questions.html#case-level-causal-effects"><i class="fa fa-check"></i><b>5.1</b> Case-level causal effects</a></li>
<li class="chapter" data-level="5.2" data-path="questions.html"><a href="questions.html#case-level-causal-attribution"><i class="fa fa-check"></i><b>5.2</b> Case-level causal attribution</a></li>
<li class="chapter" data-level="5.3" data-path="questions.html"><a href="questions.html#case-level-explanation"><i class="fa fa-check"></i><b>5.3</b> Case-level explanation</a></li>
<li class="chapter" data-level="5.4" data-path="questions.html"><a href="questions.html#average-causal-effects"><i class="fa fa-check"></i><b>5.4</b> Average causal effects</a></li>
<li class="chapter" data-level="5.5" data-path="questions.html"><a href="questions.html#causal-paths"><i class="fa fa-check"></i><b>5.5</b> Causal Paths</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bayeschapter.html"><a href="bayeschapter.html"><i class="fa fa-check"></i><b>6</b> Bayesian Answers</a><ul>
<li class="chapter" data-level="6.1" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-basics"><i class="fa fa-check"></i><b>6.1</b> Bayes Basics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-instances"><i class="fa fa-check"></i><b>6.1.1</b> Simple instances</a></li>
<li class="chapter" data-level="6.1.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-rule-for-discrete-hypotheses"><i class="fa fa-check"></i><b>6.1.2</b> Bayes’ Rule for Discrete Hypotheses</a></li>
<li class="chapter" data-level="6.1.3" data-path="bayeschapter.html"><a href="bayeschapter.html#the-dirichlet-family-and-bayes-rule-for-continuous-parameters"><i class="fa fa-check"></i><b>6.1.3</b> The Dirichlet family and Bayes’ Rule for Continuous Parameters</a></li>
<li class="chapter" data-level="6.1.4" data-path="bayeschapter.html"><a href="bayeschapter.html#moments"><i class="fa fa-check"></i><b>6.1.4</b> Moments</a></li>
<li class="chapter" data-level="6.1.5" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-estimation-in-practice"><i class="fa fa-check"></i><b>6.1.5</b> Bayes estimation in practice</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="bayeschapter.html"><a href="bayeschapter.html#bayes-applied"><i class="fa fa-check"></i><b>6.2</b> Bayes applied</a><ul>
<li class="chapter" data-level="6.2.1" data-path="bayeschapter.html"><a href="bayeschapter.html#simple-bayesian-process-tracing"><i class="fa fa-check"></i><b>6.2.1</b> Simple Bayesian Process Tracing</a></li>
<li class="chapter" data-level="6.2.2" data-path="bayeschapter.html"><a href="bayeschapter.html#a-generalization-bayesian-inference-on-queries"><i class="fa fa-check"></i><b>6.2.2</b> A Generalization: Bayesian Inference on Queries</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="bayeschapter.html"><a href="bayeschapter.html#three-principles-of-bayesian-updating"><i class="fa fa-check"></i><b>6.3</b> Three principles of Bayesian updating</a><ul>
<li class="chapter" data-level="6.3.1" data-path="bayeschapter.html"><a href="bayeschapter.html#AppPriors"><i class="fa fa-check"></i><b>6.3.1</b> Priors matter</a></li>
<li class="chapter" data-level="6.3.2" data-path="bayeschapter.html"><a href="bayeschapter.html#simultaneous-joint-updating"><i class="fa fa-check"></i><b>6.3.2</b> Simultaneous, joint updating</a></li>
<li class="chapter" data-level="6.3.3" data-path="bayeschapter.html"><a href="bayeschapter.html#posteriors-are-independent-of-the-ordering-of-data"><i class="fa fa-check"></i><b>6.3.3</b> Posteriors are independent of the ordering of data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Model-Based Causal Inference</b></span></li>
<li class="chapter" data-level="7" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>7</b> Process Tracing with Causal Models</a><ul>
<li class="chapter" data-level="7.1" data-path="pt.html"><a href="pt.html#process-tracing-and-causal-models"><i class="fa fa-check"></i><b>7.1</b> Process tracing and causal models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="pt.html"><a href="pt.html#the-intuition"><i class="fa fa-check"></i><b>7.1.1</b> The intuition</a></li>
<li class="chapter" data-level="7.1.2" data-path="pt.html"><a href="pt.html#a-formalization-of-the-general-approach"><i class="fa fa-check"></i><b>7.1.2</b> A formalization of the general approach</a></li>
<li class="chapter" data-level="7.1.3" data-path="pt.html"><a href="pt.html#illustration-with-code"><i class="fa fa-check"></i><b>7.1.3</b> Illustration with code</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pt.html"><a href="pt.html#five-principles"><i class="fa fa-check"></i><b>7.2</b> Five principles</a><ul>
<li class="chapter" data-level="7.2.1" data-path="pt.html"><a href="pt.html#classic-qualitative-tests-are-special-cases-of-updating-on-a-model"><i class="fa fa-check"></i><b>7.2.1</b> Classic qualitative tests are special cases of updating on a model</a></li>
<li class="chapter" data-level="7.2.2" data-path="pt.html"><a href="pt.html#a-dag-alone-does-not-get-you-probative-value"><i class="fa fa-check"></i><b>7.2.2</b> A DAG alone does not get you probative value</a></li>
<li class="chapter" data-level="7.2.3" data-path="pt.html"><a href="pt.html#uncertainty-does-not-alter-inference-for-single-case-causal-inference"><i class="fa fa-check"></i><b>7.2.3</b> Uncertainty does not alter inference for single case causal inference</a></li>
<li class="chapter" data-level="7.2.4" data-path="pt.html"><a href="pt.html#probative-value-requires-d-connection"><i class="fa fa-check"></i><b>7.2.4</b> Probative value requires <span class="math inline">\(d-\)</span>connection</a></li>
<li class="chapter" data-level="7.2.5" data-path="pt.html"><a href="pt.html#probative-value"><i class="fa fa-check"></i><b>7.2.5</b> Probative value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptapp.html"><a href="ptapp.html"><i class="fa fa-check"></i><b>8</b> Application: Process Tracing with a Causal Model</a><ul>
<li class="chapter" data-level="8.1" data-path="ptapp.html"><a href="ptapp.html#inequality-and-democratization-the-debate"><i class="fa fa-check"></i><b>8.1</b> Inequality and Democratization: The Debate</a></li>
<li class="chapter" data-level="8.2" data-path="ptapp.html"><a href="ptapp.html#a-structural-causal-model"><i class="fa fa-check"></i><b>8.2</b> A Structural Causal Model</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ptapp.html"><a href="ptapp.html#forming-priors"><i class="fa fa-check"></i><b>8.2.1</b> Forming Priors</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptapp.html"><a href="ptapp.html#results"><i class="fa fa-check"></i><b>8.3</b> Results</a></li>
<li class="chapter" data-level="8.4" data-path="ptapp.html"><a href="ptapp.html#pathways"><i class="fa fa-check"></i><b>8.4</b> Pathways</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ptapp.html"><a href="ptapp.html#cases-with-incomplete-data"><i class="fa fa-check"></i><b>8.4.1</b> Cases with incomplete data</a></li>
<li class="chapter" data-level="8.4.2" data-path="ptapp.html"><a href="ptapp.html#inferences-for-cases-with-observed-democratization"><i class="fa fa-check"></i><b>8.4.2</b> Inferences for cases with observed democratization</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ptapp.html"><a href="ptapp.html#model-definition-and-inference-in-code"><i class="fa fa-check"></i><b>8.5</b> Model definition and inference in code</a></li>
<li class="chapter" data-level="8.6" data-path="ptapp.html"><a href="ptapp.html#concluding-thoughts"><i class="fa fa-check"></i><b>8.6</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixing.html"><a href="mixing.html"><i class="fa fa-check"></i><b>9</b> Integrated inferences</a><ul>
<li class="chapter" data-level="9.1" data-path="mixing.html"><a href="mixing.html#theres-only-ever-one-case"><i class="fa fa-check"></i><b>9.1</b> There’s only ever one case</a></li>
<li class="chapter" data-level="9.2" data-path="mixing.html"><a href="mixing.html#general-procedure"><i class="fa fa-check"></i><b>9.2</b> General procedure</a><ul>
<li class="chapter" data-level="9.2.1" data-path="mixing.html"><a href="mixing.html#estimation"><i class="fa fa-check"></i><b>9.2.1</b> Estimation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mixing.html"><a href="mixing.html#illustration"><i class="fa fa-check"></i><b>9.3</b> Illustration</a></li>
<li class="chapter" data-level="9.4" data-path="mixing.html"><a href="mixing.html#illustrated-inferences"><i class="fa fa-check"></i><b>9.4</b> Illustrated inferences</a><ul>
<li class="chapter" data-level="9.4.1" data-path="mixing.html"><a href="mixing.html#xy-model"><i class="fa fa-check"></i><b>9.4.1</b> XY model</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="mixing.html"><a href="mixing.html#considerations"><i class="fa fa-check"></i><b>9.5</b> Considerations</a><ul>
<li class="chapter" data-level="9.5.1" data-path="mixing.html"><a href="mixing.html#the-identification-problem"><i class="fa fa-check"></i><b>9.5.1</b> The identification problem</a></li>
<li class="chapter" data-level="9.5.2" data-path="mixing.html"><a href="mixing.html#continuous-data"><i class="fa fa-check"></i><b>9.5.2</b> Continuous data</a></li>
<li class="chapter" data-level="9.5.3" data-path="mixing.html"><a href="mixing.html#measurement-error"><i class="fa fa-check"></i><b>9.5.3</b> Measurement error</a></li>
<li class="chapter" data-level="9.5.4" data-path="mixing.html"><a href="mixing.html#spillovers"><i class="fa fa-check"></i><b>9.5.4</b> Spillovers</a></li>
<li class="chapter" data-level="9.5.5" data-path="mixing.html"><a href="mixing.html#clustering-and-other-violations-of-independence"><i class="fa fa-check"></i><b>9.5.5</b> Clustering and other violations of independence</a></li>
<li class="chapter" data-level="9.5.6" data-path="mixing.html"><a href="mixing.html#parameteric-models"><i class="fa fa-check"></i><b>9.5.6</b> Parameteric models</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="mixing.html"><a href="mixing.html#conclusion-1"><i class="fa fa-check"></i><b>9.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixingapp.html"><a href="mixingapp.html"><i class="fa fa-check"></i><b>10</b> Mixed-Method Application: Inequality and Democracy Revisited</a><ul>
<li class="chapter" data-level="10.1" data-path="mixingapp.html"><a href="mixingapp.html#a-trained-model"><i class="fa fa-check"></i><b>10.1</b> A trained model</a></li>
<li class="chapter" data-level="10.2" data-path="mixingapp.html"><a href="mixingapp.html#data"><i class="fa fa-check"></i><b>10.2</b> Data</a></li>
<li class="chapter" data-level="10.3" data-path="mixingapp.html"><a href="mixingapp.html#inference"><i class="fa fa-check"></i><b>10.3</b> Inference</a><ul>
<li class="chapter" data-level="10.3.1" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-cause-democracy"><i class="fa fa-check"></i><b>10.3.1</b> Did inequality <em>cause</em> democracy?</a></li>
<li class="chapter" data-level="10.3.2" data-path="mixingapp.html"><a href="mixingapp.html#did-inequality-prevent-democracy"><i class="fa fa-check"></i><b>10.3.2</b> Did inequality <em>prevent</em> democracy?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="mixingapp.html"><a href="mixingapp.html#exercises"><i class="fa fa-check"></i><b>10.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mm.html"><a href="mm.html"><i class="fa fa-check"></i><b>11</b> Mixing models</a><ul>
<li class="chapter" data-level="11.1" data-path="mm.html"><a href="mm.html#a-jigsaw-puzzle-integrating-across-a-model"><i class="fa fa-check"></i><b>11.1</b> A jigsaw puzzle: Integrating across a model</a></li>
<li class="chapter" data-level="11.2" data-path="mm.html"><a href="mm.html#combining-observational-and-experimental-data"><i class="fa fa-check"></i><b>11.2</b> Combining observational and experimental data</a></li>
<li class="chapter" data-level="11.3" data-path="mm.html"><a href="mm.html#transportation-of-findings-across-contexts"><i class="fa fa-check"></i><b>11.3</b> Transportation of findings across contexts</a></li>
<li class="chapter" data-level="11.4" data-path="mm.html"><a href="mm.html#multilevel-models-meta-analysis"><i class="fa fa-check"></i><b>11.4</b> Multilevel models, meta-analysis</a></li>
</ul></li>
<li class="part"><span><b>III Design Choices</b></span></li>
<li class="chapter" data-level="12" data-path="elements-of-design.html"><a href="elements-of-design.html"><i class="fa fa-check"></i><b>12</b> Elements of Design</a><ul>
<li class="chapter" data-level="12.1" data-path="elements-of-design.html"><a href="elements-of-design.html#model-inquiry-data-strategy-answer-strategy"><i class="fa fa-check"></i><b>12.1</b> Model, inquiry, data strategy, answer strategy</a><ul>
<li class="chapter" data-level="12.1.1" data-path="elements-of-design.html"><a href="elements-of-design.html#defining-a-model"><i class="fa fa-check"></i><b>12.1.1</b> Defining a model</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="elements-of-design.html"><a href="elements-of-design.html#evaluating-a-design"><i class="fa fa-check"></i><b>12.2</b> Evaluating a design</a><ul>
<li class="chapter" data-level="12.2.1" data-path="elements-of-design.html"><a href="elements-of-design.html#expected-error-and-expected-posterior-variance"><i class="fa fa-check"></i><b>12.2.1</b> Expected error and expected posterior variance</a></li>
<li class="chapter" data-level="12.2.2" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-1"><i class="fa fa-check"></i><b>12.2.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="elements-of-design.html"><a href="elements-of-design.html#illustration-of-design-decaration-in-code"><i class="fa fa-check"></i><b>12.3</b> Illustration of Design Decaration in code</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="clue.html"><a href="clue.html"><i class="fa fa-check"></i><b>13</b> Clue Selection as a Decision Problem</a><ul>
<li class="chapter" data-level="13.1" data-path="clue.html"><a href="clue.html#core-logic"><i class="fa fa-check"></i><b>13.1</b> Core logic</a></li>
<li class="chapter" data-level="13.2" data-path="clue.html"><a href="clue.html#a-strategic-approach"><i class="fa fa-check"></i><b>13.2</b> A strategic approach</a><ul>
<li class="chapter" data-level="13.2.1" data-path="clue.html"><a href="clue.html#clue-selection-with-a-simple-example"><i class="fa fa-check"></i><b>13.2.1</b> Clue selection with a simple example</a></li>
<li class="chapter" data-level="13.2.2" data-path="clue.html"><a href="clue.html#dependence-on-prior-beliefs"><i class="fa fa-check"></i><b>13.2.2</b> Dependence on prior beliefs</a></li>
<li class="chapter" data-level="13.2.3" data-path="clue.html"><a href="clue.html#clue-selection-for-the-democratization-model"><i class="fa fa-check"></i><b>13.2.3</b> Clue selection for the democratization model</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="clue.html"><a href="clue.html#dynamic-strategies"><i class="fa fa-check"></i><b>13.3</b> Dynamic Strategies</a></li>
<li class="chapter" data-level="13.4" data-path="clue.html"><a href="clue.html#conclusion-2"><i class="fa fa-check"></i><b>13.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wide.html"><a href="wide.html"><i class="fa fa-check"></i><b>14</b> Going wide and going deep</a><ul>
<li class="chapter" data-level="14.1" data-path="wide.html"><a href="wide.html#motivation"><i class="fa fa-check"></i><b>14.1</b> Motivation</a></li>
<li class="chapter" data-level="14.2" data-path="wide.html"><a href="wide.html#developing-some-intuitions"><i class="fa fa-check"></i><b>14.2</b> Developing some intuitions</a></li>
<li class="chapter" data-level="14.3" data-path="wide.html"><a href="wide.html#diagnosing-mixes"><i class="fa fa-check"></i><b>14.3</b> Diagnosing mixes</a><ul>
<li class="chapter" data-level="14.3.1" data-path="wide.html"><a href="wide.html#path-model"><i class="fa fa-check"></i><b>14.3.1</b> 1-path model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="caseselection.html"><a href="caseselection.html"><i class="fa fa-check"></i><b>15</b> Case selection as a Decision Problem</a><ul>
<li class="chapter" data-level="15.1" data-path="caseselection.html"><a href="caseselection.html#case-selection-logics-depends-on-probative-value-and-queries"><i class="fa fa-check"></i><b>15.1</b> Case selection logics depends on probative value and queries</a></li>
<li class="chapter" data-level="15.2" data-path="caseselection.html"><a href="caseselection.html#new-section-dec-2020"><i class="fa fa-check"></i><b>15.2</b> New section (Dec 2020)</a><ul>
<li class="chapter" data-level="15.2.1" data-path="caseselection.html"><a href="caseselection.html#procedure"><i class="fa fa-check"></i><b>15.2.1</b> Procedure</a></li>
<li class="chapter" data-level="15.2.2" data-path="caseselection.html"><a href="caseselection.html#inferences-from-strategies-and-data-realizations"><i class="fa fa-check"></i><b>15.2.2</b> Inferences from Strategies and Data Realizations</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="caseselection.html"><a href="caseselection.html#logic-of-strategy-comparison"><i class="fa fa-check"></i><b>15.3</b> Logic of strategy comparison</a></li>
<li class="chapter" data-level="15.4" data-path="caseselection.html"><a href="caseselection.html#explorations"><i class="fa fa-check"></i><b>15.4</b> Explorations</a><ul>
<li class="chapter" data-level="15.4.1" data-path="caseselection.html"><a href="caseselection.html#procedure-1"><i class="fa fa-check"></i><b>15.4.1</b> Procedure</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="caseselection.html"><a href="caseselection.html#principles"><i class="fa fa-check"></i><b>15.5</b> Principles</a><ul>
<li class="chapter" data-level="15.5.1" data-path="caseselection.html"><a href="caseselection.html#sometimes-one-case-is-not-enough"><i class="fa fa-check"></i><b>15.5.1</b> Sometimes one case is not enough</a></li>
<li class="chapter" data-level="15.5.2" data-path="caseselection.html"><a href="caseselection.html#different-strategies-for-different-estimands"><i class="fa fa-check"></i><b>15.5.2</b> Different strategies for different estimands</a></li>
<li class="chapter" data-level="15.5.3" data-path="caseselection.html"><a href="caseselection.html#where-the-probative-value-is"><i class="fa fa-check"></i><b>15.5.3</b> Where the probative value is</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Models in Question</b></span></li>
<li class="chapter" data-level="16" data-path="justifying-models.html"><a href="justifying-models.html"><i class="fa fa-check"></i><b>16</b> Justifying models</a><ul>
<li class="chapter" data-level="16.1" data-path="justifying-models.html"><a href="justifying-models.html#nothing-from-nothing"><i class="fa fa-check"></i><b>16.1</b> Nothing from nothing</a></li>
<li class="chapter" data-level="16.2" data-path="justifying-models.html"><a href="justifying-models.html#justifying-the-classic-process-tracing-tests"><i class="fa fa-check"></i><b>16.2</b> Justifying the classic process tracing tests</a></li>
<li class="chapter" data-level="16.3" data-path="justifying-models.html"><a href="justifying-models.html#justification-from-experimental-designs"><i class="fa fa-check"></i><b>16.3</b> Justification from experimental designs</a><ul>
<li class="chapter" data-level="16.3.1" data-path="justifying-models.html"><a href="justifying-models.html#mediator"><i class="fa fa-check"></i><b>16.3.1</b> Mediator</a></li>
<li class="chapter" data-level="16.3.2" data-path="justifying-models.html"><a href="justifying-models.html#moderator"><i class="fa fa-check"></i><b>16.3.2</b> Moderator</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="justifying-models.html"><a href="justifying-models.html#causal-discovery"><i class="fa fa-check"></i><b>16.4</b> Causal discovery</a></li>
<li class="chapter" data-level="16.5" data-path="justifying-models.html"><a href="justifying-models.html#exercise"><i class="fa fa-check"></i><b>16.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>17</b> Evaluating models</a><ul>
<li class="chapter" data-level="17.1" data-path="evaluation.html"><a href="evaluation.html#five-strategies"><i class="fa fa-check"></i><b>17.1</b> Five Strategies</a><ul>
<li class="chapter" data-level="17.1.1" data-path="evaluation.html"><a href="evaluation.html#check-conditional-independence"><i class="fa fa-check"></i><b>17.1.1</b> Check conditional independence</a></li>
<li class="chapter" data-level="17.1.2" data-path="evaluation.html"><a href="evaluation.html#computational-clues"><i class="fa fa-check"></i><b>17.1.2</b> Computational clues</a></li>
<li class="chapter" data-level="17.1.3" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value-are-the-data-unexpected-given-your-model"><i class="fa fa-check"></i><b>17.1.3</b> Bayesian <span class="math inline">\(p\)</span> value: Are the data unexpected given your model?</a></li>
<li class="chapter" data-level="17.1.4" data-path="evaluation.html"><a href="evaluation.html#leave-one-out-loo-cross-validation"><i class="fa fa-check"></i><b>17.1.4</b> Leave-one-out (LOO) cross-validation</a></li>
<li class="chapter" data-level="17.1.5" data-path="evaluation.html"><a href="evaluation.html#sensitivity"><i class="fa fa-check"></i><b>17.1.5</b> Sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="evaluation.html"><a href="evaluation.html#evaluating-the-democracy-inequality-model"><i class="fa fa-check"></i><b>17.2</b> Evaluating the Democracy-Inequality model</a><ul>
<li class="chapter" data-level="17.2.1" data-path="evaluation.html"><a href="evaluation.html#check-assumptions-of-conditional-independence"><i class="fa fa-check"></i><b>17.2.1</b> Check assumptions of conditional independence</a></li>
<li class="chapter" data-level="17.2.2" data-path="evaluation.html"><a href="evaluation.html#bayesian-p-value"><i class="fa fa-check"></i><b>17.2.2</b> Bayesian <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="17.2.3" data-path="evaluation.html"><a href="evaluation.html#loo-validation"><i class="fa fa-check"></i><b>17.2.3</b> LOO validation</a></li>
<li class="chapter" data-level="17.2.4" data-path="evaluation.html"><a href="evaluation.html#sensitivity-to-priors"><i class="fa fa-check"></i><b>17.2.4</b> Sensitivity to priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>18</b> Final Words</a><ul>
<li class="chapter" data-level="18.1" data-path="final-words.html"><a href="final-words.html#gains"><i class="fa fa-check"></i><b>18.1</b> Gains</a></li>
<li class="chapter" data-level="18.2" data-path="final-words.html"><a href="final-words.html#lessons-learned-along-the-way"><i class="fa fa-check"></i><b>18.2</b> Lessons learned along the way</a></li>
<li class="chapter" data-level="18.3" data-path="final-words.html"><a href="final-words.html#thinking-about-learning"><i class="fa fa-check"></i><b>18.3</b> Thinking about learning</a></li>
<li class="chapter" data-level="18.4" data-path="final-words.html"><a href="final-words.html#worries-about-what-you-have-to-put-in"><i class="fa fa-check"></i><b>18.4</b> Worries about what you have to put in</a></li>
<li class="chapter" data-level="18.5" data-path="final-words.html"><a href="final-words.html#limits-on-what-you-can-get-out"><i class="fa fa-check"></i><b>18.5</b> Limits on what you can get out</a></li>
<li class="chapter" data-level="18.6" data-path="final-words.html"><a href="final-words.html#looking-ahead"><i class="fa fa-check"></i><b>18.6</b> Looking ahead</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="19" data-path="examplesappendix.html"><a href="examplesappendix.html"><i class="fa fa-check"></i><b>19</b> <code>CausalQueries</code></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/macartan/gbiqq/" target="blank">Uses gbiqq</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Integrated Inferences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="caseselection" class="section level1">
<h1><span class="header-section-number">Chapter 15</span> Case selection as a Decision Problem</h1>
<div class="headerbox">
<div class="center">

</div>
<p>With a causal model in hand, together with priors over parameters, you can assess in advance what conclusions you will draw from different observations and assess what kinds of observations are most worth seeking. We draw out the implications of this idea for case selection.</p>
</div>
<p><br></p>
<p>A critical decision for scholars employing mixed methods is to determine which cases are most valuable for within-case analysis.</p>
<p>A host of different strategies have been proposed for selecting cases for in-depth study based on the observed values of <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> data. Perhaps the most common strategy is to select cases in which <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span> and look to see whether in fact <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in the case in question (using some more or less formal strategy for inferring causality from within-case evidence). But many other strategies have been proposed, including strategies to select cases “on the regression line” or, for some purposes, cases “off the regression line” (e.g., <span class="citation">Lieberman (<a href="#ref-Lieberman2005nested" role="doc-biblioref">2005</a>)</span>). Some scholars suggest ensuring variation in <span class="math inline">\(X\)</span> (most prominently, <span class="citation">King, Keohane, and Verba (<a href="#ref-king1994designing" role="doc-biblioref">1994</a>)</span>), while others have proposed various kinds of matching strategies. Some have pointed to the advantages of random sampling of cases, either stratified or unstratified by values on <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> (<span class="citation">Fearon and Laitin (<a href="#ref-FL2008" role="doc-biblioref">2008</a>)</span>, <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span>).</p>
<p>Which cases you should choose will likely depend on the purposes to which you want to put them.</p>
<p>A matching strategy for instance—selecting cases that are comparable on many features but that differ on <span class="math inline">\(X\)</span>—replicates at a small scale the kind of inference done by matching estimators with large-<span class="math inline">\(n\)</span> data. The strategy emphasize the inferences to be made from <span class="math inline">\(X,Y\)</span> variation rather than inferences drawn specifically from within case information beyond what is available in the measurement of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. (Citations needed.)</p>
<p>Other treatments seek to use qualitative information to check assumptions made in <span class="math inline">\(X, Y\)</span> analysis: for example, is the measurement of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> reliable in critical cases? (Citations needed) For such questions with limited resources, it might make sense to focus on cases for which validation plausibly makes a difference to the <span class="math inline">\(X,Y\)</span> inferences: for example influential cases that have unusually extreme values on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Similar arguments are made for checking assumptions on selection processes, though we consider this a more complex desideratum since this requires making case level causal inferences and not simply measurement claims.</p>
<p>A third purpose is to use a case to generate alternative or richer theories of causal processes, as in Lieberman’s “model-building” mode of “nested analysis” (<span class="citation">Lieberman (<a href="#ref-Lieberman2005nested" role="doc-biblioref">2005</a>)</span>). Here it may be cases off the regression line that are of interest.</p>
<p>Weller and Barnes (CITE article) on case selection focus on (a) X/Y relations and (b) whether the cases are useful for hypothesis generation.</p>
<p>In what follows, we focus on a simpler goal: given existing <span class="math inline">\(X, Y\)</span> data for a set of cases and a given clue (or set of clues) that we can go looking for in the intensive analysis of some subset of these cases, for which cases would process tracing yield the greatest learning about the population-level causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>?</p>
<p>The basic insight of this chapter is simple enough: <em>the optimal strategy for case selection for a model-based analysis can be determined by the model and the query</em>, just as we saw for the optimal clue-selection strategy in Chapter <a href="#Clues"><strong>??</strong></a>. Using this strategy yields guidance that is consistent with some common advice but at odds with other advice. The main principles that emerge from the analysis can be summarized as:</p>
<ul>
<li>go where the probative value is, and</li>
<li>sample from <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values in proportion to their occurrence in the population,</li>
<li>invest in collections of cases that provide complementary learning.</li>
</ul>
<p>Beyond these general principles, other patterns are more complex and thus more difficult to neatly summarize. The most general message of this chapter is about the general approach: that is, that we can use a causal model to tell us what kinds of cases are likely to yield the greatest learning, given the model and a strategy of inference. We provide a tool for researchers to undertake this analysis, at least for simple problems with <span class="math inline">\(X, Y, K\)</span> data.</p>
<p>Most closely related to our analysis in this chapter is the contribution of <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span>, who build on <span class="citation">Seawright and Gerring (<a href="#ref-SeawrightGerring2008" role="doc-biblioref">2008</a>)</span>. While Seawright and Gerring provide a taxonomy of approaches to case selection, they do not provide a strategy for assessing the relative merits of these different approaches. As we do, <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> focus on a situation with binary <span class="math inline">\(X,Y\)</span> data and assess the gains from learning about causal type in a set of cases (interestingly in their treatment causal type, <span class="math inline">\(Z_i\)</span> is called a confounder rather than being an estimand of direct interest; in our setup, confounding as normally understood arises because of different probabilities of different causal types of being assigned to “treatment”, or an <span class="math inline">\(X=1\)</span> value). <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> assume that in any given case selected for analysis a qualitative researcher is able to infer the causal type perfectly.</p>
<p>Our setup differs from that in <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> in a few ways. <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> paramaterize differently, though this difference is not important.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Perhaps the most important difference between our analysis and that in <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> is that we connect the inference strategy to process-tracing approaches. Whereas <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> assume that causal types can be read directly, we assume that these are inferred <em>imperfectly</em> from clues. As in our baseline model, our ability to make inferences for causal types can differ by type and as a function of <span class="math inline">\(X\)</span>. And, as in the baseline model, not only can we have uncertainty about the probative value of clues, but researchers can learn about the probative value of clues by examining cases.</p>
<!-- Are Herron and Quinn's priors Jeffrey priors? -->
<p>Here we assume that the case selection decision is made after observing the <span class="math inline">\(XY\)</span> distribution and we explore a range of different possible contingency tables. In <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> the distribution from which the contingency tables are drawn is fixed, though set to exhibit an expected observed difference in means (though not necessarily a true treatment effect) of 0.2. They assume large <span class="math inline">\(XY\)</span> data sets (with 10,000) units and case selection strategies ranging from 1 to 20 cases.</p>
<p>Another important difference, is that in many of their analyses, <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> take the perspective of an outside analyst who knows the true treatment effect; they then assess the expected bias generated by a research strategy over the possible data realizations. We, instead, take the perspective of a researcher who has <em>beliefs</em> about the true treatment effect that correspond to their priors, and for whom there is therefore no <em>expected</em> bias. This has consequences also for the assessment of expected posterior variance, as in our analyses the expectation of the variance is taken with respect to the researcher’s beliefs about the world, rather than being made conditional on some specific world (ATE). We think that this setup is addressed to the question that a researcher must answer when deciding on a strategy: given what they know now, what will produce the greatest reduction in uncertainty (the lowest expected posterior variance)?</p>
<p>Finally, we proceed somewhat differently in our identification of strategies from Herron and Quinn: rather than pre-specifying particular sets of strategies (operationalizations of those identified by <span class="citation">Seawright and Gerring (<a href="#ref-SeawrightGerring2008" role="doc-biblioref">2008</a>)</span>) and evaluating them, we define a strategy as the particular distribution over <span class="math inline">\(XY\)</span> cells to be examined and proceed to examine <em>every possible strategy</em> given a choice of a certain number of cases in which to conduct process tracing. We thus let the clusters of strategies—those strategies that perform similarly—emerge from the analysis rather than being privileged by past conceptualizations of case-selection strategies.</p>
<p>Despite these various differences, our results will agree in key ways with those in <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span>.</p>
<div id="case-selection-logics-depends-on-probative-value-and-queries" class="section level2">
<h2><span class="header-section-number">15.1</span> Case selection logics depends on probative value and queries</h2>
<p>Although it might be tempting to seek general rules of the form “examine cases in which <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span>” or, “ignore cases in which <span class="math inline">\(X=0\)</span> and <span class="math inline">\(Y=0\)</span>”, it is easily demonstrated that which choices are more informative depend on how waht can be learned within a case contributes to infernecnce, and that hte contributions depend on the query in question.</p>
<p>Say we know in a given population that:</p>
<ul>
<li><span class="math inline">\(X \rightarrow Y \leftarrow K\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 0) = 1\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 0) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 1) = 0\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 1) = .9\)</span></li>
</ul>
<p>We do not know, however how common <span class="math inline">\(K\)</span> is. Thus we do not know either unit level causal effects or population level effects.</p>
<p>Given the information above we can see that if <span class="math inline">\(X=Y=1\)</span>, then <span class="math inline">\(K\)</span> is a “doubly decisive” clue for assessing whether, in a given case, <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>. In particular we have that for an <span class="math inline">\(X=Y=1\)</span> case, seeing <span class="math inline">\(K=1\)</span> implies <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> Since otherwise <span class="math inline">\(Y\)</span> would have been 0) and seeing <span class="math inline">\(K=0\)</span> implies <span class="math inline">\(X\)</span> did not cause <span class="math inline">\(Y\)</span> (since othereise <span class="math inline">\(Y\)</span> would have been 1 in any event.</p>
<p>However, if we had a case in which <span class="math inline">\(X=Y=0\)</span> then learning <span class="math inline">\(K\)</span> would be entirely uninformative for the case. In particular, we already know that <span class="math inline">\(K=1\)</span> in this case as we know there are not cases in which <span class="math inline">\(X=Y=0\)</span> and <span class="math inline">\(K=0\)</span>. And this knowledge is not enough in this case to know whether <span class="math inline">\(X=0\)</span> caused <span class="math inline">\(Y=0\)</span>.</p>
<p>For the same reason, if, off the diagonal, <span class="math inline">\(X=0, Y=1\)</span> we learn nothing from <span class="math inline">\(K\)</span>, since we learn about <span class="math inline">\(K\)</span> from <span class="math inline">\(Y\)</span>. If however we had a case in which <span class="math inline">\(X=1, Y=0\)</span>, if <span class="math inline">\(K\)</span> were 1 then we would know that <span class="math inline">\(X=1\)</span> did not cause <span class="math inline">\(Y=0\)</span>; if <span class="math inline">\(K\)</span> were 0 we would know that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>.</p>
<p>Say now we were interested in the population estimand: the average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. We can see that this is equal to <span class="math inline">\(\Pr(K=1)\times.9 + (1-\Pr(K-0))\times(-.5)) = 1.4\Pr(K=1)-.5\)</span>. For this estimand we are only interested in the prevalence of <span class="math inline">\(K\)</span> in the population. It might seem that this means that it is irrelevant what type of case you choose; however, as noted above, we have more information about the likely value of <span class="math inline">\(K\)</span> in some cases than in others. So for this estimand also, in this case, selecting an <span class="math inline">\(X=Y=1\)</span> case is informative for the population effect; selecting <span class="math inline">\(X=Y=0\)</span> case is not informative.</p>
<p>Say now we had a case in which <span class="math inline">\(X=1\)</span>. Should we choose: a case in which <span class="math inline">\(Y=1\)</span> or a case in which <span class="math inline">\(Y=0\)</span>. In both cases <span class="math inline">\(K\)</span> is doubly decisive for the case level estimand. However for a <span class="math inline">\(Y=1\)</span> case we think it likely that <span class="math inline">\(K=1\)</span> (specifically, assuming a prior of <span class="math inline">\(\Pr(K=1)\)</span> we think <span class="math inline">\(\Pr(K=1 | X=1, Y=1) = \frac{.9}{.9+.5}=.64\)</span>); for the <span class="math inline">\(Y=0\)</span> case we think <span class="math inline">\(\Pr(K=1 | X=1, Y=0) = \frac{.1}{.5+.1}=.17\)</span>. Thus we are much more uncertain about the value of <span class="math inline">\(K\)</span> in the <span class="math inline">\(X=Y=1\)</span> case. We would learn more for the avergae treatment effect then by choosing off the diagonal.</p>
<p>Specifically let <span class="math inline">\(\kappa\)</span> denote <span class="math inline">\(\Pr(K=1)\)</span>. say we begin thinking it equally likely that <span class="math inline">\(\kappa=\kappa^H = .5\)</span> and <span class="math inline">\(\kappa=\kappa^L=0\)</span>. Say <span class="math inline">\(\Pr(X=1) = .5\)</span>. Say we observe one case with <span class="math inline">\(X=Y=1\)</span> and another with <span class="math inline">\(X=1, Y=0\)</span>. From that informaation alone we can update over <span class="math inline">\(\kappa\)</span>. Specifically, conditioning on the probability that <span class="math inline">\(X=1\)</span> for both cases and focuseing only on the probability that Y=0 in one case and Y=1 in the other:</p>
<p><span class="math display">\[p(\kappa = \kappa^L|D) =  \frac{p(D|\kappa^H)}{p(D|\kappa^H)+p(D|\kappa^L)}=\frac{.5}{.5 + .25\times(2\times.5\times.5 + 2\times.9\times.1 + 2\times(.9\times.5 +.1\times.5))}\]</span></p>
<p>In summary in this case it makes sense to select and <span class="math inline">\(X=Y=1\)</span> case if you are interested in teh population estimand or if you are interested in teh case level estimand for an <span class="math inline">\(X=Y=1\)</span> case. If you are interested in the case level estimand for an <span class="math inline">\(X=Y=0\)</span> case then there are no gains from either selection strategy.</p>
<p>Sometimes however you learn more in a <span class="math inline">\(X=Y=0\)</span> than in a <span class="math inline">\(X=Y=1\)</span> case. Say instead that you knew that:</p>
<ul>
<li><span class="math inline">\(X \rightarrow Y \leftarrow K\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 0) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 0) = 0\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 1) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 1) = 1\)</span></li>
</ul>
<p>In this case you learn nothing from observing a case in which <span class="math inline">\(X=Y=1\)</span>—in this case you already expect that <span class="math inline">\(K=1\)</span>. In contrast if <span class="math inline">\(X=Y=0\)</span> then if you learn that <span class="math inline">\(K=1\)</span> you know that were <span class="math inline">\(X=1\)</span> the <span class="math inline">\(Y\)</span> would have been 1; but if you learn that <span class="math inline">\(K=0\)</span> you know that <em>were</em> <span class="math inline">\(X=1\)</span> then <span class="math inline">\(Y\)</span> would have (still) been 0. So in this case <span class="math inline">\(K\)</span> is doubly decisive for an <span class="math inline">\(X=Y=0\)</span> case but not for a <span class="math inline">\(X=Y=1\)</span> case.</p>
<p>This logic also holds for the off diagonals.</p>
<p>Say instead that you knew that:</p>
<ul>
<li><span class="math inline">\(X \rightarrow Y \leftarrow K\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 0) = 0\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 0) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 1) = 1\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 1) = .5\)</span></li>
</ul>
<p>Say you have a case in which <span class="math inline">\(X=1, Y=0\)</span>, then if <span class="math inline">\(K=1\)</span> you know that if <span class="math inline">\(X\)</span> were 0, Y would have been 1; but if <span class="math inline">\(K=0\)</span> you know that if <span class="math inline">\(X\)</span> were 0, <span class="math inline">\(Y\)</span> would have been 0. In that case <span class="math inline">\(K\)</span> would be doubly decisive for <span class="math inline">\(X=1\)</span> causing <span class="math inline">\(Y=0\)</span>.</p>
<p>Say you have a case in which <span class="math inline">\(X=0, Y=1\)</span>, then it must be that <span class="math inline">\(K=0\)</span>.</p>
<p>Say instead that you knew that:</p>
<ul>
<li><span class="math inline">\(X \rightarrow Y \leftarrow K\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 0) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 0) = 0\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=0, K = 1) = .5\)</span></li>
<li><span class="math inline">\(\Pr(Y=1|X=1, K = 1) = 1\)</span></li>
</ul>
<p>It may be better to select a case that is not “like” the cases you want to make inferences about.</p>
<p>Which cases to learn <span class="math inline">\(K\)</span> from.</p>
</div>
<div id="new-section-dec-2020" class="section level2">
<h2><span class="header-section-number">15.2</span> New section (Dec 2020)</h2>
<p>We turn now to a more general approach for deriving case-selection guidance from a causal model, given the causal query we wish to address and any data that we have already observed. This approach can be implemented using <code>CausalQueries</code> together with <code>CQTools</code>.</p>
<div id="procedure" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Procedure</h3>
<p>We imagine a situation in which we have already observed some data (the values of some nodes from the causal model in some set of cases) and must now decide in which cases we should gather additional data. To simplify the setup, we will be assuming that we are considering gathering additional observations in cases for which we already have <em>some</em> data. In other words, we are deciding which cases to investigate more <em>deeply</em>. (This is distinct from the question of “wide vs. deep”, where we might decide to observe cases we have not yet seen at all.)</p>
<p>The general intuition of the case-selection approach that we develop here is that we can use our causal model and any previously observed data to estimate what observations we are more or less likely to make under a given case-selection strategy, and then figure out how far off from the (under the model) true estimand we can expect to be under the strategy, given whatever causal question we seek to answer.</p>
<p>We proceed as follows:</p>
<p><strong>DAG</strong>. We start, as always, with a DAG representing our beliefs about which variables we believe to be direct causes of other variables. For the current illustrations, we consider two different DAGS: a simple mediation (or “chain”) model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, and a two-path model, <span class="math inline">\(X \rightarrow M \rightarrow Y \leftarrow X\)</span>.</p>
<p><strong>Priors</strong>. As when conducting mixed-method inference, we can set qualitative restrictions and/or differential quantitative weights on the (possibly conditional) nodal types in the model. We can also indicate our uncertainty over the latter, by setting the <span class="math inline">\(\alpha\)</span> parameters of the relevant Dirichlet distributions. For the current example, we start by setting flat priors over all nodal types and assume no unobserved confounding.</p>
<p><strong>Given data.</strong> If we have already made observations of any of the model’s nodes in some set of cases, we can use this information to condition our strategy for searching for further information. For instance, if we have observed <span class="math inline">\(X\)</span>’s and <span class="math inline">\(Y\)</span>’s value in a set of cases, we might select cases for process tracing based on their values of <span class="math inline">\(X\)</span> and/or <span class="math inline">\(Y\)</span>. And, importantly, what we have already observed in the cases will affect the inferences we will draw when we observe additional data, including how <em>informative</em> a particular new observation is likely to be. For the present examples, we assume that we have already observed <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in a set of cases and found a positive correlation.</p>
<p><strong>Query</strong>. We define our query. This could, for instance, be the share of cases in the population in which <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>, or it might be <span class="math inline">\(X\)</span>’s average effect on <span class="math inline">\(Y\)</span>. We can use the general procedure to identify case-selection strategies for any causal query that can be defined on a DAG. And, importantly, the optimal case-selection strategy may depend on the query. For instance, the best case-selection strategy for estimating the average causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> may not be the same as the best strategy for figuring out for what proportion of the population <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. In the example below, we focus on a set of conditional queries, asking what the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is in cases with different <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, and <span class="math inline">\(M\)</span> values.</p>
<p>FLAG: MAke sure above query definition lines up with what we end up doing.</p>
<p><strong>Define one or more strategies</strong>. A strategy is defined, generically, as the search for data on a given set of <em>nodes</em>, in a given <em>number</em> of cases that are randomly selected <em>conditional</em> on some information we already have about potential cases. Let us assume here that our strategy will involve uncovering <span class="math inline">\(M\)</span>’s value in 1 or 2 cases. What we are wondering is how to choose this one or two cases for deeper analysis. For illustrative purposes, we focus in on four possible strategies, conditional on the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values that we already know:</p>
<p>1 examine <span class="math inline">\(M\)</span> in 1 <span class="math inline">\(X=Y=1\)</span> case;
2 examine <span class="math inline">\(M\)</span> in 1 <span class="math inline">\(X=1, Y=0\)</span> case;
3 examine <span class="math inline">\(M\)</span> in 2 cases, an <span class="math inline">\(X=Y=1\)</span> and an <span class="math inline">\(X=Y=0\)</span>; and
4 examine <span class="math inline">\(M\)</span> in 2 cases, an <span class="math inline">\(X=1, Y=0\)</span> and an <span class="math inline">\(X=0, Y=1\)</span>.</p>
<p>In light of the positive <span class="math inline">\(X,Y\)</span> correlation already observed, we can think of strategies 1 and 3 as “on-the-regression line” strategies, while strategies 2 and 4 are “off-the-regression line” strategies.</p>
<p><strong>Possible data</strong>. For each strategy, there are multiple possible sets of data that we could end up observing. In particular, the data we could end up with will be the <span class="math inline">\(X,Y\)</span> patterns we have already observed plus some pattern of <span class="math inline">\(M\)</span> observations. Thus, for instance, for strategy 1, we could end up observing the initial <span class="math inline">\(X,Y\)</span> pattern plus <span class="math inline">\(M=0\)</span> in one of the <span class="math inline">\(X=1, Y=1\)</span> cases, or the initial <span class="math inline">\(X,Y\)</span> pattern plus <span class="math inline">\(M=1\)</span> in one of the <span class="math inline">\(X=1, Y=1\)</span> cases. For strategy 3, we could observe four possible combinations of <span class="math inline">\(M\)</span> values, with <span class="math inline">\(M\)</span> being 0 or 1 in each of the cases.</p>
<p><strong>Probability of the data</strong>. We now calculate a probability of each possible data realization, given the model and the data that we have already observed. In practice, we do this in <code>CQtools</code> via simulation. Starting with the model together with our priors, we update our beliefs about <span class="math inline">\(\lambda\)</span> based on the previously observed data. This posterior now represents our <em>prior</em> for the purposes of the process tracing. In the present example, we are using the already-observed <span class="math inline">\(X,Y\)</span> correlation to update our beliefs about causal-type share allocations in the population, having seen the <span class="math inline">\(X,Y\)</span> data only. We then use this posterior to draw a series of <span class="math inline">\(\lambda\)</span> values.</p>
<p>Given that the ambiguity matrix gives us the mapping from causal types to data realizations, we can calculate for each <span class="math inline">\(lambda\)</span> draw the probability of each data possibility given that particular <span class="math inline">\(\lambda\)</span> and the strategy. We then average across repeated <span class="math inline">\(\lambda\)</span> draws. Since <span class="math inline">\(\lambda\)</span>’s are being drawn from our prior, we are automatically weighting more heavily those <span class="math inline">\(\lambda\)</span>’s that we believe to be most likely.</p>
<p><strong>Posterior on estimate given the data</strong>. For each data possibility, we can then use <code>CQtools</code> to ask what inference we would get from each data possibility, given whatever query we seek to answer, as well as the variance of that posterior. Examining the inferences from possible data-realizations, as we do below, can help us understand how the learning unfolds for different strategies.</p>
<p><strong>Expected posterior variance under each strategy</strong>. The quantity of ultimate interest is the posterior variance that we expect to end up with under each <em>strategy</em>. Calculating this expectation is now elementary as we have both the posterior variance arising from each data possibility and the probability of each data possibility (given our prior beliefs and the data already observed). The expected posterior variance is simply an average of the posterior variances under each data possibility, weighted by the probability of each data possibility. We can think of the expected gains from a strategy as the expected <em>reduction</em> in posterior variance arising from that strategy.</p>
<p>Complicated as the procedure might seem, it can all be done in code using a single command from the <code>CQtools</code> package.</p>
</div>
<div id="inferences-from-strategies-and-data-realizations" class="section level3">
<h3><span class="header-section-number">15.2.2</span> Inferences from Strategies and Data Realizations</h3>
<p>In Tables XXXXX, we examine how different process-tracing case-selection strategies will play out by looking at the inferences we would draw about different kinds of causal effects depending on the results of the process tracing.</p>
<p>Starting with the chain model, for the analyses displayed in Table XXXX, we assume that we have previously observed a positive <span class="math inline">\(X,Y\)</span> correlation in 6 cases (with 4 cases on the regression line, 2 cases off). Now we see what can happen for different queries when we implement each of the four case-selection strategies. The set of queries we are interested in are, what is the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> for:</p>
<ul>
<li>any case in the population</li>
<li>any <span class="math inline">\(X=1, Y=1\)</span> case in the population</li>
<li>any <span class="math inline">\(X=1, M=1, Y=1\)</span> case in the population</li>
<li>any <span class="math inline">\(X=0, Y=1\)</span> case in the population</li>
<li>any <span class="math inline">\(X=0, M=1, Y=1\)</span> case in the population</li>
</ul>
<div id="priors-chain-model" class="section level4">
<h4><span class="header-section-number">15.2.2.1</span> Priors (Chain model)</h4>
<p>In the top row, we see our pure prior on these queries before we have seen the <span class="math inline">\(X,Y\)</span> correlation — i.e., based strictly on the DAG and flat priors over nodal types. The story here is straightforward. We start out believing that, for the <span class="math inline">\(X \rightarrow M\)</span> relationship, the population is evenly divided across the four types, <span class="math inline">\(\theta^M_{00}, \theta^M_{01}, \theta^M_{10}, \theta^M_{11}\)</span> (so 0.25 share of each). Likewise for <span class="math inline">\(\theta^Y\)</span> in relation to the <span class="math inline">\(M \rightarrow Y\)</span> relationship. We can get a positive <span class="math inline">\(X,Y\)</span> effect from a causal type involving <span class="math inline">\(\theta^M_{01}\)</span> and <span class="math inline">\(\theta^Y_{01}\)</span> or from a causal type involving <span class="math inline">\(\theta^M_{10}\)</span> and <span class="math inline">\(\theta^Y_{10}\)</span>. Each of those causal types has a 0.125 probability, implying a 0.25 share of positive effects. A mirror-image of that logic gets us to a 0.25 share of negative effects, with the remaining 0.5 of the population comprising causal types that yield null effects (involving either a null effect at one or both steps in the chain). Thus, the expected effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> for a randomly drawn case from the population, given nothing but the model, is 0.</p>
<p>Moving across the row, we see our prior beliefs for cases with more specific features. For cases with <span class="math inline">\(X=1, Y=1\)</span>, our priors imply a positive effect 25% of the time.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> As we have flat priors over <span class="math inline">\(M\)</span>’s type and its effects on <span class="math inline">\(Y\)</span>, conditioning <span class="math inline">\(M\)</span>’s value leaves this belief unaffected. By a parallel logic, the model and flat priors imply the belief that 0.25 of all <span class="math inline">\(X=0, Y=1\)</span> cases to involve a negative effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>In the next row, we see how the initial set of 6 <span class="math inline">\(X,Y\)</span> observations shift our beliefs. In this model (as there is no confounding) a positive <span class="math inline">\(X,Y\)</span> correlation is evidence of a higher relative share of cases in which <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. This implies a larger expected effect for a randomly selected case as well as for an <span class="math inline">\(X=1, Y=1\)</span> case since we now think there are more cases where <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> than there are cases in which <span class="math inline">\(Y\)</span> is fixed at 1. (Again, conditioning on <span class="math inline">\(M\)</span>’s value has no effect since we still have no information to shift us off our flat priors relating to <span class="math inline">\(M\)</span>’s causes or effects.) Notably, however, our beliefs for an <span class="math inline">\(X=0, Y=1\)</span> case are unaffected by observing the positive correlation. To return for a moment to our handy <span class="math inline">\(a,b,c,d\)</span> typology, the reason is that the positive <span class="math inline">\(X,Y\)</span> correlation affects our beliefs about the share of <span class="math inline">\(b\)</span> types relative to <span class="math inline">\(a,c,\)</span> and <span class="math inline">\(d\)</span> types (with reference to the overall <span class="math inline">\(X rightarrow Y\)</span> effect), but it is uninformative about the relative shares of <span class="math inline">\(a\)</span> vs. <span class="math inline">\(d\)</span> types, the two types in contention for an <span class="math inline">\(X=0, Y=1\)</span> case. In the <span class="math inline">\(X,Y\)</span> data, the <span class="math inline">\(X=0, Y=1\)</span> case is equally likely to be an <span class="math inline">\(a\)</span> or a <span class="math inline">\(d\)</span>, which is exactly what our prior belief was about a random <span class="math inline">\(X=0, Y=1\)</span> case.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</div>
<div id="n1-strategies-chain-model" class="section level4">
<h4><span class="header-section-number">15.2.2.2</span> <span class="math inline">\(N=1\)</span> strategies (Chain model)</h4>
<p>Now, what can we learn by selecting a single case for process tracing, that is, the observation of the additional clue, <span class="math inline">\(M\)</span>? We assume here, specifically, that we observe <span class="math inline">\(M=1\)</span> when we go looking for <span class="math inline">\(M\)</span>. We can see in the third and fourth rows how our beliefs shift if we observe <span class="math inline">\(M=1\)</span>, respectively, in one case <em>on</em> the regression line (an <span class="math inline">\(X=Y=1\)</span> case) or in one case <em>off</em> the regression line (an <span class="math inline">\(X=1, Y=0\)</span> case). We see that we cannot learn anything about the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>—whether unconditionally, conditioning on <span class="math inline">\(X=Y=1\)</span>, or conditioning on <span class="math inline">\(X=0, Y=1\)</span>—from observing <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=Y=1\)</span> case. Nor can we learn about these quantities from process-tracing in a single off-the-line case. To see why, let’s first take the on-the-line strategy. Not having observed <span class="math inline">\(M\)</span> previously, we still have flat priors over the nodal types governing <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(M\)</span> and <span class="math inline">\(M\)</span>’s effect on <span class="math inline">\(Y\)</span>. That is to say, we still have no idea whether <span class="math inline">\(X\)</span>’s positive effect on <span class="math inline">\(Y\)</span> (where present) more commonly operates through a chain of positive effects or a chain of negative effects. Thus, the observation <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=1\)</span> case is equally consistent with a positive <span class="math inline">\(X \rightarrow Y\)</span> (to the extent that effect operates via linked positive effects) and with no <span class="math inline">\(X \rightarrow Y\)</span> effect (to the extent positive effects operate through linked negative effects). Observing <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=1\)</span> case therefore tells us nothing about the causal effect in the typical case or in the typical <span class="math inline">\(X=Y=1\)</span> case. Similarly, we have no idea whether <span class="math inline">\(X\)</span>’s negative effect on <span class="math inline">\(Y\)</span> (where present) operates through a positive-negative chain or a negative-positive chain, making <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=0\)</span> case equally consistent with a negative or null <span class="math inline">\(X \rightarrow Y\)</span> effect, yielding no information about whether a random <span class="math inline">\(X=0, Y=1\)</span> case has a negative or null effect. (By a similar logic, observing <span class="math inline">\(M=1\)</span> in the <span class="math inline">\(X=1, Y=1\)</span> case is uninformative about negative effects in an <span class="math inline">\(X=0, Y=1\)</span> case, and observing <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=0\)</span> case tells us nothing about positive effects in an <span class="math inline">\(X=1, Y=1\)</span> case.)</p>
<p>Interestingly, however, observing <span class="math inline">\(M=1\)</span> in a single case <em>can</em> tell us something about effects in <em>another</em> case in which <span class="math inline">\(M=1\)</span>. Recall that the <span class="math inline">\(X,Y\)</span> pattern tells us that (with respect to the <span class="math inline">\(X \rightarrow Y\)</span> relationship) there are relatively more <span class="math inline">\(b\)</span>’s than other types in the population. This means, in turn, that an <span class="math inline">\(X=1, Y=1\)</span> case is more likely to be a <span class="math inline">\(b\)</span> than a <span class="math inline">\(d\)</span>. If we now observe <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=1\)</span>—a case we think is probably a <span class="math inline">\(b\)</span>—we now have reason to believe that positive <span class="math inline">\(X \rightarrow Y\)</span> effects operate through a positive <span class="math inline">\(X \rightarrow M\)</span> effect followed by a positive <span class="math inline">\(M \rightarrow Y\)</span> effect. (And had we seen <span class="math inline">\(M=0\)</span> in this case, we’d believe positive effects more likely operate through a negative effect followed by a positive effect.) Put differently, we now believe that <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=1\)</span> case is a clue that that case is likely a <span class="math inline">\(b\)</span> type—and our belief about the causal effect in an <span class="math inline">\(X=1, M=1, Y=1\)</span> case shifts upward. It shifts upward in two senses.</p>
<p>Thus, while we do not learn about the overall population from an N=1 process-tracing exercise, process-tracing in that single case does make <span class="math inline">\(M\)</span> <em>informative</em> about <em>other</em> cases. We can see this by comparing our beliefs about an <span class="math inline">\(X=1, M=1, Y=1\)</span> case in the row in which we have only observed the <span class="math inline">\(X,Y\)</span> correlation to our beliefs about that same kind of case in the row in which we have process-traced in an on-the-line case. While in the first instance conditioning on <span class="math inline">\(M=1\)</span> has no impact on the estimated causal effect (because we haven’t previously learned about <span class="math inline">\(M\)</span>), it does have an impact in the latter instance.</p>
<p>We also see that our belief about the causal effect in an <span class="math inline">\(X=0, M=1, Y=1\)</span> case shifts upward. Why? Updating toward the belief that positive effects — which we believe to be relatively common — more often operate via linked positive positive effects implies that <span class="math inline">\(X\)</span> more often has a positive than a negative effect on <span class="math inline">\(M\)</span>. Yet for an <span class="math inline">\(X=0, M=1, Y=1\)</span> to be a case with a negative causal effect, <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(M\)</span> would have to be negative. Thus, interestingly, evidence from <em>on</em> the regression line can inform inferences about cases <em>off</em> the regression line via information about mediating processes.</p>
<p>FLAG: Haven’t figured out why seeing M=1 in an X=1, Y=0 case reduces the estimated causal effect for an X=1, M=1, Y=1 case relative to just seeing the X,Y pattern. If we see M=1 in this off-line case, we have evidence in favor of X having a positive effect on M, and M having a negative effect on Y. So this should generally speak against positive effects in X=1, M=1, Y=1 cases. But if we’d seen M=0, wouldn’t this have the same effect? It would suggest negative X-&gt;M effects and positive M-&gt;Y effects, which would also speak against a positive effect in an X=1, M=1, Y=1 case. So how does observing M help?</p>
<p>We see even stronger learning about an off-the-line <span class="math inline">\(X=0, M=1, Y=1\)</span>, however, if we process trace off-the-line. The observation of <span class="math inline">\(M=1\)</span> in an <span class="math inline">\(X=1, Y=0\)</span> case counts as evidence against the operation of <em>both</em> steps in the causal chain through which <span class="math inline">\(X\)</span> could have a negative effect on <span class="math inline">\(Y\)</span> in an <span class="math inline">\(X=0, M=1, Y=1\)</span> case: it suggests that <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(M\)</span> is more likely positive than negative <em>and</em> that <span class="math inline">\(M\)</span>’s effect on <span class="math inline">\(Y\)</span> is more likely negative—precisely the opposite of what would have to be true for a negative effect to emerge in this kind of case. Thus, we now think this kind of case is less likely to involve a causal effect.</p>
</div>
<div id="n2-strategies-chain-model" class="section level4">
<h4><span class="header-section-number">15.2.2.3</span> <span class="math inline">\(N=2\)</span> Strategies (Chain model)</h4>
<p>Next, we consider the process tracing of <em>two</em> of our cases. Now, because we are observing <span class="math inline">\(M\)</span> in two cases, we can learn from the variation in <span class="math inline">\(M\)</span> across these cases—or, more specifically, from its covariation with <span class="math inline">\(X\)</span> aand with <span class="math inline">\(Y\)</span>. In other words, there is a critical difference between process tracing one case and process tracing two cases. When we only process trace one case in a setup like this one, we do not learn about causal effects in the cases we process-trace because we have no information about intermediate causal effects (e.g., whether they are more likely positive or negative). Thus, while we have pointed out that observing <span class="math inline">\(M\)</span> within a case can lend <span class="math inline">\(M\)</span> probative value for <em>other</em> cases in which we might choose to observe <span class="math inline">\(M\)</span>, <span class="math inline">\(M\)</span> has no probative value <em>for</em> that one case. In contrast, if we observe <span class="math inline">\(M\)</span> in two or more cases, we <em>do</em> learn about causal effects for those cases because of the leverage provided by observing covariation between the process-tracing clue and other variables.</p>
<p>We consider first, in the 5th row, a situation in which we look at <span class="math inline">\(M\)</span> in two on-the-line cases, an <span class="math inline">\(X=Y=0\)</span> case and an <span class="math inline">\(X=Y=1\)</span> case, and where we observe <span class="math inline">\(M=0\)</span> in the first case and <span class="math inline">\(M=1\)</span> in the second case. What we are seeing, then, is that <span class="math inline">\(M\)</span> covaries with both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Seeing that the mediator covaries across cases with both the cause and the outcome is evidence of a causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Since the observed pattern covariation is consistent with a positive effect (linked positive effects), our belief about the unconditional effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> goes up. For the same reason, so too does our belief about the causal effect conditional on <span class="math inline">\(X=1, Y=1\)</span>.</p>
<p>We see an even bigger boost in our estimate of the effect in an <span class="math inline">\(X=1, Y=1\)</span> case conditional on <span class="math inline">\(M\)</span> also being 1. Two things are generating this upward updating. First, just as for the unconditional estimate and the estimate conditional on <span class="math inline">\(X=1, Y=1\)</span>, the process tracing generates a stronger belief that <span class="math inline">\(X\)</span> generally has a positive effect on <span class="math inline">\(Y\)</span>. Second, as for the <span class="math inline">\(N=1\)</span> process tracing, seeing <span class="math inline">\(M=1\)</span> in two on-the-line cases (which we already believe are mostly positive-effect cases) makes <span class="math inline">\(M\)</span> informative as a clue in favor of a positive effect—indeed, more informative than if we’d only seen <span class="math inline">\(M=1\)</span> in one on-the-line case.</p>
<p>Moving across the columns, we also see that process-tracing the on-the-line cases and finding evidence consistent with positive effects in those cases leads us to update in favor of <em>negative</em> effects as well, conditional on <span class="math inline">\(X=0, Y=1\)</span> (including conditional on <span class="math inline">\(M=1\)</span>). Why is that?</p>
<p>Our answer is somewhat speculative, but we think there are two things going on. One is simply that the correlations between <span class="math inline">\(M\)</span> and <span class="math inline">\(X\)</span> and between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> across the two process-traced cases constitutes evidence of <em>effects</em>, period, at the intervening steps—a necessary condition for <em>any</em> <span class="math inline">\(X \rightarrow Y\)</span> effect, positive or negative. So, for an <span class="math inline">\(X=0, Y=1\)</span> case, a stronger belief that <span class="math inline">\(X\)</span> has some effect on <span class="math inline">\(M\)</span> and that <span class="math inline">\(M\)</span> has some effect on <span class="math inline">\(Y\)</span> implies a strong belief in a negative <span class="math inline">\(X \rightarrow Y\)</span> effect.</p>
<p>The second thing that is probably going on is constraint imposed by prior beliefs. Having seen the <span class="math inline">\(X,Y\)</span> data, we have previously formed a belief that the <em>average</em> effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is 0.05. When we find evidence in favor of positive effects, we update to a set of beliefs that are a compromise between the new data and prior beliefs. On the one hand, we upwardly update on the unconditional <span class="math inline">\(X \rightarrow Y\)</span> effect. On the other hand, our beliefs are constrained from moving <em>too</em> far away from an unconditional effect of 0.05. Recall that, in a binary setting, the average effect in a population is the share of cases with positive effects minus the share with negative effects. Thus, the conservative influence of our priors means that, as we upwardly update on positive effects, we also upwardly update our beliefs about the prevalence of <em>negative</em> effects, though not by as much, with the result that our beliefs about the unconditional effect do not shift as much as they would if we had had flat priors. By anchoring our beliefs about average effects, then, the prior <span class="math inline">\(X,Y\)</span> evidence means that any evidence in favor of positive effects also constitutes evidence in favor of negative effects.</p>
<p>To put this point another way, while we learn <em>directly</em> about positive effects from process-tracing the on-the-line cases since these are cases in which positive effects can possible occur. And we then learn <em>indirectly</em> about negative effects from these cases <em>via</em> the prior-imposed constraint on the average effect.</p>
<p>Now, supppose we chose the same case-selection strategy—we examine two on-the-line cases, from opposite cells—but instead of observing <span class="math inline">\(M\)</span> covary with <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, <span class="math inline">\(M=1\)</span> in both cases. We see the results in the 6th row. This data-realization, under the same strategy, represents clear evidence <em>against</em> positive effects, while also counting against <em>any</em> effects. We have observed that <span class="math inline">\(M\)</span> is unresponsive to changes in <span class="math inline">\(X\)</span>, and that <span class="math inline">\(Y\)</span> varies without <span class="math inline">\(M\)</span> varying—null effects at both stages of the chain. Now we see that our posterior on the unconditional effect drops to 0, and we see a sharp movement toward zero conditional on <span class="math inline">\(X=1, Y=1\)</span>, representing our updated belief that there are few positive effects. Interestingly, whereas conditioning additionally on <span class="math inline">\(M=1\)</span> generated in a <em>higher</em> estimated effect when we observed <span class="math inline">\(M\)</span> correlated with <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, it generates a <em>lower</em> estimated effect when we observe <span class="math inline">\(M=1\)</span> in both cases. One reason is likely that we have updated our belief about <span class="math inline">\(\theta^M\)</span> such that we now believe that <span class="math inline">\(X=1, M=1\)</span> cases are more likely to be <span class="math inline">\(\theta^M_{11}\)</span>’s (no effect) than <span class="math inline">\(\theta^M_{01}\)</span>’s. We have not similarly updated with respect to <span class="math inline">\(X=1, M=0\)</span> cases and the <span class="math inline">\(\theta^M_{00}\)</span>’s than <span class="math inline">\(\theta^M_{10}\)</span> shares. Thus, for an <span class="math inline">\(X=1,Y=1\)</span> case, additionally specifying that <span class="math inline">\(M=1\)</span> implies an even higher likelihood that the case contains a null effect.</p>
<p>For <span class="math inline">\(X=0, Y=1\)</span> cases, we see similar movements toward zero, reflecting the fact the <span class="math inline">\(M\)</span> pattern speaks against any effects. And, again, the movement is stronger when we condition on <span class="math inline">\(M=1\)</span>.</p>
<p>Finally, we consider an off-the-line <span class="math inline">\(N=2\)</span> strategy and two possible data-realizations under that strategy. We select for process tracing one <span class="math inline">\(X=1, Y=0\)</span> case and one <span class="math inline">\(X=0, Y=1\)</span> case. The two possible data-realizations we consisder are that <span class="math inline">\(M\)</span> varies positively with <span class="math inline">\(X\)</span> across the two cases (7th row) or that <span class="math inline">\(M=1\)</span> in both cases (8th row). One thing we can observe immediately is that we get less leverage from this strategy: across all columns, the difference in our posterior beliefs between the two data-realizations is smaller than it is for the two data-realizations of the on-the-line strategy. For instance, while we see <span class="math inline">\(0.08\)</span> swing in the unconditional effect under the on-the-line strategy, we see only a <span class="math inline">\(0.02\)</span> swing under the off-the-line strategy.</p>
<p>Unpacking this further, we know that we can learn directly about <em>negative</em> <span class="math inline">\(X \rightarrow Y\)</span> effects through process-tracing off-the-line cases. If we see <span class="math inline">\(M\)</span> covary positively with <span class="math inline">\(X\)</span> across these two cases—which also means covarying negatively with <span class="math inline">\(Y\)</span>—we have found evidence in favor of the operation of negative <span class="math inline">\(X \rightarrow Y\)</span> effects. Hence the movement in our posterior away from 0 when we condition on <span class="math inline">\(X=0, Y=1\)</span>. We also see updating away from zero for positive effects (conditioning on <span class="math inline">\(X=1, Y=1\)</span>), though by a smaller amount (using the <span class="math inline">\(X,Y\)</span>-data only as our baseline). Again, some of this movement is likely attributable to the constraint imposed by the prior generated from the <span class="math inline">\(X,Y\)</span> data. Some of this updating is also likely attributable to the fact that we have found evidence against null intermediate effects.</p>
<p>Curiously, under this strategy and data-realization, our beliefs about effects conditional on <span class="math inline">\(X=0, M=1, Y=1\)</span> move in the <em>opposite</em> direction from our beliefs conditional just on <span class="math inline">\(X=0,Y=1\)</span>. Why might this be? This is likely because of the way in which the process-tracing has lent probative value to <span class="math inline">\(M\)</span>. The pattern of <span class="math inline">\(M\)</span> data is most consistent with any negative <span class="math inline">\(X \rightarrow Y\)</span> effect operating via a <em>positive</em> <span class="math inline">\(X \rightarrow M\)</span> effect followed by a <em>negative</em> <span class="math inline">\(M \rightarrow Y\)</span> effect. Yet the intermediate effects would have to have the opposite sign for <span class="math inline">\(X=0, M=1, Y=1\)</span> to be consistent with an <span class="math inline">\(X \rightarrow Y\)</span> effect. In other words, <span class="math inline">\(M=1\)</span> rules out the likeliest way in which an <span class="math inline">\(X=0, Y=1\)</span> case could contain an effect.</p>
<p>If on the other hand we observe <span class="math inline">\(M=1\)</span> in both off-the-line cases, we have found “direct” evidence against the operation of negative effects. Hence the the strong movement of our posterior toward 0 for effects conditional on <span class="math inline">\(X=0, Y=1\)</span> and, even more so, if also conditioning on <span class="math inline">\(M=1\)</span> (since we now have evidence that <span class="math inline">\(M=1\)</span> cases are more likely <span class="math inline">\(\theta^M_{11}\)</span>’s than <span class="math inline">\(\theta^M_{01}\)</span>’s). Likewise, we see upward movement in our posterior on the unconditional effect and, for reasons discussed earlier, in our posterior on positive effects (conditioning on <span class="math inline">\(X=1, Y=1\)</span>).</p>
<p>The remaining puzzle is why the learning from the off-the-line strategy is weaker than the learning from the on-the-line strategy. Both strategies generate symmetrical opportunities to observe an <span class="math inline">\(M\)</span> pattern that is consistent or inconsistent with causal effects. We believe there are two reasons, both relating to the fact that we learn “directly” about positive effects from the on-the-line strategy (and “indirectly” about negative effects) and that we learn “directly” about negative effects (and “indirectly” about positive effects) from the off-the-line strategy.</p>
<p>The first, more mechanical reason is that we start, given the <span class="math inline">\(X,Y\)</span> data, with a higher and higher-variance posterior on the prevalence of positive effects as compared to negative effects. So there is simply more scope for the data to influence our beliefs about positive effects, and the on-the-line cases are those in which we can learn “directly” about positive effects. Note, for instance, the <span class="math inline">\(0.17\)</span> differential in beliefs about effects conditional on <span class="math inline">\(X=1, Y=1\)</span> depending on what we observe under the on-the-line strategy, as compared to the <span class="math inline">\(0.1\)</span> differential for effects conditional on <span class="math inline">\(X=0, Y=1\)</span> under the off-the-line strategy.</p>
<p>The second reason is prevalence: given the <span class="math inline">\(X,Y\)</span> correlation, we believe that there are more cases out there that potentially contain positive effects than there are cases that potentially contain negative effects. Thus, <em>whatever</em> it is we learn about positive effects is going to have a bigger impact on our beliefs about the population as a whole than is whatever we learn about negative effects. Since on-the-line case yield the most direct learning about positive effects, they are therefore the most informative about the population.</p>
<p>Note, importantly, that this finding is consistent with recommendations in the literature to investigate on-the-line cases (<span class="citation">Lieberman (<a href="#ref-Lieberman2005nested" role="doc-biblioref">2005</a>)</span>, <span class="citation">Goertz (<a href="#ref-goertz2017multimethod" role="doc-biblioref">2017</a>)</span>).<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Yet, the reason is very different. Lieberman and Goertz emphasize the importance of examining cases where the theorized mechanism connecting <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> might potentially play out, arguing that this would be in the set of cases that conform to theory in their <span class="math inline">\(X,Y\)</span> values. We would emphasize that, in the causal-model framework, one <em>can</em> learn about both overall effects and intermediate effects from off-the-line cases. The reason why on-the-line cases is simply that they are more <em>representative</em> about the universe about which we aim to learn (assuming we want to learn about the population from which the <span class="math inline">\(X,Y\)</span> pattern is drawn).</p>
</div>
<div id="two-path-model" class="section level4">
<h4><span class="header-section-number">15.2.2.4</span> Two-path model</h4>
<p>Case-selection strategies depend on the model. To see this, consider the results of the same analysis conducted for a two-path model in which <span class="math inline">\(X\)</span> can have both an indirect effect on <span class="math inline">\(Y\)</span> via <span class="math inline">\(M\)</span> and a direct effect on <span class="math inline">\(Y\)</span>. We first examine a version with flat priors over all nodal types and then a version in which we impose some monotonicity restrictions.</p>
<p>In Table XXXXXX, we see the results of the case-selection exercise for a two-path model with flat priors. The takeaway here is simple: it does not matter what kind of case(s) we choose for process-tracing because nothing can be learned from observing <span class="math inline">\(M\)</span>. We learn about effects from the <span class="math inline">\(X,Y\)</span> data. But, after that, adding observations <span class="math inline">\(M\)</span> yields no change in beliefs. The reason, we think, is the combination of the double pathway and uninformtativeness of priors. We go in with a flat distribution across nodal types <span class="math inline">\(\theta^M\)</span> and nodal types <span class="math inline">\(\theta^Y\)</span>. We then acquire some information on the <span class="math inline">\(X \rightarrow Y\)</span> effect from the <span class="math inline">\(X,Y\)</span> data, but those effects are equally consistent with all possible pathways—direct, indirect, or combined. Suppose we then find evidence that cuts against the operation of the indirect pathway: <span class="math inline">\(M=1\)</span> is observed in two on-the-line cases with different <span class="math inline">\(X\)</span> values. So we downgrade the probability of <span class="math inline">\(\theta^M_{01}\)</span> relative to <span class="math inline">\(\theta^M_{11}\)</span>. However, we are still able to preserve our prior on the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> (whether conditional or unconditional) by updating our beliefs about <span class="math inline">\(\theta^Y\)</span> in a manner that places greater weight on direct effects. To put the point in the language of levels of theory: high flexibility in our lower-level beliefs impedes learning about higher-level quantities from observations at the lower level. This is true regardless of which quadrants we select our cases from.</p>
<p>The situation changes, however, if we come in with informative beliefs at the lower level. In Table XXXXXXX, we see results for a two-path model with restrictions, such that negative <span class="math inline">\(X \rightarrow M\)</span> and negative <span class="math inline">\(M \rightarrow Y\)</span> effects are ruled out.</p>
<p>FLAG: Cannot yet see why we learn more from the restricted 2-path model than from the flat 2-path. Yes, we can learn from n=1 about the indirect path. But in both cases, we can still have compensating updating on the direct path for anything we learn about the indirect path. In fact, the prior probability of positive effects on each path is very similar across the two models. Ignoring interactions, for indirect path, b share is like 1/8 in flat model, and 1/9 in restricted, vs. 1/4 for direct path. Is it just that the learning about the indirect path is stronger with restricted priors because M starts out as informative about the indirect path? So the learning about the indirect path more easily swamps the prior?</p>
<p>FLAG: Incorporate as needed above and below any implications of Jeffreys priors.</p>
</div>
<div id="moderation-models" class="section level4">
<h4><span class="header-section-number">15.2.2.5</span> Moderation models</h4>
</div>
</div>
</div>
<div id="logic-of-strategy-comparison" class="section level2">
<h2><span class="header-section-number">15.3</span> Logic of strategy comparison</h2>
<p>Consider a situation in which one has access to <span class="math inline">\(X,Y\)</span> data on just six cases of the form:</p>
<table>
<thead>
<tr class="header">
<th align="left">event</th>
<th align="right">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X0Y0</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">X1Y0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">X0Y1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">X1Y1</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>We want to examine data on <span class="math inline">\(M\)</span> for two of these cases and are wondering about what strategy we should use to select the cases. We are considering three strategies:</p>
<ul>
<li>Strategy <span class="math inline">\(A\)</span> chooses two cases on the regression line (one in the <span class="math inline">\(X=Y=0\)</span> cell and one in the <span class="math inline">\(X=Y=1\)</span> cell)</li>
<li>Strategy <span class="math inline">\(B\)</span> chooses off the regression line</li>
<li>Strategy <span class="math inline">\(C\)</span> selects on the dependent variable – choosing cases with <span class="math inline">\(X=1, Y = 1\)</span>.</li>
</ul>
<p>Different strategies yield different possible types of data. Each one of these is likely to arise with a different probability and is associated with a different inference. Drawing on the prior beliefs embedded in a causal model, we can thus assess the <em>expected</em> posterior variance associated with each strategy.</p>
<p>For each of these possible strategies we can assess the posterior that we would obtain for each type of data we might observe.</p>
<p>The data possibilities, probabilities of each, and inferences given each, are shown in Table <a href="caseselection.html#tab:chselillustration">15.1</a>.</p>
<table>
<caption><span id="tab:chselillustration">Table 15.1: </span>Each column shows a possible distribution of data that can be generated from a given strategy. We calculate the probability of each data possibility, given the data seen so far, and the posterior variance associated with each one.</caption>
<thead>
<tr class="header">
<th align="left">event</th>
<th align="left">A1</th>
<th align="left">A2</th>
<th align="left">A3</th>
<th align="left">A4</th>
<th align="left">B1</th>
<th align="left">B2</th>
<th align="left">B3</th>
<th align="left">B4</th>
<th align="left">C1</th>
<th align="left">C2</th>
<th align="left">C3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">X0M0Y0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">X0M0Y1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">X0M1Y0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">X0M1Y1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">X0Y0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left">X0Y1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">X1M0Y0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">X1M0Y1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">2</td>
<td align="left">1</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">X1M1Y0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">X1M1Y1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">X1Y0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">X1Y1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">0</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">Probability</td>
<td align="left">0.171</td>
<td align="left">0.03</td>
<td align="left">0.625</td>
<td align="left">0.174</td>
<td align="left">0.27</td>
<td align="left">0.231</td>
<td align="left">0.23</td>
<td align="left">0.268</td>
<td align="left">0.09</td>
<td align="left">0.242</td>
<td align="left">0.668</td>
</tr>
<tr class="even">
<td align="left">Posterior mean</td>
<td align="left">0.078</td>
<td align="left">0.041</td>
<td align="left">0.171</td>
<td align="left">0.078</td>
<td align="left">0.128</td>
<td align="left">0.141</td>
<td align="left">0.143</td>
<td align="left">0.131</td>
<td align="left">0.046</td>
<td align="left">0.089</td>
<td align="left">0.161</td>
</tr>
<tr class="odd">
<td align="left">Posterior variance</td>
<td align="left">0.006</td>
<td align="left">0.002</td>
<td align="left">0.029</td>
<td align="left">0.006</td>
<td align="left">0.016</td>
<td align="left">0.02</td>
<td align="left">0.02</td>
<td align="left">0.017</td>
<td align="left">0.002</td>
<td align="left">0.008</td>
<td align="left">0.026</td>
</tr>
</tbody>
</table>
<p>Each of the first two strategies generates one of four different data patterns. The third data strategy generates up to three data patterns. None of these data patterns overlap across strategies.
From the calculated probability of each data type, given the data seen so far, and the posterior variance given each data realization, the implied <em>expected</em> variance is easily calculated. These are summarized below:</p>
<table>
<thead>
<tr class="header">
<th align="left">Strategy</th>
<th align="right">Variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Online</td>
<td align="right">0.015</td>
</tr>
<tr class="even">
<td align="left">Offline</td>
<td align="right">0.017</td>
</tr>
<tr class="odd">
<td align="left">X=1, Y=1</td>
<td align="right">0.015</td>
</tr>
</tbody>
</table>
<p>In this example, we see that we would expect to be better off—in the sense of having less posterior uncertainty—by focusing her process-tracing efforts where a greater share of the population of cases lies: on the regression line.</p>
<p>Why is this?</p>
<p>For intuition consider first the case with flat prior data:</p>
<ul>
<li><p>if we examine two cases in different quadrants <em>on the diagonal</em> (one <span class="math inline">\(X=Y=0\)</span> case and one <span class="math inline">\(X=Y=1\)</span> case) :</p>
<ul>
<li>if we find that <span class="math inline">\(M\)</span> is the same in the two cases then we increase our belief that <span class="math inline">\(X\)</span> has no effect at all on <span class="math inline">\(Y\)</span> and reduce our confidence that <span class="math inline">\(X\)</span> had a positive or a negative effect on <span class="math inline">\(Y\)</span>. Since we are looking on the regression line however, our confidence that <span class="math inline">\(X\)</span> had a <em>positive</em> effect on <span class="math inline">\(Y\)</span> is more strongly reduced, producing a posterior centered on a small negative effect.</li>
<li>Conversely if we see that <span class="math inline">\(M\)</span> is different in the two cases, then we have a correlation of the same sign between both <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> and between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> cases. We increase our confidence that <span class="math inline">\(X\)</span> mattered for <span class="math inline">\(Y\)</span> in general an din particular that it had a positive effect, resulting in a posterior centered on a small positive ATE.</li>
</ul></li>
<li><p>if we examine two cases in different quadrants <em>off the diagonal</em> (one <span class="math inline">\(X=0, Y=1\)</span> case and one <span class="math inline">\(X=1, Y=0\)</span> case) :</p>
<ul>
<li>if we find that <span class="math inline">\(M\)</span> is the same in the two cases then we increase our belief that <span class="math inline">\(X\)</span> has no effect at all on <span class="math inline">\(Y\)</span> and reduce our confidence that <span class="math inline">\(X\)</span> had a negative effect <span class="math inline">\(Y\)</span> (producing a posterior centered on a small positive effect).</li>
<li>Conversely if we see that <span class="math inline">\(M\)</span> is different in the two cases, then we have a correlation (of different signs) between both <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> and between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> cases. We increase our confidence that <span class="math inline">\(X\)</span> mattered for <span class="math inline">\(Y\)</span> in general and in particular that it had a negative effect, resulting in a posterior centered on a small negative ATE.</li>
</ul></li>
<li><p>If we examine data conditioning on the value of <span class="math inline">\(X\)</span> but with variation on <span class="math inline">\(Y\)</span> (for instance <span class="math inline">\(X=1, Y=0\)</span> and <span class="math inline">\(X=1, Y=1\)</span>)
data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in <span class="math inline">\(M\)</span> is more consistent with <span class="math inline">\(M\)</span> being responsive to <span class="math inline">\(X\)</span> and thus the chances that <span class="math inline">\(X\)</span> matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged. FLAG work though intuition more</p></li>
<li><p>If we examine data conditioning on the value of <span class="math inline">\(Y\)</span> but with variation on <span class="math inline">\(X\)</span> (for instance <span class="math inline">\(X=0, Y=1\)</span> and <span class="math inline">\(X=1, Y=1\)</span>)
data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in <span class="math inline">\(M\)</span> is more consistent with <span class="math inline">\(M\)</span> being responsive to <span class="math inline">\(X\)</span> and thus the chances that <span class="math inline">\(X\)</span> matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged.</p></li>
</ul>
<p>For correlated data similar logics apply, but the effects are stronger for evidence on the regression line. The reason is that given correlated data we believe there are more units with positive effects than negative effects. When we find evidence against causal relations on the regression line that reduces our confidence for types with positive effects more than for types with negative effects and teh difference between teh shares with positive effects and negative eeffects smaller due to the fact that the beliefs in the shares with negative effects is not so strongly reduced. Wehen we find evidence for causal relations this magnifies teh difference between beliefs in shares positive and shares negatives; these effects are magnified however since our confidence for the positive effects change more than for the negative effects, since we are examining cases on the regression line. Conversely when examining cases of teh regression line, the two forces offset each other.</p>
</div>
<div id="explorations" class="section level2">
<h2><span class="header-section-number">15.4</span> Explorations</h2>
<p>Using the same basic logic we can explore performance across a wider range of strategies that might be employed under different conditions.</p>
<p>The qualitative case-selection literature has identified a range of possible strategies for choosing cases for in-depth analysis. These include, for instance, selecting for variation on <span class="math inline">\(X\)</span> (KKV), selecting for variation on <span class="math inline">\(Y\)</span>, selecting cases on the regression line (Seawright and Gerring, Lieberman), and selecting off the regression line (Seawright and Gerring, Seawright 2017, Lieberman).[These authors view selection off the regression line as best for arriving at inductive insight. We address this strategy primarily to show the contrast with the on-the-line strategy.] While we have not seen it advocated elsewhere, we might add to this list the strategy of selecting cases that are representative in their <span class="math inline">\(X,Y\)</span> values of the larger set of cases from which we are selecting. (FLAG: insert proper citations). While it is difficult to clearly distinguish these strategies from each other with a small initial set of <span class="math inline">\(X, Y\)</span> cases, we can do so readily if we start with a larger set of <span class="math inline">\(X,Y\)</span> cases.</p>
<p>In Table <a href="#caseselectlots"><strong>??</strong></a>, we show the results of diagnoses of each of these five classes of strategies, assuming that we will be process-tracing 6 cases. In each diagnosis we start with 500 <span class="math inline">\(X, Y\)</span> cases, with 100 <span class="math inline">\(X=Y=0\)</span> cases, 200 <span class="math inline">\(X=Y=1\)</span> cases, 130 <span class="math inline">\(X=0, Y=1\)</span> cases, and 70 <span class="math inline">\(X=1, Y=0\)</span> cases. The regression line here represents a positive association. We work with the same model and priors as above. Importantly, this means that the results we show here are not <em>general</em> evaluations of these strategies, but contingent on this particular model and set of priors. And that is precisely our point: optimal case-selection will always hinge on our model, a claim that we demonstrate further below.</p>
<div id="procedure-1" class="section level3">
<h3><span class="header-section-number">15.4.1</span> Procedure</h3>
<p>The procedure requires as inputs (i) a causal model, (ii) any data we have already observed, and (iii) the causal query we seek to answer.</p>
<p>The general intuition is that we can use the causal model and any previously observed data to estimate what observations we are more or less likely to make under a given case-selection strategy, and then figure out how far off from the (under the model) true estimand we can expect to be under the strategy, given whatever causal question we seek to answer.</p>
<p>Suppose that we want to estimate the average treatment effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a population and have initially observed <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> data on a set of cases.</p>
<p>Suppose that we are now considering gathering process-tracing evidence for one of these cases to inform our estimate of the ATE. There are many different case-selection strategies we might pursue, and each of these can give rise to different possible data and thus to different possible conclusions. What should we do?</p>
<p><strong>DAG</strong>. We start, as always, with a DAG representing our beliefs about which variables we believe to be direct causes of other variables. For the current illustration, suppose that we are operating with a simple mediation model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>.</p>
<p><strong>Given data.</strong> If we have already observed something in a set of cases, we can use this information to condition our strategy for searching for further information. For instance, if we have observed <span class="math inline">\(X\)</span>’s and <span class="math inline">\(Y\)</span>’s value in a set of cases, we might select cases for process tracing based on their values of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Further, what we have already observed in the cases may constrain what possible data we could end up with once we have collected the additional (process tracing) data.</p>
<p><strong>Priors</strong>. As when conducting mixed-method inference, we can set qualitative restrictions and/or differential quantitative weights on the (possibly conditional) nodal types in the model. And we can indicate our uncertainty over the latter, by setting the <span class="math inline">\(\alpha\)</span> parameters of the relevant Dirichlet distributions. For the current example, let us define restrictions at both the <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> nodes, positing beliefs that <span class="math inline">\(X\)</span> never has a negative effect on <span class="math inline">\(M\)</span> and that <span class="math inline">\(M\)</span> never has a negative effect on <span class="math inline">\(Y\)</span>. Let us further assume that we have flat priors over the remaining nodal types and posit similar assignment propensities for all types (no unobserved confounding).</p>
<p><strong>Query</strong>. We define our query. This might, for instance, be the share of cases in the population in which <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>; or it might be <span class="math inline">\(X\)</span>’s average effect on <span class="math inline">\(Y\)</span>. We can use the general procedure to identify case-selection strategies for any causal query that can be defined on a DAG. And, importantly, the optimal case-selection strategy may depend on the query. For instance, the best case-selection strategy for estimating the average causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> may not be the same as the best strategy for figuring out for what proportion of the population <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>.</p>
<p><strong>Define one or more strategies</strong>. A strategy is defined, generically, as the search for data on a given set of <em>nodes</em>, in a given <em>number</em> of cases randomly selected <em>conditional</em> on some information we already have about potential cases. Let us assume here that our strategy will involve uncovering <span class="math inline">\(M\)</span>’s value in 1 case—but we are wondering how to choose this case. Consider four possible strategies, conditional on the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values that we already know. We could do process tracing on a randomly selected <span class="math inline">\(X=1, Y=1\)</span> case, a randomly selected <span class="math inline">\(X=0, Y=0\)</span> case, the <span class="math inline">\(X=1, Y=0\)</span> case, or the <span class="math inline">\(X=0, Y=1\)</span> case. We itemize this set of possible strategies in the first column in Table <a href="#tab:caseselect1"><strong>??</strong></a>.</p>
<p><strong>Possible data</strong>. For each strategy, there are multiple possible sets of data that we could end up observing. In particular, the data we could end up with will be the <span class="math inline">\(X,Y\)</span> patterns we have already observed plus <em>either</em> <span class="math inline">\(M=0\)</span> <em>or</em> <span class="math inline">\(M=1\)</span> in the case that our strategy leads us to select for process tracing. We represent the data possibilities (showing just the possible <span class="math inline">\(M\)</span> values) in the second column in Table <a href="#tab:caseselect1"><strong>??</strong></a>. Thus, for instance, for a strategy in which we choose a random <span class="math inline">\(X=1, Y=1\)</span> case, we could end up observing the initial <span class="math inline">\(X,Y\)</span> pattern plus <span class="math inline">\(M=0\)</span> in one of the <span class="math inline">\(X=1, Y=1\)</span> cases, or the initial <span class="math inline">\(X,Y\)</span> pattern plus <span class="math inline">\(M=1\)</span> in one of the <span class="math inline">\(X=1, Y=1\)</span> cases.</p>
<p><strong>Probability of the data</strong>. We now calculate a probability of each possible data realization, given the model and the data (the <span class="math inline">\(X\)</span>’s and <span class="math inline">\(Y\)</span>’s) that we have already observed. In practice, we do this in <code>CQtools</code> via simulation. Starting with the model together with our priors, we update our beliefs about <span class="math inline">\(\lambda\)</span> based on the initial <span class="math inline">\(X,Y\)</span> data. This posterior now represents our <em>prior</em> for the purposes of the process tracing; it represents what we believe about causal-type share allocations in the population, having seen the <span class="math inline">\(X,Y\)</span> data only. We then use this posterior to draw a series of <span class="math inline">\(\lambda\)</span> values.</p>
<p>Given that the ambiguity matrix gives us the mapping from causal types to data realizations, we can calculate for each <span class="math inline">\(lambda\)</span> draw the probability of each data possibility given that particular <span class="math inline">\(\lambda\)</span> and the strategy. We then average across repeated <span class="math inline">\(\lambda\)</span> draws. (Since <span class="math inline">\(\lambda\)</span>’s are being drawn from our prior, we are automatically weighting more heavily those <span class="math inline">\(\lambda\)</span>’s that we believe to be most likely.) We show the data probabilities in the third column of Table <a href="#tab:caseselect1"><strong>??</strong></a>: one probability for each data-possibility given each strategy.</p>
<p><strong>Posterior variance on estimate given the data</strong>. For each data possibility, we can then use <code>CQtools</code> to ask what inference we would get from each data possibility, given whatever query we seek to answer. What we are in fact interested in for the purposes of case selection is the <em>variance</em> of the posterior. We indicate in the fourth column of Table <a href="#tab:caseselect1"><strong>??</strong></a> the posterior variance for each possible data realization.</p>
<p><strong>Expected posterior variance under each strategy</strong>. The quantity of ultimate interest is the posterior variance that we expect to end up with under each <em>strategy</em>. Calculating this expectation is now elementary as we have both the posterior variance arising from each data possibility and the probability of each data possibility (given our prior beliefs and the data already observed). The expected posterior variance is simply an average of the posterior variances under each data possibility, weighted by the probability of each data possibility. The final column provides the expected posterior variances, one for each strategy.</p>
<p>Complicated as the procedure might seem, it can all be done in code using a single command from the <code>CQtools</code> package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="caseselection.html#cb1-1"></a><span class="kw">diagnose_strategies</span>(</span>
<span id="cb1-2"><a href="caseselection.html#cb1-2"></a>    </span>
<span id="cb1-3"><a href="caseselection.html#cb1-3"></a>   <span class="dt">analysis_model =</span> model,</span>
<span id="cb1-4"><a href="caseselection.html#cb1-4"></a>   </span>
<span id="cb1-5"><a href="caseselection.html#cb1-5"></a>   <span class="dt">observed =</span> observed,</span>
<span id="cb1-6"><a href="caseselection.html#cb1-6"></a>   </span>
<span id="cb1-7"><a href="caseselection.html#cb1-7"></a>   <span class="dt">data_strategies =</span> <span class="kw">list</span>(</span>
<span id="cb1-8"><a href="caseselection.html#cb1-8"></a>     <span class="dt">A_online  =</span> <span class="kw">list</span>(<span class="dt">N=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">within =</span> <span class="ot">TRUE</span>, <span class="dt">vars =</span> <span class="st">&quot;M&quot;</span>, </span>
<span id="cb1-9"><a href="caseselection.html#cb1-9"></a>                       <span class="dt">conditions =</span> <span class="kw">c</span>(<span class="st">&quot;X==1 &amp; Y==1&quot;</span>, <span class="st">&quot;X==0 &amp; Y==0&quot;</span>)),</span>
<span id="cb1-10"><a href="caseselection.html#cb1-10"></a>     <span class="dt">B_offline =</span> <span class="kw">list</span>(<span class="dt">N=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">within =</span> <span class="ot">TRUE</span>, <span class="dt">vars =</span> <span class="st">&quot;M&quot;</span>, </span>
<span id="cb1-11"><a href="caseselection.html#cb1-11"></a>                       <span class="dt">conditions =</span> <span class="kw">c</span>(<span class="st">&quot;X==1 &amp; Y==0&quot;</span>, <span class="st">&quot;X==0 &amp; Y==1&quot;</span>)),</span>
<span id="cb1-12"><a href="caseselection.html#cb1-12"></a>     <span class="dt">C_X1Y1    =</span> <span class="kw">list</span>(<span class="dt">N=</span><span class="dv">2</span>, <span class="dt">within =</span> <span class="ot">TRUE</span>, <span class="dt">vars =</span> <span class="st">&quot;M&quot;</span>, </span>
<span id="cb1-13"><a href="caseselection.html#cb1-13"></a>                       <span class="dt">conditions =</span> <span class="kw">c</span>(<span class="st">&quot;X==1 &amp; Y==1&quot;</span>))),</span>
<span id="cb1-14"><a href="caseselection.html#cb1-14"></a>   </span>
<span id="cb1-15"><a href="caseselection.html#cb1-15"></a>   <span class="dt">queries =</span> <span class="st">&quot;Y[X=1] - Y[X=0]&quot;</span></span>
<span id="cb1-16"><a href="caseselection.html#cb1-16"></a>   </span>
<span id="cb1-17"><a href="caseselection.html#cb1-17"></a>   )</span></code></pre></div>
<table>
<caption><span id="tab:ch13diagnosis387">Table 15.2: </span>The estimand and the expected estimate are the same under each data strategy.</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">strategy</th>
<th align="right">estimand</th>
<th align="right">estimates</th>
<th align="right">MSE</th>
<th align="right">post_var</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">estimands_database</td>
<td align="left">Prior</td>
<td align="right">0.1347</td>
<td align="right">0.1340</td>
<td align="right">0.0238</td>
<td align="right">0.0166</td>
</tr>
<tr class="even">
<td align="left">estimands_database1</td>
<td align="left">A_online</td>
<td align="right">0.1347</td>
<td align="right">0.1406</td>
<td align="right">0.0180</td>
<td align="right">0.0156</td>
</tr>
<tr class="odd">
<td align="left">estimands_database2</td>
<td align="left">B_offline</td>
<td align="right">0.1347</td>
<td align="right">0.1359</td>
<td align="right">0.0236</td>
<td align="right">0.0175</td>
</tr>
<tr class="even">
<td align="left">estimands_database3</td>
<td align="left">C_X1Y1</td>
<td align="right">0.1347</td>
<td align="right">0.1362</td>
<td align="right">0.0197</td>
<td align="right">0.0158</td>
</tr>
<tr class="odd">
<td align="left">estimands_database4</td>
<td align="left">D_random</td>
<td align="right">0.1347</td>
<td align="right">0.1377</td>
<td align="right">0.0202</td>
<td align="right">0.0163</td>
</tr>
</tbody>
</table>
<p>Graph full set</p>
<pre><code>## Joining, by = c(&quot;Query&quot;, &quot;given&quot;, &quot;model&quot;, &quot;N&quot;)</code></pre>
<p><img src="ii_files/figure-html/graph-1.png" width="672" /><img src="ii_files/figure-html/graph-2.png" width="672" /><img src="ii_files/figure-html/graph-3.png" width="672" /></p>
<p>Starting with the results for the <span class="math inline">\(ATE\)</span> estimand, let us first look at the results for the simple chain model. Where the given data are flat, we see that we do not expect to learn about the <span class="math inline">\(ATE\)</span> from observing <span class="math inline">\(M\)</span> under any case-selection strategy. To be clear, we can certainly learn about the likelihood of <em>effects</em>. For instance, if we observe <span class="math inline">\(M=0\)</span> in both an <span class="math inline">\(X=Y=1\)</span> case and in an <span class="math inline">\(X=Y=0\)</span> case, then we know that a causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is less likely since <span class="math inline">\(M\)</span> is not correlated with either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>. The trouble is that we become equally less confident in <em>positive</em> and in <em>negative</em> effects since the given data, implying an <span class="math inline">\(ATE\)</span> of 0, have us believing that both effects are about equally likely: incremental evidence against a positive effect, in this situation, is also incremental evidence against a negative effect. also neither the original model nor the given data give us any reason to put a higher prior probability on either positive or negative effects (i.e., our prior belief is in an <span class="math inline">\(ATE\)</span> of 0). Thus, evidence of no effect is taken to be evidence, equally, against negative effects and against positive effects.</p>
<p>However, observe what happens if we are using the chain model and have given data that falls along a positive regression line, rather than being flat. Now, if we observe cases on the regression line (say, that <span class="math inline">\(X=Y=1\)</span> case and the <span class="math inline">\(X=Y=0\)</span> case again), we can learn something. Again, observing <span class="math inline">\(M=0\)</span> in both cases would count against a causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. But <em>now</em>, prior to the process tracing, we start out with a belief that the <span class="math inline">\(ATE\)</span> is <em>positive</em>, given the positive <span class="math inline">\(X,Y\)</span> correlation. So evidence against any causal effect counts more strongly against a positive effect (the effect we start out thinking is more likely) than against a negative effect, with the result that our posterior on the <span class="math inline">\(ATE\)</span> will fall.</p>
<p>Note, however, that we do</p>
<p>we can immediately see striking differences across the three causal models. In particular, we only see clear evidence of expected learning for <em>any</em> strategy when operating with the chain or restricted models. For the base model — in which <span class="math inline">\(X\)</span> may operate directly or indirectly, via <span class="math inline">\(M\)</span>, and all nodal types are permitted — <span class="math inline">\(M\)</span> looks entirely uninformative about average effects. The problem is that the base model is too unconstrained to allow an <span class="math inline">\(M\)</span> data pattern to be informative. We can certainly learn about the likelihood of <em>effects</em>. For instance, if we observe <span class="math inline">\(M=0\)</span> in both an <span class="math inline">\(X=Y=1\)</span> case and in an <span class="math inline">\(X=Y=0\)</span> case, then we know that an indirect causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is less likely since <span class="math inline">\(M\)</span> is not correlated with either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>. And while there could still be a direct effect, reducing the probability of one pathway carrying the effect reduces our overall confidence that there’s an effect. The trouble is that we become equally less confident in <em>positive</em> and in <em>negative</em> effects since we start out with no prior belief about one of these effects being more likely than the other (i.e., our prior belief is in an <span class="math inline">\(ATE\)</span> of 0). Thus, there can be no change in our beliefs about the <em>average</em> effect.</p>
<p>Consider, by contrast, the restricted model, which is identical to the base model but with built-in monotonicity restrictions for all nodes. Now, for an <span class="math inline">\(X=Y=1\)</span> case, only <span class="math inline">\(M=1\)</span> is consistent with a mediated causal effect, thus making <span class="math inline">\(M\)</span> informative about the total effect: if we observe <span class="math inline">\(M=0\)</span>, we don’t know for sure whether <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> since the effect could have run via the direct path, but the probability of an effect is now lower.</p>
<p>Notably, the chain model also allows for the possibility of learning but <em>only</em> if we start out with <span class="math inline">\(X,Y\)</span> data consistent with a strong effect. These given data shift our priors in favor of there being a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. In turn, they shift our priors in favor of there being an effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> and an effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span>, since any <span class="math inline">\(X \rightarrow Y\)</span> effect has to run through these two mediating effects. While these new priors do not operate with the full force of a restriction, they</p>
</div>
</div>
<div id="principles" class="section level2">
<h2><span class="header-section-number">15.5</span> Principles</h2>
<div id="sometimes-one-case-is-not-enough" class="section level3">
<h3><span class="header-section-number">15.5.1</span> Sometimes one case is not enough</h3>
<p>For on regression line cases, you can see cases where M correlates positively with X and Y correlates positively to Y; or cases where M is correlated with neither</p>
<p>For off regression line cases, you can see cases where M correlates negatively with X and positively with Y, or vice versa; and you can see cases where M is correlated with neither.</p>
<p>With no restrictions, you can’t actually learn from a single data point because you have flat priors over X-&gt;M and M-&gt;Y effects. You’re only able to learn from correlations.</p>
</div>
<div id="different-strategies-for-different-estimands" class="section level3">
<h3><span class="header-section-number">15.5.2</span> Different strategies for different estimands</h3>
</div>
<div id="where-the-probative-value-is" class="section level3">
<h3><span class="header-section-number">15.5.3</span> Where the probative value is</h3>
<!-- For the general intuition, recall that the probative value of a process-tracing test hinges on the difference in clue likelihoods associated with the alternative hypotheses in play for a given case. Recall that for different values of $X$ and $Y$ cell, we want to use process tracing to help us distinguish between two specific types that are consistent with the $X, Y$ pattern. Which types are in question varies across $X,Y$ combinations. Table \@ref(tab:FP) illustrates. -->
<!-- | \small      |          $Y=0$           |           $Y=1$             |   -->
<!-- |-------------|:------------------------:|:---------------------------:| -->
<!-- |     $X=0$   |     $b$ or $c$           |       $a$ or $d$            | -->
<!-- |     $X=1$   |     $a$ or $c$           |       $b$ or $d$            | -->
<!-- Table: (\#tab:FP). The ambiguity about types in each $X, Y$ cell. -->
<!-- Thus, in the $X=0, Y=0$ cell, what would be most useful is a clue that has high probative value in distinguishing between an untreated ($X=0$) $b$ type and and an untreated $c$ type. For a case in the $X=1, Y=0$ cell, on the other hand, what matters is how well the clue can discriminate between treated ($X=1$) $a$ and $c$ types. In our notation, it is the difference in $\phi_{jx}$ values for that indicates these cell-specific degrees of leverage.  -->
<!-- To illustrate, consider a situation in which for a given clue we have  $\phi_{b1}$=0.5^[The probability of observing the clue for a $b$ type (positive causal effect) case with $X=1$.]; $\phi_{d1}$=0.5 ^[The probability of observing the clue for a $d$ type (zero causal effect, $Y$ fixed at 1) case with $X=1$.]; $\phi_{b0}$=0.5^^[The probability of observing the clue for a $b$ type (positive causal effect) case with $X=0$.]; and $\phi_{c0}$=0.1^[The probability of observing the clue for a $c$ type (zero causal effect, $Y$ fixed at 0) case with $X=0$.]. In this situation, searching for the clue in $X=Y=1$ cases will yield no leverage since the clue does not discriminate between the two types ($b$ and $d$) that need to be distinguished given $X=Y=1$. Here there is no additional learning about $\lambda_b$ that can be gained from looking for the clue. In contrast, $X=0, Y=0$ cases will be informative since the clue is much better at distinguishing between $b$ and $c$ types---the two types in contention for this kind of case. Thus, although process tracing here does not provide information on the prevalence of positive causal effects ($b$ types) for an $X=Y=1$ case, it does provide information when $X=Y=0$.  -->
<!-- While it is common practice for mixed-method researchers to perform their process tracing "on the regression line," the BIQQ framework suggests that the gains to process tracing for different $X$ and $Y$ values in fact depend on the particular constellations of $\phi$ values for the potentially available clues. More generally, the framework allows one to assess the expected gains from any given case-selection strategy *ex ante* once priors have been specified.  -->
<!-- ## Appendix: Stan uncertainty -->

</div>
</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-FL2008">
<p>Fearon, James, and David Laitin. 2008. “Integrating Qualitative and Quantitative Methods.” In <em>Oxford Handbook of Political Methodology</em>, edited by Janet M. Box-Steffenmeier, David Collier, and Henry E Brady, 756–76. Cambridge, UK: Oxford University Press.</p>
</div>
<div id="ref-goertz2017multimethod">
<p>Goertz, Gary. 2017. <em>Multimethod Research, Causal Mechanisms, and Case Studies: An Integrated Approach</em>. Princeton University Press.</p>
</div>
<div id="ref-HerronQuinn">
<p>Herron, Michael C, and Kevin M Quinn. 2016. “A Careful Look at Modern Case Selection Methods.” <em>Sociological Methods &amp; Research</em> 45 (3): 458–92.</p>
</div>
<div id="ref-king1994designing">
<p>King, G., R. O. Keohane, and S. Verba. 1994. <em>Designing Social Inquiry: Scientific Inference in Qualitative Research</em>. Princeton University Press. <a href="http://books.google.de/books?id=A7VFF-JR3b8C">http://books.google.de/books?id=A7VFF-JR3b8C</a>.</p>
</div>
<div id="ref-Lieberman2005nested">
<p>Lieberman, Evan S. 2005. “Nested Analysis as a Mixed-Method Strategy for Comparative Research.” <em>American Political Science Review</em> 99 (03): 435–52. <a href="https://doi.org/10.1017/S0003055405051762">https://doi.org/10.1017/S0003055405051762</a>.</p>
</div>
<div id="ref-SeawrightGerring2008">
<p>Seawright, Jason, and John Gerring. 2008. “Case Selection Techniques in Case Study Research: A Menu of Qualitative and Quantitative Options.” <em>Political Research Quarterly</em> 61 (2): 294–308. <a href="https://doi.org/10.1177/1065912907313077">https://doi.org/10.1177/1065912907313077</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note: We can say more about why these would be good choices from a Bayesian perspective, based on the idea that measurement is more likely to be wrong in such cases and shifting them to more typical values would make a big difference.<a href="caseselection.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> have a parameter <span class="math inline">\(\theta\)</span> that governs the distribution of data over <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and then, conditional on <span class="math inline">\(X,Y\)</span> values, a set of parameters <span class="math inline">\(\psi_{xy}\)</span> that describe the probability of a case’s being of a given causal type. We take both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\psi_{xy}\)</span> to derive from the fundamental distribution of causal types and assignment probabilities. Thus, for example, <span class="math inline">\(\psi_{00}\)</span> from <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> corresponds to <span class="math inline">\(\frac{(1-\pi_b)\lambda_b}{(1-\pi_b)\lambda_b + (1-\pi_c)\lambda_c}\)</span> in our notation. The difference in paramaterization does have implications for interpretations of the priors. For example flat priors over <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\psi\)</span> implies a tighter distribution that a uniform prior over the causal types. In fact <span class="citation">Herron and Quinn (<a href="#ref-HerronQuinn" role="doc-biblioref">2016</a>)</span> use priors with greater variance than uniform in any event.<a href="caseselection.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>This belief arises from a straightforward calculation involving the different combinations of nodal types that could generate <span class="math inline">\(X=1, Y=1\)</span> and their prior probabilities.<a href="caseselection.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Put differently, the observed <span class="math inline">\(X,Y\)</span> correlation is equally consistent with all <span class="math inline">\(X=0, Y=1\)</span> cases being <span class="math inline">\(a\)</span>’s, with them all being <span class="math inline">\(d\)</span>’s, or with anything in between.<a href="caseselection.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>We set aside here Lieberman’s recommendation to choose off-the-line cases for discovery-oriented “model-building” because we see that enterprise as distinct from the estimation endeavor to which our analysis is oriented.<a href="caseselection.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="wide.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="justifying-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ii.pdf"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
