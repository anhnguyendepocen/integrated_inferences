# Mixed methods data strategies {#caseselection}

```{r packagesused13, include = FALSE}
source("_packages_used.R")
do_diagnosis = FALSE
```

:::: {.headerbox data-latex=""}
::: {.center data-latex=""}
:::
With a causal model in hand, together with priors over parameters, you can assess in advance what conclusions you will draw from different observations and assess what kinds of observations are most worth seeking. We draw out the implications of this idea for case selection. We then turn to the problem of choosing between going "wide" and going "deep." We discuss the tradeoffs and communicate an intuition that clue data, even on a small number of cases, can be informative even when there is $X, Y$ data on a very large number of cases, but only if it provides information that cannot be gathered from $X,Y$ data, such as selection into treatment. Simulations suggest that going deep is especially valuable for observational research, situations with homogeneous treatment effects, and, of course, when clues have strong probative value.
::::


A critical decision for scholars employing mixed methods is to determine when and where to look deep and when to look wide. We address this question if two steps, first addressing the problem of case selection and second the question of qualitative/quantitative mixing.  

## Case selection strategies

A host of different strategies have been proposed for selecting cases for in-depth study based on the observed values of $X$, $Y$ data. Perhaps the most common strategy is to select cases in which $X=1$ and $Y=1$ and look to see whether in fact $X$ caused $Y$ in the case in question (using some more or less formal strategy for inferring causality from within-case evidence). But many other strategies have been proposed, including strategies to select cases "on the regression line" or, for some purposes, cases "off the regression line" (e.g., @Lieberman2005nested). Some scholars suggest ensuring variation in $X$ (most prominently, @king1994designing), while others have proposed various kinds of matching strategies. Some have pointed to the advantages of random sampling of cases, either stratified or unstratified by values on $X$ or $Y$ (@FL2008, @HerronQuinn). 

Which cases you should choose will likely depend on the purposes to which you want to put them. 

A matching strategy for instance---selecting cases that are comparable on many features but that differ on $X$---replicates at a small scale the kind of inference done by matching estimators with large-$n$ data. The strategy emphasize the inferences to be made from $X,Y$ variation rather than inferences drawn specifically from within case information beyond what is available in the measurement of $X$ and $Y$. (Citations needed.)

Other treatments seek to use qualitative information to check assumptions made in $X, Y$ analysis: for example, is the measurement of $X$ and $Y$ reliable in critical cases? (Citations needed) For such questions with limited resources, it might make sense to focus on cases for which validation plausibly makes a difference to the $X,Y$ inferences: for example influential cases that have unusually extreme values on $X$ and $Y$.^[Note: We can say more about why these would be good choices from a Bayesian perspective, based on the idea that measurement is more likely to be wrong in such cases and shifting them to more typical values would make a big difference.] Similar arguments are made for checking assumptions on selection processes, though we consider this a more complex desideratum since this requires making case level causal inferences and not simply measurement claims.

A third purpose is to use a case to generate alternative or richer theories of causal processes, as in Lieberman's "model-building" mode of "nested analysis" (@Lieberman2005nested). Here it may be cases off the regression line that are of interest.

Weller and Barnes (CITE article) on case selection focus on (a) X/Y relations and (b) whether the cases are useful for hypothesis generation. 

In what follows, we focus on a simpler goal: given existing $X, Y$ data for a set of cases and a given clue (or set of clues) that we can go looking for in the intensive analysis of some subset of these cases, for which cases would process tracing yield the greatest learning about the population-level causal effect of $X$ on $Y$?

The basic insight of this chapter is simple enough: *the optimal strategy for case selection for a model-based analysis can be determined by the model and the query*, just as we saw for the optimal clue-selection strategy in Chapter \@ref(Clues). Using this strategy yields guidance that is consistent with some common advice but at odds with other advice. The main principles that emerge from the analysis can be summarized as:

* go where the probative value is, and
* sample from $X$ and $Y$ values in proportion to their occurrence in the population,
* invest in collections of cases that provide complementary learning. 

Beyond these general principles, other patterns are more complex and thus more difficult to neatly summarize. The most general message of this chapter is about the general approach: that is, that we can use a causal model to tell us what kinds of cases are likely to yield the greatest learning, given the model and a strategy of inference. We provide a tool for researchers to undertake this analysis, at least for simple problems with $X, Y, K$ data.


Most closely related to our analysis in this chapter is the contribution of @HerronQuinn, who build on @SeawrightGerring2008. While Seawright and Gerring provide a taxonomy of approaches to case selection, they do not provide a strategy for assessing the relative merits of these different approaches.  As we do, @HerronQuinn focus on a situation with binary $X,Y$ data and assess the gains from learning about causal type in a set of cases (interestingly in their treatment causal type, $Z_i$  is called a confounder rather than being an estimand of direct interest; in our setup, confounding as normally understood arises because of different probabilities of different causal types of being assigned to "treatment", or an $X=1$ value). @HerronQuinn assume that in any given case selected for analysis a qualitative researcher is able to infer the causal type perfectly.  

Our setup differs from that in @HerronQuinn in a few ways.  @HerronQuinn paramaterize differently, though this difference is not important.^[@HerronQuinn have a parameter $\theta$ that governs the distribution of data over $X$ and $Y$ and then, conditional on $X,Y$ values, a set of parameters $\psi_{xy}$ that describe the probability of a case's being of a given causal type. We take both $\theta$ and $\psi_{xy}$ to derive from the fundamental distribution of causal types and assignment probabilities. Thus, for example, $\psi_{00}$ from @HerronQuinn corresponds to $\frac{(1-\pi_b)\lambda_b}{(1-\pi_b)\lambda_b + (1-\pi_c)\lambda_c}$ in our notation. The difference in  paramaterization does have implications for interpretations of the priors. For example flat priors over $\theta$ and $\psi$ implies a tighter distribution that a uniform prior over the causal types. In fact @HerronQuinn use priors with greater variance than uniform in any event.] Perhaps the most important difference between our analysis and that in @HerronQuinn  is that we connect the inference strategy to process-tracing approaches. Whereas @HerronQuinn assume that causal types can be read directly, we assume that these are inferred *imperfectly* from clues. As in our baseline model, our ability to make inferences for causal types can differ by type and as a function of $X$. And, as in the baseline model, not only can we have uncertainty about the probative value of clues, but researchers can learn about the probative value of clues by examining cases.

<!-- Are Herron and Quinn's priors Jeffrey priors? -->

Here we assume that the case selection decision is made after observing the $XY$ distribution and we explore a range of different possible contingency tables. In  @HerronQuinn the distribution from which the contingency tables are drawn is fixed, though set to  exhibit an expected  observed difference in means (though not necessarily a true treatment effect) of 0.2. They assume large $XY$ data sets (with 10,000) units and case selection strategies ranging from 1 to 20 cases.

Another important difference, is that in many of their analyses, @HerronQuinn take the perspective of an outside analyst who knows the true treatment effect; they then assess the expected bias generated by a research strategy over the possible data realizations. We, instead, take the perspective of a researcher who has *beliefs* about the true treatment effect that correspond to their priors, and for whom there is therefore no *expected* bias. This has consequences also for the assessment of expected posterior variance, as in our analyses the expectation of the variance is taken with respect to the researcher's beliefs about the world, rather than being made conditional on some specific world (ATE). We think that this setup is addressed to the question that a researcher must answer when deciding on a strategy: given what they know now, what will produce the greatest reduction in uncertainty (the lowest expected posterior variance)?

Finally, we proceed somewhat differently in our identification of strategies from Herron and Quinn: rather than pre-specifying particular sets of strategies (operationalizations of those identified by @SeawrightGerring2008) and evaluating them, we define a strategy as the particular distribution over $XY$ cells to be examined and proceed to examine *every possible strategy* given a choice of a certain number of cases in which to conduct process tracing. We thus let the clusters of strategies---those strategies that perform similarly---emerge from the analysis rather than being privileged by past conceptualizations of case-selection strategies.

Despite these various differences, our results will agree in key ways with those in @HerronQuinn.


### No general rules

Case selection logics depends on probative value and queries.

Although it might be tempting to seek general rules of the form "examine cases in which $X=1$ and $Y=1$" or, "ignore cases in which $X=0$ and $Y=0$", it is easily demonstrated that which choices are more informative depend on how waht can be learned within a case contributes to infernecnce, and that hte contributions depend on the query in question.

Say we know in a given population that:

  * $X \rightarrow Y \leftarrow K$
  * $\Pr(Y=1|X=0, K = 0) = 1$
  * $\Pr(Y=1|X=1, K = 0) = .5$
  * $\Pr(Y=1|X=0, K = 1) = 0$
  * $\Pr(Y=1|X=1, K = 1) = .9$

We do not know, however how common $K$ is. Thus we do not know either unit level causal effects or population level effects.

Given the information above we can see that if $X=Y=1$, then $K$ is a "doubly decisive" clue for assessing whether, in a given case, $X$ causes $Y$. In particular we have that for an $X=Y=1$ case, seeing $K=1$ implies  $X$ caused $Y$ Since otherwise $Y$ would have been 0) and seeing $K=0$ implies   $X$ did not cause $Y$ (since othereise $Y$ would have been 1 in any event.

However, if we had a case in which $X=Y=0$ then learning $K$ would be entirely uninformative for the case. In particular, we already know that $K=1$ in this case as we know there are not cases in which  $X=Y=0$ and $K=0$. And this knowledge is not enough in this case to know whether $X=0$ caused $Y=0$.

For the same reason, if, off the diagonal, $X=0, Y=1$ we learn nothing from $K$, since we learn about $K$ from $Y$. If however we had a case in which $X=1, Y=0$, if $K$ were 1 then we would know that $X=1$ did not cause $Y=0$; if $K$ were 0 we would know that  $X=1$ caused $Y=1$.


```{r, eval= FALSE, echo = FALSE}
py_k0 = .5
py_k1 = .9

py_k1 / (py_k0 + py_k1)

(1-py_k1) / (1-py_k0 + 1-py_k1)

```

Say now we were interested in the population estimand: the average effect of $X$ on $Y$. We can see that this is equal to $\Pr(K=1)\times.9 + (1-\Pr(K-0))\times(-.5)) = 1.4\Pr(K=1)-.5$. For this estimand we are only interested in the prevalence of $K$ in the population. It might seem that this means that it is irrelevant what type of case you choose; however, as noted above, we have more information about the likely value of $K$ in some cases than in others. So for this estimand also, in this case, selecting an $X=Y=1$ case  is informative for the population effect; selecting $X=Y=0$ case is not informative. 

Say now we had a case in which $X=1$. Should we choose: a case in which $Y=1$ or a case in which $Y=0$. In both cases $K$ is doubly decisive for the case level estimand. However for a $Y=1$ case we think it likely that $K=1$ (specifically, assuming a prior of $\Pr(K=1)$ we think $\Pr(K=1 | X=1, Y=1) = \frac{.9}{.9+.5}=.64$); for the  $Y=0$ case we think  $\Pr(K=1 | X=1, Y=0) = \frac{.1}{.5+.1}=.17$. Thus we are much more uncertain about the value of $K$ in the $X=Y=1$ case. We would learn more for the avergae treatment effect then by choosing off the diagonal.

Specifically let $\kappa$ denote $\Pr(K=1)$. say we begin thinking it equally likely that $\kappa=\kappa^H = .5$ and $\kappa=\kappa^L=0$. Say $\Pr(X=1) = .5$. Say we observe one case with $X=Y=1$ and another with $X=1, Y=0$. From that informaation alone we can update over $\kappa$. Specifically, conditioning on the probability that $X=1$ for both cases and focuseing only on the probability that Y=0 in one case and Y=1 in the other:

$$p(\kappa = \kappa^L|D) =  \frac{p(D|\kappa^H)}{p(D|\kappa^H)+p(D|\kappa^L)}=\frac{.5}{.5 + .25\times(2\times.5\times.5 + 2\times.9\times.1 + 2\times(.9\times.5 +.1\times.5))}$$



In summary in this case it makes sense to select and $X=Y=1$ case if you are interested in teh population estimand or if you are interested in teh case level estimand for an $X=Y=1$ case. If you are interested in the case level estimand for an $X=Y=0$ case then there are no gains from either selection strategy.

Sometimes however you learn more in a $X=Y=0$ than in a  $X=Y=1$ case. Say instead that you knew that: 

  * $X \rightarrow Y \leftarrow K$
  * $\Pr(Y=1|X=0, K = 0) = .5$
  * $\Pr(Y=1|X=1, K = 0) = 0$
  * $\Pr(Y=1|X=0, K = 1) = .5$
  * $\Pr(Y=1|X=1, K = 1) = 1$

In this case you learn nothing from observing a case in which $X=Y=1$---in this case you already expect that $K=1$. In contrast if $X=Y=0$ then if you learn that $K=1$ you know that were $X=1$ the $Y$ would have been 1; but if you learn that $K=0$ you know that *were* $X=1$ then $Y$ would have (still) been 0. So in this case $K$ is doubly decisive for an $X=Y=0$ case but not for a   $X=Y=1$ case. 


This logic also holds for the off diagonals.

Say instead that you knew that: 

  * $X \rightarrow Y \leftarrow K$
  * $\Pr(Y=1|X=0, K = 0) = 0$
  * $\Pr(Y=1|X=1, K = 0) = .5$
  * $\Pr(Y=1|X=0, K = 1) = 1$
  * $\Pr(Y=1|X=1, K = 1) = .5$

Say you have a case in which $X=1, Y=0$, then if $K=1$ you know that if $X$ were 0, Y would have been 1; but if $K=0$ you know that if $X$ were 0, $Y$ would have been 0. In that case $K$ would be doubly decisive for $X=1$ causing $Y=0$.  

Say you have a case in which $X=0, Y=1$, then it must be that $K=0$.   
  
Say instead that you knew that: 

  * $X \rightarrow Y \leftarrow K$
  * $\Pr(Y=1|X=0, K = 0) = .5$
  * $\Pr(Y=1|X=1, K = 0) = 0$
  * $\Pr(Y=1|X=0, K = 1) = .5$
  * $\Pr(Y=1|X=1, K = 1) = 1$

It may be better to select a case that is not "like" the cases you want to make inferences about.


### An approach to comparing strategies

```{r selectioncode, echo = FALSE}

# We define a model
model <- make_model("X->M->Y")  %>%
 set_restrictions(c("(Y[M=1]<Y[M=0])", "(M[X=1]<M[X=0])")) %>%
 set_parameter_matrix() %>%
 set_parameters(type = "flat")

# We imagine some preexisting data we have observed
data  <-  data.frame(X = c(0,0,0,1,1,1), M = NA, Y = c(0,0,1,0,1,1))
observed <-  collapse_data(data, model, drop_family = TRUE)

# We can then imagine what data we might observe if we examine M inside some subset of cases
A_on_regression_line <- 
  make_possible_data(
    model, 
    observed = observed, vars = "M", 
    N = c(1,1), 
    condition = c("X==1 & Y==1", "X==0 & Y==0"), 
    prefix = "A")
names(A_on_regression_line)[-c(1:2)] <- c("A1", "A2", "A3", "A4")

B_off_regression_line <- 
  make_possible_data(model, observed = observed, vars = "M", N = c(1,1), 
                     condition = c("X==1 & Y==0", "X==0 & Y==1"), prefix = "B")
names(B_off_regression_line)[-c(1:2)] <- c("B1", "B2", "B3", "B4")

C_X1Y1_only <- 
  make_possible_data(model, observed = observed, vars = "M", N = 2, 
                     condition = c("X==1 & Y==1"), prefix = "C")
names(C_X1Y1_only)[-c(1:2)] <- c("C1", "C2", "C3")

```

Consider a situation in which one has access to $X,Y$ data on just six cases of the form:

```{r observed, echo = FALSE}
kable(observed)
```

We want to examine data on $M$ for two of these cases and are wondering about what strategy we should use to select the cases. We are considering three strategies:

* Strategy $A$ chooses two cases on the regression line (one in the $X=Y=0$ cell and one in the $X=Y=1$ cell)
* Strategy $B$ chooses off the regression line 
* Strategy $C$ selects on the dependent variable -- choosing cases with $X=1, Y = 1$.

Different strategies yield different possible types of data. Each one of these is likely to arise with a different probability and is associated with a different inference. Drawing on the prior beliefs embedded in a causal model, we can thus assess the *expected* posterior variance associated with each strategy. 


```{r dtypes, echo = FALSE}
# Combine data types
df <- A_on_regression_line[,-2] %>% 
  merge(B_off_regression_line[,-2], by = "event", all = TRUE) %>%
  merge(C_X1Y1_only[,-2], by = "event", all = TRUE) %>%
  dplyr:::mutate_if(is.numeric, ~replace(., is.na(.), 0))

# table(duplicated(t(df)))
```

For each of these possible strategies we can assess the posterior that we would obtain for each type of data we might observe.

```{r illustration, echo = FALSE}

if(do_diagnosis){

# We define a model
model <- make_model("X->M->Y")  %>%
 set_restrictions(c("(Y[M=1]<Y[M=0])", "(M[X=1]<M[X=0])")) %>%
 set_parameter_matrix() %>%
 set_parameters(type = "jeffreys")
  
 strategies <- 
   list(A_on_regression_line, B_off_regression_line, C_X1Y1_only)

 	write_rds(strategies, "saved/14_illustration_strategies.rds")
  
 
 estimates_dbs <- lapply(strategies, function(s) 
    make_estimates_database(model, observed, possible_data = s, queries = "Y[X=1]-Y[X=0]")
    )
    
	write_rds(estimates_dbs, "saved/14_illustration_estimates.rds")

# The reference model is the original model updated with the XY data we've already seen.
 reference_model <- update_model(model, data)
 
	write_rds(reference_model, "saved/14_reference_XMY_updated_model.rds")

 probabilities <- lapply(strategies, function(s) 
#    average_data_probabilities(reference_model, s, using = "posteriors", sims = 3000)

   apply(reference_model$posterior_distribution, 1, function(pars) {
  					make_data_probabilities(model = reference_model, pars = pars, possible_data = s, normalize = TRUE)
  			})
   )
   
	write_rds(probabilities, "saved/14_illustration_probabilities.rds")

}

  reference_model <- read_rds("saved/reference_XMY_updated_model.rds")
	probabilities   <- read_rds("saved/illustration_probabilities.rds")
  strategies      <- read_rds("saved/illustration_strategies.rds")
  estimates_db    <- read_rds("saved/illustration_estimates.rds")
  
  digits <- 3

  df <- rbind(df, 
          c("Probability", round(unlist(probabilities),digits)),
          c("Posterior mean",   (unlist(lapply(estimates_db, function(j)   unlist(unlist(lapply(j, function(k) k$mean))))))),
          c("Posterior variance",   round(unlist(lapply(estimates_db, function(j)   unlist(unlist(lapply(j, function(k) k$mean^2))))), digits)))
```

The data possibilities, probabilities of each, and inferences given each, are shown in Table \@ref(tab:chselillustration).
  
```{r chselillustration, echo = FALSE}  
kable(df, caption = "Each column shows a possible distribution of data that can be generated from a given strategy. We calculate the probability of each data possibility, given the data seen so far, and the posterior variance associated with each one.", digits = 2)
```

Each of the first two strategies generates one of four different data patterns. The third data strategy generates up to three data patterns. None of these data patterns overlap across strategies. 
From the calculated  probability of each data type, given the data seen so far, and the posterior variance given each data realization, the implied *expected* variance is  easily calculated. These are summarized below:

```{r exppostvar, echo = FALSE}
expected_posterior_var <- sapply(1:3, function(i) 
  sum(probabilities[[i]]*unlist(lapply(estimates_db[[i]], function(x) x$sd^2)))
 )
kable(data.frame(Strategy = c("Online", "Offline", "X=1, Y=1"), Variance = expected_posterior_var), digits = 3)
```


In this example, we see that we would expect to be better off---in the sense of having less posterior uncertainty---by focusing her process-tracing efforts where a greater share of the population of cases lies: on the regression line.  

Why is this?


```{r test, include = FALSE}
# source("_packages_used.R")

model <- make_model("X -> M -> Y")
  
gen_observed_data <- function(n00=1, n01=1, n10=1, n11=1,times = 1) {
  data.frame(X = c(0,0,1,1), Y =c(0,1,0,1), M = NA, ns = c(n00, n01, n10, n11)*times) %>%
    tidyr::uncount(ns) %>%
    collapse_data(model, drop_family = TRUE)}


# Data strategies

data_strats <- function(N = 4) {
  if(N%%2 != 0) stop("even Ns only please")
  list(
    all_on = list(N=c(N,N)/2, withins = TRUE, vars = "M",
                  conditions = list("X==0 & Y==0", "X==1 & Y==1")),
    all_off = list(N=c(N,N)/2, withins = TRUE, vars = "M",
                   conditions = list("X==0 & Y==1", "X==1 & Y==0")),
    all_x1 = list(N=c(N,N)/2, withins = TRUE, vars = "M",
                   conditions = list("X==1 & Y==0", "X==1 & Y==1")),
    all_y1 = list(N=c(N,N)/2, withins = TRUE, vars = "M",
                   conditions = list("X==0 & Y==1", "X==1 & Y==1"))
  )
}

# Queries

# if(!exists("fit")) fit <- fitted_model()

# Diagnosis function 

if(do_diagnosis){
test_corr <- 
  diagnose_strategies(
    analysis_model = model,
    data_strategies = data_strats(2),
    given = gen_observed_data(6,2,2,6),
    queries = list(ATE = "Y[X=1]-Y[X=0]", 
                   a = "Y[X=1]<Y[X=0]", 
                   b = "Y[X=1]>Y[X=0]", 
                   c = "(Y[X=1]==0) & (Y[X=0]==0)", 
                   d = "(Y[X=1]==1) & (Y[X=0]==1)",
                   a1 = "M[X=1]<M[X=0]", 
                   b1 = "M[X=1]>M[X=0]", 
                   c1 = "(M[X=1]==0) & (M[X=0]==0)", 
                   d1 = "(M[X=1]==1) & (M[X=0]==1)",
                   a2 = "Y[M=1]<Y[M=0]", 
                   b2 = "Y[M=1]>Y[M=0]", 
                   c2 = "(Y[M=1]==0) & (Y[M=0]==0)", 
                   d2 = "(Y[M=1]==1) & (Y[M=0]==1)"
                   ),
    subsets = list(TRUE, TRUE,  TRUE,  TRUE),
    sims = 8000,
    fit = fit, 
    refresh = 1000,
    iter = 8000)

write_rds(test_corr, "saved/test_corr.rds")

test_flat <- 
  diagnose_strategies(
    analysis_model = model,
    data_strategies = data_strats(2),
    given = gen_observed_data(4,4,4,4),
    queries = list(ATE = "Y[X=1]-Y[X=0]", 
                   a = "Y[X=1]<Y[X=0]", 
                   b = "Y[X=1]>Y[X=0]", 
                   c = "(Y[X=1]==0) & (Y[X=0]==0)", 
                   d = "(Y[X=1]==1) & (Y[X=0]==1)",
                   a1 = "M[X=1]<M[X=0]", 
                   b1 = "M[X=1]>M[X=0]", 
                   c1 = "(M[X=1]==0) & (M[X=0]==0)", 
                   d1 = "(M[X=1]==1) & (M[X=0]==1)",
                   a2 = "Y[M=1]<Y[M=0]", 
                   b2 = "Y[M=1]>Y[M=0]", 
                   c2 = "(Y[M=1]==0) & (Y[M=0]==0)", 
                   d2 = "(Y[M=1]==1) & (Y[M=0]==1)"
                   ),
    subsets = list(TRUE, TRUE,  TRUE,  TRUE),
    sims = 8000, fit = fit, refresh = 1000, iter = 8000)


write_rds(test_flat, "saved/test_flat.rds") 
}

test_corr <- read_rds("saved/test_corr.rds") 
test_flat <- read_rds("saved/test_flat.rds") 

# key thing to note is for $all_x1[[1]] a2 = b2
# and for $all_x1[[2]] a1 = b1 
# so in both cases shareas of a and b remains contstant


```

For intuition consider first the case with flat prior data:

* if we examine two cases in different quadrants *on the diagonal* (one $X=Y=0$ case and one $X=Y=1$ case) :
  * if  we find that $M$ is the same in the two cases then we  increase our belief that $X$ has no effect at all on $Y$ and reduce our confidence that $X$ had a positive or a negative effect on $Y$. Since we are looking on the regression line however, our confidence that $X$ had a *positive* effect on $Y$ is more strongly reduced, producing a  posterior centered on a small negative effect. 
  * Conversely if we see that $M$ is different in the two cases, then we have a correlation of the same sign between both $X$ and $M$ and between $M$ and $Y$  cases. We increase our confidence that $X$ mattered for $Y$ in general an din particular that it had a positive effect, resulting in a posterior centered on a small positive ATE.

* if we examine two cases in different quadrants *off the diagonal* (one $X=0, Y=1$ case and one $X=1, Y=0$ case) :
  * if  we find that $M$ is the same in the two cases then we  increase our belief that $X$ has no effect at all on $Y$ and reduce our confidence that $X$ had a negative effect  $Y$ (producing a  posterior centered on a small positive effect). 
  * Conversely if we see that $M$ is different in the two cases, then we have a correlation (of different signs) between both $X$ and $M$ and between $M$ and $Y$  cases. We increase our confidence that $X$ mattered for $Y$ in general and in particular that it had a negative effect, resulting in a posterior centered on a small negative ATE.

* If we examine data conditioning on the value of $X$ but with variation on $Y$ (for instance $X=1, Y=0$ and   $X=1, Y=1$) 
data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in $M$ is more consistent with $M$ being responsive to $X$ and thus the chances that $X$ matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged. FLAG work though intuition  more

* If we examine data conditioning on the value of $Y$ but with variation on $X$ (for instance $X=0, Y=1$ and   $X=1, Y=1$) 
data patterns do not discriminate between X having a positive effect on Y an d X having a negative effect on Y. However variation in $M$ is more consistent with $M$ being responsive to $X$ and thus the chances that $X$ matters, positively or negatively, overall. In teh case with flat data this changes beliefs on positve and negative effects but not the difference between them. The ate then remains unchanged.

For correlated data similar logics apply, but the effects are stronger for evidence on the regression line. The reason is that given correlated data we believe there are more units with positive effects than negative effects. When we find evidence against causal relations on the regression line that reduces our confidence for types with positive effects more than for types with negative effects and teh difference between teh shares with positive effects and negative eeffects smaller due to the fact that the beliefs in the shares with negative effects is not so strongly reduced. Wehen we find evidence for causal relations this magnifies teh difference between beliefs in shares positive and shares negatives; these effects are magnified however since our confidence for the positive effects change more than for the negative effects, since we are examining cases on the regression line. Conversely when examining cases of teh regression line, the two forces offset each other. 



```{r cinfer, include = FALSE}
# Make sense given process tracing approach

long_data <-  expand_data(gen_observed_data(4,2,2,4), model)

if(do_diagnosis){
  updated <- update_model(model, long_data, iter = 14000, chains = 12) %>%
  set_parameters(param_type = "posterior_mean")
  write_rds(updated, "saved/ch13_longupdated.rds") 
}
updated <- read_rds("saved/ch13_longupdated.rds") 

get_parameters(updated)

conditional_inferences(updated, query = "Y[X=1]!=Y[X=0]", given = "!is.na(X) & !is.na(Y) & !is.na(M)") %>%
  arrange(X, Y, M)
```



### Case selection: Lessons from simulations

We turn now to a more general approach for deriving case-selection guidance from a causal model, given the causal query we wish to address and any data that we have already observed. This approach can be implemented using `CausalQueries` together with `CQTools`.

We imagine a situation in which we have already observed some data (the values of some nodes from the causal model in some set of cases) and must now decide in which cases we should gather additional data. To simplify the setup, we will be assuming that we are considering gathering additional observations in cases for which we already have *some* data. In other words, we are deciding which cases to investigate more *deeply*. (This is distinct from the question of "wide vs. deep", where we might decide to observe cases we have not yet seen at all.) 

The general intuition of the case-selection approach that we develop here is that we can use our causal model and any previously observed data to estimate what observations we are more or less likely to make under a given case-selection strategy, and then figure out how far off from the (under the model) true estimand we can expect to be under the strategy, given whatever causal question we seek to answer. 

We proceed as follows:

**DAG**. We start, as always, with a DAG representing our beliefs about which variables we believe to be direct causes of other variables. For the current illustrations, we consider two different DAGS: a simple mediation (or "chain") model, $X \rightarrow M \rightarrow Y$, and a two-path model, $X \rightarrow M \rightarrow Y \leftarrow X$.

**Priors**. As when conducting mixed-method inference, we can set qualitative restrictions and/or differential quantitative weights on the (possibly conditional) nodal types in the model. We can also indicate our uncertainty over the latter, by setting the $\alpha$ parameters of the relevant Dirichlet distributions. For the current example, we start by setting flat priors over all nodal types and assume no unobserved confounding.

**Given data.** If we have already made observations of any of the model's nodes in some set of cases, we can use this information to condition our strategy for searching for further information. For instance, if we have observed $X$'s and $Y$'s value in a set of cases, we might select cases for process tracing based on their values of $X$ and/or $Y$. And, importantly, what we have already observed in the cases will affect the inferences we will draw when we observe additional data, including how *informative* a particular new observation is likely to be. For the present examples, we assume that we have already observed $X$ and $Y$ in a set of cases and found a positive correlation.

**Query**. We define our query. This could, for instance, be the share of cases in the population in which $X$ has a positive effect on $Y$, or it might be $X$'s average effect on $Y$. We can use the general procedure to identify case-selection strategies for any causal query that can be defined on a DAG. And, importantly, the optimal case-selection strategy may depend on the query. For instance, the best case-selection strategy for estimating the average causal effect of $X$ on $Y$ may not be the same as the best strategy for figuring out for what proportion of the population $X$ has a positive effect on $Y$. In the example below, we focus on a set of conditional queries, asking what the effect of $X$ on $Y$ is in cases with different $X$, $Y$, and $M$ values. 

FLAG: MAke sure above query definition lines up with what we end up doing.

**Define one or more strategies**. A strategy is defined, generically, as the search for data on a given set of *nodes*, in a given *number* of cases that are randomly selected *conditional* on some information we already have about potential cases. Let us assume here that our strategy will involve uncovering $M$'s value in 1 or 2 cases. What we are wondering is how to choose this one or two cases for deeper analysis. For illustrative purposes, we focus in on four possible strategies, conditional on the $X$ and $Y$ values that we already know: 

1 examine $M$ in 1 $X=Y=1$ case; 
2 examine $M$ in 1 $X=1, Y=0$ case; 
3 examine $M$ in 2 cases, an $X=Y=1$ and an $X=Y=0$; and 
4 examine $M$ in 2 cases, an $X=1, Y=0$ and an $X=0, Y=1$.

In light of the positive $X,Y$ correlation already observed, we can think of strategies 1 and 3 as "on-the-regression line" strategies, while strategies 2 and 4 are "off-the-regression line" strategies.

**Possible data**. For each strategy, there are multiple possible sets of data that we could end up observing. In particular, the data we could end up with will be the $X,Y$ patterns we have already observed plus some pattern of $M$ observations. Thus, for instance, for strategy 1, we could end up observing the initial $X,Y$ pattern plus $M=0$ in one of the $X=1, Y=1$ cases, or the initial $X,Y$ pattern plus $M=1$ in one of the $X=1, Y=1$ cases. For strategy 3, we could observe four possible combinations of $M$ values, with $M$ being 0 or 1 in each of the cases. 

**Probability of the data**. We now calculate a probability of each possible data realization, given the model and the data that we have already observed. In practice, we do this in `CQtools` via simulation. Starting with the model together with our priors, we update our beliefs about $\lambda$ based on the previously observed data. This posterior now represents our *prior* for the purposes of the process tracing. In the present example, we are using the already-observed $X,Y$ correlation to update our beliefs about causal-type share allocations in the population, having seen the $X,Y$ data only. We then use this posterior to draw a series of $\lambda$ values. 

Given that the ambiguity matrix gives us the mapping from causal types to data realizations, we can calculate for each $lambda$ draw the probability of each data possibility given that particular $\lambda$ and the strategy. We then average across repeated $\lambda$ draws. Since $\lambda$'s are being drawn from our prior, we are automatically weighting more heavily those $\lambda$'s that we believe to be most likely.

**Posterior on estimate given the data**. For each data possibility, we can then use `CQtools` to ask what inference we would get from each data possibility, given whatever query we seek to answer, as well as the variance of that posterior. Examining the inferences from possible data-realizations, as we do below, can help us understand how the learning unfolds for different strategies. 

**Expected posterior variance under each strategy**. The quantity of ultimate interest is the posterior variance that we expect to end up with under each *strategy*. Calculating this expectation is now elementary as we have both the posterior variance arising from each data possibility and the probability of each data possibility (given our prior beliefs and the data already observed). The expected posterior variance is simply an average of the posterior variances under each data possibility, weighted by the probability of each data possibility. We can think of the expected gains from a strategy as the expected *reduction* in posterior variance arising from that strategy.

Complicated as the procedure might seem, it can all be done in code using a single command from the `CQtools` package.  


### Inferences from Strategies and Data Realizations

In Figure \@ref(figcaseselection), we examine how different process-tracing case-selection strategies will play out by looking at the inferences we would draw about different kinds of causal effects depending on the results of the process tracing.



```{r caseselection, echo = FALSE, fig.cap="Case selection: Distribution of possible posterior beliefs from possible data realizations"}

results <- list(
  chain = read_rds("rep/case_selection/XMY_chain.rds"),
  base = read_rds("rep/case_selection/XMY_base.rds"),
  restricted = read_rds("rep/case_selection/restricted_model.rds"),
  moderator = read_rds("rep/case_selection/XMY_moderator.rds")) %>%
  bind_rows(.id = "model") %>% 
  mutate(n = ifelse(strategy=="prior" | strategy=="XY_only", 0, 2))  %>%
  mutate(n = ifelse(strategy=="one_on" | strategy=="one_off", 1, n)) %>%
  group_by(Case.estimand, Given) %>% mutate(root = mean(mean[n==0])) %>%
  mutate(strategy_2 = strategy) %>%
  mutate(strategy_2 = ifelse(strategy_2=="one_off" | strategy_2=="one_on", "one", strategy_2)) %>%
  mutate(strategy_2 = ifelse(grepl("two_off", strategy_2, fixed = TRUE), "two_off", strategy_2)) %>%
  mutate(strategy_2 = ifelse(grepl("two_on", strategy_2, fixed = TRUE), "two_on", strategy_2)) %>% 
  filter(strategy != "prior") %>%
  filter(Case.estimand == "FALSE") %>%
  ungroup()  %>% 
  mutate(Given = factor(Given, 
         c("-", "X == 1 & Y == 1", "X == 1 & M == 1 & Y == 1",
"X == 0 & Y == 1", "X == 0 & M == 1 & Y == 1"), 
c("ATE", "PC 11: X == 1 & Y == 1", "PC | M == 1",
"PC 01: X == 0 & Y == 1", "PC 01 | M == 1")))


results %>%
  ggplot(aes(n, mean, color = strategy_2)) + geom_point() +
  facet_grid(model  ~ Given, scales = "free_y") + 
  scale_x_continuous(breaks = c(0:2)) +
  xlab("Number of cases with M observed")  +
  ylab("Inferences") + 
  ggtitle("Moderate XY")

```




Starting with the chain model, for the analyses displayed in Table XXXX, we assume that we have previously observed a positive $X,Y$ correlation in 6 cases (with 4 cases on the regression line, 2 cases off). Now we see what can happen for different queries when we implement each of the four case-selection strategies. The set of queries we are interested in are, what is the effect of $X$ on $Y$ for:

* any case in the population
* any $X=1, Y=1$ case in the population
* any $X=1, M=1, Y=1$ case in the population
* any $X=0, Y=1$ case in the population
* any $X=0, M=1, Y=1$ case in the population

#### Priors (Chain model)

In the top row, we see our pure prior on these queries before we have seen the $X,Y$ correlation --- i.e., based strictly on the DAG and flat priors over nodal types. The story here is straightforward. We start out believing that, for the $X \rightarrow M$ relationship, the population is evenly divided across the four types, $\theta^M_{00}, \theta^M_{01}, \theta^M_{10}, \theta^M_{11}$ (so 0.25 share of each). Likewise for $\theta^Y$ in relation to the $M \rightarrow Y$ relationship. We can get a positive $X,Y$ effect from a causal type involving $\theta^M_{01}$ and $\theta^Y_{01}$ or from a causal type involving $\theta^M_{10}$ and $\theta^Y_{10}$. Each of those causal types has a 0.125 probability, implying a 0.25 share of positive effects. A mirror-image of that logic gets us to a 0.25 share of negative effects, with the remaining 0.5 of the population comprising causal types that yield null effects (involving either a null effect at one or both steps in the chain). Thus, the expected effect of $X$ on $Y$ for a randomly drawn case from the population, given nothing but the model, is 0. 

Moving across the row, we see our prior beliefs for cases with more specific features. For cases with $X=1, Y=1$, our priors imply a positive effect 25\% of the time.^[This belief arises from a straightforward calculation involving the different combinations of nodal types that could generate $X=1, Y=1$ and their prior probabilities.] As we have flat priors over $M$'s type and its effects on $Y$, conditioning $M$'s value leaves this belief unaffected. By a parallel logic, the model and flat priors imply the belief that 0.25 of all $X=0, Y=1$ cases to involve a negative effect of $X$ on $Y$.

In the next row, we see how the initial set of 6 $X,Y$ observations shift our beliefs. In this model (as there is no confounding) a positive $X,Y$ correlation is evidence of a higher relative share of cases in which $X$ has a positive effect on $Y$. This implies a larger expected effect for a randomly selected case as well as for an $X=1, Y=1$ case since we now think there are more cases where $X$ has a positive effect on $Y$ than there are cases in which $Y$ is fixed at 1. (Again, conditioning on $M$'s value has no effect since we still have no information to shift us off our flat priors relating to $M$'s causes or effects.) Notably, however, our beliefs for an $X=0, Y=1$ case are unaffected by observing the positive correlation. To return for a moment to our handy $a,b,c,d$ typology, the reason is that the positive $X,Y$ correlation affects our beliefs about the share of $b$ types relative to $a,c,$ and $d$ types (with reference to the overall $X rightarrow Y$ effect), but it is uninformative about the relative shares of $a$ vs. $d$ types, the two types in contention for an $X=0, Y=1$ case. In the $X,Y$ data, the $X=0, Y=1$ case is equally likely to be an $a$ or a $d$, which is exactly what our prior belief was about a random $X=0, Y=1$ case.^[Put differently, the observed $X,Y$ correlation is equally consistent with all $X=0, Y=1$ cases being $a$'s, with them all being $d$'s, or with anything in between.]

#### $N=1$ strategies (Chain model)

Now, what can we learn by selecting a single case for process tracing, that is, the observation of the additional clue, $M$? We assume here, specifically, that we observe $M=1$ when we go looking for $M$. We can see in the third and fourth rows how our beliefs shift if we observe $M=1$, respectively, in one case *on* the regression line (an $X=Y=1$ case) or in one case *off* the regression line (an $X=1, Y=0$ case). We see that we cannot learn anything about the causal effect of $X$ on $Y$---whether unconditionally, conditioning on $X=Y=1$, or conditioning on $X=0, Y=1$---from observing $M=1$ in an $X=Y=1$ case. Nor can we learn about these quantities from process-tracing in a single off-the-line case. To see why, let's first take the on-the-line strategy. Not having observed $M$ previously, we still have flat priors over the nodal types governing $X$'s effect on $M$ and $M$'s effect on $Y$. That is to say, we still have no idea whether $X$'s positive effect on $Y$ (where present) more commonly operates through a chain of positive effects or a chain of negative effects. Thus, the observation $M=1$ in an $X=1, Y=1$ case is equally consistent with a positive $X \rightarrow Y$ (to the extent that effect operates via linked positive effects) and with no $X \rightarrow Y$ effect (to the extent positive effects operate through linked negative effects). Observing $M=1$ in an $X=1, Y=1$ case therefore tells us nothing about the causal effect in the typical case or in the typical $X=Y=1$ case. Similarly, we have no idea whether $X$'s negative effect on $Y$ (where present) operates through a positive-negative chain or a negative-positive chain, making $M=1$ in an $X=1, Y=0$ case equally consistent with a negative or null $X \rightarrow Y$ effect, yielding no information about whether a random $X=0, Y=1$ case has a negative or null effect. (By a similar logic, observing $M=1$ in the $X=1, Y=1$ case is uninformative about negative effects in an $X=0, Y=1$ case, and observing $M=1$ in an $X=1, Y=0$ case tells us nothing about positive effects in an $X=1, Y=1$ case.)

Interestingly, however, observing $M=1$ in a single case *can* tell us something about effects in *another* case in which $M=1$. Recall that the $X,Y$ pattern tells us that (with respect to the $X \rightarrow Y$ relationship) there are relatively more $b$'s than other types in the population. This means, in turn, that an $X=1, Y=1$ case is more likely to be a $b$ than a $d$. If we now observe $M=1$ in an $X=1, Y=1$---a case we think is probably a $b$---we now have reason to believe that positive $X \rightarrow Y$ effects operate through a positive $X \rightarrow M$ effect followed by a positive $M \rightarrow Y$ effect. (And had we seen $M=0$ in this case, we'd believe positive effects more likely operate through a negative effect followed by a positive effect.) Put differently, we now believe that $M=1$ in an $X=1, Y=1$ case is a clue that that case is likely a $b$ type---and our belief about the causal effect in an $X=1, M=1, Y=1$ case shifts upward. It shifts upward in two senses. 

Thus, while we do not learn about the overall population from an N=1 process-tracing exercise, process-tracing in that single case does make $M$ *informative* about *other* cases. We can see this by comparing our beliefs about an $X=1, M=1, Y=1$ case in the row in which we have only observed the $X,Y$ correlation to our beliefs about that same kind of case in the row in which we have process-traced in an on-the-line case. While in the first instance conditioning on $M=1$ has no impact on the estimated causal effect (because we haven't previously learned about $M$), it does have an impact in the latter instance.

We also see that our belief about the causal effect in an $X=0, M=1, Y=1$ case shifts upward. Why? Updating toward the belief that positive effects --- which we believe to be relatively common --- more often operate via linked positive positive effects implies that $X$ more often has a positive than a negative effect on $M$. Yet for an $X=0, M=1, Y=1$ to be a case with a negative causal effect, $X$'s effect on $M$ would have to be negative. Thus, interestingly, evidence from *on* the regression line can inform inferences about cases *off* the regression line via information about mediating processes.

FLAG: Haven't figured out why seeing M=1 in an X=1, Y=0 case reduces the estimated causal effect for an X=1, M=1, Y=1 case relative to just seeing the X,Y pattern. If we see M=1 in this off-line case, we have evidence in favor of X having a positive effect on M, and M having a negative effect on Y. So this should generally speak against positive effects in  X=1, M=1, Y=1 cases. But if we'd seen M=0, wouldn't this have the same effect? It would suggest negative X->M effects and positive M->Y effects, which would also speak against a positive effect in an  X=1, M=1, Y=1 case. So how does observing M help?

We see even stronger learning about an off-the-line $X=0, M=1, Y=1$, however, if we process trace off-the-line. The observation of $M=1$ in an $X=1, Y=0$ case counts as evidence against the operation of *both* steps in the causal chain through which $X$ could have a negative effect on $Y$ in an $X=0, M=1, Y=1$ case: it suggests that $X$'s effect on $M$ is more likely positive than negative *and* that $M$'s effect on $Y$ is more likely negative---precisely the opposite of what would have to be true for a negative effect to emerge in this kind of case. Thus, we now think this kind of case is less likely to involve a causal effect.

#### $N=2$ Strategies (Chain model)

Next, we consider the process tracing of *two* of our cases. Now, because we are observing $M$ in two cases, we can learn from the variation in $M$ across these cases---or, more specifically, from its covariation with $X$ aand with $Y$. In other words, there is a critical difference between process tracing one case and process tracing two cases. When we only process trace one case in a setup like this one, we do not learn about causal effects in the cases we process-trace because we have no information about intermediate causal effects (e.g., whether they are more likely positive or negative). Thus, while we have pointed out that observing $M$ within a case can lend $M$ probative value for *other* cases in which we might choose to observe $M$, $M$ has no probative value *for* that one case. In contrast, if we observe $M$ in two or more cases, we *do* learn about causal effects for those cases because of the leverage provided by observing covariation between the process-tracing clue and other variables.

We consider first, in the 5th row, a situation in which we look at $M$ in two on-the-line cases, an $X=Y=0$ case and an $X=Y=1$ case, and where we observe $M=0$ in the first case and $M=1$ in the second case. What we are seeing, then, is that $M$ covaries with both $X$ and $Y$. Seeing that the mediator covaries across cases with both the cause and the outcome is evidence of a causal effect of $X$ on $Y$. Since the observed pattern covariation is consistent with a positive effect (linked positive effects), our belief about the unconditional effect of $X$ on $Y$ goes up. For the same reason, so too does our belief about the causal effect conditional on $X=1, Y=1$. 

We see an even bigger boost in our estimate of the effect in an $X=1, Y=1$ case conditional on $M$ also being 1. Two things are generating this upward updating. First, just as for the unconditional estimate and the estimate conditional on $X=1, Y=1$, the process tracing generates a stronger belief that $X$ generally has a positive effect on $Y$. Second, as for the $N=1$ process tracing, seeing $M=1$ in two on-the-line cases (which we already believe are mostly positive-effect cases) makes $M$ informative as a clue in favor of a positive effect---indeed, more informative than if we'd only seen $M=1$ in one on-the-line case.

Moving across the columns, we also see that process-tracing the on-the-line cases and finding evidence consistent with positive effects in those cases leads us to update in favor of *negative* effects as well, conditional on $X=0, Y=1$ (including conditional on $M=1$). Why is that? 

Our answer is somewhat speculative, but we think there are two things going on. One is simply that the correlations between $M$ and $X$ and between $M$ and $Y$ across the two process-traced cases constitutes evidence of *effects*, period, at the intervening steps---a necessary condition for *any* $X \rightarrow Y$ effect, positive or negative. So, for an $X=0, Y=1$ case, a stronger belief that $X$ has some effect on $M$ and that $M$ has some effect on $Y$ implies a strong belief in a negative $X \rightarrow Y$ effect. 

The second thing that is probably going on is constraint imposed by prior beliefs. Having seen the $X,Y$ data, we have previously formed a belief that the *average* effect of $X$ on $Y$ is 0.05. When we find evidence in favor of positive effects, we update to a set of beliefs that are a compromise between the new data and prior beliefs. On the one hand, we upwardly update on the unconditional $X \rightarrow Y$ effect. On the other hand, our beliefs are constrained from moving *too* far away from an unconditional effect of 0.05. Recall that, in a binary setting, the average effect in a population is the share of cases with positive effects minus the share with negative effects. Thus, the conservative influence of our priors means that, as we upwardly update on positive effects, we also upwardly update our beliefs about the prevalence of *negative* effects, though not by as much, with the result that our beliefs about the unconditional effect do not shift as much as they would if we had had flat priors. By anchoring our beliefs about average effects, then, the prior $X,Y$ evidence means that any evidence in favor of positive effects also constitutes evidence in favor of negative effects. 

To put this point another way, while we learn *directly* about positive effects from process-tracing the on-the-line cases since these are cases in which positive effects can possible occur. And we then learn *indirectly* about negative effects from these cases *via* the prior-imposed constraint on the average effect.

Now, supppose we chose the same case-selection strategy---we examine two on-the-line cases, from opposite cells---but instead of observing $M$ covary with $X$ and $Y$, $M=1$ in both cases. We see the results in the 6th row. This data-realization, under the same strategy, represents clear evidence *against* positive effects, while also counting against *any* effects. We have observed that $M$ is unresponsive to changes in $X$, and that $Y$ varies without $M$ varying---null effects at both stages of the chain. Now we see that our posterior on the unconditional effect drops to 0, and we see a sharp movement toward zero conditional on $X=1, Y=1$, representing our updated belief that there are few positive effects. Interestingly, whereas conditioning additionally on $M=1$ generated in a *higher* estimated effect when we observed $M$ correlated with $X$ and $Y$, it generates a *lower* estimated effect when we observe $M=1$ in both cases. One reason is likely that we have updated our belief about $\theta^M$ such that we now believe that $X=1, M=1$ cases are more likely to be $\theta^M_{11}$'s (no effect) than $\theta^M_{01}$'s. We have not similarly updated with respect to $X=1, M=0$ cases and the $\theta^M_{00}$'s than $\theta^M_{10}$ shares. Thus, for an $X=1,Y=1$ case, additionally specifying that $M=1$ implies an even higher likelihood that the case contains a null effect. 

For $X=0, Y=1$ cases, we see similar movements toward zero, reflecting the fact the $M$ pattern speaks against any effects. And, again, the movement is stronger when we condition on $M=1$.

Finally, we consider an off-the-line $N=2$ strategy and two possible data-realizations under that strategy. We select for process tracing one $X=1, Y=0$ case and one $X=0, Y=1$ case. The two possible data-realizations we consisder are that $M$ varies positively with $X$ across the two cases (7th row) or that $M=1$ in both cases (8th row). One thing we can observe immediately is that we get less leverage from this strategy: across all columns, the difference in our posterior beliefs between the two data-realizations is smaller than it is for the two data-realizations of the on-the-line strategy. For instance, while we see $0.08$ swing in the unconditional effect under the on-the-line strategy, we see only a $0.02$ swing under the off-the-line strategy.

Unpacking this further, we know that we can learn directly about *negative* $X \rightarrow Y$ effects through process-tracing off-the-line cases. If we see $M$ covary positively with $X$ across these two cases---which also means covarying negatively with $Y$---we have found evidence in favor of the operation of negative $X \rightarrow Y$ effects. Hence the movement in our posterior away from 0 when we condition on $X=0, Y=1$. We also see updating away from zero for positive effects (conditioning on $X=1, Y=1$), though by a smaller amount (using the $X,Y$-data only as our baseline). Again, some of this movement is likely attributable to the constraint imposed by the prior generated from the $X,Y$ data. Some of this updating is also likely attributable to the fact that we have found evidence against null intermediate effects.

Curiously, under this strategy and data-realization, our beliefs about effects conditional on $X=0, M=1, Y=1$ move in the *opposite* direction from our beliefs conditional just on $X=0,Y=1$. Why might this be? This is likely because of the way in which the process-tracing has lent probative value to $M$. The pattern of $M$ data is most consistent with any negative $X \rightarrow Y$ effect operating via a *positive* $X \rightarrow M$ effect followed by a *negative* $M \rightarrow Y$ effect. Yet the intermediate effects would have to have the opposite sign for $X=0, M=1, Y=1$ to be consistent with an $X \rightarrow Y$ effect. In other words, $M=1$ rules out the likeliest way in which an $X=0, Y=1$ case could contain an effect. 

If on the other hand we observe $M=1$ in both off-the-line cases, we have found "direct" evidence against the operation of negative effects. Hence the the strong movement of our posterior toward 0 for effects conditional on $X=0, Y=1$ and, even more so, if also conditioning on $M=1$ (since we now have evidence that $M=1$ cases are more likely $\theta^M_{11}$'s than $\theta^M_{01}$'s). Likewise, we see upward movement in our posterior on the unconditional effect and, for reasons discussed earlier, in our posterior on positive effects (conditioning on $X=1, Y=1$).

The remaining puzzle is why the learning from the off-the-line strategy is weaker than the learning from the on-the-line strategy. Both strategies generate symmetrical opportunities to observe an $M$ pattern that is consistent or inconsistent with causal effects. We believe there are two reasons, both relating to the fact that we learn "directly" about positive effects from the on-the-line strategy (and "indirectly" about negative effects) and that we learn "directly" about negative effects (and "indirectly" about positive effects) from the off-the-line strategy. 

The first, more mechanical reason is that we start, given the $X,Y$ data, with a higher and higher-variance posterior on the prevalence of positive effects as compared to negative effects. So there is simply more scope for the data to influence our beliefs about positive effects, and the on-the-line cases are those in which we can learn "directly" about positive effects. Note, for instance, the $0.17$ differential in beliefs about effects conditional on $X=1, Y=1$ depending on what we observe under the on-the-line strategy, as compared to the $0.1$ differential for effects conditional on $X=0, Y=1$ under the off-the-line strategy.

The second reason is prevalence: given the $X,Y$ correlation, we believe that there are more cases out there that potentially contain positive effects than there are cases that potentially contain negative effects. Thus, *whatever* it is we learn about positive effects is going to have a bigger impact on our beliefs about the population as a whole than is whatever we learn about negative effects. Since on-the-line case yield the most direct learning about positive effects, they are therefore the most informative about the population.

Note, importantly, that this finding is consistent with recommendations in the literature to investigate on-the-line cases (@Lieberman2005nested, @goertz2017multimethod).^[We set aside here Lieberman's recommendation to choose off-the-line cases for discovery-oriented "model-building" because we see that enterprise as distinct from the estimation endeavor to which our analysis is oriented.] Yet, the reason is very different. Lieberman and Goertz emphasize the importance of examining cases where the theorized mechanism connecting $X$ to $Y$ might potentially play out, arguing that this would be in the set of cases that conform to theory in their $X,Y$ values. We would emphasize that, in the causal-model framework, one *can* learn about both overall effects and intermediate effects from off-the-line cases. The reason why on-the-line cases is simply that they are more *representative* about the universe about which we aim to learn (assuming we want to learn about the population from which the $X,Y$ pattern is drawn).  



#### Two-path model

Case-selection strategies depend on the model. To see this, consider the results of the same analysis conducted for a two-path model in which $X$ can have both an indirect effect on $Y$ via $M$ and a direct effect on $Y$. We first examine a version with flat priors over all nodal types and then a version in which we impose some monotonicity restrictions. 

In Table XXXXXX, we see the results of the case-selection exercise for a two-path model with flat priors. The takeaway here is simple: it does not matter what kind of case(s) we choose for process-tracing because nothing can be learned from observing $M$. We learn about effects from the $X,Y$ data. But, after that, adding observations $M$ yields no change in beliefs. The reason, we think, is the combination of the double pathway and uninformtativeness of priors. We go in with a flat distribution across nodal types $\theta^M$ and nodal types $\theta^Y$. We then acquire some information on the $X \rightarrow Y$ effect from the $X,Y$ data, but those effects are equally consistent with all possible pathways---direct, indirect, or combined. Suppose we then find evidence that cuts against the operation of the indirect pathway: $M=1$ is observed in two on-the-line cases with different $X$ values. So we downgrade the probability of $\theta^M_{01}$ relative to $\theta^M_{11}$. However, we are still able to preserve our prior on the effect of $X$ on $Y$ (whether conditional or unconditional) by updating our beliefs about $\theta^Y$ in a manner that places greater weight on direct effects. To put the point in the language of levels of theory: high flexibility in our lower-level beliefs impedes learning about higher-level quantities from observations at the lower level. This is true regardless of which quadrants we select our cases from.

The situation changes, however, if we come in with informative beliefs at the lower level. In Table XXXXXXX, we see results for a two-path model with restrictions, such that negative $X \rightarrow M$ and negative $M \rightarrow Y$ effects are ruled out. 

FLAG: Cannot yet see why we learn more from the restricted 2-path model than from the flat 2-path. Yes, we can learn from n=1 about the indirect path. But in both cases, we can still have compensating updating on the direct path for anything we learn about the indirect path. In fact, the prior probability of positive effects on each path is very similar across the two models. Ignoring interactions, for indirect path, b share is like 1/8 in flat model, and 1/9 in restricted, vs. 1/4 for direct path. Is it just that the learning about the indirect path is stronger with restricted priors because M starts out as informative about the indirect path? So the learning about the indirect path more easily swamps the prior?

FLAG: Incorporate as needed above and below any implications of Jeffreys priors.


#### Moderation models




## Wide or Deep

We continue our journey through the space of research-design choices. Suppose, now, that we have identified those clues that will be most informative, given our beliefs about the world. A further question that we face is the quintessential dilemma of *mixing* methods: what mixture of quantitative and qualitative evidence is optimal? We have, of course, argued in in Chapter \ref(mixing) that the distinction between quantitative and qualitative inference is, in a causal-model framework, without much of a difference. But here we are framing a more precise question: given finite resources, how should we trade off between studying a larger number of cases and drilling down to learn more about some subset of the cases in our sample? How should we decide between going "wide" and going "deep"?

Just as with the selection of clues and cases, how much we should expect to learn from going wide versus going deep will *depend* on how we think the world works. In this chapter, we separate out two forms that these prior beliefs might take: the structural causal model with which we start the analysis and any data that we have seen at the point of making the wide-versus-deep decision. As we will see, the expected opportunities for learning about different causal estimands depends greatly on both of these.

We examine here both queries commonly associated with extensive, quantitative strategies of analysis (such as average treatment effects) and queries commonly associated with more intensive, qualitative approaches (queries about causal pathways and about causal effects at the case level). The analysis in this chapter makes clear the opportunities for integration across these lines of inquiry. We show that investing in-depth process tracing will sometimes make sense even when one aims to learn about average effects in a population. Likewise, collecting $X, Y$ data can sometimes help us draw inferences that will aid in case-level explanation. Particular kinds of case-level information can teach us about populations, and understanding population-level patterns can help us get individual cases right. 


### Developing some intuitions

To build up our intuitions about how the optimal mix of strategies might depend on how the world works, let us explore a simple example. We focus here on the question of how much we can learn from drilling deeper, given an initial set of $X,Y$ data and beliefs about the world. To simplify the exposition, we revert here to using our four basic causal types from Chapter \ref(models): $a, b, c, and d$.^[For this illustration, we just need to keep track of $b$ (positive effect), $a$ (negative effect), and $d$ (no effect, $Y$ fixed at $1$).]

<!-- e begin by considering the learning that occurs upon observing outcomes from varying numbers of cases given different $XY$ data ranging from small to quite large.  -->

<!-- The goal here is to build up intuitions on how beliefs change given different observations and how this affects posterior variance. We address the question in a very controlled setting in which  -->

Suppose that:

* a researcher is confronted with $X,Y$ data that exhibits no correlation; observations are balanced across the 4 cells defined by possible combinations of $X, Y$ values.
* the researcher can seek information on a highly informative ("doubly decisive") clue, $K$, within cases in the $X=Y=1$ cell; thus, we are imagining a scenaior in which the information we will get about the case in question is about as informative about that case as it could possibly be.
* although not known in advance, each time the researcher collects a within-case clue, she finds evidence suggesting that the case is a $b$ type.

We consider two different data-generating processes: 

1 There may be unobserved confounding between $X$ and $Y$, and we have flat priors over this confounding. Put differently, assignment propensities are unknown.

2 There is no confounding; $X$ can be treated as randomly assigned. 

We consider what happens as the number of cases on which we collect $K$ increases from 0 to 5. We also consider different amounts of initial $X,Y$ data, considering situations in which we have 5, 10, 50, and 5000 observations in each $X,Y$ cell.

We would expect that seeking a clue in a case---which, in this simulation, always delivers evidence consistent with a positive causal effect in that case---will lead the researcher to believe there are more $b$ types and that there is thus a higher average causal effect. But how strong will these shifts be? And how does the amount of belief change depend on the amount of $X, Y$ data available and the underlying data-generating process? When does the signal from the $X,Y$ data drown out any signal from the $K$ data, and when does $K$ data add value?

Figure MISSING reports answers to these questions. In the top row, we report the average causal effect that we will estimate for different combinations of $X,Y$ and $K$ data. In the bottom row, we show the reductions in uncertainty (posterior variance) that we get with each strategy. On the left, we allow for unobserved confounding, and on the right we have random assignment. Each curve represents a different sample size for which we have $X,Y$ data. The number of cases in which we go "deep," collecting $K$ data, is represented on the horizontal axis. 




1. With unobserved confounding, we see clear gains to collecting clues on a greater number of cases across the 1 to 5 range. Collecting clue information on a greater number of cases shifts our beliefs about the average causal effect and reduces our uncertainty about that quantity. Moreover, with unobserved confounding, the value of the clue information is *independent* of how many $X,Y$ cases there are. 

What is happening here is that the clues are providing information on assignment propensities, which are informative about the share of each type in each cell. With flat priors over assignment propensities, our beliefs are centered around equal propensities for all types (though we're also very uncertain about this). Moreover, given equal assignment propensities, the flat data $X,Y$ pattern has us believing that there the average treatment effect is 0 (also with great uncertainty). For every additional $X=1, Y=1$ for which we observe $K=1$, however, we shift upward our belief about the share of $b$'s in the cell. We are, thus, now learning about assignment propensities: now it looks like $b$ types were more commonly assigned to $X=1$, implying that $d$'s must have been more commonly assigned to $X=0$. Put differently, we are learning that the flat data pattern has arisen via confounding that is "suppressing" a positive treatment effect. 

The value of the clue data, moreover, does not depend on how many $X,Y$ cases we've observed because no amount of $X,Y$ data can tell us about $X$<->$Y$ confounding. As we see in the bottom-left graph, we end up more certain, the more $X, Y$ data we have. But there's just as much to be *gained* from a given amount of clue data whether we've started with 5 $X,Y$ cases or 5000.

2. When assignment propensities are known (and so we can treat the data as experimental), the learning from clue data depends heavily on how many $X,Y$ cases we start out with. Where we have a large amount of $X,Y$ data, clue evidence adds little to nothing to our inferences about average treatment effects. There is nothing to be learned from the clues about assignment propensities since these are already known. And, with assignment propensities known, $X,Y$ information alone are sufficient for convergence on the average treatment effect as sample size increases. Clue information shifts beliefs about the types of the particular cases for which clue data is gathered --- i.e., for this case-level-estimand --- but has almost no effect on estimates of the population estimand. 

However, we can learn about average effects from clue data when we have few $X,Y$ cases. While we can infer the average causal effect from a known $X,Y$ distribution (and known assignment propensities), we have a lot of uncertainty about that distribution when we only have a handful of $X,Y$ cases. Thus, clue data help us by uniquely providing information about the types of individual cases. It is still only from observing $K=1$ in a case that we can learn that that case is a $b$ type, allowing us to update upwardly on the relative proportions of $b$'s and $d$'s. With little other information on the average effect, this pushes our belief about average effects upward.^[We also, by implication, update upwardly on the share of $a$'s relative to $d$'s in the $X=0, Y=1$ cell; but the direct learning about the $X=1, Y=1$ cell will be sharper than the indirect learning about the $a$'s, generating a net increase in the estimated average causal effect.] And, in the absence of a large amount of of $X,Y$ data, knowing there is one more $b$ and one less $d$ type still benefits from learning  

3. Though not visible from the figure, clue data help us learn about a different population-level estimand --- the *distribution* of causal effects in the population --- even when we have a large $N$ and known propensities. The same average causal effect could be consistent with a large share of $a$'s and $b$'s combined, with few no-effect cases, or with a small share of $a$'s and $b$'s combined, with many no-effect cases. In other words, we don't actually learn from $X,Y$ data about the distribution of types, even with a large $X,Y$ sample and known propensities. But observation of clues identifying $b$ types in the $X=Y=1$ cell, while it does not change estimates of *average* treatment effects, tells us that there is greater *heterogeneity* of effects in the population. More $b$ types, holding the average effect constant, means that there must also be more $a$ types. Thus, we have learned that there are more offsetting effects playing out in the population --- positive effects alongside negative effects --- than we knew before we saw the clue data. In fact, we learn *more* about heterogeneity from clue data where the average causal effect is already known than where we are highly uncertain about the average effect.

`r flag()` Can we show the heterogenity point graphically, too? Seems odd to say it's not visible when we could make it so.


### Results from simulations


```{r morn, fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE}
path = "rep/wide_deep_2"
results <- 
  list(
    Chain = read_rds(paste0(path, "/chain.rds")),
    Confounded = read_rds(paste0(path, "/confounded.rds")),
    Confounded_large_n = read_rds(paste0(path, "/confounded_large.rds")),
    Restricted = read_rds(paste0(path, "/restricted.rds")),
    Base = read_rds(paste0(path, "/base.rds")),
    Chain_homogeneous = read_rds(paste0(path, "/chain_homog.rds")),
    Chain_with_priors = read_rds(paste0(path, "/chain_with_prior.rds"))
) %>% bind_rows(.id = "Model") %>%
    mutate(Model = ifelse(Model == "Confounded_large_n", "Confounded", Model))

short <- results %>% group_by(Model, design, Given) %>% 
  dplyr::summarize(mean_post_var = mean(sd^2), se_of_post_var = (var(sd^2)/n())^.5, deep = mean(deep_n), wide = mean(wide_n))  %>%
  mutate(Estimand = ifelse(Given == "-", "Effect of X on Y", "X=1 caused Y=1")) %>%
  mutate(Wide = factor(wide))

short %>%  # filter(Model %in% c("Chain", "Confounded")) %>%
  ggplot(aes(deep, mean_post_var, color = Wide)) +
  geom_line() + 
  facet_grid(Estimand ~ Model, scales = "free_y") +
  ylab("Expected posterior variance")+ scale_x_continuous(breaks = c(0, 50, 100))
```


## Principles

*  Qualitative and quantitative data can act as partial substitutes for assessing causal effects.
*  The *relative* marginal gains from going wider and going deeper vary with the study design. 
* Optimal strategies might involve going deep in a subsample of cases only.




